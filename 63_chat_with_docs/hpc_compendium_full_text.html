
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Erkl√§rung zur Barrierefreiheit &#8212; Generative Artificial Intelligence Notebooks</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '63_chat_with_docs/hpc_compendium_full_text';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../intro.html">

  
  
  
  
  
  
  

  
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../00_setup/readme.html">
                        Setting up your computer
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../10_prompting_basics/readme.html">
                        Prompting basics
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../15_endpoint_apis/readme.html">
                        Accessing LLMs
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../20_chatbots/readme.html">
                        Chatbots
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../30_function_calling/readme.html">
                        Function / Tool calling
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../40_image_generation_openai/readme.html">
                        Image generation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../40_image_generation_openai/readme_manipulation.html">
                        Image manipulation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../42_video_generation/readme.html">
                        Generating Videos, Books, Slides and online content
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../43_generating_data/readme.html">
                        Synthesizing data
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/readme.html">
                        Code generation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../47_vision/readme.html">
                        Vision language models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../45_pptx_generation/prompting_rdm.html">
                        Auto-generating PowerPoint files with chatGPT and Dall-E
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../60_rag/readme.html">
                        Retrieval Augmented Generation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="readme.html">
                        Chat with Docs
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../64_github_interaction/solving_github_issues.html">
                        Solving github issues
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../35_agents/readme.html">
                        Agents
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../70_fine_tuning/readme.html">
                        Model Fine-Tuning in the cloud
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../71_fine_tuning_hf/readme.html">
                        Model Fine-Tuning locally
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../80_benchmarking_llms/readme.html">
                        Benchmarking
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../81_benchmarking_vlms_counting/readme.html">
                        Benchmarking Vision Language Models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../imprint.html">
                        Imprint
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../00_setup/readme.html">
                        Setting up your computer
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../10_prompting_basics/readme.html">
                        Prompting basics
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../15_endpoint_apis/readme.html">
                        Accessing LLMs
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../20_chatbots/readme.html">
                        Chatbots
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../30_function_calling/readme.html">
                        Function / Tool calling
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../40_image_generation_openai/readme.html">
                        Image generation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../40_image_generation_openai/readme_manipulation.html">
                        Image manipulation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../42_video_generation/readme.html">
                        Generating Videos, Books, Slides and online content
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../43_generating_data/readme.html">
                        Synthesizing data
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/readme.html">
                        Code generation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../47_vision/readme.html">
                        Vision language models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../45_pptx_generation/prompting_rdm.html">
                        Auto-generating PowerPoint files with chatGPT and Dall-E
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../60_rag/readme.html">
                        Retrieval Augmented Generation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="readme.html">
                        Chat with Docs
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../64_github_interaction/solving_github_issues.html">
                        Solving github issues
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../35_agents/readme.html">
                        Agents
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../70_fine_tuning/readme.html">
                        Model Fine-Tuning in the cloud
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../71_fine_tuning_hf/readme.html">
                        Model Fine-Tuning locally
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../80_benchmarking_llms/readme.html">
                        Benchmarking
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../81_benchmarking_vlms_counting/readme.html">
                        Benchmarking Vision Language Models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../imprint.html">
                        Imprint
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item">
  


<a class="navbar-brand logo" href="../intro.html">

  
  
  
  
  
  
  

  
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    </div>
    <div class="sidebar-start-items__item">
<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Generative Artificial Intelligence Notebooks
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Setup</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../00_setup/readme.html">Setting up your computer</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../00_setup/install_paula.html">Installation instructions for Scientific Computing Uni Leipzig (paula)</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM basics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../10_prompting_basics/readme.html">Prompting basics</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../10_prompting_basics/01_prompting.html">Prompting basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../10_prompting_basics/02_use_cases.html">Use cases</a></li>
<li class="toctree-l2"><a class="reference internal" href="../10_prompting_basics/03_prompt_engineering.html">Basic prompt Engineering</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../15_endpoint_apis/readme.html">Accessing LLMs</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../15_endpoint_apis/01_openai_api.html">OpenAI API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../15_endpoint_apis/02_ollama_endpoint.html">Ollama</a></li>
<li class="toctree-l2"><a class="reference internal" href="../15_endpoint_apis/04_scadsai_llm_endpoint.html">ScaDS.AI LLM endpoint</a></li>
<li class="toctree-l2"><a class="reference internal" href="../15_endpoint_apis/09_kiara_llm_endpoint.html">Kiara LLM endpoint</a></li>
<li class="toctree-l2"><a class="reference internal" href="../15_endpoint_apis/06_kisski_endpoint.html">KISSKI / GWDG endpoint</a></li>
<li class="toctree-l2"><a class="reference internal" href="../15_endpoint_apis/03_blablador_endpoint.html">Blablador endpoint</a></li>
<li class="toctree-l2"><a class="reference internal" href="../15_endpoint_apis/05_azure_endpoints.html">Github Models Marketplace</a></li>
<li class="toctree-l2"><a class="reference internal" href="../15_endpoint_apis/07_mistral_endpoint.html">Mistral</a></li>
<li class="toctree-l2"><a class="reference internal" href="../15_endpoint_apis/08_deepseek_endpoint.html">DeepSeek endpoint</a></li>
<li class="toctree-l2"><a class="reference internal" href="../15_endpoint_apis/10_anthropic_api.html">Anthropic Claude</a></li>
<li class="toctree-l2"><a class="reference internal" href="../15_endpoint_apis/20_google_gemini.html">Gemini API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../15_endpoint_apis/30_huggingface.html">Huggingface API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../15_endpoint_apis/31_huggingface_serverless_inference_api.html">Huggingface Serverless Inference</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../20_chatbots/readme.html">Chatbots</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../20_chatbots/10_chatbot.html">Programming an LLM-based chatbot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../20_chatbots/gui.html">A Chatbot GUI</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../30_function_calling/readme.html">Function / Tool calling</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../30_function_calling/10_function_calling.html">Function calling using ollama</a></li>
<li class="toctree-l2"><a class="reference internal" href="../30_function_calling/12_function_calling_scadsai_llm.html">Function calling using ScaDS.AI‚Äôs LLM service</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Multi-Modal LLMs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../40_image_generation_openai/readme.html">Image generation</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../40_image_generation_openai/10_generating_images_dall_e.html">Generating images using DALL-E</a></li>
<li class="toctree-l2"><a class="reference internal" href="../40_image_generation_openai/20_generating_mri_images_dall_e.html">Generating Magnetic Resonance images using DALL-E</a></li>
<li class="toctree-l2"><a class="reference internal" href="../41_image_generation_huggingface/30_generating_images_using_huggingface.html">Generating images using Stable Diffusion</a></li>

</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../40_image_generation_openai/readme_manipulation.html">Image manipulation</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../40_image_generation_openai/51_inpainting_dall-e.html">Inpainting using Dall-E</a></li>
<li class="toctree-l2"><a class="reference internal" href="../40_image_generation_openai/52_inpainting_dall-e_copernicus.html">Replacing parts of satellite images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../41_image_generation_huggingface/50_inpainting_huggingface.html">Inpainting using Stable Diffusion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../41_image_generation_huggingface/60_image_variations_huggingface.html">Image variations using Stable Diffusion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../41_image_generation_huggingface/60_image_variations_pix2pix.html">Image editing using instruct-pix2pix</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../42_video_generation/readme.html">Generating Videos, Books, Slides and online content</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../42_video_generation/videogen.html">Video generation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../43_generating_data/readme.html">Synthesizing data</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../43_generating_data/synthetic_customer_data_llms.html">Generating synthetic customer data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../43_generating_data/synthetic_customer_data_rnd_generators.html">Combining LLMs with Random number generators for data generation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../50_code_generation/readme.html">Code generation</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../50_code_generation/02_generating_code.html">Code generation</a></li>

<li class="toctree-l2"><a class="reference internal" href="../50_code_generation/03_generating_code.html">Prompt engineering for code generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../50_code_generation/04_generating_code_for_processing_images.html">Generating code for processing images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../50_code_generation/06_system_messages.html">Powerful system messages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../50_code_generation/10_reflection.html">Reflection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../50_code_generation/20_bia-bob_demo.html">BIA Bob demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../50_code_generation/21_documenting_code.html">Documenting code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../50_code_generation/22_bug_fixing.html">Bug fixing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../50_code_generation/23_generate_notebooks.html">Generating notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../50_code_generation/24_vision-microscopy.html">Vision models for image interpretation and code generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../50_code_generation/25_vision-microscopy-hints.html">Precise prompting for code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../44_generating_jupyter_books/generator.html">Generating Jupyter books</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../47_vision/readme.html">Vision language models</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../47_vision/10_vision_CLIP.html">CLIP transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../47_vision/20_vision_ollama.html">LLAVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../47_vision/21_vision_openai.html">GPT4-omni VLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../47_vision/22_vision_qwen.html">Qwen2-VL</a></li>
<li class="toctree-l2"><a class="reference internal" href="../47_vision/23_vision_claude.html">Claude vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../47_vision/35_vision_moondream.html">Moondream LLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../47_vision/30_vision_models_structred_output.html">Vision models with structured output</a></li>
<li class="toctree-l2"><a class="reference internal" href="../47_vision/40_vlms_guessing_segmentation_alg.html">VLMs guessing image segmentation strategies</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Prompt Engineering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../45_pptx_generation/prompting_rdm.html">Auto-generating PowerPoint files with chatGPT and Dall-E</a></li>

<li class="toctree-l1 has-children"><a class="reference internal" href="../60_rag/readme.html">Retrieval Augmented Generation</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../60_rag/10_text-embeddings.html">Text embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../60_rag/11_text-embeedings-openai.html">OpenAI Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../60_rag/05_tokenization.html">Tokenization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../60_rag/20-simple-rag.html">Simple retrieval augmented generation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="readme.html">Chat with Docs</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="chat-with-docs.html">Chat with your PDFs!</a></li>
<li class="toctree-l2"><a class="reference internal" href="hpc-compendium-prepare-data.html">Chat with documentation about HPC systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="long-context-prompting.html">Long context prompting</a></li>
<li class="toctree-l2"><a class="reference internal" href="chat-with-hpc-compendium.html">Ask about the HPC compendium</a></li>
<li class="toctree-l2"><a class="reference internal" href="llm-based-rag.html">LLM-based Retrieval Augmented Generation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../64_github_interaction/solving_github_issues.html">Solving github issues</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../35_agents/readme.html">Agents</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../30_function_calling/20_langchain.html">Prompting tasks using LangChain</a></li>
<li class="toctree-l2"><a class="reference internal" href="../30_function_calling/30_langchain_bia.html">Prompting bio-image analysis tasks using LangChain</a></li>
<li class="toctree-l2"><a class="reference internal" href="../30_function_calling/35_langchain_bia_choosing_algorithms.html">Allowing language models to choose the right algorithm</a></li>

<li class="toctree-l2"><a class="reference internal" href="../30_function_calling/50_blablado.html"><code class="docutils literal notranslate"><span class="pre">blablado</span></code> calls functions for you</a></li>
<li class="toctree-l2"><a class="reference internal" href="../30_function_calling/55_microscope_stage_demo.html">Demo: Controlling a simulated microscope</a></li>

<li class="toctree-l2"><a class="reference internal" href="../35_agents/autogen_agentchat.html">Autogen Agentchat</a></li>
<li class="toctree-l2"><a class="reference internal" href="../35_agents/react_agent_llama_index.html">Agentic workflows using Llama-Index</a></li>
<li class="toctree-l2"><a class="reference internal" href="../66_arxiv_agent/arxiv_powerpoint_karaoke.html">PowerPoint Karaoke about Arxiv papers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../35_agents/smolagents.html">Smolagents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../66_arxiv_agent/multiagent_write_review.html">A multi-agent system writing a manuscript</a></li>
<li class="toctree-l2"><a class="reference internal" href="../66_arxiv_agent/simplifying_agentic_workflows.html">Simplifing agentic workflows</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../70_fine_tuning/readme.html">Model Fine-Tuning in the cloud</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../70_fine_tuning/10_generate_qa.html">Turning knowledge into a list of question and answers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../70_fine_tuning/40_fine_tuning.html">Fine-tuning an OpenAI GPT from questions and answers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../70_fine_tuning/50_model_testing.html">Test fine-tuned models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../70_fine_tuning/checking_job_status.html">Checking a fine-tuning job status</a></li>
<li class="toctree-l2"><a class="reference internal" href="../70_fine_tuning/list_available_models.html">Listing available models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../71_fine_tuning_hf/readme.html">Model Fine-Tuning locally</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../71_fine_tuning_hf/fine-tune-gemma.html">Fine-tuning Gemma on local hardware</a></li>
<li class="toctree-l2"><a class="reference internal" href="../71_fine_tuning_hf/merging_model.html">Merging fine-tuned models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../71_fine_tuning_hf/test_model.html">Testing the model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../71_fine_tuning_hf/hf_data_upload.html">Uploading training data to the Huggingface Hub</a></li>
<li class="toctree-l2"><a class="reference internal" href="../72_quantization/quantization.html">Quantization</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../80_benchmarking_llms/readme.html">Benchmarking</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../80_benchmarking_llms/10_CLIP_scores.html">Optimizing image generation prompting using CLIP scores</a></li>
<li class="toctree-l2"><a class="reference internal" href="../80_benchmarking_llms/30_measuring_executability.html">Measuring code executability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../80_benchmarking_llms/40_summarize_error_messages.html">Summarizing generated code failure reasons</a></li>

</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../81_benchmarking_vlms_counting/readme.html">Benchmarking Vision Language Models</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../80_benchmarking_llms/20_vision_models.html">Vision Large Language Models for Counting objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../82_benchmarking_vlms/open_weight_llms_counting.html">Open Weight VLMs  for Counting objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../81_benchmarking_vlms_counting/limits_of_vision_moondream.html">Benchmarking spot counting using Vision Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../81_benchmarking_vlms_counting/limits_of_vision_moondream_bb.html">Moondream for bounding-box segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../81_benchmarking_vlms_counting/limits_of_vision-claude.html">Claude VLM for bounding-box segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../81_benchmarking_vlms_counting/limits_of_vision-gpt.html">GPT 4 omni  for bounding-box segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../81_benchmarking_vlms_counting/limits_of_vision-llama4.html">Llama4 (Scout) for bounding-box segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../81_benchmarking_vlms_counting/limits_of_vision-gemma3.html">gemma 3 for bounding-box segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../81_benchmarking_vlms_counting/limits_of_vision-qwen.html">Qwen 2.5 VL for bounding-box segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../81_benchmarking_vlms_counting/vlms_guess_library.html">VLMs guessing algorithms to process images</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Links</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../imprint.html">Imprint</a></li>

</ul>

    </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        <label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" data-toggle="tooltip" data-placement="right" title="Toggle primary sidebar">
            <span class="fa-solid fa-bars"></span>
        </label>
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="btn btn-sm"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<div class="dropdown dropdown-repository-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="https://github.com/ScaDS/generative-ai-notebooks" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">repository</span>
</a>
</a>
      
      <li><a href="https://github.com/ScaDS/generative-ai-notebooks/issues/new?title=Issue%20on%20page%20%2F63_chat_with_docs/hpc_compendium_full_text.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">open issue</span>
</a>
</a>
      
  </ul>
</div>



<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="../_sources/63_chat_with_docs/hpc_compendium_full_text.md" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</a>
      
      <li>
<button onclick="printPdf(this)"
  class="btn btn-sm dropdown-item"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</a>
      
  </ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary" data-toggle="tooltip" data-placement="left" title="Toggle secondary sidebar">
            <span class="fa-solid fa-list"></span>
        </label>
    </div>
</div>
            </div>
            
            

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Erkl√§rung zur Barrierefreiheit</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Erkl√§rung zur Barrierefreiheit
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#erstellung-dieser-erklarung-zur-barrierefreiheit">
     Erstellung dieser Erkl√§rung zur Barrierefreiheit
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stand-der-barrierefreiheit">
     Stand der Barrierefreiheit
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kontakt">
     Kontakt
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#durchsetzungsverfahren">
     Durchsetzungsverfahren
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#datenschutzerklarung">
   Datenschutzerkl√§rung
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#zih-hpc-documentation">
   ZIH HPC Documentation
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#contribution">
     Contribution
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#news">
     News
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-and-courses">
     Training and Courses
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#support-and-consultation">
     Support and Consultation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#legal-notice">
   Legal Notice
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#impressum">
     Impressum
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#ansprechpartner-betreiber">
       Ansprechpartner/Betreiber
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#konzeption-technische-umsetzung-anbieter">
       Konzeption, Technische Umsetzung, Anbieter
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#license">
     License
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#desktop-cloud-visualization-dcv">
   Desktop Cloud Visualization (DCV)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-with-jupyterhub">
     Access with JupyterHub
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#notes-on-gpu-support">
     Notes on GPU Support
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#graphical-applications-with-webvnc">
   Graphical Applications with WebVNC
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-via-jupyterhub">
     Access via JupyterHub
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-via-terminal">
     Access via terminal
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#step-1">
       Step 1
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#step-2">
       Step 2
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#step-3">
       Step 3
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#step-4">
       Step 4
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#jupyterhub">
   JupyterHub
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#disclaimer">
     Disclaimer
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access">
     Access
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#login-page">
     Login Page
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#start-a-session">
     Start a Session
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#standard-profiles">
       Standard Profiles
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#advanced-options">
       Advanced Options
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jupyterlab">
     JupyterLab
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jupyter-notebooks-in-general">
     Jupyter Notebooks in General
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#version-control-of-jupyter-notebooks-with-git">
       Version Control of Jupyter Notebooks with Git
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stop-a-session">
     Stop a Session
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#error-handling">
     Error Handling
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#error-message-in-jupyterlab">
       Error Message in JupyterLab
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#advanced-tips">
     Advanced Tips
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#loading-modules">
       Loading Modules
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#custom-kernels">
       Custom Kernels
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#custom-environments-for-jupyterhub">
   Custom Environments for JupyterHub
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preliminary-steps">
     Preliminary Steps
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#python-virtualenv">
     Python Virtualenv
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conda-environment">
     Conda Environment
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-your-custom-environment">
     Using your custom environment
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#jupyterhub-for-teaching">
   JupyterHub for Teaching
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clone-a-repository-with-a-link">
     Clone a Repository With a Link
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#spawn-options-pass-through-with-url-parameters">
     Spawn Options Pass-through with URL Parameters
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#combination-of-quickstart-and-git-pull-feature">
       Combination of Quickstart and Git-Pull Feature
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#open-a-notebook-automatically-with-a-single-link">
     Open a Notebook Automatically with a Single Link
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-a-shared-python-environment">
     Create a Shared Python Environment
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#jupyterhub-teaching-example">
   JupyterHub Teaching Example
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#context">
     Context
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prerequisites">
     Prerequisites
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preparation-on-the-lecturer-s-side">
     Preparation on the Lecturer‚Äôs Side
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#creating-a-custom-python-environment">
       1. Creating a custom Python environment
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#clone-the-repository-and-store-environment-setup">
       2. Clone the repository and store environment setup
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#prepare-an-activation-file">
       3. Prepare an activation file
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#prepare-the-spawn-link">
       4. Prepare the spawn link
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#usage-on-the-student-s-side">
     Usage on the Student‚Äôs Side
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#preparing-activation-of-the-custom-environment-in-notebooks">
       Preparing activation of the custom environment in notebooks
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#test-spawn-link-and-environment-activation">
     Test spawn link and environment activation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary">
     Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   JupyterLab
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-without-jupyterhub">
     Access without JupyterHub
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#access-with-port-forwarding">
       Access with port forwarding
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#access-with-x11-forwarding">
       Access with X11 forwarding
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#custom-jupyterlab">
   Custom JupyterLab
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Disclaimer
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prepare-the-installation">
     Prepare the Installation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#key-fingerprints">
   Key Fingerprints
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#barnard">
     Barnard
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#romeo">
     Romeo
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#capella">
     Capella
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alpha-centauri">
     Alpha Centauri
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#julia">
     Julia
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#power9">
     Power9
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataport-nodes">
     Dataport Nodes
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#access-to-zih-systems">
   Access to ZIH Systems
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#security-restrictions">
   Security Restrictions
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#connecting-via-terminal-linux-mac-windows">
   Connecting via Terminal (Linux, Mac, Windows)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#before-your-first-connection">
     Before Your First Connection
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#configuring-default-parameters-for-ssh">
       Configuring Default Parameters for SSH
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#x11-forwarding">
     X11-Forwarding
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#connecting-with-mobaxterm-windows">
   Connecting with MobaXterm (Windows)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#download-and-install">
     Download and install
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#configure-local-settings">
     Configure local settings
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#start-a-new-session">
     Start a new session
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#connecting-with-putty-windows">
   Connecting with PuTTY (Windows)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     Download and install
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#start-a-new-ssh-session">
     Start a new SSH session
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#connection-configuration-optional">
     Connection Configuration (optional)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acknowledgement">
   Acknowledgement
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#application-for-hpc-resources">
   Application for HPC Resources
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nhr-center">
     NHR Center
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#user-management-for-project-leaders">
   User Management for Project Leaders
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Access
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#projects">
     Projects
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#manage-project-members-dis-enable">
       Manage Project Members (dis-/enable)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#statistic">
       Statistic
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#terms-of-use">
   Terms of Use
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#history">
     History
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#content-rules">
   Content Rules
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#motivation-and-rationale">
     Motivation and Rationale
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#responsibility-and-license">
     Responsibility and License
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quick-overview">
     Quick Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#detailed-overview">
     Detailed Overview
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#writing-style">
       Writing Style
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pages-structure-and-new-page">
       Pages Structure and New Page
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#preserve-urls">
         Preserve URLs
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#markdown">
       Markdown
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#brief-how-to-on-markdown">
         Brief How-To on Markdown
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#attachments">
         Attachments
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#graphics-and-videos">
         Graphics and Videos
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#resizing-and-alignment-of-graphics">
           Resizing and Alignment of Graphics
          </a>
         </li>
        </ul>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#special-feature-admonitions">
         Special Feature: Admonitions
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#spelling-and-technical-wording">
       Spelling and Technical Wording
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#code-blocks-and-command-prompts">
       Code Blocks and Command Prompts
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#code-blocks-and-syntax-highlighting">
         Code Blocks and Syntax Highlighting
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#data-privacy-and-generic-names">
         Data Privacy and Generic Names
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#placeholders">
         Placeholders
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#mark-omissions">
         Mark Omissions
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#code-styling-rules">
         Code Styling Rules
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#list-of-prompts">
         List of Prompts
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#long-options">
         Long Options
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#equal-signs-in-command-line-options">
         Equal Signs in Command-Line Options
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#customize-search">
       Customize Search
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#contribute-via-browser">
   Contribute via Browser
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preparation">
     Preparation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-a-branch">
     Create a Branch
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#editing-existing-articles">
     Editing Existing Articles
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adding-new-article">
     Adding New Article
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#submitting-articles-for-publication">
     Submitting Articles for Publication
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#revision-of-articles">
     Revision of Articles
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#contribute-via-local-clone">
   Contribute via Local Clone
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#initial-setup-of-your-local-clone">
     Initial Setup of your Local Clone
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#working-with-your-local-clone">
     Working with your Local Clone
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#merging-of-forked-repositories">
     Merging of Forked Repositories
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tools-to-ensure-quality">
     Tools to Ensure Quality
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#working-with-the-docker-container">
     Working with the Docker Container
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#start-the-local-web-server">
       Start the Local Web Server
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#run-the-proposed-checks-inside-container">
       Run the Proposed Checks Inside Container
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#pre-commit-git-hook">
         Pre-commit Git Hook
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#linter">
         Linter
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#spell-checker">
         Spell Checker
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#check-pages-structure">
         Check Pages Structure
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#link-checker">
         Link Checker
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#single-file">
           Single File
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#all-modified-files">
           All Modified Files
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#all-files">
           All Files
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-to-contribute">
   How-To Contribute
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#technical-setup">
     Technical Setup
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#git-workflow">
     Git Workflow
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     Content Rules
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#contribute-via-issue">
     Contribute via Issue
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#contribute-via-web-ide">
     Contribute via Web IDE
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     Contribute via Local Clone
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ci-cd-pipeline">
     CI/CD Pipeline
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sharing-data">
   Sharing Data
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grant-access-on-some-file-or-directory-to-persons-in-your-project">
     Grant access on some file or directory to persons in your project
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grant-access-on-some-file-or-directory-to-persons-from-various-projects">
     Grant access on some file or directory to persons from various projects
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#filesystems">
   Filesystems
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recommendations-for-filesystem-usage">
     Recommendations for Filesystem Usage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cheat-sheet-for-debugging-filesystem-issues">
     Cheat Sheet for Debugging Filesystem Issues
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#general">
       General
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#long-term-preservation-of-research-data">
   Long-Term Preservation of Research Data
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-should-research-data-be-preserved">
     Why should research data be preserved?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#which-research-data-should-be-preserved">
     Which research data should be preserved?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-should-i-add-meta-data-to-my-data">
     Why should I add Meta-Data to my data?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-are-meta-data">
     What are Meta-Data?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#where-can-i-get-more-information-about-management-of-research-data">
     Where can I get more information about management of research data?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#i-want-to-archive-my-research-data-at-zih-safely-how-can-i-do-that">
     I want to archive my research data at ZIH safely. How can I do that?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#storing-very-infrequently-used-data-during-the-course-of-the-project">
       Storing very infrequently used data during the course of the project
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#archiving-data-beyond-the-project-lifetime-for-10-years-and-above">
       Archiving data beyond the project lifetime, for 10 years and above
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lustre">
   Lustre
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#good-practices">
     Good Practices
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#searching-the-directory-tree">
       Searching the Directory Tree
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#useful-commands-for-lustre">
     Useful Commands for Lustre
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#listing-disk-space-usage">
       Listing Disk Space Usage
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#listing-personal-disk-usages-and-limits">
       Listing Personal Disk Usages and Limits
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#listing-osts">
       Listing OSTs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#view-striping-information">
       View Striping Information
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-life-cycle-management">
   Data Life Cycle Management
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-storage-and-management">
     Data Storage and Management
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#backup">
       Backup
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#folder-structure-and-organizing-data">
       Folder Structure and Organizing Data
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#readme-recommendation">
         README Recommendation
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#metadata">
       Metadata
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#data-hygiene">
       Data Hygiene
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#access-rights">
       Access Rights
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#permanent-filesystems">
   Permanent Filesystems
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#global-home-filesystem">
     Global /home Filesystem
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#global-projects-filesystem">
     Global /projects Filesystem
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     Backup
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quotas">
     Quotas
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#working-filesystems">
   Working Filesystems
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     Recommendations for Filesystem Usage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     Cheat Sheet for Debugging Filesystem Issues
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       General
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#workspaces">
   Workspaces
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#workspace-management">
     Workspace Management
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#workspace-lifetimes">
       Workspace Lifetimes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#list-available-filesystems">
       List Available Filesystems
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#list-current-workspaces">
       List Current Workspaces
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#allocate-a-workspace">
       Allocate a Workspace
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#extension-of-a-workspace">
       Extension of a Workspace
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#send-reminder-for-workspace-expiration-date">
       Send Reminder for Workspace Expiration Date
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#send-daily-reminder">
         Send Daily Reminder
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#send-calendar-invitation">
         Send Calendar Invitation
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#deletion-of-a-workspace">
       Deletion of a Workspace
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#expire-process">
         Expire Process
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#restoring-expired-workspaces">
       Restoring Expired Workspaces
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linking-workspaces-in-home">
     Linking Workspaces in HOME
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-use-workspaces">
     How to use Workspaces
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#per-job-storage">
       Per-Job Storage
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#data-for-a-campaign">
       Data for a Campaign
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mid-term-storage">
       Mid-Term Storage
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cooperative-usage-group-workspaces">
     Cooperative Usage (Group Workspaces)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#faq-and-troubleshooting">
     FAQ and Troubleshooting
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transfer-data-inside-zih-systems-with-datamover">
   Transfer Data Inside ZIH Systems with Datamover
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#managing-transfer-jobs">
     Managing Transfer Jobs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#usage-of-datamover">
     Usage of Datamover
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transferring-files-between-zih-systems-and-group-drive">
     Transferring Files Between ZIH Systems and Group Drive
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transfer-data-to-from-zih-systems-via-dataport-nodes">
   Transfer Data to/from ZIH Systems via Dataport Nodes
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-from-linux">
     Access From Linux
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#scp">
       SCP
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sftp">
       SFTP
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#rsync">
       Rsync
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-from-windows">
     Access From Windows
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#command-line">
       Command Line
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gui-using-winscp">
       GUI - Using WinSCP
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transfer-data-between-zih-systems-and-object-storage-s3">
   Transfer Data between ZIH Systems and Object Storage (S3)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#initial-configuration">
     Initial Configuration
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#copying-data-from-to-object-storage">
     Copying Data from/to Object Storage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accessing-the-object-storage">
     Accessing the Object Storage
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#copying-a-file-from-object-storage-to-zih-systems">
       Copying a File from Object Storage to ZIH systems
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#copying-a-file-from-object-storage-to-your-workstation">
       Copying a File from Object Storage to Your Workstation
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#accessing-a-public-readable-file">
       Accessing a Public-Readable File
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-transfer">
   Data Transfer
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-transfer-to-from-zih-systems-dataport-nodes">
     Data Transfer to/from ZIH Systems: Dataport Nodes
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-transfer-inside-zih-systems-datamover">
     Data Transfer Inside ZIH Systems: Datamover
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gpu-cluster-alpha-centauri">
   GPU Cluster Alpha Centauri
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overview">
     Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hardware-specification">
     Hardware Specification
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     Filesystems
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#usage">
     Usage
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#modules">
       Modules
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#python-virtual-environments">
       Python Virtual Environments
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id12">
       JupyterHub
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#containers">
       Containers
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nvidia-arm-hpc-developer-kit">
   NVIDIA Arm HPC Developer Kit
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hardware">
     Hardware
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#further-information">
     Further Information
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#getting-access">
     Getting Access
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#running-applications">
     Running Applications
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cross-compiling-for-the-arm-architecture">
       Cross compiling for the Arm Architecture
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#binding-and-distribution-of-tasks">
   Binding and Distribution of Tasks
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     General
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#openmp-strategies">
     OpenMP Strategies
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mpi-strategies">
     MPI Strategies
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#default-binding-and-distribution-pattern">
       Default Binding and Distribution Pattern
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#core-bound">
       Core Bound
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#distribution-block-block">
         Distribution: block:block
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#distribution-cyclic-cyclic">
         Distribution: cyclic:cyclic
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#distribution-cyclic-block">
         Distribution: cyclic:block
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#socket-bound">
       Socket Bound
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#default-distribution">
         Default Distribution
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id14">
         Distribution: block:block
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#distribution-block-cyclic">
         Distribution: block:cyclic
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hybrid-strategies">
     Hybrid Strategies
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id15">
       Default Binding and Distribution Pattern
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id16">
       Core Bound
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id17">
         Distribution: block:block
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id18">
         Distribution: cyclic:block
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gpu">
     GPU
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gpu-cluster-capella">
   GPU Cluster Capella
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id19">
     Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hardware-specifications">
     Hardware Specifications
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-and-login-nodes">
     Access and Login Nodes
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id20">
     Filesystems
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cluster-specific-filesystem-cat">
       Cluster-Specific Filesystem
       <code class="docutils literal notranslate">
        <span class="pre">
         cat
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#software-and-modules">
     Software and Modules
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id21">
       Python Virtual Environments
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#batch-system">
     Batch System
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#virtual-gpus-mig">
     Virtual GPUs-MIG
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#checkpoint-restart">
   Checkpoint/Restart
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-w-r-t-chain-jobs">
     Using w.r.t. Chain Jobs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-dmtcp-manually">
     Using DMTCP Manually
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#signal-handler">
     Signal Handler
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hpc-resources">
   HPC Resources
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#architectural-design">
     Architectural Design
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#login-and-dataport-nodes">
     Login and Dataport Nodes
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id22">
     Barnard
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id23">
     Alpha Centauri
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id24">
     Capella
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id25">
     Romeo
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id26">
     Julia
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id27">
     Power9
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#smp-cluster-julia">
   SMP Cluster Julia
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id28">
     Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hardware-resources">
     Hardware Resources
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#local-temporary-on-nvme-storage">
     Local Temporary on NVMe Storage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hints-for-usage">
     Hints for Usage
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#known-issues-with-mpi">
   Known Issues with MPI
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#open-mpi">
     Open MPI
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#performance-loss-with-mpi-io-module-ompio">
       Performance Loss with MPI-IO-Module OMPIO
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mpirun-on-clusters-alpha-and-power9">
       Mpirun on clusters
       <code class="docutils literal notranslate">
        <span class="pre">
         alpha
        </span>
       </code>
       and
       <code class="docutils literal notranslate">
        <span class="pre">
         power9
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#r-parallel-library-on-multiple-nodes">
       R Parallel Library on Multiple Nodes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mpi-function-mpi-win-allocate">
       MPI Function
       <code class="docutils literal notranslate">
        <span class="pre">
         MPI_Win_allocate
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nvme-storage">
   NVMe Storage
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction-hpc-resources-and-jobs">
   Introduction HPC Resources and Jobs
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#selection-of-suitable-hardware">
     Selection of Suitable Hardware
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#which-cluster-do-i-need">
       Which Cluster Do I Need?
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-or-batch-mode">
       Interactive or Batch Mode
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#parallel-jobs">
       Parallel Jobs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#multithreading">
       Multithreading
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#what-do-i-need-a-cpu-or-gpu">
       What do I need, a CPU or GPU?
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#how-much-time-do-i-need">
       How much time do I need?
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#runtime-limits">
         Runtime limits
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#how-many-cores-do-i-need">
       How many cores do I need?
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#how-much-memory-do-i-need">
       How much memory do I need?
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#memory-limits">
         Memory Limits
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#which-software-is-required">
       Which software is required?
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#available-software">
         Available software
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#processing-of-data-for-input-and-output">
     Processing of Data for Input and Output
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exclusive-reservation-of-hardware">
     Exclusive Reservation of Hardware
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gpu-cluster-power9">
   GPU Cluster Power9
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id29">
     Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id30">
     Hardware Resources
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id31">
     Usage
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id32">
       Containers
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#power-ai">
       Power AI
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cpu-cluster-romeo">
   CPU Cluster Romeo
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id33">
     Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id34">
     Hardware Resources
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id35">
     Usage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-running-cp2k-on-rome">
     Example, running CP2K on Rome
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-the-intel-toolchain-on-rome">
     Using the Intel Toolchain on Rome
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#intel-mpi">
       Intel MPI
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#search-boost-2-0">
     search:
boost: 2.0
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#batch-system-slurm">
   Batch System Slurm
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#job-submission">
     Job Submission
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#options">
     Options
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#host-list">
       Host List
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#number-of-switches">
       Number of Switches
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interactive-jobs">
     Interactive Jobs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-x11-gui-jobs">
       Interactive X11/GUI Jobs
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#batch-jobs">
     Batch Jobs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#job-files">
       Job Files
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-simultaneous-multithreading-smt">
     Using Simultaneous Multithreading (SMT)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#heterogeneous-jobs">
     Heterogeneous Jobs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#limitations">
       Limitations
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#manage-and-control-jobs">
     Manage and Control Jobs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#job-and-slurm-monitoring">
       Job and Slurm Monitoring
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#editing-jobs">
       Editing Jobs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#canceling-jobs">
       Canceling Jobs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#evaluating-jobs">
       Evaluating Jobs
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jobs-at-reservations">
     Jobs at Reservations
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#node-local-storage-in-jobs">
     Node-Local Storage in Jobs
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#job-examples">
   Job Examples
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id36">
     Parallel Jobs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#openmp-jobs">
       OpenMP Jobs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mpi-jobs">
       MPI Jobs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#multiple-programs-running-simultaneously-in-a-job">
       Multiple Programs Running Simultaneously in a Job
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#request-resources-for-parallel-make">
       Request Resources for Parallel Make
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exclusive-jobs-for-benchmarking">
     Exclusive Jobs for Benchmarking
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#array-jobs">
     Array Jobs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#chain-jobs">
     Chain Jobs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#requesting-gpus">
     Requesting GPUs
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#job-examples-with-gpu">
   Job Examples with GPU
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id37">
     Requesting GPUs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#limitations-of-gpu-job-allocations">
       Limitations of GPU Job Allocations
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#running-multiple-gpu-applications-simultaneously-in-a-batch-job">
       Running Multiple GPU Applications Simultaneously in a Batch Job
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#solution">
         Solution
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#slurm-job-file-generator">
   Slurm Job File Generator
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#slurm-resource-limits">
   Slurm Resource Limits
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id38">
     Runtime Limits
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id39">
     Memory Limits
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#slurm-resource-limits-table">
     Slurm Resource Limits Table
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quick-start">
   Quick Start
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#introductory-instructions">
     Introductory Instructions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#obtaining-access">
     Obtaining Access
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accessing-zih-hpc-systems">
     Accessing ZIH HPC Systems
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id40">
       JupyterHub
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#ssh-connection-command-line">
       SSH Connection (Command Line)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-transfer-and-data-management">
     Data Transfer and Data Management
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#create-a-workspace">
       Create a Workspace
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transferring-data-within-zih-hpc-systems">
       Transferring Data
       <em>
        Within
       </em>
       ZIH HPC Systems
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transferring-data-to-from-zih-hpc-systems">
       Transferring Data
       <em>
        To/From
       </em>
       ZIH HPC Systems
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#permission-rights">
       Permission Rights
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#software-environment">
     Software Environment
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#running-a-program-job">
     Running a Program/Job
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#big-data-analytics">
   Big Data Analytics
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id41">
     Interactive Jobs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#default-configuration">
       Default Configuration
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#custom-configuration">
       Custom Configuration
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-hadoop-distributed-filesystem-hdfs">
       Using Hadoop Distributed Filesystem (HDFS)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id42">
     Batch Jobs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jupyter-notebook">
     Jupyter Notebook
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#spawning-a-notebook">
       Spawning a Notebook
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#faq">
     FAQ
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#building-software">
   Building Software
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#computational-fluid-dynamics-cfd">
   Computational Fluid Dynamics (CFD)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#openfoam">
     OpenFOAM
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ansys-cfx">
     Ansys CFX
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ansys-fluent">
     Ansys Fluent
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#star-ccm">
     STAR-CCM+
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ci-cd-on-hpc">
   CI/CD on HPC
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#requirements">
     Requirements
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#setup-process">
     Setup process
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gitlab-pipelines">
     GitLab pipelines
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#passing-slurm-parameters">
       Passing Slurm parameters
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#current-limitations">
     Current limitations
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pitfalls-and-recommendations">
     Pitfalls and Recommendations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#compilers-and-flags">
   Compilers and Flags
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compiler-flags">
     Compiler Flags
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#architecture-specific-optimizations">
       Architecture-specific Optimizations
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#singularity">
   Singularity
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#usage-of-singularity">
     Usage of Singularity
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#local-installation">
       Local Installation
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#container-creation">
       Container Creation
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#new-custom-container">
         New Custom Container
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#import-a-docker-container">
         Import a Docker Container
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#start-from-a-dockerfile">
         Start from a Dockerfile
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#use-the-containers">
       Use the Containers
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#enter-a-shell-in-your-container">
         Enter a Shell in Your Container
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#run-a-command-inside-the-container">
         Run a Command Inside the Container
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#use-cases">
       Use-Cases
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#software-installation-with-easybuild">
   Software Installation with EasyBuild
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id43">
     Prerequisites
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#set-up-a-custom-module-environment-and-build-your-own-modules">
     Set Up a Custom Module Environment and Build Your Own Modules
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id44">
       Prerequisites
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#step-by-step-guide">
       Step by Step Guide
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#troubleshooting">
     Troubleshooting
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-analytics">
   Data Analytics
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-analytics-with-python">
   Data Analytics with Python
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#python-console-and-virtual-environments">
     Python Console and Virtual Environments
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jupyter-notebooks">
     Jupyter Notebooks
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parallel-computing-with-python">
     Parallel Computing with Python
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pandas-with-pandarallel">
       Pandas with Pandarallel
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#dask">
       Dask
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#dask-modules-on-zih-systems">
         Dask Modules on ZIH Systems
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#scheduling-by-dask">
         Scheduling by Dask
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#distributed-scheduler">
           Distributed Scheduler
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#dask-mpi">
           Dask-mpi
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#dask-jobqueue">
           Dask-jobqueue
          </a>
          <ul class="nav section-nav flex-column">
           <li class="toc-h6 nav-item toc-entry">
            <a class="reference internal nav-link" href="#example-of-using-dask-jobqueue-with-slurmcluster">
             Example of Using Dask-Jobqueue with SLURMCluster
            </a>
           </li>
          </ul>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mpi4py-mpi-for-python">
       Mpi4py -  MPI for Python
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-analytics-with-r">
   Data Analytics with R
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#r-console">
     R Console
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#r-in-jupyterhub">
     R in JupyterHub
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rstudio">
     RStudio
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#install-packages-in-r">
     Install Packages in R
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#deep-learning-with-r">
     Deep Learning with R
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#r-interface-to-tensorflow">
       R Interface to TensorFlow
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parallel-computing-with-r">
     Parallel Computing with R
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#basic-lapply-based-parallelism">
       Basic lapply-Based Parallelism
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#shared-memory-parallelism">
       Shared-Memory Parallelism
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#distributed-memory-parallelism">
       Distributed-Memory Parallelism
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#mpi-cluster">
         MPI Cluster
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#psock-cluster">
         PSOCK cluster
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#fork-cluster">
         FORK Cluster
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#other-parallel-options">
       Other Parallel Options
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-analytics-with-rstudio">
   Data Analytics with RStudio
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#debugging">
   Debugging
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overview-of-available-debuggers-at-zih">
     Overview of available Debuggers at ZIH
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#general-advice">
     General Advice
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gnu-debugger-gdb">
     GNU Debugger (GDB)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#arm-ddt">
     Arm DDT
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#serial-program-example">
       Serial Program Example
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#multi-threaded-program-example">
       Multi-threaded Program Example
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mpi-parallel-program-example">
       MPI-Parallel Program Example
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#memory-debugging">
     Memory Debugging
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#valgrind-memcheck">
       Valgrind (Memcheck)
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#distributed-training">
   Distributed Training
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#internal-distribution">
     Internal Distribution
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#distributed-tensorflow">
       Distributed TensorFlow
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#distributed-pytorch">
       Distributed PyTorch
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-multiple-gpus-with-pytorch">
         Using Multiple GPUs with PyTorch
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#distributed-data-parallel">
         Distributed Data-Parallel
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#external-distribution">
     External Distribution
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#horovod">
       Horovod
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#why-use-horovod">
         Why use Horovod?
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#horovod-as-module">
         Horovod as Module
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#horovod-installation">
         Horovod Installation
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#install-horovod-for-tensorflow-with-python-and-pip">
           Install Horovod for TensorFlow with Python and Pip
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#verify-horovod-works">
           Verify Horovod Works
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measure-energy-consumption">
   Measure Energy Consumption
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary-of-measurement-interfaces">
     Summary of Measurement Interfaces
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#accuracy-temporal-and-spatial-resolution">
       Accuracy, Temporal and Spatial Resolution
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#command-line-interface">
     Command Line Interface
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#integration-in-application-performance-traces">
     Integration in Application Performance Traces
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-using-slurm-tools">
     Access Using Slurm Tools
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#post-mortem-per-job-accounting">
       Post-Mortem Per-Job Accounting
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#slurm-energy-profiling">
       Slurm Energy Profiling
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-the-hdeem-c-api">
     Using the HDEEM C API
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#further-information-and-citing">
     Further Information and Citing
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fem-software">
   FEM Software
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#abaqus">
     Abaqus
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#guide-by-user">
       Guide by User
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id45">
       General
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ansys">
     Ansys
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-workbench-interactively">
       Using Workbench Interactively
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-workbench-in-batch-mode">
       Using Workbench in Batch Mode
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#running-workbench-in-parallel">
       Running Workbench in Parallel
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#running-mapdl">
       Running MAPDL
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#shared-memory-mode">
         Shared-Memory Mode
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#interactive-mode">
           Interactive mode
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#batch-mode">
           Batch mode
          </a>
         </li>
        </ul>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#distributed-memory-mode">
         Distributed-Memory Mode
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id46">
           Interactive Mode
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id47">
           Batch Mode
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comsol-multiphysics">
     COMSOL Multiphysics
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#client-server-mode">
       Client-Server Mode
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id48">
       Usage
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-usage-with-x11-forwarding">
       Interactive Usage with X11 Forwarding
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ls-dyna">
     LS-DYNA
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gpu-programming">
   GPU Programming
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#available-gpus">
     Available GPUs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-gpus-with-slurm">
     Using GPUs with Slurm
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#directive-based-gpu-programming">
     Directive Based GPU Programming
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#openacc">
       OpenACC
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#introduction">
         Introduction
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-openacc-with-pgi-compilers">
         Using OpenACC with PGI compilers
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-openacc-with-nvidia-hpc-compilers">
         Using OpenACC with NVIDIA HPC compilers
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#openmp-target-offloading">
       OpenMP target offloading
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-openmp-target-offloading-with-nvidia-hpc-compilers">
         Using OpenMP target offloading with NVIDIA HPC compilers
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-openmp-target-offloading-with-the-ibm-xl-compilers">
         Using OpenMP target offloading with the IBM XL compilers
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#native-gpu-programming">
     Native GPU Programming
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cuda">
       CUDA
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#usage-of-the-cuda-compiler">
         Usage of the CUDA Compiler
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#performance-analysis">
     Performance Analysis
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nvidia-nvprof-visual-profiler">
       NVIDIA nvprof &amp; Visual Profiler
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nvidia-nsight-systems">
       NVIDIA Nsight Systems
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nvidia-nsight-compute">
       NVIDIA Nsight Compute
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyperparameter-optimization-omniopt">
   Hyperparameter Optimization (OmniOpt)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quick-start-with-omniopt">
     Quick start with OmniOpt
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#prepare-application-script-and-software-environment">
       Prepare Application Script and Software Environment
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#configure-and-run-omniopt">
       Configure and Run OmniOpt
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#check-and-evaluate-omniopt-results">
       Check and Evaluate OmniOpt Results
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#external-licenses">
   External Licenses
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-adjust-the-license-setting">
     How to adjust the license setting
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#record-course-of-events-with-lo2s">
   Record Course of Events with lo2s
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id49">
     Usage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#required-permissions">
     Required Permissions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#memory-requirements">
     Memory Requirements
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#advanced-topic-system-monitoring">
     Advanced Topic: System Monitoring
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#advanced-topic-metric-plugins">
     Advanced Topic: Metric Plugins
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning">
   Machine Learning
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id50">
     Modules
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-via-console">
     Machine Learning via Console
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#python-and-virtual-environments">
       Python and Virtual Environments
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#r">
       R
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-with-jupyter">
     Machine Learning with Jupyter
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-with-containers">
     Machine Learning with Containers
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#additional-libraries-for-machine-learning">
     Additional Libraries for Machine Learning
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#hpc-related-software">
       HPC-Related Software
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#datasets-for-machine-learning">
     Datasets for Machine Learning
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-imagenet-dataset">
       The ImageNet Dataset
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mathematics-applications">
   Mathematics Applications
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mathematica">
     Mathematica
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#fonts">
       Fonts
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#linux-workstation">
         Linux Workstation
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#windows-workstation">
         Windows Workstation
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-textual-interface-of-mathematica">
       Using Textual Interface of Mathematica
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mathematica-and-slurm">
       Mathematica and Slurm
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matlab">
     MATLAB
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-matlab-gui">
       Interactive MATLAB-GUI
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#interactive">
         Interactive
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#matlab-container">
         MATLAB container
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#non-interactive">
       Non-interactive
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-the-matlab-compiler">
       Using the MATLAB Compiler
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#parallel-matlab">
       Parallel MATLAB
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#with-local-configuration">
         With ‚Äòlocal‚Äô Configuration
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#with-parfor">
         With parfor
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#matlab-parallel-computing-toolbox">
       MATLAB Parallel Computing Toolbox
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#configuration-matlab-client-on-the-cluster">
         Configuration ‚Äì MATLAB client on the cluster
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#installation-and-configuration-matlab-client-off-the-cluster">
         Installation and Configuration ‚Äì MATLAB client off the cluster
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#configuring-jobs">
         Configuring Jobs
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#interactive-jobs-matlab-client-on-the-cluster">
         Interactive Jobs - MATLAB Client on the Cluster
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#independent-batch-job">
         Independent Batch Job
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#parallel-batch-job">
         Parallel Batch Job
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id51">
         Debugging
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#further-reading">
         Further Reading
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mathematics-libraries">
   Mathematics Libraries
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#blas-lapack-and-scalapack">
     BLAS, LAPACK and ScaLAPACK
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#amd-optimizing-cpu-libraries-aocl">
     AMD Optimizing CPU Libraries (AOCL)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#math-kernel-library-mkl">
     Math Kernel Library (MKL)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#linking">
       Linking
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#libraries-for-gpus">
     Libraries for GPUs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#magma">
       MAGMA
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fftw">
     FFTW
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#environment-modules">
   Environment Modules
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#module-commands">
     Module Commands
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#examples">
       Examples
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#front-end-ml">
       Front-End ml
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#module-environments">
     Module Environments
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#searching-for-software">
       Searching for Software
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#toolchains">
     Toolchains
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#per-architecture-builds">
     Per-Architecture Builds
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#advanced-usage">
     Advanced Usage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id52">
     Troubleshooting
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#when-i-log-in-the-wrong-modules-are-loaded-by-default">
       When I log in, the wrong modules are loaded by default
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#i-can-t-load-module-tensorflow">
       I can‚Äôt load module TensorFlow
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-mpi-correctness-with-must">
   Check MPI Correctness with MUST
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#must">
     MUST
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#setup-and-modules">
       Setup and Modules
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#running-your-application-with-must">
       Running your Application with MUST
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#result-files">
       Result Files
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-usage-of-must">
       Example Usage of MUST
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#further-mpi-correctness-tools">
     Further MPI Correctness Tools
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nanoscale-simulations">
   Nanoscale Simulations
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#abinit">
     ABINIT
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cp2k">
     CP2K
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cpmd">
     CPMD
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gamess">
     GAMESS
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gaussian">
     Gaussian
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#guidance-on-data-management-with-gaussian">
       Guidance on Data Management with Gaussian
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gromacs">
     GROMACS
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lammps">
     LAMMPS
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#namd">
     NAMD
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#orca">
     ORCA
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#siesta">
     Siesta
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vasp">
     VASP
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gpu-accelerated-containers-for-deep-learning-ngc-containers">
   GPU-accelerated Containers for Deep Learning (NGC Containers)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-ngc-containers-on-the-zih-system">
     Run NGC Containers on the ZIH System
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#run-ngc-container-on-a-single-gpu">
       Run NGC container on a Single GPU
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#multi-gpu-usage">
       Multi-GPU Usage
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#multi-node-usage">
       Multi-node Usage
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#environment-and-software">
   Environment and Software
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#user-environment">
     User Environment
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id53">
     Software Environment
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id54">
     Modules
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id55">
     Jupyter Notebook
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id56">
     Containers
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#read-cpu-performance-counters-with-papi">
   Read CPU Performance Counters with PAPI
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id57">
     Introduction
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#papi-counter-interfaces">
     PAPI Counter Interfaces
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#high-level-api">
       High-Level API
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#low-level-api">
       Low-Level API
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#usage-on-zih-systems">
     Usage on ZIH Systems
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#search-boost-450-0">
     search:
boost: 450.0
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#performance-engineering-overview">
   Performance Engineering Overview
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#objectives">
     Objectives
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#installed-tools-in-a-nutshell">
     Installed Tools in a Nutshell
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#approach-and-terminology">
     Approach and Terminology
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#instrumentation">
       Instrumentation
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#measurement">
       Measurement
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#profile">
         Profile
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#trace">
         Trace
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#analysis">
       Analysis
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#presentation">
       Presentation
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#evaluation">
       Evaluation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#installed-tools-summary">
     Installed Tools Summary
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#lo2s">
       lo2s
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id61">
       MUST
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#papi">
       PAPI
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#perf-tools">
       Perf Tools
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pika">
       PIKA
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#score-p">
       Score-P
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#vampir">
       Vampir
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#produce-performance-overview-with-perf">
   Produce Performance Overview with Perf
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#configuration">
     Configuration
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#perf-stat">
     Perf Stat
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#for-users">
       For Users
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#for-admins">
       For Admins
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#perf-record">
     Perf Record
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id62">
       For Users
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-perf-with-mpi">
         Using Perf with MPI
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id63">
       For Admins
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#perf-report">
     Perf Report
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#on-zih-systems">
       On ZIH Systems
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#perf-script">
     Perf Script
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#perf-top">
     Perf Top
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#search-boost-4-0">
     search:
boost: 4.0
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#track-slurm-jobs-with-pika">
   Track Slurm Jobs with PIKA
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id64">
     Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#table-view-and-job-search">
     Table View and Job Search
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#timeline-visualization">
     Timeline Visualization
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#footprint-visualization">
     Footprint Visualization
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hints">
     Hints
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#case-studies">
     Case Studies
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#idle-cpus">
       Idle CPUs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#blocking-i-o-operations">
       Blocking I/O Operations
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#memory-leaks">
       Memory Leaks
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning-with-powerai">
   Machine Learning with PowerAI
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#general-overview">
     General Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#specific-user-guides">
     Specific User Guides
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#powerai-container">
     PowerAI Container
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#private-modules">
   Private Modules
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#setup">
     Setup
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#build-and-install-software">
       0. Build and Install Software
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#create-directory">
       1. Create Directory
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#create-modulefile">
       2. Create Modulefile
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id65">
     Usage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#caveats">
     Caveats
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id66">
   Python Virtual Environments
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#python-virtual-environment">
     Python Virtual Environment
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#persistence-of-python-virtual-environment">
       Persistence of Python Virtual Environment
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conda-virtual-environment">
     Conda Virtual Environment
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#persistence-of-conda-virtual-environment">
       Persistence of Conda Virtual Environment
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#neural-networks-with-pytorch">
   Neural Networks with PyTorch
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pytorch-console">
     PyTorch Console
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pytorch-in-jupyterhub">
     PyTorch in JupyterHub
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id67">
     Distributed PyTorch
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#migrate-pytorch-script-from-cpu-to-gpu">
     Migrate PyTorch-script from CPU to GPU
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id68">
       Caveats
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#moving-data-back-to-the-cpu-memory">
         Moving Data Back to the CPU-Memory
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#speed-improvements-and-batch-size">
         Speed Improvements and Batch Size
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#record-course-of-events-with-score-p">
   Record Course of Events with Score-P
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#serial-programs">
     Serial Programs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mpi-parallel-programs">
     MPI Parallel Programs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#openmp-parallel-programs">
     OpenMP Parallel Programs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hybrid-mpi-openmp-parallel-programs">
     Hybrid MPI/OpenMP Parallel Programs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#score-p-instrumenter-option-overview">
     Score-P Instrumenter Option Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#application-measurement">
     Application Measurement
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#singularity-for-power9-architecture">
   Singularity for Power9 Architecture
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#build-a-singularity-container-in-a-job">
     Build a Singularity Container in a Job
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#filesystem">
     Filesystem
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#start-a-job-in-a-vm">
     Start a Job in a VM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#singularity-recipes-and-hints">
   Singularity Recipes and Hints
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-definitions">
     Example Definitions
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#basic-example">
       Basic Example
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#distributed-memory">
       Distributed memory
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#mpich">
         MPICH
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cuda-cudnn-open-mpi">
       CUDA + CuDNN + Open MPI
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id69">
     Hints
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gui-x11-applications">
       GUI (X11) Applications
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#hardware-acceleration">
       Hardware Acceleration
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#singularity-temporary-and-cache-directories">
       Singularity Temporary and Cache Directories
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#software-development-and-tools">
   Software Development and Tools
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#compare-system-performance-with-spechpc">
   Compare System Performance with SPEChpc
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#installation">
     Installation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id70">
     Configuration
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#execution">
     Execution
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#submit-spechpc-benchmarks-with-a-job-file">
       Submit SPEChpc Benchmarks with a Job File
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#solved-issues">
     Solved Issues
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#fortran-compilation-error">
       Fortran Compilation Error
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pmix-error">
       pmix Error
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#orte-error-too-many-processes">
       ORTE Error (too many processes)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#error-with-openfabrics-device">
       Error with OpenFabrics Device
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#out-of-memory">
       Out of Memory
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unresolved-issues">
     Unresolved Issues
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cuda-reduction-operation-error">
       CUDA Reduction Operation Error
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#slurm-bug">
       Slurm Bug
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#benchmark-hangs-forever">
       Benchmark Hangs Forever
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#other-issues">
       Other Issues
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inspect-model-training-with-tensorboard">
   Inspect Model Training with TensorBoard
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-jupyterhub">
     Using JupyterHub
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-tensorboard-from-module-environment">
     Using TensorBoard from Module Environment
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#neural-networks-with-tensorflow">
   Neural Networks with TensorFlow
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensorflow-console">
     TensorFlow Console
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensorflow-in-jupyterhub">
     TensorFlow in JupyterHub
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensorflow-in-containers">
     TensorFlow in Containers
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensorflow-with-python-or-r">
     TensorFlow with Python or R
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id71">
     Distributed TensorFlow
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compatibility-tf2-and-tf1">
     Compatibility TF2 and TF1
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#keras">
     Keras
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#utilities">
   Utilities
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tmux">
     Tmux
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#best-practices">
       Best Practices
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#basic-usage">
       Basic Usage
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-a-more-recent-version">
       Using a More Recent Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#error-protocol-version-mismatch">
       Error: Protocol Version Mismatch
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-tmux-on-compute-nodes">
       Using Tmux on Compute Nodes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#where-is-my-tmux-session">
       Where Is My Tmux Session?
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#architecture-information-lstopo">
     Architecture Information (lstopo)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#working-with-large-archives-and-compressed-files">
     Working with Large Archives and Compressed Files
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#parallel-gzip-decompression">
       Parallel Gzip Decompression
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#direct-archive-access-without-extraction-using-ratarmount">
       Direct Archive Access Without Extraction Using Ratarmount
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#example-workflow">
         Example Workflow
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#study-course-of-events-with-vampir">
   Study Course of Events with Vampir
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id72">
     Introduction
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#starting-vampir">
     Starting Vampir
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-vampirserver">
     Using VampirServer
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id73">
     Advanced Usage
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#manual-server-startup">
       Manual Server Startup
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#port-forwarding">
       Port Forwarding
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nightly-builds-unstable">
       Nightly Builds (unstable)
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#virtual-desktops">
   Virtual Desktops
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#launch-a-virtual-desktop">
     Launch a Virtual Desktop
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#demonstration">
       Demonstration
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-the-quickstart-feature">
       Using the Quickstart Feature
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reconnecting-to-a-session">
     Reconnecting to a Session
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#terminate-a-remote-session">
     Terminate a Remote Session
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id74">
       Demonstration
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#virtual-machines">
   Virtual Machines
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-a-virtual-machine">
     Create a Virtual Machine
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#on-power9-architecture">
       On Power9 Architecture
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#on-x86-architecture">
       On x86 Architecture
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-a-virtual-machine">
     Access a Virtual Machine
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-usage">
     Example Usage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#automation">
     Automation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#known-issues">
     Known Issues
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#temporary-memory">
       Temporary Memory
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transport-endpoint-is-not-connected">
       Transport Endpoint is not Connected
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization">
   Visualization
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#paraview">
     ParaView
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#paraview-modules">
       ParaView Modules
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id75">
       Interactive Mode
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-the-gui-via-nice-dcv">
         Using the GUI via NICE DCV
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-client-server-mode-with-mpi-parallel-offscreen-rendering">
         Using Client-Server Mode with MPI-parallel Offscreen-Rendering
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id76">
           Caveats
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#batch-mode-pvbatch">
       Batch Mode (
       <code class="docutils literal notranslate">
        <span class="pre">
         pvbatch
        </span>
       </code>
       )
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-gpus">
         Using GPUs
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#zsh-as-alternative-shell">
   ZSH as Alternative Shell
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#oh-my-zsh">
     <code class="docutils literal notranslate">
      <span class="pre">
       oh-my-zsh
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#features">
     Features
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#themes">
       Themes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#auto-completion">
       Auto-completion
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#syntax-highlighting">
       Syntax-highlighting
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#typo-correction">
       Typo-correction
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#automatic-cd">
       Automatic
       <code class="docutils literal notranslate">
        <span class="pre">
         cd
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#fish-like-auto-suggestions">
       <code class="docutils literal notranslate">
        <span class="pre">
         fish
        </span>
       </code>
       -like auto-suggestions
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#setting-zsh-as-default-shell">
     Setting
     <code class="docutils literal notranslate">
      <span class="pre">
       zsh
      </span>
     </code>
     as default-shell
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#user-support">
   User Support
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-a-ticket">
     Create a Ticket
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#open-q-a-sessions">
     Open Q&amp;A Sessions
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>

            <article class="bd-article" role="main">
              
  <section class="tex2jax_ignore mathjax_ignore" id="erklarung-zur-barrierefreiheit">
<h1>Erkl√§rung zur Barrierefreiheit<a class="headerlink" href="#erklarung-zur-barrierefreiheit" title="Permalink to this heading">#</a></h1>
<p>Diese Erkl√§rung zur Barrierefreiheit gilt f√ºr die unter
<a class="reference external" href="https://doc.zih.tu-dresden.de">https://doc.zih.tu-dresden.de</a>,
<a class="reference external" href="https://doc.hpc.tu-dresden.de">https://doc.hpc.tu-dresden.de</a>,
<a class="reference external" href="https://compendium.hpc.tu-dresden.de">https://compendium.hpc.tu-dresden.de</a> und
<a class="reference external" href="https://hpc-wiki.zih.tu-dresden.de">https://hpc-wiki.zih.tu-dresden.de</a> ver√∂ffentlichte Website
der Technischen Universit√§t Dresden.
Als √∂ffentliche Stelle im Sinne des Barrierefreie-Websites-Gesetz (BfWebG) ist die Technische
Universit√§t Dresden bem√ºht, ihre Websites und mobilen Anwendungen im Einklang mit den Bestimmungen
des Barrierefreie-Websites-Gesetz (BfWebG) in Verbindung mit der
Barrierefreie-Informationstechnik-Verordnung (BITV 2.0) barrierefrei zug√§nglich zu machen.</p>
<section id="erstellung-dieser-erklarung-zur-barrierefreiheit">
<h2>Erstellung dieser Erkl√§rung zur Barrierefreiheit<a class="headerlink" href="#erstellung-dieser-erklarung-zur-barrierefreiheit" title="Permalink to this heading">#</a></h2>
<p>Diese Erkl√§rung wurde am 17.09.2020 erstellt und zuletzt am 17.09.2020 aktualisiert. Grundlage der
Erstellung dieser Erkl√§rung zur Barrierefreiheit ist eine am 17.09.2020 von der TU Dresden
durchgef√ºhrte Selbstbewertung.</p>
</section>
<section id="stand-der-barrierefreiheit">
<h2>Stand der Barrierefreiheit<a class="headerlink" href="#stand-der-barrierefreiheit" title="Permalink to this heading">#</a></h2>
<p>Es wurde bisher noch kein BITV-Test f√ºr die Website durchgef√ºhrt. Dieser ist bis 30.11.2020 geplant.</p>
</section>
<section id="kontakt">
<h2>Kontakt<a class="headerlink" href="#kontakt" title="Permalink to this heading">#</a></h2>
<p>Sollten Ihnen M√§ngel in Bezug auf die barrierefreie Gestaltung auffallen, k√∂nnen Sie uns diese √ºber
das Formular <a class="reference external" href="https://tu-dresden.de/barrierefreiheit/barriere-melden">Barriere melden</a> mitteilen und
im zug√§nglichen Format anfordern. Alternativ k√∂nnen Sie sich direkt an die Meldestelle f√ºr Barrieren
wenden (Koordinatorin: Mandy Weickert, E-Mail: <a class="reference external" href="mailto:barrieren&#37;&#52;&#48;tu-dresden&#46;de">barrieren<span>&#64;</span>tu-dresden<span>&#46;</span>de</a>, Telefon: +49 351
463-42022, Fax: +49 351 463-42021, Besucheradresse: N√∂thnitzer Stra√üe 46, APB 1102, 01187 Dresden).</p>
</section>
<section id="durchsetzungsverfahren">
<h2>Durchsetzungsverfahren<a class="headerlink" href="#durchsetzungsverfahren" title="Permalink to this heading">#</a></h2>
<p>Wenn wir Ihre R√ºckmeldungen aus Ihrer Sicht nicht befriedigend bearbeiten, k√∂nnen Sie sich an die
S√§chsische Durchsetzungsstelle wenden:</p>
<p>Beauftragter der S√§chsischen Staatsregierung f√ºr die Belange von Menschen mit Behinderungen
Albertstra√üe 10
01097 Dresden
Postanschrift: Archivstra√üe 1, 01097 Dresden
E-Mail: <a class="reference external" href="mailto:info&#46;behindertenbeauftragter&#37;&#52;&#48;sk&#46;sachsen&#46;de">info<span>&#46;</span>behindertenbeauftragter<span>&#64;</span>sk<span>&#46;</span>sachsen<span>&#46;</span>de</a>
Telefon: +49 351 564-12161
Fax: +49 351 564-12169
Webseite: <a class="reference external" href="https://www.inklusion.sachsen.de/">https://www.inklusion.sachsen.de/</a></p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="datenschutzerklarung">
<h1>Datenschutzerkl√§rung<a class="headerlink" href="#datenschutzerklarung" title="Permalink to this heading">#</a></h1>
<p>Zur Bereitstellung des Dienstes werden folgende personenbeziehbaren Daten verarbeitet: IP Addresse.</p>
<p>Eine Nutzung dieser Daten f√ºr andere Zwecke erfolgt nicht. Eine Speicherung dieser Daten erfolgt nur
zur Fehleranalyse. Eine √úbermittlung dieser Daten an Dritte erfolgt nur, wenn dies gesetzlich
bestimmt ist.</p>
<p>Jeder Nutzer kann sich jederzeit an den <a class="reference external" href="https://tu-dresden.de/tu-dresden/organisation/gremien-und-beauftragte/beauftragte/datenschutzbeauftragter">Datenschutzbeauftragten der TU
Dresden</a>
sowie an die <a class="reference external" href="https://www.saechsdsb.de/">zust√§ndige Aufsichtsbeh√∂rde f√ºr den Datenschutz</a> wenden.</p>
<p>Weiterhin besteht die M√∂glichkeit jederzeit Auskunft √ºber die zu seiner Person verarbeiteten Daten
zu verlangen und es steht eine Antwort mit der Frist von einem Monat nach Eingang des
Auskunftsersuchens zu.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="zih-hpc-documentation">
<h1>ZIH HPC Documentation<a class="headerlink" href="#zih-hpc-documentation" title="Permalink to this heading">#</a></h1>
<p>This is the documentation of the HPC systems and services provided at
<a class="reference external" href="https://tu-dresden.de/zih/">TU Dresden/ZIH</a>.</p>
<p>This documentation will be continuously updated, since we try
to incorporate more information with increasing experience and with every question you ask us.</p>
<p>If the provided HPC systems and services helped to advance your research, please cite us. Why this
is important and acknowledgment examples can be found in the section
<span class="xref myst">Acknowledgement</span>.</p>
<section id="contribution">
<h2>Contribution<a class="headerlink" href="#contribution" title="Permalink to this heading">#</a></h2>
<p>The HPC team invites you to take part in the improvement of these pages by correcting or adding
useful information. Your contributions are highly welcome!</p>
<p>The easiest way for you to contribute is to report issues via
the GitLab
<a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/zih/hpcsupport/hpc-compendium/-/issues">issue tracking system</a>.
Please check for any already existing issue before submitting your issue in order to avoid duplicate
issues.</p>
<p>Please also find out the other ways you could contribute in our
<span class="xref myst">guidelines how to contribute</span>.</p>
<p>!!! tip ‚ÄúReminder‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Non-documentation issues and requests need to be send to
[hpc-support@tu-dresden.de](mailto:hpc-support@tu-dresden.de).
</pre></div>
</div>
</section>
<section id="news">
<h2>News<a class="headerlink" href="#news" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>2024-12-13</strong> Regular user operation of the new
<span class="xref myst">GPU cluster <code class="docutils literal notranslate"><span class="pre">Capella</span></code></span> started</p></li>
<li><p><strong>2024-11-18</strong> The GPU cluster <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Capella</span></code></span> was
ranked #51 in the <a class="reference external" href="https://top500.org/system/180298/">TOP500</a>, #3 in the German systems and #5 in
the <a class="reference external" href="https://top500.org/lists/green500/list/2024/11/">GREEN500</a> lists of the world‚Äôs fastest
computers in November 2024.</p></li>
<li><p><strong>2024-11-04</strong> Slides from the HPC Introduction tutorial in October
2024 are available for <span class="xref myst">download now</span></p></li>
</ul>
</section>
<section id="training-and-courses">
<h2>Training and Courses<a class="headerlink" href="#training-and-courses" title="Permalink to this heading">#</a></h2>
<p>We offer a rich and colorful bouquet of courses from classical <em>HPC introduction</em>
(<span class="xref myst">HPC introduction slides</span>) to various
<em>Performance Analysis</em> and <em>Machine Learning</em> trainings. Please refer to the page
<a class="reference external" href="https://tu-dresden.de/zih/hochleistungsrechnen/nhr-training">Training Offers</a>
for a detailed overview of the courses and the respective dates at ZIH.</p>
<p>Furthermore, Center for Scalable Data Analytics and Artificial Intelligence
<a class="reference external" href="https://scads.ai">ScaDS.AI</a> Dresden/Leipzig offers various trainings with HPC focus.
Current schedule and registration is available at the
<a class="reference external" href="https://scads.ai/transfer/teaching-and-training/">ScaDS.AI trainings page</a>.</p>
</section>
<section id="support-and-consultation">
<h2>Support and Consultation<a class="headerlink" href="#support-and-consultation" title="Permalink to this heading">#</a></h2>
<p>We offer regular
<span class="xref myst">public and personal consultation opportunities</span>
with HPC experts.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="legal-notice">
<h1>Legal Notice<a class="headerlink" href="#legal-notice" title="Permalink to this heading">#</a></h1>
<section id="impressum">
<h2>Impressum<a class="headerlink" href="#impressum" title="Permalink to this heading">#</a></h2>
<p>Es gilt das <a class="reference external" href="https://tu-dresden.de/impressum">Impressum der TU Dresden</a> mit folgenden √Ñnderungen:</p>
<section id="ansprechpartner-betreiber">
<h3>Ansprechpartner/Betreiber<a class="headerlink" href="#ansprechpartner-betreiber" title="Permalink to this heading">#</a></h3>
<p>Technische Universit√§t Dresden
Zentrum f√ºr Informationsdienste und Hochleistungsrechnen
01062 Dresden</p>
<p>Tel.: +49 351 463-40000
Fax: +49 351 463-42328
E-Mail: <a class="reference external" href="mailto:servicedesk&#37;&#52;&#48;tu-dresden&#46;de">servicedesk<span>&#64;</span>tu-dresden<span>&#46;</span>de</a></p>
</section>
<section id="konzeption-technische-umsetzung-anbieter">
<h3>Konzeption, Technische Umsetzung, Anbieter<a class="headerlink" href="#konzeption-technische-umsetzung-anbieter" title="Permalink to this heading">#</a></h3>
<p>Technische Universit√§t Dresden
Zentrum f√ºr Informationsdienste und Hochleistungsrechnen
Prof. Dr. Wolfgang E. Nagel
01062 Dresden</p>
<p>Tel.: +49 351 463-35450
Fax: +49 351 463-37773
E-Mail: <a class="reference external" href="mailto:zih&#37;&#52;&#48;tu-dresden&#46;de">zih<span>&#64;</span>tu-dresden<span>&#46;</span>de</a></p>
</section>
</section>
<section id="license">
<h2>License<a class="headerlink" href="#license" title="Permalink to this heading">#</a></h2>
<p>This documentation and the repository have two licenses:</p>
<ul class="simple">
<li><p>All documentation is licensed under <a class="reference external" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>.</p></li>
<li><p>All software components are licensed under <span class="xref myst">MIT license</span>.</p></li>
</ul>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="desktop-cloud-visualization-dcv">
<h1>Desktop Cloud Visualization (DCV)<a class="headerlink" href="#desktop-cloud-visualization-dcv" title="Permalink to this heading">#</a></h1>
<p>NICE DCV enables remote accessing OpenGL 3D applications running on ZIH systems using the
server‚Äôs GPUs. If you don‚Äôt need OpenGL acceleration, you might also want to try our
<span class="xref myst">WebVNC</span> solution.</p>
<p>See <a class="reference external" href="https://docs.aws.amazon.com/dcv/latest/userguide/client-web.html">the official DCV documentation</a>
if you want to know whether your browser is supported by DCV.</p>
<section id="access-with-jupyterhub">
<h2>Access with JupyterHub<a class="headerlink" href="#access-with-jupyterhub" title="Permalink to this heading">#</a></h2>
<p><strong>Check out our new documentation about</strong> <span class="xref myst">Virtual Desktops</span>.</p>
<p>To start a JupyterHub session on the cluster <code class="docutils literal notranslate"><span class="pre">vis</span></code> (<code class="docutils literal notranslate"><span class="pre">vis[1-4]</span></code>) with one GPU, 2 CPU cores
and 2 GB memory per core, click on:</p>
<p><a class="reference external" href="https://jupyterhub.hpc.tu-dresden.de/hub/spawn#/~(cluster~'vis~nodes~'1~ntasks~'1~cpuspertask~'2~mempercpu~'2048)">https://jupyterhub.hpc.tu-dresden.de/hub/spawn#/~(cluster~‚Äôvis~nodes~‚Äô1~ntasks~‚Äô1~cpuspertask~‚Äô2~mempercpu~‚Äô2048)</a></p>
<p>Optionally, you can modify many different Slurm parameters. For this
follow the general <span class="xref myst">JupyterHub</span> documentation.</p>
<p>Your browser should load JupyterLab, which looks like this:</p>
<p><img alt="JupyterLab and DCV" src="63_chat_with_docs/misc/jupyterlab_and_dcv.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>Click on the <code class="docutils literal notranslate"><span class="pre">DCV</span></code> button. A new tab with the DCV client will be opened.</p>
</section>
<section id="notes-on-gpu-support">
<h2>Notes on GPU Support<a class="headerlink" href="#notes-on-gpu-support" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Check GPU support via:</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>glxinfo<span class="w"> </span><span class="p">|</span><span class="w"> </span>head
<span class="go">name of display: :1</span>
<span class="go">display: :1  screen: 0</span>
<span class="go">direct rendering: Yes</span>
<span class="go">[...]</span>
</pre></div>
</div>
<p>If direct rendering is not set to <code class="docutils literal notranslate"><span class="pre">Yes</span></code>, please contact <a class="reference external" href="mailto:hpc-support&#37;&#52;&#48;tu-dresden&#46;de">HPC support</a>.</p>
<ul class="simple">
<li><p>Expand LD_LIBRARY_PATH:</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/usr/lib64/nvidia
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="graphical-applications-with-webvnc">
<h1>Graphical Applications with WebVNC<a class="headerlink" href="#graphical-applications-with-webvnc" title="Permalink to this heading">#</a></h1>
<p>While many of the applications that run on ZIH systems are used from the command line,
graphical user interfaces are sometimes beneficial for particular use cases.
In order to simplify the setup, few solutions are available, which are described in the following.</p>
<p>The solutions provided here are based on a Singularity container with a VNC setup that can be
used as an alternative to SSH‚Äôs X-Forwarding option to start graphical applications.</p>
<p>Internally, the solution utilizes <a class="reference external" href="https://novnc.com">noVNC</a> to offer a web-based client that you
can use with your browser, so there‚Äôs no additional client software necessary.</p>
<section id="access-via-jupyterhub">
<h2>Access via JupyterHub<a class="headerlink" href="#access-via-jupyterhub" title="Permalink to this heading">#</a></h2>
<p><strong>Check out our new documentation about <span class="xref myst">Virtual Desktops</span>.</strong></p>
<p>To start a JupyterHub session on the cluster <code class="docutils literal notranslate"><span class="pre">vis</span></code> with one CPU
cores and  1,5 GB memory per core, click on:</p>
<p><a class="reference external" href="https://jupyterhub.hpc.tu-dresden.de/hub/spawn#/~(cluster~'vis~nodes~'1~ntasks~'1~cpuspertask~'1~mempercpu~'1536)">https://jupyterhub.hpc.tu-dresden.de/hub/spawn#/~(cluster~‚Äôvis~nodes~‚Äô1~ntasks~‚Äô1~cpuspertask~‚Äô1~mempercpu~‚Äô1536)</a></p>
<p>Optionally, you can modify many different Slurm parameters.
For this, follow the general <span class="xref myst">JupyterHub</span> documentation.</p>
<p>Your browser should load JupyterLab, which looks like this:</p>
<p><img alt="JupyterLab and WebVNC" src="63_chat_with_docs/misc/jupyterlab_and_webvnc.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>Click on the <code class="docutils literal notranslate"><span class="pre">WebVNC</span></code> button. A new tab with the noVNC client will be opened.</p>
</section>
<section id="access-via-terminal">
<h2>Access via terminal<a class="headerlink" href="#access-via-terminal" title="Permalink to this heading">#</a></h2>
<section id="step-1">
<h3>Step 1<a class="headerlink" href="#step-1" title="Permalink to this heading">#</a></h3>
<p>Start the <code class="docutils literal notranslate"><span class="pre">runVNC</span></code> script in our prepared container in an interactive batch job (here with 2 cores
and 1,5 GB of memory per core):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>srun<span class="w"> </span>--pty<span class="w"> </span>--mem-per-cpu<span class="o">=</span><span class="m">1536</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">2</span><span class="w"> </span>--time<span class="o">=</span><span class="m">4</span>:00:00<span class="w"> </span>singularity<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>/scratch/singularity/xfce.sif<span class="w"> </span>runVNC
<span class="go">[...]</span>
</pre></div>
</div>
<p>Of course, you can adjust the batch job parameters to your liking. Note that the default time limit
in cluster <code class="docutils literal notranslate"><span class="pre">vis</span></code> is only 1 hour, so you should specify a longer one with <code class="docutils literal notranslate"><span class="pre">--time</span></code> (or <code class="docutils literal notranslate"><span class="pre">-t</span></code>).</p>
<p>The script will automatically generate a self-signed SSL certificate and place it in your home
directory under the name <code class="docutils literal notranslate"><span class="pre">self.pem</span></code>. This path can be overridden via the parameter <code class="docutils literal notranslate"><span class="pre">--cert</span></code> to
<code class="docutils literal notranslate"><span class="pre">runVNC</span></code>.</p>
<p>On success, it will give you an URL and a one-time password:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">[...]</span>
<span class="go">Note: Certificate file /home/user/self.pem already exists. Skipping generation.  Starting VNC</span>
<span class="go">server...  Server started successfully.  Please browse to: https://172.24.146.46:5901/vnc.html</span>
<span class="go">The one-time password is: 71149997</span>
</pre></div>
</div>
</section>
<section id="step-2">
<h3>Step 2<a class="headerlink" href="#step-2" title="Permalink to this heading">#</a></h3>
<p>Direct access to the compute nodes is not allowed. Therefore, you have to create a tunnel from your
laptop or workstation to the specific compute node and port as follows.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@local$<span class="w"> </span>ssh<span class="w"> </span>-NL<span class="w"> </span>&lt;<span class="nb">local</span><span class="w"> </span>port&gt;:&lt;compute<span class="w"> </span>node&gt;:&lt;remote<span class="w"> </span>port&gt;<span class="w"> </span>barnard
</pre></div>
</div>
<p>e.g.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>ssh<span class="w"> </span>-NL<span class="w"> </span><span class="m">5901</span>:172.24.146.46:5901<span class="w"> </span>barnard
</pre></div>
</div>
<p>!!! important ‚ÄúSSH command‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The previous SSH command requires that you have already set up your [SSH configuration
](../access/ssh_login.md#configuring-default-parameters-for-ssh).
</pre></div>
</div>
</section>
<section id="step-3">
<h3>Step 3<a class="headerlink" href="#step-3" title="Permalink to this heading">#</a></h3>
<p>Open your local web-browser and connect to the following URL, replacing <code class="docutils literal notranslate"><span class="pre">&lt;local</span> <span class="pre">port&gt;</span></code> with the
local port you specified in the previous step:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">localhost</span><span class="p">:</span><span class="o">&lt;</span><span class="n">local</span> <span class="n">port</span><span class="o">&gt;/</span><span class="n">vnc</span><span class="o">.</span><span class="n">html</span>
</pre></div>
</div>
<p>e.g.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">localhost</span><span class="p">:</span><span class="mi">5901</span><span class="o">/</span><span class="n">vnc</span><span class="o">.</span><span class="n">html</span>
</pre></div>
</div>
<p>Since you are using a self-signed certificate and the node does not have a public DNS name, your
browser will not be able to verify it and you will have to add an exception (via the ‚ÄúAdvanced‚Äù
button).</p>
</section>
<section id="step-4">
<h3>Step 4<a class="headerlink" href="#step-4" title="Permalink to this heading">#</a></h3>
<p>On the website, click the <code class="docutils literal notranslate"><span class="pre">Connect</span></code> button and enter the one-time password that was previously
displayed in order to authenticate. You will then see an Xfce4 desktop and can start a terminal in
there, where you can use the ‚Äúml‚Äù or ‚Äúmodule‚Äù command as usual to load and then run your graphical
applications. Enjoy!</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="jupyterhub">
<h1>JupyterHub<a class="headerlink" href="#jupyterhub" title="Permalink to this heading">#</a></h1>
<p>With our JupyterHub service, we offer you a quick and easy way to work with
Jupyter notebooks on ZIH systems. This page covers starting and stopping
JupyterHub sessions, error handling and customizing the environment.</p>
<p>We also provide a comprehensive documentation on how to use
<span class="xref myst">JupyterHub for Teaching (git-pull feature, quickstart links, direct links to notebook files)</span>.</p>
<section id="disclaimer">
<h2>Disclaimer<a class="headerlink" href="#disclaimer" title="Permalink to this heading">#</a></h2>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The JupyterHub service is provided *as-is*, use at your own discretion.
</pre></div>
</div>
<p>Please understand that JupyterHub is a complex software system of which we are
not the developers and don‚Äôt have any downstream support contracts for, so we
merely offer an installation of it but cannot give extensive support in every
case.</p>
</section>
<section id="access">
<h2>Access<a class="headerlink" href="#access" title="Permalink to this heading">#</a></h2>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>This service is only available for users with an active HPC project.
See [Application for Login and Resources](../application/overview.md), if
you need to apply for an HPC project.
</pre></div>
</div>
<p>JupyterHub is available at
<a class="reference external" href="https://jupyterhub.hpc.tu-dresden.de">https://jupyterhub.hpc.tu-dresden.de</a>.</p>
</section>
<section id="login-page">
<h2>Login Page<a class="headerlink" href="#login-page" title="Permalink to this heading">#</a></h2>
<p>At login page please use your ZIH credentials (without &#64;tu-dresden.de).</p>
<p><img alt="Simple form" src="63_chat_with_docs/misc/jupyterhub_loginpage_marie.png" />
{: align=‚Äùcenter‚Äù}</p>
</section>
<section id="start-a-session">
<h2>Start a Session<a class="headerlink" href="#start-a-session" title="Permalink to this heading">#</a></h2>
<p>Start a new session by clicking on the <code class="docutils literal notranslate"><span class="pre">Start</span></code> button.</p>
<section id="standard-profiles">
<h3>Standard Profiles<a class="headerlink" href="#standard-profiles" title="Permalink to this heading">#</a></h3>
<p>Our simple form offers you the most important settings to start quickly.</p>
<p><img alt="Advanced form" src="63_chat_with_docs/misc/jupyterhub_profile_selector.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>We have created three profiles for each cluster, namely:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Cluster</p></th>
<th class="head"><p>Resources</p></th>
<th class="head"><p>Optimized for</p></th>
<th class="head"><p>Recommended for</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Alpha</p></td>
<td><p>1 core, 1.5 GB 1 hour</p></td>
<td><p>x86_64 (AMD)</p></td>
<td><p>Python programming</p></td>
</tr>
<tr class="row-odd"><td><p>Alpha</p></td>
<td><p>2 core, 3 GB, 4 hours</p></td>
<td><p>x86_64 (AMD)</p></td>
<td><p>R programming</p></td>
</tr>
<tr class="row-even"><td><p>Alpha</p></td>
<td><p>4 core, 8 GB, 8 hours</p></td>
<td><p>x86_64 (AMD)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>Barnard</p></td>
<td><p>1 core, 1.5 GB, 1 hour</p></td>
<td><p>x86_64 (Intel)</p></td>
<td><p>Python programming</p></td>
</tr>
<tr class="row-even"><td><p>Barnard</p></td>
<td><p>2 core, 3 GB, 4 hours</p></td>
<td><p>x86_64 (Intel)</p></td>
<td><p>Julia and R programming</p></td>
</tr>
<tr class="row-odd"><td><p>Barnard</p></td>
<td><p>4 core, 8 GB, 8 hours</p></td>
<td><p>x86_64 (Intel)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>Capella</p></td>
<td><p>1 core, 1.5 GB, 1 hour</p></td>
<td><p>x86_64 (AMD)</p></td>
<td><p>Python programming</p></td>
</tr>
<tr class="row-odd"><td><p>Capella</p></td>
<td><p>2 core, 3 GB, 4 hours</p></td>
<td><p>x86_64 (AMD)</p></td>
<td><p>R programming</p></td>
</tr>
<tr class="row-even"><td><p>Capella</p></td>
<td><p>4 core, 8 GB, 8 hours</p></td>
<td><p>x86_64 (AMD)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>Romeo</p></td>
<td><p>1 core, 1.5 GB 1 hour</p></td>
<td><p>x86_64 (AMD)</p></td>
<td><p>Python programming</p></td>
</tr>
<tr class="row-even"><td><p>Romeo</p></td>
<td><p>2 core, 3 GB, 4 hours</p></td>
<td><p>x86_64 (AMD)</p></td>
<td><p>R programming</p></td>
</tr>
<tr class="row-odd"><td><p>Romeo</p></td>
<td><p>4 core, 8 GB, 8 hours</p></td>
<td><p>x86_64 (AMD)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>VIS</p></td>
<td><p>1 core, 1.5 GB, 1 hours</p></td>
<td><p>Visualization</p></td>
<td><p>ANSYS</p></td>
</tr>
<tr class="row-odd"><td><p>VIS</p></td>
<td><p>2 core, 4 GB, 2 hours</p></td>
<td><p>Visualization</p></td>
<td><p>ANSYS</p></td>
</tr>
<tr class="row-even"><td><p>VIS</p></td>
<td><p>4 core, 8 GB, 6 hours</p></td>
<td><p>Visualization</p></td>
<td><p>ANSYS</p></td>
</tr>
</tbody>
</table>
</section>
<section id="advanced-options">
<h3>Advanced Options<a class="headerlink" href="#advanced-options" title="Permalink to this heading">#</a></h3>
<p>Aside of the standard profiles there is the possibility to specify custom parameters to the job
spawner. This can be activated cby licking at the <code class="docutils literal notranslate"><span class="pre">Advanced</span></code> button located below to the profile
list.</p>
<p><img alt="Advanced form" src="63_chat_with_docs/misc/jupyterhub_advanced_form.png" />
{: align=‚Äùcenter‚Äù}</p>
</section>
</section>
<section id="jupyterlab">
<h2>JupyterLab<a class="headerlink" href="#jupyterlab" title="Permalink to this heading">#</a></h2>
<p>After your session it is spawned you will be redirected to JupyterLab. The main interface looks
like as following:</p>
<p><img alt="JupyterLab overview" src="63_chat_with_docs/misc/jupyterlab_overview_2023-12-19.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Your interface may differ from the picture above as not all icons (launchers) are available
at all profiles.
</pre></div>
</div>
<p>The main workspace is used for multiple notebooks, consoles or
terminals. Those documents are organized with tabs and a very versatile
split screen feature. On the left side of the screen you can open
several views:</p>
<ul class="simple">
<li><p>file manager</p></li>
<li><p>controller for running kernels and terminals</p></li>
<li><p>overview of commands and settings</p></li>
<li><p>details about selected notebook cell</p></li>
<li><p>list of open tabs</p></li>
</ul>
<p>At the following table it‚Äôs possible to see what is available at each cluster.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Cluster</p></th>
<th class="head"><p>Julia</p></th>
<th class="head"><p>R</p></th>
<th class="head"><p>RStudio</p></th>
<th class="head"><p>MATLAB</p></th>
<th class="head"><p>MATLAB Web</p></th>
<th class="head"><p>WebVNC</p></th>
<th class="head"><p>DCV</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Alpha</p></td>
<td><p>-</p></td>
<td><p>OK</p></td>
<td><p>OK</p></td>
<td><p>OK</p></td>
<td><p>OK*</p></td>
<td><p>OK*</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p>Barnard</p></td>
<td><p>OK</p></td>
<td><p>OK</p></td>
<td><p>OK</p></td>
<td><p>OK</p></td>
<td><p>OK*</p></td>
<td><p>OK*</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p>Capella</p></td>
<td><p>OK</p></td>
<td><p>OK</p></td>
<td><p>OK</p></td>
<td><p>OK</p></td>
<td><p>-</p></td>
<td><p>-</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p>Romeo</p></td>
<td><p>-</p></td>
<td><p>OK</p></td>
<td><p>OK</p></td>
<td><p>OK</p></td>
<td><p>OK*</p></td>
<td><p>OK*</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p>VIS</p></td>
<td><p>OK</p></td>
<td><p>OK</p></td>
<td><p>OK</p></td>
<td><p>OK</p></td>
<td><p>OK*</p></td>
<td><p>OK*</p></td>
<td><p>OK</p></td>
</tr>
</tbody>
</table>
<p>!!! note ‚Äú*Note‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>All small profiles for all clusters do not include MATLAB Web neither WebVNC.
</pre></div>
</div>
</section>
<section id="jupyter-notebooks-in-general">
<h2>Jupyter Notebooks in General<a class="headerlink" href="#jupyter-notebooks-in-general" title="Permalink to this heading">#</a></h2>
<p>In JupyterHub, you can create scripts in notebooks. Notebooks are programs which are split into
multiple logical code blocks. Each block can be executed individually. In between those code
blocks, you can insert text blocks for documentation. Each notebook is paired with a kernel running
the code.</p>
<p>We offer some custom kernel for Julia*, MATLAB and R.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Some kernels may not be available depending of the amounting of resources requested for the
job or due to the availability of modules to an specific cluster.
</pre></div>
</div>
<section id="version-control-of-jupyter-notebooks-with-git">
<h3>Version Control of Jupyter Notebooks with Git<a class="headerlink" href="#version-control-of-jupyter-notebooks-with-git" title="Permalink to this heading">#</a></h3>
<p>Since Jupyter notebooks are files containing multiple blocks for input code,
documentation, output and further information, it is difficult to use them with
Git. Version tracking of the <code class="docutils literal notranslate"><span class="pre">.ipynb</span></code> notebook files can be improved with the
<a class="reference external" href="https://jupytext.readthedocs.io/en/latest/">Jupytext plugin</a>. Jupytext will
provide Markdown (<code class="docutils literal notranslate"><span class="pre">.md</span></code>) and Python (<code class="docutils literal notranslate"><span class="pre">.py</span></code>) conversions of notebooks on the fly,
next to <code class="docutils literal notranslate"><span class="pre">.ipynb</span></code>. Tracking these files will then provide a cleaner Git history.
A further advantage is that Python notebook versions can be imported, allowing
to split larger notebooks into smaller ones, based on chained imports.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The Jupytext plugin is not installed on the ZIH systems at the moment.
Currently, it can be [installed](https://jupytext.readthedocs.io/en/latest/install.html)
by the users with parameter `--user`.
Therefore, `ipynb` files need to be made available in a repository for shared
usage within the ZIH system.
</pre></div>
</div>
</section>
</section>
<section id="stop-a-session">
<h2>Stop a Session<a class="headerlink" href="#stop-a-session" title="Permalink to this heading">#</a></h2>
<p>It is good practice to stop your session once your work is done. This releases
resources for other users and your quota is less charged. If you just log out or
close the window, your server continues running and <strong>will not stop</strong> until the
Slurm job runtime hits the limit (usually 8 hours).</p>
<p>At first, you have to open the JupyterHub control panel.</p>
<p>=== ‚ÄúJupyterLab‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Open the file menu and then click on `Logout`. You can
also click on `Hub Control Panel`, which opens the control panel in a new tab instead.

![JupyterLab logout](misc/jupyterlab_logout.png)
{: align=&quot;center&quot;}
</pre></div>
</div>
</section>
<section id="error-handling">
<h2>Error Handling<a class="headerlink" href="#error-handling" title="Permalink to this heading">#</a></h2>
<p>We want to explain some errors that you might face sooner or later.
If you need help, open a ticket and ask for support as described in
<span class="xref myst">How to Ask for Support</span>.</p>
<section id="error-message-in-jupyterlab">
<h3>Error Message in JupyterLab<a class="headerlink" href="#error-message-in-jupyterlab" title="Permalink to this heading">#</a></h3>
<p><img alt="JupyterLab error directory not found" src="63_chat_with_docs/misc/jupyterlab_error_directory_not_found.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>If the connection to your notebook server unexpectedly breaks, you will get this
error message. Sometimes your notebook server might hit a batch system or
hardware limit and gets killed. Then, the log file of the corresponding
batch job usually contains useful information. These log files are located in your
home directory and have the name <code class="docutils literal notranslate"><span class="pre">jupyterhub-&lt;clustername&gt;.log</span></code>.</p>
</section>
</section>
<section id="advanced-tips">
<h2>Advanced Tips<a class="headerlink" href="#advanced-tips" title="Permalink to this heading">#</a></h2>
<section id="loading-modules">
<h3>Loading Modules<a class="headerlink" href="#loading-modules" title="Permalink to this heading">#</a></h3>
<p>Inside your terminal session you can load modules from the <span class="xref myst">module system</span>.</p>
</section>
<section id="custom-kernels">
<h3>Custom Kernels<a class="headerlink" href="#custom-kernels" title="Permalink to this heading">#</a></h3>
<p>As you might have noticed, after launching Jupyter<strong>Lab</strong>,
there are several boxes with icons therein visible in the <code class="docutils literal notranslate"><span class="pre">Launcher</span></code>.
Each box therein represents a so called ‚ÄòKernel‚Äô.
(note that these are not to be confused with operating system kernel,
but similarly provide basic functionality for running your use cases,
e.g. Python or R)</p>
<p>You can also <span class="xref myst">create your own Kernels</span>.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="custom-environments-for-jupyterhub">
<h1>Custom Environments for JupyterHub<a class="headerlink" href="#custom-environments-for-jupyterhub" title="Permalink to this heading">#</a></h1>
<p>!!! info</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Interactive code interpreters which are used by Jupyter notebooks are called
*kernels*. Creating and using your own kernel has the benefit, that you can
install your own preferred Python packages and use them in your notebooks.
</pre></div>
</div>
<p>We currently have two different architectures at ZIH systems.
Build your kernel environment on the <strong>same architecture</strong> that you want to use
later on with the kernel. In the examples below, we use the name
‚Äúmy-kernel‚Äù for our user kernel. We recommend to prefix your kernels
with keywords like <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, <code class="docutils literal notranslate"><span class="pre">barnard</span></code>, <code class="docutils literal notranslate"><span class="pre">romeo</span></code>, <code class="docutils literal notranslate"><span class="pre">power9</span></code>, <code class="docutils literal notranslate"><span class="pre">venv</span></code>, <code class="docutils literal notranslate"><span class="pre">conda</span></code>.
This way, you can later recognize easier how you built the kernel and on which hardware it
will work. Depending on that hardware, allocate resources as follows.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Cluster</p></th>
<th class="head"><p>Architecture name</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Alpha</p></td>
<td><p>x86_64 (AMD)</p></td>
</tr>
<tr class="row-odd"><td><p>Barnard</p></td>
<td><p>x86_64 (Intel)</p></td>
</tr>
<tr class="row-even"><td><p>Capella</p></td>
<td><p>x86_64 (AMD)</p></td>
</tr>
<tr class="row-odd"><td><p>Romeo</p></td>
<td><p>x86_64 (AMD)</p></td>
</tr>
<tr class="row-even"><td><p>Power9</p></td>
<td><p>ppc64le (IBM)</p></td>
</tr>
</tbody>
</table>
<section id="preliminary-steps">
<h2>Preliminary Steps<a class="headerlink" href="#preliminary-steps" title="Permalink to this heading">#</a></h2>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Start an interactive job

```console
maria@login.&lt;cluster&gt;$ srun --pty --ntasks=1 --cpus-per-task=2 \
 --mem-per-cpu=2541 --time=02:00:00 bash -l
```
</pre></div>
</div>
<p>When creating a virtual environment in your home directory, you got to decide
to either use ‚ÄúPython virtualenv‚Äù or ‚Äúconda environment‚Äù.</p>
<p>!!! note
Please keep in mind that Python virtualenv is the preferred way to create a Python
virtual environment.
For working with conda virtual environments, it may be necessary to configure your shell
as described in <span class="xref myst">Python virtual environments</span></p>
</section>
<section id="python-virtualenv">
<h2>Python Virtualenv<a class="headerlink" href="#python-virtualenv" title="Permalink to this heading">#</a></h2>
<p>While we have a general description on
<span class="xref myst">Python Virtual Environments</span>, here we have a more detailed
description on using them with JupyterHub:</p>
<p>Depending on the Cluster that you are targeting, please choose the right modules:</p>
<p>=== ‚Äúrelease/23.10‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>For use with Python version 3.10.4,
please try to initialize your Python Virtual Environment like this:

```console
[marie@barnard ~]$ module load release/23.10  GCC/11.3.0  Python/3.10.4
Module GCC/11.3.0, Python/3.10.4 and 12 dependencies loaded.
```
</pre></div>
</div>
<p>=== ‚Äúrelease/23.04‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
[marie@barnard ~]$ module load release/23.04  GCC/11.3.0  Python/3.10.4
Module GCC/11.3.0, Python/3.10.4 and 12 dependencies loaded.
```
</pre></div>
</div>
<p>Then continue with the steps below.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
[marie@barnard ~]$ mkdir -p ~/usr/jlab-kernels # please use workspaces!
[marie@barnard ~]$ cd ~/usr/jlab-kernels
[marie@barnard jlab-kernels]$ python3 -m venv --system-site-packages my-kernel
[marie@barnard jlab-kernels]$
[marie@barnard jlab-kernels]$ source my-kernel/bin/activate
(my-kernel) [marie@barnard jlab-kernels]$
(my-kernel) [marie@barnard jlab-kernels]$ pip install ipykernel
Collecting ipykernel
[...]
Successfully installed [...] ipykernel-x.x.x ipython-x.x.x [...]
```
</pre></div>
</div>
<p>After following the initialization of the environment (above),
the usage of Python‚Äôs Package manager <code class="docutils literal notranslate"><span class="pre">pip</span></code> is the same:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp gp-VirtualEnv">(my-kernel)</span> <span class="gp">marie@compute$ </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>pip
<span class="gp gp-VirtualEnv">(my-kernel)</span> <span class="gp">marie@compute$ </span>python<span class="w"> </span>-m<span class="w"> </span>ipykernel<span class="w"> </span>install<span class="w"> </span>--user<span class="w"> </span>--name<span class="w"> </span>my-kernel<span class="w"> </span>--display-name<span class="o">=</span><span class="s2">&quot;my kernel&quot;</span>
<span class="go">Installed kernelspec my-kernel in .../.local/share/jupyter/kernels/my-kernel</span>
<span class="gp gp-VirtualEnv">(my-kernel)</span> <span class="gp">marie@compute$ </span>pip<span class="w"> </span>install<span class="w"> </span><span class="o">[</span>...<span class="o">]</span><span class="w"> </span><span class="c1"># now install additional packages for your notebooks</span>
<span class="gp gp-VirtualEnv">(my-kernel)</span> <span class="gp">marie@compute$ </span>deactivate
</pre></div>
</div>
</section>
<section id="conda-environment">
<h2>Conda Environment<a class="headerlink" href="#conda-environment" title="Permalink to this heading">#</a></h2>
<p>Load the needed module depending on Cluster architecture:</p>
<p>=== ‚ÄúNodes with x86_64 CPU‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">module</span> <span class="pre">load</span> <span class="pre">Anaconda3</span>&#160;&#160;&#160;&#160; </code></p>
<p>=== ‚ÄúNodes with ppc64le CPU‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;ml$</span> <span class="pre">module</span> <span class="pre">load</span> <span class="pre">PythonAnaconda</span>&#160;&#160;&#160;&#160; </code></p>
<p>!!! hint
For working with conda virtual environments, it may be necessary to configure your shell as
described in
<span class="xref myst">Python virtual environments</span>.</p>
<p>Continue with environment creation, package installation and kernel
registration:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>mkdir<span class="w"> </span>user-kernel<span class="w"> </span><span class="c1"># please use workspaces!</span>
<span class="gp">marie@compute$ </span>conda<span class="w"> </span>create<span class="w"> </span>--prefix<span class="w"> </span><span class="nv">$HOME</span>/user-kernel/my-kernel<span class="w"> </span><span class="nv">python</span><span class="o">=</span><span class="m">3</span>.8.6
<span class="go">Collecting package metadata: done</span>
<span class="go">Solving environment: done</span>
<span class="go">[...]</span>
<span class="gp">marie@compute$ </span>conda<span class="w"> </span>activate<span class="w"> </span><span class="nv">$HOME</span>/user-kernel/my-kernel
<span class="gp">marie@compute$ </span>conda<span class="w"> </span>install<span class="w"> </span>ipykernel
<span class="go">Collecting package metadata: done</span>
<span class="go">Solving environment: done</span>
<span class="go">[...]</span>
<span class="gp">marie@compute$ </span>python<span class="w"> </span>-m<span class="w"> </span>ipykernel<span class="w"> </span>install<span class="w"> </span>--user<span class="w"> </span>--name<span class="w"> </span>my-kernel<span class="w"> </span>--display-name<span class="o">=</span><span class="s2">&quot;my kernel&quot;</span>
<span class="go">Installed kernelspec my-kernel in [...]</span>
<span class="gp">marie@compute$ </span>conda<span class="w"> </span>install<span class="w"> </span><span class="o">[</span>..<span class="o">]</span><span class="w"> </span><span class="c1"># now install additional packages for your notebooks</span>
<span class="gp">marie@compute$ </span>conda<span class="w"> </span>deactivate
</pre></div>
</div>
</section>
<section id="using-your-custom-environment">
<h2>Using your custom environment<a class="headerlink" href="#using-your-custom-environment" title="Permalink to this heading">#</a></h2>
<p>Now you can start a new session and your kernel should be available.</p>
<p>=== ‚ÄúJupyterLab‚Äù
Your kernels are listed on the launcher page:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>![JupyterLab user kernel launcher](misc/jupyterlab_user_kernel_launcher.png)
{: align=&quot;center&quot;}

You can switch kernels of existing notebooks in the menu:

![JupyterLab change kernel](misc/jupyterlab_change_kernel.png)
{: align=&quot;center&quot;}
</pre></div>
</div>
<p>=== ‚ÄúClassic Jupyter notebook‚Äù
Your kernel is listed in the New menu:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>![Jupyter notebook user kernel launcher](misc/jupyter_notebook_user_kernel_launcher.png)
{: align=&quot;center&quot;}

You can switch kernels of existing notebooks in the kernel menu:

![Jupyter notebook change kernel](misc/jupyter_notebook_change_kernel.png)
{: align=&quot;center&quot;}
</pre></div>
</div>
<p>!!! note
Both python venv and conda virtual environments will be mentioned in the same
list.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="jupyterhub-for-teaching">
<h1>JupyterHub for Teaching<a class="headerlink" href="#jupyterhub-for-teaching" title="Permalink to this heading">#</a></h1>
<p>On this page, we want to introduce to you some useful features if you want to
use JupyterHub for teaching.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>JupyterHub uses compute resources from ZIH systems.
</pre></div>
</div>
<p>Please be aware of the following notes:</p>
<ul class="simple">
<li><p>ZIH systems operate at a lower availability level than your usual Enterprise
Cloud VM. There can always be downtimes, e.g. of the filesystems or the batch
system.</p></li>
<li><p>Scheduled downtimes are announced by e-mail. Please plan your courses
accordingly.</p></li>
<li><p>Access to HPC resources is handled through projects. See your course as a
project. Projects need to be registered beforehand (more info on the page
<span class="xref myst">Access</span>).</p></li>
<li><p>Don‚Äôt forget to <span class="xref myst">add your users</span>
(e.g. students or tutors) to your project.</p></li>
<li><p>It might be a good idea to <span class="xref myst">request a reservation</span>
of part of the compute resources for your project/course to avoid unnecessary
waiting times in the batch system queue.</p></li>
</ul>
<section id="clone-a-repository-with-a-link">
<h2>Clone a Repository With a Link<a class="headerlink" href="#clone-a-repository-with-a-link" title="Permalink to this heading">#</a></h2>
<p>This feature bases on <a class="reference external" href="https://github.com/jupyterhub/nbgitpuller">nbgitpuller</a>.
Further information can be found in the <a class="reference external" href="https://jupyterhub.github.io/nbgitpuller/">external documentation about nbgitpuller</a>.</p>
<p>This extension for Jupyter notebooks can clone every public Git repository into
the users work directory. It‚Äôs offering a quick way to distribute notebooks and
other material to your students.</p>
<p><img alt="Git pull progress screen" src="63_chat_with_docs/misc/gitpull_progress.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>To create a shareable link, we recommend to use <a class="reference external" href="https://en.wikipedia.org/wiki/Percent-encoding">URL encoding</a>
instead of plain text for the link in order to avoid defective links. The
<a class="reference external" href="https://jupyterhub.github.io/nbgitpuller/link?hub=https://jupyterhub.hpc.tu-dresden.de/">nbgitpuller link generator</a>
supports you in generating valid links for sharing.</p>
<p>??? example
A shareable link for this feature looks like this:
<code class="docutils literal notranslate">&#160;&#160;&#160; <span class="pre">https://jupyterhub.hpc.tu-dresden.de/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fjdwittenauer%2Fipython-notebooks&amp;urlpath=tree%2Fipython-notebooks%2Fnotebooks%2Flanguage%2FIntro.ipynb</span>&#160;&#160;&#160; </code></p>
<p>!!! warning
For illustration purposes, we use plain text links in the following parts. In practice, we
highly recommend to use URL encoded links instead.</p>
<p><img alt="URL with git-pull parameters" src="63_chat_with_docs/misc/url-git-pull.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>This example would clone the repository
<a class="github reference external" href="https://github.com/jdwittenauer/ipython-notebooks">jdwittenauer/ipython-notebooks</a>
and afterwards open the <strong>Intro.ipynb</strong> notebook in the given path.</p>
<p>The following parameters are available:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Info</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">repo</span></code></p></td>
<td><p>path to Git repository</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">branch</span></code></p></td>
<td><p>branch in the repository to pull from default: <code class="docutils literal notranslate"><span class="pre">master</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">urlpath</span></code></p></td>
<td><p>URL to redirect the user to a certain file, <a class="reference external" href="https://jupyterhub.github.io/nbgitpuller/topic/url-options.html#urlpath">more info about parameter urlpath</a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">depth</span></code></p></td>
<td><p>clone only a certain amount of latest commits not recommended</p></td>
</tr>
</tbody>
</table>
</section>
<section id="spawn-options-pass-through-with-url-parameters">
<h2>Spawn Options Pass-through with URL Parameters<a class="headerlink" href="#spawn-options-pass-through-with-url-parameters" title="Permalink to this heading">#</a></h2>
<p>The spawn form now offers a quick start mode by passing URL parameters.</p>
<p>!!! example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The following link would create a jupyter notebook session on the
cluster `barnard` with 1 CPU and 1,5 GB RAM:

```
https://jupyterhub.hpc.tu-dresden.de/hub/spawn#/~(cluster~&#39;barnard~nodes~&#39;1~ntasks~&#39;1~cpuspertask~&#39;1~mempercpu~&#39;1536)
```
</pre></div>
</div>
<p><img alt="URL with quickstart parameters" src="63_chat_with_docs/misc/url-quick-start.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>Every parameter of the advanced form can be set with this parameter. If the
parameter is not mentioned, the default value will be loaded.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Parameter</p></th>
<th class="head text-left"><p>Default Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">cluster</span></code></p></td>
<td class="text-left"><p>barnard</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">nodes</span></code></p></td>
<td class="text-left"><p>1</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">ntasks</span></code></p></td>
<td class="text-left"><p>1</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">cpuspertask</span></code></p></td>
<td class="text-left"><p>1</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">gres</span></code></p></td>
<td class="text-left"><p><em>empty</em> (no generic resources)</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">mempercpu</span></code></p></td>
<td class="text-left"><p>1000</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">runtime</span></code></p></td>
<td class="text-left"><p>1:00:00</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">reservation</span></code></p></td>
<td class="text-left"><p><em>empty</em> (use no reservation)</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">project</span></code></p></td>
<td class="text-left"><p><em>empty</em> (use default project)</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">workspace_scope</span></code></p></td>
<td class="text-left"><p><em>empty</em> (home directory)</p></td>
</tr>
</tbody>
</table>
<p>You can use the advanced form to generate a URL for the settings you want. The
address bar contains the encoded parameters starting with <code class="docutils literal notranslate"><span class="pre">#/</span></code>.</p>
<section id="combination-of-quickstart-and-git-pull-feature">
<h3>Combination of Quickstart and Git-Pull Feature<a class="headerlink" href="#combination-of-quickstart-and-git-pull-feature" title="Permalink to this heading">#</a></h3>
<p>You can combine both features in a single link:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>https://jupyterhub.hpc.tu-dresden.de/hub/user-redirect/git-pull?repo=https://github.com/jdwittenauer/ipython-notebooks&amp;urlpath=/tree/ipython-notebooks/notebooks/language/Intro.ipynb#/~(cluster~&#39;barnard~nodes~&#39;1~ntasks~&#39;1~cpuspertask~&#39;1~mempercpu~&#39;1536)
</pre></div>
</div>
<p><img alt="URL with quickstart parameters" src="63_chat_with_docs/misc/url-git-pull-and-quick-start.png" />
{: align=‚Äùcenter‚Äù}</p>
</section>
</section>
<section id="open-a-notebook-automatically-with-a-single-link">
<h2>Open a Notebook Automatically with a Single Link<a class="headerlink" href="#open-a-notebook-automatically-with-a-single-link" title="Permalink to this heading">#</a></h2>
<p>With the following link you will be redirected to a certain file in your
home directory.</p>
<p><a class="reference external" href="https://jupyterhub.hpc.tu-dresden.de/user-redirect/notebooks/demo.ipynb">https://jupyterhub.hpc.tu-dresden.de/user-redirect/notebooks/demo.ipynb</a></p>
<p>The file needs to exist, otherwise a 404 error will be thrown.</p>
<p><img alt="URL with git-pull and quickstart parameters" src="63_chat_with_docs/misc/url-user-redirect.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>This link would redirect to
<code class="docutils literal notranslate"><span class="pre">https://jupyterhub.hpc.tu-dresden.de/user/{login}/notebooks/demo.ipynb</span></code>.</p>
</section>
<section id="create-a-shared-python-environment">
<h2>Create a Shared Python Environment<a class="headerlink" href="#create-a-shared-python-environment" title="Permalink to this heading">#</a></h2>
<p>To provide a consistent Python environment, you can create a shared <span class="xref myst">workspace</span>
and prepare a <span class="xref myst">Python virtual environment</span>
in it. Then use a custom Jupyter Kernel to use this environment in JupyterHub.
Please note the following:</p>
<ul class="simple">
<li><p>Set the correct permissions to the workspace and all relevant subdirectories
and files via <code class="docutils literal notranslate"><span class="pre">chmod</span></code>.</p></li>
<li><p>Install all relevant Python packages in the shared Python virtual environment
(either pip or conda). Note that standard environments (as <em>production</em> or
<em>test</em>) are not available in that case.</p></li>
<li><p>Modules can also be loaded in the Jupyter spawner via preload modules
(considering the Python version of your virtual environment).</p></li>
</ul>
<p>Set up your shared Python virtual environment for JupyterHub.
!!! hint
For working with conda virtual environments, it may be necessary to configure your shell as
described in <span class="xref myst">Python virtual environments</span>.</p>
<p>=== ‚Äúvirtualenv‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@compute$ module load Python #Load default Python
[...]
marie@compute$ ws_allocate -F scratch python_virtual_environment_teaching 1
Info: creating workspace.
/scratch/ws/1/python_virtual_environment_teaching
[...]
marie@compute$ virtualenv --system-site-packages /scratch/ws/1/python_virtual_environment_teaching/env #Create virtual environment
[...]
marie@compute$ source /scratch/ws/1/python_virtual_environment_teaching/env/bin/activate    #Activate virtual environment. Example output: (envtest) bash-4.2$
marie@compute$ pip install ipykernel
Collecting ipykernel
[...]
Successfully installed ... ipykernel-5.1.0 ipython-7.5.0 ...
marie@compute$ pip install --upgrade pip
marie@compute$ python -m ipykernel install --user --name my-teaching-kernel --display-name=&quot;my teaching kernel&quot;
Installed kernelspec my-teaching-kernel in .../.local/share/jupyter/kernels/my-teaching-kernel
marie@compute$ pip install [...] #Now install additional packages for your notebooks
marie@compute$ deactivate
marie@compute$ chmod g+rx /scratch/ws/1/python_virtual_environment_teaching -R #Make the environment accesible for others

```
</pre></div>
</div>
<p>=== ‚Äúconda‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@compute$ module load Anaconda3 #Load Anaconda
[...]
marie@compute$ ws_allocate -F scratch conda_virtual_environment_teaching 1
Info: creating workspace.
/scratch/ws/1/conda_virtual_environment_teaching
[...]
marie@compute$ conda create --prefix /scratch/ws/1/conda_virtual_environment_teaching/conda-env python=3.8 #create virtual environment with Python version 3.8
[...]
marie@compute$ conda activate /scratch/ws/1/conda_virtual_environment_teaching/conda-env #activate conda-env virtual environment
marie@compute$ conda install ipykernel
[...]
marie@compute$ python -m ipykernel install --user --name my-teaching-kernel --display-name=&quot;my teaching kernel&quot;
Installed kernelspec my-teaching-kernel in .../.local/share/jupyter/kernels/my-teaching-kernel
marie@compute$ conda install [...] # now install additional packages for your notebooks
marie@compute$ conda deactivate
marie@compute$ chmod g+rx /scratch/ws/1/conda_virtual_environment_teaching -R #Make the environment accesible for others

```
</pre></div>
</div>
<p>Now, users have to install the kernel in order to use the shared Python virtual
environment in JupyterHub:
=== ‚Äúvirtualenv‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@compute$ module load Python #Load default Python
[...]
marie@compute$ source /scratch/ws/1/python_virtual_environment_teaching/env/bin/activate #Activate virtual environment. Example output: (envtest) bash-4.2$
marie@compute$ python -m ipykernel install --user --name my-teaching-kernel --display-name=&quot;my teaching kernel&quot;
Installed kernelspec my-teaching-kernel in .../.local/share/jupyter/kernels/my-teaching-kernel
marie@compute$ deactivate

```
</pre></div>
</div>
<p>=== ‚Äúconda‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@compute$ module load Anaconda3 #Load Anaconda
[...]
marie@compute$ conda activate /scratch/ws/1/conda_virtual_environment_teaching
marie@compute$ python -m ipykernel install --user --name my-teaching-kernel --display-name=&quot;my teaching kernel&quot;
Installed kernelspec my-teaching-kernel in .../.local/share/jupyter/kernels/my-teaching-kernel
marie@compute$ conda deactivate

```
</pre></div>
</div>
<p>After spawning the Notebook, you can select the kernel with the created Python
virtual environment.</p>
<p>!!! hint
You can also execute the commands for installing the kernel from the Jupyter
as described in <span class="xref myst">JupyterHub Teaching Example</span>. Then users do not
have to use the command line interface after the preparation.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="jupyterhub-teaching-example">
<h1>JupyterHub Teaching Example<a class="headerlink" href="#jupyterhub-teaching-example" title="Permalink to this heading">#</a></h1>
<p>Setting up a Jupyter Lab Course involves additional steps, beyond JupyterHub, such as creating
course specific environments and allowing participants to link and activate these environments during
the course. This page includes a work through of these additional steps, with best practice examples
for each part.</p>
<section id="context">
<h2>Context<a class="headerlink" href="#context" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>The common situation described here is that one or several Jupyter Lab Notebooks
(<code class="docutils literal notranslate"><span class="pre">ipynb</span></code> files) are available and prepared. Students are supposed to open these notebooks
through the <span class="xref myst">ZIH JupyterHub</span> and work through them during a course.</p></li>
<li><p>These notebooks are typically prepared for specific dependencies (Python packages)
that need to be activated by participants in the course, when opening the notebooks.</p></li>
<li><p>These environments can either be chosen based on the pre-configured
ZIH virtualenv/conda environments,
or built in advance. We will focus on the custom environment approach here.</p></li>
</ul>
</section>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>A public Git repository with the notebook files (<code class="docutils literal notranslate"><span class="pre">ipynb</span></code>) and all other starting files required
by participants. One option to host the repository is the <a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/">GitLab of TU Chemnitz</a>.</p></li>
<li><p>A <span class="xref myst">HPC project</span> for teaching,
with students as registered participants</p></li>
<li><p>For the tutor, a shell access to the HPC resources and project folder.</p></li>
</ul>
</section>
<section id="preparation-on-the-lecturer-s-side">
<h2>Preparation on the Lecturer‚Äôs Side<a class="headerlink" href="#preparation-on-the-lecturer-s-side" title="Permalink to this heading">#</a></h2>
<p>The following part describes several steps for the preparation of a course with the JupyterHub at
ZIH.</p>
<section id="creating-a-custom-python-environment">
<h3>1. Creating a custom Python environment<a class="headerlink" href="#creating-a-custom-python-environment" title="Permalink to this heading">#</a></h3>
<p>Prepare a Python virtual environment (<code class="docutils literal notranslate"><span class="pre">virtualenv</span></code>) or conda virtual environment as described in
<span class="xref myst">Python virtual environments</span>. Note, for preparing a
custom environment for a Jupyter Lab course, all participants will need to have read-access to this
environment. This is best done by storing the environment in either a <span class="xref myst">workspace</span>
with a limited lifetime or in a projects folder (e.g. <code class="docutils literal notranslate"><span class="pre">/projects/p_lv_jupyter_course/</span></code>) without a
limited lifetime.</p>
</section>
<section id="clone-the-repository-and-store-environment-setup">
<h3>2. Clone the repository and store environment setup<a class="headerlink" href="#clone-the-repository-and-store-environment-setup" title="Permalink to this heading">#</a></h3>
<p>First prepare the <code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code> or the <code class="docutils literal notranslate"><span class="pre">environment.yml</span></code> to persist the environment as
described in <span class="xref myst">Python virtual environments</span>.</p>
<p>Then clone the repository of your course to your home directory or into a directory in the projects
folder and add the file to the repository.</p>
<p>=== ‚Äúvirtualenv‚Äù
```console
marie&#64;compute<span class="math notranslate nohighlight">\( git clone git&#64;gitlab.hrz.tu-chemnitz.de:zih/jupyterlab_course.git /projects/p_lv_jupyter_course/clone_marie/
    [...]
    marie&#64;compute\)</span> cp requirements.txt /projects/p_lv_jupyter_course/clone_marie/jupyterlab_course
marie&#64;compute<span class="math notranslate nohighlight">\( cd /projects/p_lv_jupyter_course/clone_marie/jupyterlab_course
    marie&#64;compute\)</span> git add requirements.txt
marie&#64;compute<span class="math notranslate nohighlight">\( git commit
    marie&#64;compute\)</span> git push</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```
</pre></div>
</div>
<p>=== ‚Äúconda‚Äù
```console
marie&#64;compute<span class="math notranslate nohighlight">\( git clone git&#64;gitlab.hrz.tu-chemnitz.de:zih/jupyterlab_course.git /projects/p_lv_jupyter_course/clone_marie/
    [...]
    marie&#64;compute\)</span> cp requirements.txt /projects/p_lv_jupyter_course/clone_marie/jupyterlab_course
marie&#64;compute<span class="math notranslate nohighlight">\( cd /projects/p_lv_jupyter_course/clone_marie/jupyterlab_course
    marie&#64;compute\)</span> git add environment.yml
marie&#64;compute<span class="math notranslate nohighlight">\( git commit
    marie&#64;compute\)</span> git push</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```
</pre></div>
</div>
<p>Now, you can re-create the environment and the whole course from the Git repository in the future.</p>
<p>To test the activation of the environment use:</p>
<p>=== ‚Äúvirtualenv‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@compute$ source /scratch/ws/1/python_virtual_environment_teaching/env/bin/activate #Activate virtual environment. Example output: (envtest) bash-4.2$

```
</pre></div>
</div>
<p>=== ‚Äúconda‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@compute$ conda activate /scratch/ws/1/conda_virtual_environment_teaching

```
</pre></div>
</div>
</section>
<section id="prepare-an-activation-file">
<h3>3. Prepare an activation file<a class="headerlink" href="#prepare-an-activation-file" title="Permalink to this heading">#</a></h3>
<p>Create a file to install the <code class="docutils literal notranslate"><span class="pre">ipykernel</span></code> to the user-folder, linking the central <code class="docutils literal notranslate"><span class="pre">workshop_env</span></code> to
the ZIH JupyterLab. An <code class="docutils literal notranslate"><span class="pre">activate_workshop_env.sh</span></code> should have the following content:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">/projects/jupyterlab_course/workshop_env/bin/python -m ipykernel install --user --name workshop_env --display-name=&quot;workshop_env&quot;</span>
</pre></div>
</div>
<p>!!! note
The file for installing the kernel should also be added to the Git repository.</p>
</section>
<section id="prepare-the-spawn-link">
<h3>4. Prepare the spawn link<a class="headerlink" href="#prepare-the-spawn-link" title="Permalink to this heading">#</a></h3>
<p>Have a look at the instructions to prepare
<span class="xref myst">a custom spawn link in combination with the git-pull feature</span>.</p>
</section>
</section>
<section id="usage-on-the-student-s-side">
<h2>Usage on the Student‚Äôs Side<a class="headerlink" href="#usage-on-the-student-s-side" title="Permalink to this heading">#</a></h2>
<section id="preparing-activation-of-the-custom-environment-in-notebooks">
<h3>Preparing activation of the custom environment in notebooks<a class="headerlink" href="#preparing-activation-of-the-custom-environment-in-notebooks" title="Permalink to this heading">#</a></h3>
<p>When students open the notebooks (e.g. through a Spawn Link that pulls the Git files
and notebooks from our repository), the Python environment must be activated first by installing a
Jupyter kernel. This can be done inside the first notebook using a shell command (<code class="docutils literal notranslate"><span class="pre">.sh</span></code>).</p>
<p>Therefore the students will need to run the <code class="docutils literal notranslate"><span class="pre">activation_workshop_env.sh</span></code> file, which can be done
in the first cell of the first notebook (e.g. inside <code class="docutils literal notranslate"><span class="pre">01_intro.ipynb</span></code>).</p>
<p>In a code cell in <code class="docutils literal notranslate"><span class="pre">01_intro.ipynb</span></code>, add:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">!cd .. &amp;&amp; sh activate_workshop_env.sh</span>
</pre></div>
</div>
<p>When students run this file, the following output signals a successful setup.</p>
<p><img alt="Installed kernelspec" src="63_chat_with_docs/misc/kernelspec.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>Afterwards, the <code class="docutils literal notranslate"><span class="pre">workshop_env</span></code> Jupyter kernel can be selected in the top-right corner of Jupyter
Lab.</p>
<p>!!! note
A few seconds may be needed until the environment becomes available in the list.</p>
</section>
</section>
<section id="test-spawn-link-and-environment-activation">
<h2>Test spawn link and environment activation<a class="headerlink" href="#test-spawn-link-and-environment-activation" title="Permalink to this heading">#</a></h2>
<p>During testing, it may be necessary to reset the workspace to the initial state. There are two steps
involved:</p>
<p>First, remove the cloned Git repository in user home folder.</p>
<p>!!! warning
Check carefully the syntax below, to avoid removing the wrong files.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cd ~</span>
<span class="go">rm -rf ./jupyterlab_course.git</span>
</pre></div>
</div>
<p>Second, the IPython Kernel must be un-linked from the user workshop_env.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">jupyter kernelspec uninstall workshop_env</span>
</pre></div>
</div>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">#</a></h2>
<p>The following video shows an example of the process of opening the
spawn link and activating the environment, from the students perspective.
Note that this video shows the case for a conda virtual environment.</p>
<p><video src="63_chat_with_docs/misc/startup_hub.webm" title="type:video"><a href="63_chat_with_docs/misc/startup_hub.webm">type:video</a></video></p>
<p>!!! note
- The spawn link may not work the first time a user logs in.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- Students must be advised to _not_ click &quot;Start My Server&quot; or edit the form,
if the server does not start automatically.

- If the server does not start automatically, click (or copy &amp; paste) the spawn link again.
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1>JupyterLab<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h1>
<section id="access-without-jupyterhub">
<h2>Access without JupyterHub<a class="headerlink" href="#access-without-jupyterhub" title="Permalink to this heading">#</a></h2>
<section id="access-with-port-forwarding">
<h3>Access with port forwarding<a class="headerlink" href="#access-with-port-forwarding" title="Permalink to this heading">#</a></h3>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">[marie@login ~]$ </span>start_jupyterlab.sh
</pre></div>
</div>
<p><img alt="profile select" src="63_chat_with_docs/misc/jupyterlab_wout_hub.png" />
{: align=‚Äùcenter‚Äù}</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Starting JupyterLab...</span>
<span class="go">Submitted batch job 1984</span>
<span class="gp">[marie@login ~]$</span>
</pre></div>
</div>
<p>Do not disconnect/logout.
Wait until you receive a message with further instructions on how to connect to yours lab session.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Message from marie@login on &lt;no tty&gt; at 14:22 ...</span>

<span class="go"> At your local machine, run:</span>
<span class="go"> ssh marie@login.&lt;cluster&gt;.hpc.tu-dresden.de -NL 8946:&lt;node&gt;:8138</span>

<span class="go"> and point your browser to http://localhost:8946/?token=M7SHy...5HnsY...GMaRj0e2X</span>
<span class="go"> To stop this notebook, run &#39;scancel 1984&#39;</span>
<span class="go">EOF</span>
</pre></div>
</div>
</section>
<section id="access-with-x11-forwarding">
<h3>Access with X11 forwarding<a class="headerlink" href="#access-with-x11-forwarding" title="Permalink to this heading">#</a></h3>
<p>=== ‚ÄúAlpha Centauri‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@local$ ssh -XC marie@login1.alpha.hpc.tu-dresden.de
marie@login$ ml release/23.04 GCCcore/12.2.0
marie@login$ ml Python/3.10.8
marie@login$ source /software/util/JupyterLab/alpha/jupyterlab-4.0.4/bin/activate
marie@login$ srun --nodes=1 --ntasks=1 --cpus-per-task=4 --mem-per-cpu=8192 --x11 --pty --gres=gpu:1 bash -l
marie@compute$ jupyter lab -y
```
</pre></div>
</div>
<p>=== ‚ÄúBarnard‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@local$ ssh -XC marie@login1.barnard.hpc.tu-dresden.de
marie@login$ ml release/23.10 GCCcore/12.2.0
marie@login$ ml Python/3.10.8
marie@login$ source /software/util/JupyterLab/barnard/jupyterlab-4.0.4/bin/activate
marie@login$ srun --nodes=1 --ntasks=1 --cpus-per-task=4 --mem-per-cpu=8192 --x11 --pty bash -l
marie@compute$ jupyter lab -y
```
</pre></div>
</div>
<p>=== ‚ÄúCapella‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@local$ ssh -XC marie@login1.capella.hpc.tu-dresden.de
marie@login$ module load release/24.04 GCCcore/12.2.0
marie@login$ module load Python/3.10.8
marie@login$ source /software/util/JupyterLab/barnard/jupyterlab-4.0.4/bin/activate
marie@login$ srun --nodes=1 --ntasks=1 --cpus-per-task=4 --mem-per-cpu=8192 --x11 --pty --gres=gpu:1 bash -l
marie@compute$ jupyter lab -y
```
</pre></div>
</div>
<p>=== ‚ÄúRomeo‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@local$ ssh -XC marie@login1.romeo.hpc.tu-dresden.de
marie@login$ ml release/23.04 GCCcore/12.2.0
marie@login$ ml Python/3.10.8
marie@login$ source /software/util/JupyterLab/romeo/jupyterlab-4.0.4/bin/activate
marie@login$ srun --nodes=1 --ntasks=1 --cpus-per-task=4 --mem-per-cpu=8192 --x11 --pty bash -l
marie@compute$ jupyter lab -y
```
</pre></div>
</div>
<p>=== ‚ÄúVisualization‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@local$ ssh -XC marie@login4.barnard.hpc.tu-dresden.de
marie@login$ ml release/23.10 GCCcore/12.2.0
marie@login$ ml Python/3.10.8
marie@login$ source /software/util/JupyterLab/vis/jupyterlab-4.0.4/bin/activate
marie@login$ export SLURM_CONF=/software/util/dcv/etc/slurm/slurm.conf
marie@login$ srun --nodes=1 --ntasks=1 --cpus-per-task=4 --mem-per-cpu=8192 --x11 --pty bash -l
marie@compute$ jupyter lab -y --browser=chromium-browser
```

If you then want to start a DCV session, click on the DCV tile in the lower section &#39;DC Apps&#39;
and wait for the new browser tab to appear. Copy the URL and paste it into your local browser
instead of working with the slow X11-forwarded browser. After you have successfully logged in
with your ZIH credentials, it should work fine.
</pre></div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="custom-jupyterlab">
<h1>Custom JupyterLab<a class="headerlink" href="#custom-jupyterlab" title="Permalink to this heading">#</a></h1>
<p>Is it now possible to install your custom JupyterLab.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>It&#39;s supported at barnard only now..
</pre></div>
</div>
<section id="id2">
<h2>Disclaimer<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Please note that our technicias will not mantain your own JupyterLab installation.
</pre></div>
</div>
<p>Please understand that JupyterLab is a complex software system of which we are
not the developers and don‚Äôt have any downstream support contracts for, so we
merely offer an installation of it and will not provide additional support.</p>
<p>Start a new JupyterLab session at: <a class="reference external" href="https://jupyterhub.hpc.tu-dresden.de">jupyterhub</a> as
described at: <a class="reference external" href="https://doc.zih.tu-dresden.de/access/jupyterhub/#start-a-session">start session</a></p>
</section>
<section id="prepare-the-installation">
<h2>Prepare the Installation<a class="headerlink" href="#prepare-the-installation" title="Permalink to this heading">#</a></h2>
<p>Create a new notebook using the <code class="docutils literal notranslate"><span class="pre">Python3</span> <span class="pre">(ipykernel)</span></code> kernel.</p>
<p>Include at the cells the following commands:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">install_script = ! which install_home_jlab.sh</span>
<span class="go">result = ! {install_script[0]}</span>
<span class="gp">%</span>run<span class="w"> </span><span class="o">{</span>result<span class="o">[</span><span class="m">0</span><span class="o">]}</span>
</pre></div>
</div>
<p>After execute the kernel you will see the following:</p>
<p><img alt="cell_commands2" src="63_chat_with_docs/misc/jupyterlab_user_2.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>Follow the instructions displayed for continue to the installation, the click the install
button.</p>
<p>At end you will see the resume of yours installation:</p>
<p><img alt="cell_commands2" src="63_chat_with_docs/misc/jupyterlab_user_3.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>This is all, next time you spawn a session at JupyterHub you will use your own JupyterLab.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>For using the system installation please remove/rename the folder ~/usr/opt/jupyterlab.
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="key-fingerprints">
<h1>Key Fingerprints<a class="headerlink" href="#key-fingerprints" title="Permalink to this heading">#</a></h1>
<p>!!! hint</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The key fingerprints of login and export nodes can occasionally change. This page holds
up-to-date fingerprints.
</pre></div>
</div>
<p>Each cluster can be accessed via so-called <strong>login nodes</strong> using specific hostnames. All login nodes
of a cluster share common SSH key fingerprints that are unique. When connecting to one of our HPC
systems via the corresponding login nodes, please make sure that the provided fingerprint matches
one of the table. This is the only way to ensure you are connecting to the correct server from the
very beginning. If the <strong>fingerprint differs</strong>, please contact the
<span class="xref myst">HPC support team</span>.</p>
<p>In case an additional login node of the same cluster is used, the key needs to be checked and
approved again.</p>
<p>??? example ‚ÄúConnecting with SSH to Barnard‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@local$ ssh login1.barnard.hpc.tu-dresden.de
The authenticity of host &#39;login1.barnard.hpc.tu-dresden.de (172.24.95.28)&#39; can&#39;t be established.
ECDSA key fingerprint is SHA256:8Coljw7yoVH6HA8u+K3makRK9HfOSfe+BG8W/CUEPp0.
Are you sure you want to continue connecting (yes/no)?
```

In this case, the fingerprint matches the one given in the table. Thus, you can proceed by
typing &#39;yes&#39;.
</pre></div>
</div>
<p>??? info ‚ÄúVerify key fingerprints without login‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>To verify the fingerprint without login, use `ssh-keyscan` and `ssh-keygen`:

```console
marie@local$ ssh-keyscan login1.barnard.hpc.tu-dresden.de 2&gt;/dev/null | ssh-keygen -l -f -
3072 SHA256:lVQOvnci07jkxmFnX58pQf3cD7lz1mf4K4b9jZrAlVU login1.barnard.hpc.tu-dresden.de (RSA)
256 SHA256:Xan2MYazewT0V5agNazaQfWzLKBD3P48zRwR6reoXhI login1.barnard.hpc.tu-dresden.de (ECDSA)
256 SHA256:Gn4n5IX9eEvkpOGrtZzs9T9yAfJUB200bgRchchiKAQ login1.barnard.hpc.tu-dresden.de (ED25519)
```
</pre></div>
</div>
<section id="barnard">
<h2>Barnard<a class="headerlink" href="#barnard" title="Permalink to this heading">#</a></h2>
<p>The cluster <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Barnard</span></code></span> can be accessed via the
four login nodes <code class="docutils literal notranslate"><span class="pre">login[1-4].barnard.hpc.tu-dresden.de</span></code>. (Please choose one concrete login node when
connecting, see example below.)</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Key Type</p></th>
<th class="head text-left"><p>Fingerprint</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>RSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:lVQOvnci07jkxmFnX58pQf3cD7lz1mf4K4b9jZrAlVU</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>RSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:5b:39:ae:03:3a:60:15:21:4b:e8:ba:72:52:b8:a1:ad</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>ECDSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:Xan2MYazewT0V5agNazaQfWzLKBD3P48zRwR6reoXhI</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>ECDSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:02:fd:ab:c8:39:f9:94:cc:3f:e0:7e:78:5f:76:b8:4c</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>ED25519</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:Gn4n5IX9eEvkpOGrtZzs9T9yAfJUB200bgRchchiKAQ</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>ED25519</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:e8:10:96:67:e8:4c:fd:87:f0:c6:4e:e8:1f:53:a9:be</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>{: summary=‚ÄùList of valid fingerprints for Barnard login[1-4] nodes‚Äù}</p></td>
<td class="text-left"><p></p></td>
</tr>
</tbody>
</table>
</section>
<section id="romeo">
<h2>Romeo<a class="headerlink" href="#romeo" title="Permalink to this heading">#</a></h2>
<p>The cluster <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Romeo</span></code></span> can be accessed via the two
login nodes <code class="docutils literal notranslate"><span class="pre">login[1-2].romeo.hpc.tu-dresden.de</span></code>. (Please choose one concrete login node when
connecting, see example below.)</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Key Type</p></th>
<th class="head text-left"><p>Fingerprint</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>RSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:BvYEYJtIYDGr3U0up58q5F7aog7JA2RP+w53XKmwO8I</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>RSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:5d:dc:40:3b:8b:89:77:5d:0f:29:84:31:0f:73:25:9f</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>ECDSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:lgxNRgGcKe7oDGuwf0WV9VPukA30kEqg0sNDLLQwu8Y</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>ECDSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:e1:bd:e4:77:06:97:f9:f3:03:18:56:66:14:5d:8d:18</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>ED25519</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:QNjH0ulelqykywMkt3UNTG4W1HzRkHqrhu0f6oq302I</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>ED25519</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:e4:4e:7a:76:aa:87:da:17:92:b1:17:c6:a1:25:29:7e</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>{: summary=‚ÄùList of valid fingerprints for Romeo login[1-2] node‚Äù}</p></td>
<td class="text-left"><p></p></td>
</tr>
</tbody>
</table>
</section>
<section id="capella">
<h2>Capella<a class="headerlink" href="#capella" title="Permalink to this heading">#</a></h2>
<p>The cluster <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Capella</span></code></span> can be accessed via the two
login nodes <code class="docutils literal notranslate"><span class="pre">login[1-2].capella.hpc.tu-dresden.de</span></code>. (Please choose one concrete login node when
connecting, see example below.)</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Key Type</p></th>
<th class="head text-left"><p>Fingerprint</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>RSA</p></td>
<td class="text-left"><p>``</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>RSA</p></td>
<td class="text-left"><p>``</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>ECDSA</p></td>
<td class="text-left"><p>``</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>ECDSA</p></td>
<td class="text-left"><p>``</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>ED25519</p></td>
<td class="text-left"><p>``</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>ED25519</p></td>
<td class="text-left"><p>``</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>{: summary=‚ÄùList of valid fingerprints for Capella login[1-2] node‚Äù}</p></td>
<td class="text-left"><p></p></td>
</tr>
</tbody>
</table>
</section>
<section id="alpha-centauri">
<h2>Alpha Centauri<a class="headerlink" href="#alpha-centauri" title="Permalink to this heading">#</a></h2>
<p>The cluster <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Alpha</span> <span class="pre">Centauri</span></code></span> can be
accessed via the two login nodes <code class="docutils literal notranslate"><span class="pre">login[1-2].alpha.hpc.tu-dresden.de</span></code>. (Please choose one concrete
login node when connecting, see example below.)</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Key Type</p></th>
<th class="head text-left"><p>Fingerprint</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>RSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:BvYEYJtIYDGr3U0up58q5F7aog7JA2RP+w53XKmwO8I</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>RSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:5d:dc:40:3b:8b:89:77:5d:0f:29:84:31:0f:73:25:9f</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>ECDSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:lgxNRgGcKe7oDGuwf0WV9VPukA30kEqg0sNDLLQwu8Y</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>ECDSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:e1:bd:e4:77:06:97:f9:f3:03:18:56:66:14:5d:8d:18</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>ED25519</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:QNjH0ulelqykywMkt3UNTG4W1HzRkHqrhu0f6oq302I</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>ED25519</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:e4:4e:7a:76:aa:87:da:17:92:b1:17:c6:a1:25:29:7e</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>{: summary=‚ÄùList of valid fingerprints for Alpha Centauri login[1-2] node‚Äù}</p></td>
<td class="text-left"><p></p></td>
</tr>
</tbody>
</table>
</section>
<section id="julia">
<h2>Julia<a class="headerlink" href="#julia" title="Permalink to this heading">#</a></h2>
<p>The cluster <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Julia</span></code></span> can be accessed via <code class="docutils literal notranslate"><span class="pre">julia.hpc.tu-dresden.de</span></code>.
(Note, there is no separate login node.)</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Key Type</p></th>
<th class="head text-left"><p>Fingerprint</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>RSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:MPRhcFxLstI76W8Sg/5KiQlGPVOHUGM/B0+qIZHFj9E</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>RSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:5f:22:e2:e2:c3:dc:b1:ee:a9:ba:61:af:34:f6:27:f0</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>ECDSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:LkHMlx6VewoPBvOhmNbue8kBsvlljtsEAjCZA8vxRWc</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>ECDSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:3f:5a:f2:f9:9d:30:5c:83:c0:e5:0e:87:42:1a:d8:b0</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>ED25519</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:k5zc2E0Y8zcLErDD1Ej3g0OqkoLDF22ADmfX+b+8Z9g</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>ED25519</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:41:03:a2:7c:e9:4d:1c:bd:30:77:7d:91:d7:93:9f:8c</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>{: summary=‚ÄùList of valid fingerprints for Julia login node‚Äù}</p></td>
<td class="text-left"><p></p></td>
</tr>
</tbody>
</table>
</section>
<section id="power9">
<h2>Power9<a class="headerlink" href="#power9" title="Permalink to this heading">#</a></h2>
<p>The cluster <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Power9</span></code></span> can be accessed via the
two login nodes <code class="docutils literal notranslate"><span class="pre">login[1-2].power9.hpc.tu-dresden.de</span></code>. (Please choose one concrete login node when
connecting, see example below.)</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Key Type</p></th>
<th class="head text-left"><p>Fingerprint</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>RSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:BvYEYJtIYDGr3U0up58q5F7aog7JA2RP+w53XKmwO8I</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>RSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:5d:dc:40:3b:8b:89:77:5d:0f:29:84:31:0f:73:25:9f</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>ECDSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:lgxNRgGcKe7oDGuwf0WV9VPukA30kEqg0sNDLLQwu8Y</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>ECDSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:e1:bd:e4:77:06:97:f9:f3:03:18:56:66:14:5d:8d:18</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>ED25519</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:QNjH0ulelqykywMkt3UNTG4W1HzRkHqrhu0f6oq302I</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>ED25519</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:e4:4e:7a:76:aa:87:da:17:92:b1:17:c6:a1:25:29:7e</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>{: summary=‚ÄùList of valid fingerprints for Power9 login[1-2] nodes‚Äù}</p></td>
<td class="text-left"><p></p></td>
</tr>
</tbody>
</table>
</section>
<section id="dataport-nodes">
<h2>Dataport Nodes<a class="headerlink" href="#dataport-nodes" title="Permalink to this heading">#</a></h2>
<p>When you transfer files using the <span class="xref myst">dataport nodes</span>, please make
sure that the fingerprint shown matches one of the table.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Key Type</p></th>
<th class="head text-left"><p>Fingerprint</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>RSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:t4Vl4rHRHbglZIm+hck2MWld+0smYAb2rx7EGWWmya0</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>RSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:59:7f:c1:7b:34:ec:c8:07:3d:fe:b8:b5:6a:96:ea:0c</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>ECDSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:Ga1dXpp1yM5GRJC77PgDCQwDy7oHdrTY7z11V1Eq1L8</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>ECDSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:43:1b:b8:f6:23:ab:4a:08:dc:a1:b3:09:8c:8c:be:f9</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>ED25519</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:SRYDLKt7YTQkXmkv+doWV/b55xQz1nT4ZZtXYGhydg4</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>ED25519</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:eb:96:21:d7:61:9f:39:10:82:b9:21:e9:4a:87:c2:9a</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>{: summary=‚ÄùList of valid fingerprints for <a class="reference external" href="http://dataport1.hpc.tu-dresden.de">dataport1.hpc.tu-dresden.de</a>‚Äù}</p></td>
<td class="text-left"><p></p></td>
</tr>
</tbody>
</table>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Key Type</p></th>
<th class="head text-left"><p>Fingerprint</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>RSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:aMVmc3E0+ndXPiQ8EpY6lFk5CFdfGJfjy/0UBcxor58</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>RSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:03:b8:8a:2b:10:e5:6b:c8:0b:78:ab:4e:5b:2c:0e:2c</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>ECDSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:6t69R86zhJjGDlIobdsSbKFn8Km3cs9JYWlDW22nEvI</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>ECDSA</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:58:70:7d:df:e5:c8:43:cf:a5:75:ad:f5:da:9f:1a:6d</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>ED25519</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SHA256:KAD9xwCRK5C8Ch6Idfnfy88XrzZcqEJ9Ms6O+AzGfDE</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>ED25519</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">MD5:2b:61:5a:89:fe:96:95:0d:3d:f6:29:40:55:ea:e6:11</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>{: summary=‚ÄùList of valid fingerprints for <a class="reference external" href="http://dataport2.hpc.tu-dresden.de">dataport2.hpc.tu-dresden.de</a>‚Äù}</p></td>
<td class="text-left"><p></p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="access-to-zih-systems">
<h1>Access to ZIH Systems<a class="headerlink" href="#access-to-zih-systems" title="Permalink to this heading">#</a></h1>
<p>There are several different ways to access ZIH systems depending on the intended usage:</p>
<ul class="simple">
<li><p><span class="xref myst">SSH connection</span> is the classical way to connect to the login nodes and work from
the command line to set up experiments and manage batch jobs</p></li>
<li><p><span class="xref myst">Desktop Cloud Visualization</span> provides a virtual Linux desktop
with access to GPU resources for OpenGL 3D applications</p></li>
<li><p><span class="xref myst">WebVNC service</span> allows better support for graphical
applications than SSH with X forwarding</p></li>
<li><p><span class="xref myst">JupyterHub service</span> offers a quick and easy way to work with Jupyter notebooks on
ZIH systems.</p></li>
</ul>
<p>!!! hint</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Prerequisite for accessing ZIH systems is a HPC project and a login. Please refer to the pages
within [Application for Login and Resources](../application/overview.md) for detailed
information.
</pre></div>
</div>
<p>For security reasons, ZIH systems are only accessible for hosts within the domains of TU Dresden.</p>
<p>To access the ZIH systems from outside the campus networks it is recommended to set up a Virtual
Private Network (VPN) connection to enter the campus network. While active, it allows the user
to connect directly to the HPC login nodes.</p>
<p>For more information on our VPN and how to set it up, please visit the corresponding
<a class="reference external" href="https://tu-dresden.de/zih/dienste/service-katalog/arbeitsumgebung/zugang_datennetz/vpn">ZIH service catalog page</a>.</p>
<p>The page <span class="xref myst">key fingerprints</span> holds the up-to-date fingerprints for the login
nodes. Make sure they match.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="security-restrictions">
<h1>Security Restrictions<a class="headerlink" href="#security-restrictions" title="Permalink to this heading">#</a></h1>
<p>As a result of a security incident the German HPC sites in Gau√ü Alliance have adjusted their
measurements to prevent infection and spreading of malware.</p>
<p>The most important items for ZIH systems are:</p>
<ul class="simple">
<li><p>All users (who haven‚Äôt done so recently) have to
<a class="reference external" href="https://selfservice.zih.tu-dresden.de/l/index.php/pswd/change_zih_password">change their ZIH password</a>.</p>
<ul>
<li><p><strong>Login to ZIH systems is denied with an old password.</strong></p></li>
</ul>
</li>
<li><p>All old (private and public) keys have been moved away.</p></li>
<li><p>All public ssh keys for ZIH systems have to</p>
<ul>
<li><p>be re-generated using only the ED25519 algorithm (<code class="docutils literal notranslate"><span class="pre">ssh-keygen</span> <span class="pre">-t</span> <span class="pre">ed25519</span></code>)</p></li>
<li><p><strong>passphrase for the private key must not be empty</strong></p></li>
</ul>
</li>
<li><p>Ideally, there should be no private key on ZIH system except for local use.</p></li>
<li><p>Keys to other systems must be passphrase-protected!</p></li>
<li><p><strong>ssh to ZIH systems</strong> is only possible from inside TU Dresden campus
(<code class="docutils literal notranslate"><span class="pre">login[1,2].zih.tu-dresden.de</span></code> will be blacklisted). Users from outside can use
<a class="reference external" href="https://tu-dresden.de/zih/dienste/service-katalog/arbeitsumgebung/zugang_datennetz/vpn">VPN</a>.</p></li>
<li><p><strong>ssh from ZIH system</strong> is only possible inside TU Dresden campus.
(Direct SSH access to other computing centers was the spreading vector of the recent incident.)</p></li>
</ul>
<p>Data transfer is possible via the <span class="xref myst">Dataport Nodes</span>.</p>
<p>We understand that all this will change convenient workflows. If the measurements would render your
work on ZIH systems completely impossible, please <span class="xref myst">contact the HPC support</span>.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="connecting-via-terminal-linux-mac-windows">
<h1>Connecting via Terminal (Linux, Mac, Windows)<a class="headerlink" href="#connecting-via-terminal-linux-mac-windows" title="Permalink to this heading">#</a></h1>
<p>Connecting via terminal works on every operating system. For Linux and Mac operating systems
no additional software is required. For users of a Windows OS a recent version of Windows is
required (Windows 10, Build 1809 and higher). It is possible to use
<a class="reference external" href="https://en.wikipedia.org/wiki/Cmd.exe">Command Prompt</a> or <a class="reference external" href="https://en.wikipedia.org/wiki/PowerShell">PowerShell</a>).
Ensure that <a class="reference external" href="https://docs.microsoft.com/en-us/windows-hardware/manufacture/desktop/factoryos/connect-using-ssh?view=windows-10">OpenSSH</a>
is installed on the system.</p>
<p>SSH establishes secure connections using authentication and encryption. The login nodes accept
the following encryption algorithms: <code class="docutils literal notranslate"><span class="pre">aes128-ctr</span></code>, <code class="docutils literal notranslate"><span class="pre">aes192-ctr</span></code>, <code class="docutils literal notranslate"><span class="pre">aes256-ctr</span></code>,
<code class="docutils literal notranslate"><span class="pre">aes128-gcm&#64;openssh.com</span></code>, <code class="docutils literal notranslate"><span class="pre">aes256-gcm&#64;openssh.com</span></code>, <code class="docutils literal notranslate"><span class="pre">chacha20-poly1305&#64;openssh.com</span></code>,
<code class="docutils literal notranslate"><span class="pre">chacha20-poly1305&#64;openssh.com</span></code>.</p>
<section id="before-your-first-connection">
<h2>Before Your First Connection<a class="headerlink" href="#before-your-first-connection" title="Permalink to this heading">#</a></h2>
<p>We suggest to create an SSH key pair before you work with the ZIH systems. This ensures high
connection security.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>mkdir<span class="w"> </span>-p<span class="w"> </span>~/.ssh
<span class="gp">marie@local$ </span>ssh-keygen<span class="w"> </span>-t<span class="w"> </span>ed25519<span class="w"> </span>-f<span class="w"> </span>~/.ssh/id_ed25519
<span class="go">Generating public/private ed25519 key pair.</span>
<span class="go">Enter passphrase (empty for no passphrase):</span>
<span class="go">Enter same passphrase again:</span>
<span class="go">[...]</span>
</pre></div>
</div>
<p>Type in a passphrase for the protection of your key. The passphrase should be <strong>non-empty</strong>.
Copy the <strong>public key</strong> to the ZIH system (Replace placeholder <code class="docutils literal notranslate"><span class="pre">marie</span></code> with your ZIH login):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>ssh-copy-id<span class="w"> </span>-i<span class="w"> </span>~/.ssh/id_ed25519.pub<span class="w"> </span>marie@login2.barnard.hpc.tu-dresden.de
<span class="go">The authenticity of host &#39;barnard.hpc.tu-dresden.de (141.30.73.104)&#39; can&#39;t be established.</span>
<span class="go">RSA key fingerprint is SHA256:HjpVeymTpk0rqoc8Yvyc8d9KXQ/p2K0R8TJ27aFnIL8.</span>
<span class="go">Are you sure you want to continue connecting (yes/no)?</span>
</pre></div>
</div>
<p>Compare the shown fingerprint with the <span class="xref myst">documented fingerprints</span>. Make sure
they match. Then you can accept by typing <code class="docutils literal notranslate"><span class="pre">yes</span></code>.</p>
<p>!!! note ‚ÄúOne <code class="docutils literal notranslate"><span class="pre">ssh-copy-id</span></code> command for all clusters‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Since your home directory, where the file `.ssh/authorized_keys` is stored, is available on all HPC
systems, this task is only required once and you can freely choose a target system for the
`ssh-copy-id` command. Afterwards, you can access all clusters with this key file.
</pre></div>
</div>
<p>??? info ‚Äússh-copy-id is not available‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If `ssh-copy-id` is not available, you need to do additional steps:

```console
marie@local$ scp ~/.ssh/id_ed25519.pub marie@login2.barnard.hpc.tu-dresden.de:
The authenticity of host &#39;barnard.hpc.tu-dresden.de (141.30.73.104)&#39; can&#39;t be established.
RSA key fingerprint is SHA256:Gn4n5IX9eEvkpOGrtZzs9T9yAfJUB200bgRchchiKAQ.
Are you sure you want to continue connecting (yes/no)?
```

After that, you need to manually copy the key to the right place:

```console
marie@local$ ssh marie@login2.barnard.hpc.tu-dresden.de
[...]
marie@login.barnard$ mkdir -p ~/.ssh
marie@login.barnard$ touch ~/.ssh/authorized_keys
marie@login.barnard$ cat id_ed25519.pub &gt;&gt; ~/.ssh/authorized_keys
```
</pre></div>
</div>
<section id="configuring-default-parameters-for-ssh">
<h3>Configuring Default Parameters for SSH<a class="headerlink" href="#configuring-default-parameters-for-ssh" title="Permalink to this heading">#</a></h3>
<p>After you have copied your key to the ZIH system, you should be able to connect using:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>ssh<span class="w"> </span>marie@login2.barnard.hpc.tu-dresden.de
<span class="go">[...]</span>
<span class="gp">marie@login.barnard$ </span><span class="nb">exit</span>
</pre></div>
</div>
<p>However, you can make this more comfortable if you prepare an SSH configuration on your local
workstation. Navigate to the subdirectory <code class="docutils literal notranslate"><span class="pre">.ssh</span></code> in your home directory and open the file <code class="docutils literal notranslate"><span class="pre">config</span></code>
(<code class="docutils literal notranslate"><span class="pre">~/.ssh/config</span></code>) in your favorite editor. If it does not exist, create it. Put the following lines
in it (you can omit lines starting with <code class="docutils literal notranslate"><span class="pre">#</span></code>):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Host<span class="w"> </span>barnard
<span class="w">  </span><span class="c1">#For login (shell access)</span>
<span class="w">  </span>HostName<span class="w"> </span>login1.barnard.hpc.tu-dresden.de
<span class="w">  </span><span class="c1">#Put your ZIH-Login after keyword &quot;User&quot;:</span>
<span class="w">  </span>User<span class="w"> </span>marie
<span class="w">  </span><span class="c1">#Path to private key:</span>
<span class="w">  </span>IdentityFile<span class="w"> </span>~/.ssh/id_ed25519
<span class="w">  </span><span class="c1">#Don&#39;t try other keys if you have more:</span>
<span class="w">  </span>IdentitiesOnly<span class="w"> </span>yes
<span class="w">  </span><span class="c1">#Enable X11 forwarding for graphical applications and compression. You don&#39;t need parameter -X and -C when invoking ssh then.</span>
<span class="w">  </span>ForwardX11<span class="w"> </span>yes
<span class="w">  </span>Compression<span class="w"> </span>yes
Host<span class="w"> </span>dataport
<span class="w">  </span><span class="c1">#For copying data without shell access</span>
<span class="w">  </span>HostName<span class="w"> </span>dataport1.hpc.tu-dresden.de
<span class="w">  </span><span class="c1">#Put your ZIH-Login after keyword &quot;User&quot;:</span>
<span class="w">  </span>User<span class="w"> </span>marie
<span class="w">  </span><span class="c1">#Path to private key:</span>
<span class="w">  </span>IdentityFile<span class="w"> </span>~/.ssh/id_ed25519
<span class="w">  </span><span class="c1">#Don&#39;t try other keys if you have more:</span>
<span class="w">  </span>IdentitiesOnly<span class="w"> </span>yes
</pre></div>
</div>
<p>Afterwards, you can connect to the ZIH system using:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>ssh<span class="w"> </span>barnard
</pre></div>
</div>
<p>If you want to copy data from/to ZIH systems, please refer to the documentation
<span class="xref myst">Dataport Nodes: Transfer Data to/from ZIH‚Äôs Filesystems</span>
for more information on Dataport nodes.</p>
<p>!!! note ‚ÄúGernalization to all HPC systems‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>In the above `.ssh/config` file, the HPC system `Barnard` is chosen as an example.
The very same settings can be made for individuall or all ZIH systems, e.g. `Capella`, `Alpha`,
 `Julia`, `Romeo` etc.
</pre></div>
</div>
</section>
</section>
<section id="x11-forwarding">
<h2>X11-Forwarding<a class="headerlink" href="#x11-forwarding" title="Permalink to this heading">#</a></h2>
<p>If you plan to use an application with graphical user interface (GUI), you need to enable
X11-forwarding for the connection. If you use the SSH configuration described above, everything is
already prepared and you can simply use:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>ssh<span class="w"> </span>barnard
</pre></div>
</div>
<p>If you have omitted the last two lines in the default configuration above, you need to add the
option <code class="docutils literal notranslate"><span class="pre">-X</span></code> or <code class="docutils literal notranslate"><span class="pre">-XC</span></code> to your SSH command. The <code class="docutils literal notranslate"><span class="pre">-C</span></code> enables compression which usually improves
usability in this case:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>ssh<span class="w"> </span>-XC<span class="w"> </span>barnard
</pre></div>
</div>
<p>!!! info</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Also consider to use a [DCV session](desktop_cloud_visualization.md) for remote desktop
visualization at ZIH systems.
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="connecting-with-mobaxterm-windows">
<h1>Connecting with MobaXterm (Windows)<a class="headerlink" href="#connecting-with-mobaxterm-windows" title="Permalink to this heading">#</a></h1>
<p><a class="reference external" href="https://mobaxterm.mobatek.net">MobaXterm</a> is an enhanced terminal for Windows with an X11 server,
a tabbed SSH client, network tools and more.</p>
<section id="download-and-install">
<h2>Download and install<a class="headerlink" href="#download-and-install" title="Permalink to this heading">#</a></h2>
<p>To download go to <a class="reference external" href="https://mobaxterm.mobatek.net/download-home-edition.html">MobaXterm download page</a>
and download a free home edition.</p>
<p><img alt="Downloading MobaXterm" src="63_chat_with_docs/misc/mobaxterm1_download.png" /></p>
<p>Pick the installer suiting best your current system and run it afterwards. Follow the instructions.
You should see the following interface after starting the MobaXterm application.</p>
<p><img alt="First opening MobaXterm" src="63_chat_with_docs/misc/mobaxterm2_first.png" /></p>
</section>
<section id="configure-local-settings">
<h2>Configure local settings<a class="headerlink" href="#configure-local-settings" title="Permalink to this heading">#</a></h2>
<p>Select the menu entry ‚ÄúSettings‚Äù ‚Üí ‚ÄúConfiguration‚Äù or click the button ‚ÄúSettings‚Äù in the
toolbar. A new window will open.</p>
<p><img alt="Settings in MobaXterm" src="63_chat_with_docs/misc/mobaxterm3_config.png" /></p>
<p>Here you can set different options in the following tabs:</p>
<ul class="simple">
<li><p>‚ÄúGeneral‚Äù - local path options for local MobaXterm-session,</p></li>
<li><p>‚ÄúTerminal‚Äù -  options, which alter your terminal, e.g. color scheme,</p></li>
<li><p>‚ÄúX11‚Äù - options for X11-forwarding. It is enabled by default,</p></li>
<li><p>‚ÄúSSH‚Äù - general SSH settings, e.g. keep-alive, SSH agent, browser-options,</p></li>
<li><p>‚ÄúDisplay‚Äù - general display-options for the application,</p></li>
<li><p>‚ÄúToolbar‚Äù - customization of the toolbar,</p></li>
<li><p>‚ÄúMisc‚Äù - options to alter specific actions inside the MobaXterm-application.</p></li>
</ul>
</section>
<section id="start-a-new-session">
<h2>Start a new session<a class="headerlink" href="#start-a-new-session" title="Permalink to this heading">#</a></h2>
<ol class="arabic">
<li><p>Select the tab ‚ÄúSessions‚Äù  ‚Üí ‚ÄúNew session‚Äù or click the button ‚ÄúSession‚Äù in the toolbar.</p>
<p><img alt="Opening a new session in MobaXterm" src="63_chat_with_docs/misc/mobaxterm4_session.png" /></p>
</li>
<li><p>Select a SSH section. Insert ‚ÄúRemote host‚Äù (<code class="docutils literal notranslate"><span class="pre">login2.barnard.hpc.tu-dresden.de</span></code>), ‚ÄúUsername‚Äù
(replace <code class="docutils literal notranslate"><span class="pre">marie</span></code> with your ZIH login), and ‚ÄúPort‚Äù 22. Using the button right from the username
option, you can store and manage credentials. To access a different cluster, change the name
accordingly (e.g.<code class="docutils literal notranslate"><span class="pre">login1.alpha.hpc.tu-dresden.de</span></code>)</p>
<p><img alt="Settings for SSH connection in MobaXterm" src="63_chat_with_docs/misc/MobaXterm_remote_host.png" /></p>
</li>
<li><p>Advanced settings can be configured in the same window below. These are</p>
<ul class="simple">
<li><p>‚ÄúAdvanced SSH settings‚Äù - set defaults for this specific session. For example, set a SSH key
or change the remote environment,</p></li>
<li><p>‚ÄúTerminal settings‚Äù - change terminal options,</p></li>
<li><p>‚ÄúNetwork settings‚Äù - configure how the connection is built over the network. For example, by
adding a proxy as gateway to the targeted system,</p></li>
<li><p>‚ÄúBookmark settings‚Äù - specify how the session will be saved to your session list, which is
afterwards accessible by the button ‚ÄúSessions‚Äù.</p></li>
</ul>
</li>
<li><p>Start the session by clicking the button ‚ÄúOK‚Äù.</p>
<p>Your previous sessions are saved in the bookmarks and can be accessed via the menu entry
‚ÄúSessions‚Äù  ‚Üí  ‚ÄúUser sessions‚Äù. Alternatively, double click on one of the previous
sessions on the left panel.</p>
<p><img alt="Opening a saved session in MobaXterm" src="63_chat_with_docs/misc/mobaxterm6_oldse.png" /></p>
</li>
<li><p>The last thing to do is to input your ZIH password in the command line and to press enter.
The entered symbols of your password are invisible and will not appear as typed in.</p>
<p><img alt="Saving your password in MobaXterm" src="63_chat_with_docs/misc/MobaXterm_password.png" /></p>
</li>
</ol>
<p>!!! Caution</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Do not forget to close the session after your jobs are finished. Just type `exit` in the
command line and complete with pressing enter.
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="connecting-with-putty-windows">
<h1>Connecting with PuTTY (Windows)<a class="headerlink" href="#connecting-with-putty-windows" title="Permalink to this heading">#</a></h1>
<p>PuTTY is a free and open-source terminal emulator, serial console and network file transfer
application, supports several network protocols, including SCP, SSH. Visit the
<a class="reference external" href="https://www.putty.org">homepage</a> for more information.</p>
<section id="id3">
<h2>Download and install<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h2>
<p>Download the installer suiting best your current system and run it afterwards. Follow the
instructions for installation.</p>
<p><img alt="Downloading PuTTY" src="63_chat_with_docs/misc/putty1_download.png" /></p>
</section>
<section id="start-a-new-ssh-session">
<h2>Start a new SSH session<a class="headerlink" href="#start-a-new-ssh-session" title="Permalink to this heading">#</a></h2>
<ol class="arabic">
<li><p>Start PuTTY and insert the ‚ÄúHost Name‚Äù (<code class="docutils literal notranslate"><span class="pre">login2.barnard.hpc.tu-dresden.de</span></code>) and leave the default
port (22). To access a different cluster, change the name accordingly (e.g.<code class="docutils literal notranslate"><span class="pre">login1.alpha.hpc.tu-dresden.de</span></code>)</p>
<p><img alt="Settings for SSH connection in PuTTY" src="63_chat_with_docs/misc/putty2_quickstart.png" /></p>
</li>
<li><p>Click ‚ÄúOpen‚Äù to start a new session. A terminal window will open up.</p>
<p><img alt="Login in PuTTY" src="63_chat_with_docs/misc/putty3_login.png" /></p>
</li>
<li><p>After entering your ZIH login and password you will be logged in to one of the login nodes.</p></li>
</ol>
</section>
<section id="connection-configuration-optional">
<h2>Connection Configuration (optional)<a class="headerlink" href="#connection-configuration-optional" title="Permalink to this heading">#</a></h2>
<p>You can pre-configure some connection details additionally. It will save time in the future.</p>
<ul>
<li><p>Set your user name. For that choose the tab ‚ÄúConnection‚Äù ‚Üí ‚ÄúData‚Äù in the navigation tree
on the left. Insert your ZIH username in the text field ‚ÄúAuto-login username‚Äù.</p>
<p><img alt="Auto-login username in PuTTY" src="63_chat_with_docs/misc/putty4_username.png" /></p>
</li>
<li><p>Configure SSH-key (recommended for security reason).</p>
<p>??? note ‚ÄúGenerate your key pair‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you do not have your SSH key pair (public and private keys) yet, you can generate
it using PuTTYgen program, which was installed together with the main PuTTY client.

![PuTTY generate key pair](misc/putty8_gen_key.png){: width=400}

Click on the button &quot;Generate&quot; to create a new key pair. Move the mouse pointer in the
respective field as requested. Afterwards save your public and private keys in separate
files. It is recommended to use a passphrase for the private key.
</pre></div>
</div>
<p>To configure the SSH key to use, navigate to ‚ÄúConnection‚Äù ‚Üí ‚ÄúSSH‚Äù ‚Üí ‚ÄúAuth‚Äù in the
tree left. Insert the path to your local key-file in a text field ‚ÄúPrivate key file for
authentication‚Äù or select it with ‚ÄúBrowse‚Ä¶‚Äù.</p>
<p><img alt="SSH-key in PuTTY" src="63_chat_with_docs/misc/putty5_key.png" /></p>
<p>!!! note ‚ÄúAdd public key to ZIH system‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>For being able to use a SSH key to login to ZIH system, you have to register the key
on the system before!

Login to the ZIH system using your password and add your public-key to
`~/.ssh/authorized_keys`.
</pre></div>
</div>
</li>
<li><p>Enable X-forwarding. Navigate to ‚ÄúConnection‚Äù ‚Üí ‚ÄúSSH‚Äù ‚Üí ‚ÄúX11‚Äù in the tree on the
left. Select the checkbox ‚ÄúEnable X11 forwarding‚Äù.</p>
<p><img alt="X-forwarding in PuTTY" src="63_chat_with_docs/misc/putty6_x11.png" /></p>
</li>
</ul>
<p>After editing the connection details save your configuration. Go back to the ‚ÄúSession‚Äù in the tree
left. Insert a session bookmark name into the text field ‚ÄúSaved Sessions‚Äù and click the button
‚ÄúSave‚Äù. Afterwards you will see the name in the list below.</p>
<p><img alt="Saving settings in PuTTY" src="63_chat_with_docs/misc/putty7_save.png" /></p>
<p>Now, you can start a configured session by double-clicking its name in the list.</p>
<p>You can change your saved configuration by selecting its name in the list and clicking the button
‚ÄúLoad‚Äù. Make your changes and save it again under the same name. This will overwrite the old
configuration permanently.</p>
<p>You can delete saved configuration by clicking the button ‚ÄúDelete‚Äù. This will remove the
configured session permanently.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="acknowledgement">
<h1>Acknowledgement<a class="headerlink" href="#acknowledgement" title="Permalink to this heading">#</a></h1>
<p>To provide you with modern and powerful HPC systems in future as well, we have to show that these
systems help to advance research. For that purpose we rely on your help. In most cases, the results
of your computations are used for presentations and publications, especially in peer-reviewed
magazines, journals, and conference proceedings. We kindly ask you to mention the HPC resource usage
in the acknowledgment section of all publications that are based on granted HPC resources of the
<a class="reference external" href="https://tu-dresden.de/zih/hochleistungsrechnen/nhr-center">NHR center at TU Dresden</a>. Examples:</p>
<p>!!! note ‚ÄúStandard case‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The authors gratefully acknowledge the computing time made available to them on
the high-performance computer &lt;XY&gt; at the NHR Center of TU Dresden. This center is jointly
supported by the Federal Ministry of Education and Research and the state governments
participating in the NHR (www.nhr-verein.de/unsere-partner).
</pre></div>
</div>
<p>!!! note ‚ÄúTwo NHR centers‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The authors gratefully acknowledge the computing time made available to them on
the high-performance computers &lt;XY&gt; and &lt;YZ&gt; at the NHR Centers at TU Dresden and &lt;YZ&gt;.
These centers are jointly supported by the Federal Ministry of Education and Research
and the state governments participating in the NHR (www.nhr-verein.de/unsere-partner).
</pre></div>
</div>
<p>!!! note ‚ÄúGerman‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Die Autoren bedanken sich f√ºr die ihnen zur Verf√ºgung gestellte Rechenzeit auf
dem Hochleistungsrechner &lt;XY&gt; am NHR-Zentrum der TU Dresden. Dieses wird gemeinsam durch
das Bundesministerium f√ºr Bildung und Forschung und den am NHR beteiligten
Landesregierungen (www.nhr-verein.de/unsere-partner) unterst√ºtzt.
</pre></div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="application-for-hpc-resources">
<h1>Application for HPC Resources<a class="headerlink" href="#application-for-hpc-resources" title="Permalink to this heading">#</a></h1>
<p>You will find comprehensive information regarding the application process on the webpage
<a class="reference external" href="https://tu-dresden.de/zih/hochleistungsrechnen/zugang/projektantrag">Project Application for using the HPC Systems</a>.</p>
<p>You will find in this section information about:</p>
<ul class="simple">
<li><p><span class="xref myst">Terms of Use</span></p></li>
<li><p>Manage members and their access to the project via
<span class="xref myst">User Management for Project Leaders</span></p></li>
<li><p><span class="xref myst">Acknowledgment in Publications</span></p></li>
</ul>
<section id="nhr-center">
<h2>NHR Center<a class="headerlink" href="#nhr-center" title="Permalink to this heading">#</a></h2>
<p>Since 2021, HPC at universities has been restructured by the
<a class="reference external" href="https://www.nhr-verein.de/">NHR network</a>.
The network consists of nine centers which operate the systems and offer
a coordinated consulting service on the methodological competence of scientific HPC.
The aim is to provide scientists at German universities with computing capacity
for their research and to strengthen their skills in the efficient use of these resources.</p>
<p>In order to use the HPC systems installed at ZIH, it is necessary to apply for the resources.
The applicant (HPC project manager) is required to have a doctorate/PhD.
It is possible to apply for different
<a class="reference external" href="https://tu-dresden.de/zih/hochleistungsrechnen/zugang/projektantrag#section-1">project types</a>
depending on the project demands.</p>
<p>However, the
<a class="reference external" href="https://tu-dresden.de/zih/hochleistungsrechnen/zugang/projektantrag">application workflow with JARDS</a>
is identical for all types.</p>
<p>??? Info  ‚ÄúWho can apply?‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Please note: Researchers with a doctorate from universities or universities of applied sciences
in Germany are eligible to apply.

We particularly invite researchers to apply with research projects related to our focus topics:

   * Life Sciences
   * Earth System Sciences
   * Methods for big data, data analysis and management
   * Machine Learning
   * Tiered storage architectures and I/O optimization
   * Performance and energy efficiency analysis and optimization
   * Research projects not related to our focus topics but from Universities within Saxony.

We recommend **all other researchers** to review the focus topics of the remaining
[NHR centers](https://www.nhr-verein.de/anwendungsunterstuetzung) and apply to the most suitable
for your research topic. Working at the specialized NHR center related to your research topic
provides you with the advantage of receiving topic specific support.
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="user-management-for-project-leaders">
<h1>User Management for Project Leaders<a class="headerlink" href="#user-management-for-project-leaders" title="Permalink to this heading">#</a></h1>
<p>The HPC project leader (PI/PC) has overall responsibility for the project and for all activities
within the corresponding project on ZIH systems. In particular the project leader shall:</p>
<ul class="simple">
<li><p>add and remove users from the project,</p></li>
<li><p>update contact details of the project members,</p></li>
<li><p>monitor the resources of the project,</p></li>
<li><p>inspect and store data of retiring users.</p></li>
</ul>
<p>The project leader can appoint a <em>project administrator</em> with an HPC account to manage these
technical details.</p>
<p>The <span class="xref myst">project management site</span> enables the project leader and the project administrator
to</p>
<ul class="simple">
<li><p>get a <span class="xref myst">project overview</span></p></li>
<li><p><span class="xref myst">add and remove users from the project</span></p></li>
<li><p><span class="xref myst">define a technical administrator</span></p></li>
<li><p><span class="xref myst">view statistics (resource consumption)</span></p></li>
<li><p>file a new HPC proposal,</p></li>
<li><p>file results of the HPC project.</p></li>
</ul>
<section id="id4">
<h2>Access<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://hpcprojekte.zih.tu-dresden.de/managers">Entry point to the project management system</a>
The project leaders of an ongoing project and their accredited admins
are allowed to login to the system. In general each of these persons
should possess a ZIH login at the Technical University of Dresden, with
which it is possible to log in to the website. In some cases, it may
happen that a project leader of a foreign organization does not have a ZIH
login. For this purpose, it is possible to set a local password:
‚Äú<a class="reference external" href="https://hpcprojekte.zih.tu-dresden.de/managers/members/missingPassword">Missing Password</a>‚Äù.</p>
<p><img alt="Login Screen" src="63_chat_with_docs/misc/external_login.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>On the ‚ÄòMissing Password‚Äô page, it is possible to reset the passwords of a ‚Äònon-ZIH-login‚Äô. For this
you write your login, which usually corresponds to your e-mail address, in the ‚ÄòLogin‚Äô field and
click on ‚Äòreset‚Äô. Within 10 minutes the system sends a signed e-mail from
<a class="reference external" href="mailto:hpcprojekte&#37;&#52;&#48;zih&#46;tu-dresden&#46;de">hpcprojekte<span>&#64;</span>zih<span>&#46;</span>tu-dresden<span>&#46;</span>de</a> to the registered e-mail address. this e-mail contains a link to
reset the password.</p>
<p><img alt="Password Reset" src="63_chat_with_docs/misc/password.png" />
{: align=‚Äùcenter‚Äù}</p>
</section>
<section id="projects">
<h2>Projects<a class="headerlink" href="#projects" title="Permalink to this heading">#</a></h2>
<p>After login you reach an overview that displays all available projects. In each of these listed
projects, you are either project leader or an assigned project administrator. From this list, you
have the option to view the details of a project or make a follow-up application (extension). The
latter is only possible if a project has been approved and is active or was. In the upper right
area you will find a red button to log out from the system.</p>
<p><img alt="Project Overview" src="63_chat_with_docs/misc/overview.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>The project details provide information about the requested and allocated resources. The other tabs
show the employee and the statistics about the project.</p>
<p><img alt="Project Details" src="63_chat_with_docs/misc/project_details.png" />
{: align=‚Äùcenter‚Äù}</p>
<section id="manage-project-members-dis-enable">
<h3>Manage Project Members (dis-/enable)<a class="headerlink" href="#manage-project-members-dis-enable" title="Permalink to this heading">#</a></h3>
<p>The project members can be managed under the tab ‚Äòemployee‚Äô in the project details. This page gives
an overview of all ZIH logins that are a member of a project and its status. If a project member
marked in green, it can work on all authorized HPC machines when the project has been approved. If
an employee is marked in red, this can have several causes:</p>
<ul class="simple">
<li><p>the employee was manually disabled by project managers, project administrator
or ZIH staff</p></li>
<li><p>the employee was disabled by the system because its ZIH login expired</p></li>
<li><p>confirmation of the current HPC-terms is missing</p></li>
</ul>
<p>You can specify a user as an administrator. This user can then access the project management system.
Next, you can disable individual project members. This disabling is only a ‚Äúrequest of disabling‚Äù
and has a time delay of 5 minutes. A user can add or reactivate itself within a specific project by
clicking the link on the end of the page. To prevent misuse this link is valid for 2 weeks and
will then be renewed automatically.</p>
<p><img alt="Project Members" src="63_chat_with_docs/misc/members.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>The link leads to a page where you can sign in to a project by accepting the terms of use. You also
need a valid ZIH-Login. After this step it can take 1-1.5 h to transfer the login to all cluster
nodes.</p>
<p><img alt="Add Member" src="63_chat_with_docs/misc/add_member.png" />
{: align=‚Äùcenter‚Äù}</p>
</section>
<section id="statistic">
<h3>Statistic<a class="headerlink" href="#statistic" title="Permalink to this heading">#</a></h3>
<p>The statistic is located under the tab ‚ÄòStatistic‚Äô in the project details. The data will be updated
once a day and shows used CPU-time and used disk space of a project. Follow-up projects also show
the data of their predecessor(s).</p>
<p><img alt="Project Statistic" src="63_chat_with_docs/misc/stats.png" />
{: align=‚Äùcenter‚Äù}</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="terms-of-use">
<h1>Terms of Use<a class="headerlink" href="#terms-of-use" title="Permalink to this heading">#</a></h1>
<p>!!! attention</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Only the German version of the *Terms of Use* is binding.
</pre></div>
</div>
<p>These new Terms of Use are valid from April 1, 2018: <span class="xref myst">HPC-Nutzungsbedingungen_20180305.pdf</span></p>
<p>The key points are are:</p>
<ul class="simple">
<li><p>For support reasons, we store your contact data according to our <a class="reference external" href="https://tu-dresden.de/zih/dienste/service-katalog/zugangsvoraussetzung">identity management system</a>.
(Will be anonymized at least 15 months after the cancellation of the HPC login.)
The data of the HPC project (incl. contact of project leader) will be kept for
further reference.</p>
<ul>
<li><p>Our HPC resources may only be used according to the project description.</p></li>
</ul>
</li>
<li><p>Responsibilities for the project leader:</p>
<ul>
<li><p>She has to assign a team member with an HPC login as the technical project
administrator. She can do this herself if she has a login at our systems.</p></li>
<li><p>The project leader or the administrator will have to add/remove members to
their project. She has access to accounting data for her project.</p></li>
</ul>
</li>
<li><p>These issues cover the data storage in our systems:</p>
<ul>
<li><p>Please work in the scratch filesystems.</p></li>
<li><p>Upon request, the project leader or the administrator can be given access
to a user‚Äôs directory.</p></li>
<li><p>The scratch filesystems (<code class="docutils literal notranslate"><span class="pre">/tmp</span></code>, <code class="docutils literal notranslate"><span class="pre">/scratch</span></code>, <code class="docutils literal notranslate"><span class="pre">/lustre/ssd</span></code>) are for
temporary use only. After a certain time, files may be removed
automatically (for <code class="docutils literal notranslate"><span class="pre">/tmp</span></code> after 7 days, parallel <code class="docutils literal notranslate"><span class="pre">/scratch</span></code>: after 100 days).</p></li>
<li><p>Before a user leaves a project the leader/administrator has to store away
worthy data. For this, the storage services of ZIH (long term storage,
intermediate archive) can be used.</p></li>
</ul>
</li>
<li><p>Project termination (<strong>new</strong>)</p>
<ul>
<li><p>At project‚Äôs end, jobs cannot be submitted and started any longer.</p></li>
<li><p>Logins are valid for 30 more days for saving data.</p></li>
<li><p>Hundred days after project termination, it‚Äôs files will be deleted in
the HPC filesystems.</p></li>
</ul>
</li>
<li><p>The HPC user agrees to follow the instructions and hints of the support
team. In case of non-compliance, she can be disabled for the batch system
or banned from the system.</p></li>
<li><p>Working with logs and HPC performance data (<strong>new</strong>)</p>
<ul>
<li><p>For HPC related research ZIH will collect and analyze
performance data. Anonymized, it might be shared with research partners.</p></li>
<li><p>Log data will be kept for long term analyzes.</p></li>
</ul>
</li>
</ul>
<p>These key points are only a brief summary. If in doubt, please consult the German original.</p>
<section id="history">
<h2>History<a class="headerlink" href="#history" title="Permalink to this heading">#</a></h2>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Valid</p></th>
<th class="head text-left"><p>Document</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>1 April 2018 -</p></td>
<td class="text-left"><p><span class="xref myst">HPC-Nutzungsbedingungen_20180305.pdf</span></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>1 October 2016 - 31 March 2018</p></td>
<td class="text-left"><p><span class="xref myst">HPC-Nutzungsbedingungen_20160901.pdf</span></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>5 June 2014 - 30 September 2016</p></td>
<td class="text-left"><p><span class="xref myst">HPC-Nutzungsbedingungen_20140606.pdf</span></p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p>Not binding translation in english: <span class="xref myst">Terms-of-use-HPC-20180305-engl.pdf</span></p></li>
</ul>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="content-rules">
<h1>Content Rules<a class="headerlink" href="#content-rules" title="Permalink to this heading">#</a></h1>
<p>!!! cite ‚ÄúGeorge Bernard Shaw‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The golden rule is that there are no golden rules.
</pre></div>
</div>
<section id="motivation-and-rationale">
<h2>Motivation and Rationale<a class="headerlink" href="#motivation-and-rationale" title="Permalink to this heading">#</a></h2>
<p>This page holds rules regarding the layout, content, and writing of this
documentation. The goals are to provide a comprehensive, consistent and well-written
documentation that is pure joy to read and use. It shall help to find answers and provide knowledge
instead of being the bottleneck and a great annoyance. Therefore, we set up some rules which
are outlined in the following.</p>
<p>!!! tip</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Following these rules when contributing speeds up the review process. Furthermore, your
changes will not be blocked by the automatic checks implemented in the CI pipeline.
</pre></div>
</div>
</section>
<section id="responsibility-and-license">
<h2>Responsibility and License<a class="headerlink" href="#responsibility-and-license" title="Permalink to this heading">#</a></h2>
<p>This documentation and the repository have two licenses (cf. <span class="xref myst">Legal Notice</span>):</p>
<ul class="simple">
<li><p>All documentation is licensed under <a class="reference external" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>.</p></li>
<li><p>All software components are licensed under <span class="xref myst">MIT license</span>.</p></li>
</ul>
<p>These licenses also apply to your contributions.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you contribute, you are fully and solely responsible for the content you create and have to
ensure that you have the right to create it under the laws which apply.
</pre></div>
</div>
<p>If you are in doubt, please contact us either via
<a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/zih/hpcsupport/hpc-compendium/-/issues">GitLab Issue</a>
or via <a class="reference external" href="mailto:hpc-support&#37;&#52;&#48;tu-dresden&#46;de">e-mail</a>.</p>
</section>
<section id="quick-overview">
<h2>Quick Overview<a class="headerlink" href="#quick-overview" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>All documentation is written in <span class="xref myst">Markdown</span>.</p></li>
<li><p>Use spaces (not tabs) both in Markdown files and in <code class="docutils literal notranslate"><span class="pre">mkdocs.yml</span></code>.</p></li>
<li><p>Respect the line length limit of 100 characters (exception: links).</p></li>
<li><p>Do not add large binary files or high-resolution images to the repository (cf.
<span class="xref myst">adding images and attachments</span>).</p></li>
<li><p><span class="xref myst">Admonitions</span> may be actively used for longer code examples,
warnings, tips, important information, etc.</p></li>
<li><p>Respect the <span class="xref myst">writing style</span> and the rules for
<span class="xref myst">spelling and technical wording</span>.</p></li>
<li><p>For code blocks:</p>
<ul>
<li><p>Use <span class="xref myst">syntax highlighting and appropriate prompts</span>.</p></li>
<li><p>Respect <span class="xref myst">data privacy</span>.</p></li>
<li><p>Stick to the <span class="xref myst">rules on optional and required arguments</span>.</p></li>
</ul>
</li>
<li><p>Save attachments, graphics and videos within the respective <code class="docutils literal notranslate"><span class="pre">misc</span></code> subdirectory.</p></li>
</ul>
</section>
<section id="detailed-overview">
<h2>Detailed Overview<a class="headerlink" href="#detailed-overview" title="Permalink to this heading">#</a></h2>
<section id="writing-style">
<h3>Writing Style<a class="headerlink" href="#writing-style" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Assume that a future reader is eager to start typing commands. Thus, encourage the reader by
addressing him/her directly:</p>
<ul>
<li><p>Example: Use ‚ÄúYou can/should ‚Ä¶‚Äù instead of ‚ÄúUsers can/should ‚Ä¶‚Äù</p></li>
<li><p>Example: Use ‚ÄúYour contribution is highly welcome‚Äù instead of ‚ÄúContributions from user-side
are highly welcome‚Äù</p></li>
</ul>
</li>
<li><p>Be brief! Provide the main idea/commands first, and special cases later. If it is not necessary to
know how a special piece of software works, don‚Äôt explain it.</p></li>
<li><p>Provide the often-used commands first.</p></li>
<li><p>Use active over passive voice</p>
<ul>
<li><p>Write with confidence. This confidence should be reflected in the documentation so that
the readers trust and follow it.</p></li>
<li><p>Example: ‚ÄúWe recommend something‚Äù instead of ‚ÄúSomething is recommended.‚Äù</p></li>
</ul>
</li>
<li><p>Capitalize headings, e.g. <em>Exclusive Reservation of Hardware</em></p></li>
<li><p>Give keywords in link texts, e.g. <span class="xref myst">Code Blocks</span> is more
descriptive than <span class="xref myst">this subsection</span></p></li>
<li><p>Avoid using tabs both in Markdown files and in <code class="docutils literal notranslate"><span class="pre">mkdocs.yaml</span></code>. Type spaces instead.</p></li>
</ul>
</section>
<section id="pages-structure-and-new-page">
<h3>Pages Structure and New Page<a class="headerlink" href="#pages-structure-and-new-page" title="Permalink to this heading">#</a></h3>
<p>The documentation and pages structure is defined in the configuration file
<a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/zih/hpcsupport/hpc-compendium/-/blob/main/doc.zih.tu-dresden.de/mkdocs.yml"><code class="docutils literal notranslate"><span class="pre">mkdocs.yml</span></code></a>:</p>
<div class="highlight-Markdown notranslate"><div class="highlight"><pre><span></span>nav:
<span class="w">  </span><span class="k">-</span><span class="w"> </span>Home: index.md
<span class="w">  </span><span class="k">-</span><span class="w"> </span>Application for Login and Resources:
<span class="w">    </span><span class="k">-</span><span class="w"> </span>Overview: application/overview.md
<span class="w">    </span><span class="k">-</span><span class="w"> </span>Terms of Use: application/terms_of_use.md
<span class="w">    </span><span class="k">-</span><span class="w"> </span>Request for Resources: application/request_for_resources.md
<span class="w">    </span><span class="k">-</span><span class="w"> </span>Project Request Form: application/project_request_form.md
<span class="w">    </span><span class="k">-</span><span class="w"> </span>Project Management: application/project_management.md
<span class="w">    </span><span class="k">-</span><span class="w"> </span>Acknowledgement: application/acknowledgement.md
<span class="w">  </span><span class="k">-</span><span class="w"> </span>Access to ZIH Systems:
<span class="w">    </span><span class="k">-</span><span class="w"> </span>Overview: access/overview.md
  [...]
</pre></div>
</div>
<p>Follow these two steps to <strong>add a new page</strong> to the documentation:</p>
<ol class="arabic simple">
<li><p>Create a new Markdown file under <code class="docutils literal notranslate"><span class="pre">docs/subdir/file_name.md</span></code> and put the documentation inside.
The sub-directory structure represents different topics of the documentation. Try to fit the
contribution into the existing structure. The file name should reflect the title of the
documentation page, i. e. <code class="docutils literal notranslate"><span class="pre">shortened_page_heading.md</span></code>.</p></li>
<li><p>Add <code class="docutils literal notranslate"><span class="pre">subdir/file_name.md</span></code> to the configuration file <code class="docutils literal notranslate"><span class="pre">mkdocs.yml</span></code> by updating the navigation
section. Yes, the order of files is crucial and defines the structure of the content. Thus,
carefully consider the right spot and section for the new page.</p></li>
</ol>
<p>Make sure that the new page <strong>is not floating</strong>, i.e., it can be reached directly from
the documentation structure.</p>
<section id="preserve-urls">
<h4>Preserve URLs<a class="headerlink" href="#preserve-urls" title="Permalink to this heading">#</a></h4>
<p>For several reasons it is important to preserve URLs within this documentation, e.g., pages with
description of specific hardware might be used as references in papers. Therefore, existing pages
shall not be renamed or moved on directory level. Outdated pages are marked with ‚ÄúOutdated‚Äù tag
and moved to the archive by changing the page‚Äôs navigation entry in the <code class="docutils literal notranslate"><span class="pre">mkdocs.yaml</span></code> file.</p>
</section>
</section>
<section id="markdown">
<h3>Markdown<a class="headerlink" href="#markdown" title="Permalink to this heading">#</a></h3>
<p>All documentation is written in Markdown. Please keep things simple, i.e., avoid using fancy
Markdown dialects.</p>
<section id="brief-how-to-on-markdown">
<h4>Brief How-To on Markdown<a class="headerlink" href="#brief-how-to-on-markdown" title="Permalink to this heading">#</a></h4>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Purpose</p></th>
<th class="head"><p>Markdown</p></th>
<th class="head"><p>Rendered HTML</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Bold text</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">**Bold</span> <span class="pre">Text**</span></code></p></td>
<td><p><strong>Bold Text</strong></p></td>
</tr>
<tr class="row-odd"><td><p>Italic text</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">*Italic</span> <span class="pre">Text*</span></code></p></td>
<td><p><em>Italic Text</em></p></td>
</tr>
<tr class="row-even"><td><p>Headings</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">#</span> <span class="pre">Level</span> <span class="pre">1</span></code>, <code class="docutils literal notranslate"><span class="pre">##</span> <span class="pre">Level</span> <span class="pre">2</span></code>, <code class="docutils literal notranslate"><span class="pre">###</span> <span class="pre">Level</span> <span class="pre">3</span></code>, ‚Ä¶</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>External link</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[website</span> <span class="pre">of</span> <span class="pre">TU</span> <span class="pre">Dresden](https://tu-dresden.de)</span></code></p></td>
<td><p><a class="reference external" href="https://tu-dresden.de">website of TU Dresden</a></p></td>
</tr>
<tr class="row-even"><td><p>Internal link</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[Slurm</span> <span class="pre">page](../jobs_and_resources/slurm.md)</span></code></p></td>
<td><p><span class="xref myst">Slurm page</span></p></td>
</tr>
<tr class="row-odd"><td><p>Internal link to section</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[section</span> <span class="pre">on</span> <span class="pre">batch</span> <span class="pre">jobs](../jobs_and_resources/slurm.md#batch-jobs)</span></code></p></td>
<td><p><span class="xref myst">section on batch jobs</span></p></td>
</tr>
</tbody>
</table>
<p>Further tips can be found on this
<a class="reference external" href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet">cheat sheet</a>.</p>
</section>
<section id="attachments">
<h4>Attachments<a class="headerlink" href="#attachments" title="Permalink to this heading">#</a></h4>
<p>Of course, you can provide attachments in sections and pages.
Such attachment documents may contain information that are more detailed and go far beyond the
scope of the compendium, e.g. user manuals for application-specific software.</p>
<p>Save attachments within the <code class="docutils literal notranslate"><span class="pre">misc</span></code> subdirectory of the corresponding section.</p>
<p>!!! note ‚ÄúSyntax for attachments‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The syntax for attachments is the very same as for links. As the attachment is within the `misc`
subdirectory, you can refer to it as local file.

```markdown
[&lt;description&gt;](misc/&lt;attachment_file_name&gt;)
```

Since the `&lt;description&gt;` is rendered as link text, you should choose a clear and precise text:

```markdown
[slides of HPC introduction](misc/HPC-Introduction.pdf)
```
</pre></div>
</div>
</section>
<section id="graphics-and-videos">
<h4>Graphics and Videos<a class="headerlink" href="#graphics-and-videos" title="Permalink to this heading">#</a></h4>
<p>Please use graphics and videos for illustration purposes and to improve comprehensibility.
All graphics and attachments are saved within <code class="docutils literal notranslate"><span class="pre">misc</span></code> directory of the respective subdirectory in
<code class="docutils literal notranslate"><span class="pre">docs</span></code>.
For video attachments please use either webm or mp4 format. We make use of the
<a class="reference external" href="https://github.com/soulless-viewer/mkdocs-video">mkdocs-video extension</a>.</p>
<p>!!! note ‚ÄúSyntax for graphics and videos‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The syntax to insert a **graphic** into a page is

```markdown
![Alternative text](misc/graphics_file.png)
```

The syntax to insert a **video** attachment into a page is

```html
![type:video](misc/terminate-virtual-desktop-dcv.mp4)
```
</pre></div>
</div>
<p>It is possible to add captions for tables and figures using <code class="docutils literal notranslate"><span class="pre">{:</span> <span class="pre">summary=&quot;This</span> <span class="pre">is</span> <span class="pre">a</span> <span class="pre">table</span> <span class="pre">caption&quot;}</span></code>.
The <code class="docutils literal notranslate"><span class="pre">summary</span></code> and <code class="docutils literal notranslate"><span class="pre">align</span></code> parameters can be combined as well:
<code class="docutils literal notranslate"><span class="pre">{:</span> <span class="pre">summary=&quot;This</span> <span class="pre">is</span> <span class="pre">a</span> <span class="pre">table</span> <span class="pre">caption&quot;</span> <span class="pre">align=&quot;top&quot;}</span></code>.</p>
<section id="resizing-and-alignment-of-graphics">
<h5>Resizing and Alignment of Graphics<a class="headerlink" href="#resizing-and-alignment-of-graphics" title="Permalink to this heading">#</a></h5>
<p>In general, graphics and images should be added to the repository with the desired size.</p>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Do not add large binary files or high-resolution images to the repository. See this valuable
document for [image optimization](https://web.dev/fast/#optimize-your-images).
</pre></div>
</div>
<p>We recommend the well-know Linux package <a class="reference external" href="https://imagemagick.org/">ImageMagick</a> for resizing
graphics.</p>
<p>!!! example ‚ÄúResize image using ImageMagick‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The command

```console
marie@local$ magick cluster.jpeg -resize 600 cluster_600.jpeg
```

will resize the graphic `cluster.jpeg` to a width of 600 pixels keeping the aspect ratio.
Depending on the resolution of the original file, the resulting file can be way smaller in terms
of memory foot print.
</pre></div>
</div>
<p>Nevertheless you can explicitly specify the size a graphic. The syntax is as follows</p>
<div class="highlight-markdown notranslate"><div class="highlight"><pre><span></span>![<span class="nt">Alternative text</span>](<span class="na">misc/graphics_file.png</span>){: style=&quot;width:150px&quot;}
</pre></div>
</div>
<p>By default, graphics are left-aligned. In most cases, this is not elegant and you probably wish to
center-align your graphics. <strong>Alignment</strong> of graphics can be controlled via the <code class="docutils literal notranslate"><span class="pre">{:</span> <span class="pre">align=&lt;value&gt;}</span></code>
attribute. Possible values are <code class="docutils literal notranslate"><span class="pre">left</span></code>, <code class="docutils literal notranslate"><span class="pre">right</span></code> and <code class="docutils literal notranslate"><span class="pre">center</span></code>. <strong>Note:</strong> It is crucial to
have <code class="docutils literal notranslate"><span class="pre">{:</span> <span class="pre">align=center}</span></code> on a new line and the value without quotation marks.</p>
<p>Resize and alignment specification can be combined as depicted in the following example.</p>
<p>!!! example ‚ÄúResize image to 150px width and specify alignment‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The three tabs show the Markdown syntax to resize the image of the beautiful
[cluster `Barnard`](../jobs_and_resources/hardware_overview.md#barnard) to a height of 150
pixels keeping the aspect ratio and left, center and right-align it, respectively.

=== &quot;Scale and default-align&quot;

    ```markdown
    ![Beauty Barnard](misc/barnard.jpeg){: style=&quot;height:150px&quot;}
    ```

    ![Beauty Barnard](misc/barnard.jpeg){: style=&quot;height:150px&quot;}

=== &quot;Scale and center-align&quot;

    ```markdown
    ![Beauty Barnard](misc/barnard.jpeg){: style=&quot;height:150px&quot;}
    {: align=&quot;center&quot;}
    ```

    ![Beauty Barnard](misc/barnard.jpeg){: style=&quot;height:150px&quot;}
    {: align=&quot;center&quot;}

=== &quot;Scale and right-align&quot;

    ```markdown
    ![Beauty Barnard](misc/barnard.jpeg){: style=&quot;height:150px&quot;}
    {: align=&quot;right&quot;}
    ```

    ![Alternative text](misc/barnard.jpeg){: style=&quot;height:150px&quot;}
    {: align=&quot;right&quot;}
</pre></div>
</div>
</section>
</section>
<section id="special-feature-admonitions">
<h4>Special Feature: Admonitions<a class="headerlink" href="#special-feature-admonitions" title="Permalink to this heading">#</a></h4>
<p><a class="reference external" href="https://squidfunk.github.io/mkdocs-material/reference/admonitions/">Admonitions</a>, also known as
call-outs, may be actively used to highlight examples, warnings, tips, important information, etc.
Admonitions are an excellent choice for including side content without significantly interrupting
the document flow.</p>
<p>Several different admonitions are available within the used
<a class="reference external" href="https://squidfunk.github.io/mkdocs-material/">material theme</a>, e.g., <code class="docutils literal notranslate"><span class="pre">note</span></code>, <code class="docutils literal notranslate"><span class="pre">info</span></code>, <code class="docutils literal notranslate"><span class="pre">example</span></code>,
<code class="docutils literal notranslate"><span class="pre">tip</span></code>, <code class="docutils literal notranslate"><span class="pre">warning</span></code>, and <code class="docutils literal notranslate"><span class="pre">cite</span></code>. Please refer to the
<a class="reference external" href="https://squidfunk.github.io/mkdocs-material/reference/admonitions/#supported-types">documentation page</a>
for a comprehensive overview.</p>
<p>!!! example ‚ÄúSyntax‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>All admonitions blocks start with `!!! &lt;type&gt;` and the following content block is indented by
(exactly) four spaces.
If no title is provided, the title corresponds to the admonition type.

```markdown
!!! note &quot;Descriptive title&quot;

    Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod
    tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At
    vero eos et accusam et justo duo dolores et ea rebum.
```
</pre></div>
</div>
<p>!!! note Folding</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Admonitions can be made foldable by using `???` instead of `!!!`. A small toggle on the right
side is displayed. The block is open by default if `???+` is used. Long code examples should be
folded by default.
</pre></div>
</div>
</section>
</section>
<section id="spelling-and-technical-wording">
<h3>Spelling and Technical Wording<a class="headerlink" href="#spelling-and-technical-wording" title="Permalink to this heading">#</a></h3>
<p>To provide consistent and high-quality documentation, and help users to find the right pages,
there is a list of conventions w.r.t. spelling and technical wording.</p>
<ul class="simple">
<li><p>Language settings: en_us</p></li>
</ul>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Do</p></th>
<th class="head"><p>Don‚Äôt</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>I/O</p></td>
<td><p>IO</p></td>
</tr>
<tr class="row-odd"><td><p>Slurm</p></td>
<td><p>SLURM</p></td>
</tr>
<tr class="row-even"><td><p>filesystem(s)</p></td>
<td><p>file system(s)</p></td>
</tr>
<tr class="row-odd"><td><p>ZIH system(s)</p></td>
<td><p>Taurus, HRSK II, our HPC systems, etc.</p></td>
</tr>
<tr class="row-even"><td><p>workspace</p></td>
<td><p>work space</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>HPC-DA</p></td>
</tr>
<tr class="row-even"><td><p>cluster <code class="docutils literal notranslate"><span class="pre">romeo</span></code></p></td>
<td><p>ROMEO cluster, romeo cluster, <code class="docutils literal notranslate"><span class="pre">romeo</span></code> cluster, ‚Äúromeo‚Äù cluster, etc.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="code-blocks-and-command-prompts">
<h3>Code Blocks and Command Prompts<a class="headerlink" href="#code-blocks-and-command-prompts" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Use ticks to mark code blocks and commands, not an italic font.</p></li>
<li><p>Specify language for code blocks (<span class="xref myst">see below</span>).</p></li>
<li><p>All code blocks and commands should be runnable from a login node or a node within a specific
cluster (e.g., <code class="docutils literal notranslate"><span class="pre">alpha</span></code>).</p></li>
<li><p>It should be clear from the <span class="xref myst">prompt</span>, where the command is run (e.g., local
machine, login node, or specific cluster).</p></li>
</ul>
<section id="code-blocks-and-syntax-highlighting">
<h4>Code Blocks and Syntax Highlighting<a class="headerlink" href="#code-blocks-and-syntax-highlighting" title="Permalink to this heading">#</a></h4>
<p>Providing code blocks and snippets is the meat and bones of this documentation.
Code blocks and command examples should give the general idea of invocation and be as precise as
possible, i.e., allowing for copy-and-paste. Please mark replaceable code parts and optional and
required arguments as outlined in the section <span class="xref myst">required and optional arguments</span>
below. Long, non-meaningful output should be omitted.</p>
<p>We make use of the extension
<a class="reference external" href="https://squidfunk.github.io/mkdocs-material/reference/code-blocks/">pymdownx.highlight</a> for syntax
highlighting. There is a complete list of supported
<a class="reference external" href="https://pygments.org/docs/lexers/">language short codes</a>.</p>
<p>??? note ‚ÄúSyntax for command line‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>For normal commands executed in the terminal, use the language short code `console`.

````markdown
```console
marie@login$ module list
[...]
```
````
</pre></div>
</div>
<p>??? note ‚ÄúSyntax for job files and scripts‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Use the language short code `bash` for job files and shell scripts.

````markdown
```bash
#!/bin/bash
#SBATCH --nodes=1
#SBATCH --time=01:00:00
#SBATCH --output=slurm-%j.out

module load foss

srun a.out
```
````
</pre></div>
</div>
<p>??? note ‚ÄúSyntax for Python‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>`python` for Python source code:

````markdown
```python
from time import gmtime, strftime
print(strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, gmtime()))
```
````

And `pycon` for Python console:

````markdown
```pycon
&gt;&gt;&gt; from time import gmtime, strftime
&gt;&gt;&gt; print(strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, gmtime()))
2021-08-03 07:20:33
```
````
</pre></div>
</div>
<p>??? note ‚ÄúLine numbers‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>More sugar can be applied by adding line numbers.

````markdown
```bash linenums=&quot;1&quot;
#!/bin/bash

#SBATCH --nodes=1
#SBATCH --ntasks=23
#SBATCH --time=02:10:00

srun a.out
```
````

_Result_:

![lines](misc/lines.png)

Specific Lines can be highlighted by using

````markdown
```bash hl_lines=&quot;2 3&quot;
#!/bin/bash

#SBATCH --nodes=1
#SBATCH --ntasks=23
#SBATCH --time=02:10:00

srun a.out
```
````

_Result_:

![lines](misc/highlight_lines.png)
</pre></div>
</div>
</section>
<section id="data-privacy-and-generic-names">
<h4>Data Privacy and Generic Names<a class="headerlink" href="#data-privacy-and-generic-names" title="Permalink to this heading">#</a></h4>
<p>Where possible, replace login, project name, and other private data with clearly recognizable
placeholders. In particular, use the generic placeholders depicted in the following table.
The table also holds a second placeholder, if, e.g., you need a second login to formulate an example.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Description</p></th>
<th class="head"><p>Placeholder</p></th>
<th class="head"><p>2nd Placeholder</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Username</p></td>
<td><p>Marie</p></td>
<td><p>Martin</p></td>
</tr>
<tr class="row-odd"><td><p>Login</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">marie</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">martin</span></code></p></td>
</tr>
<tr class="row-even"><td><p>E-mail</p></td>
<td><p><a class="reference external" href="mailto:marie&#37;&#52;&#48;tu-dresden&#46;de">marie<span>&#64;</span>tu-dresden<span>&#46;</span>de</a></p></td>
<td><p><a class="reference external" href="mailto:martin&#37;&#52;&#48;tu-dresden&#46;de">martin<span>&#64;</span>tu-dresden<span>&#46;</span>de</a></p></td>
</tr>
<tr class="row-odd"><td><p>Project title</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">p_number_crunch</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">p_long_computations</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Workspace title</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">number_crunch</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">long_computations</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Job ID</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">123456</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">456789</span></code></p></td>
</tr>
<tr class="row-even"><td><p>{: summary=‚ÄùGeneric placeholders‚Äù, align=‚Äùbottom‚Äù}</p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p>!!! example ‚ÄúOutput of <code class="docutils literal notranslate"><span class="pre">ls</span></code> command‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The following code listing depicts the usage of the generic user names and projects as well as
recognizable placeholders for files and directory names.

```console
marie@login$ ls -l
drwxr-xr-x   3 marie p_number_crunch      4096 Jan 24  2020 code
drwxr-xr-x   3 marie p_number_crunch      4096 Feb 12  2020 data
-rw-rw----   1 marie p_number_crunch      4096 Jan 24  2020 readme.md
```
</pre></div>
</div>
<p>!!! info ‚ÄúMarie‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>We choose *marie* as generic login and placeholder. There is no magic story on this decision.
Feel free to associate this generic login for example with
physicist and chemist [Marie Curie](https://en.wikipedia.org/wiki/Marie_Curie),
and [Marianne](https://en.wikipedia.org/wiki/Marianne), symbol of France standing for liberty,
equality and fraternity.

The very same holds for the generic login *martin*.
</pre></div>
</div>
</section>
<section id="placeholders">
<h4>Placeholders<a class="headerlink" href="#placeholders" title="Permalink to this heading">#</a></h4>
<p>Placeholders represent arguments or code parts that can be adapted to the user‚Äôs needs. Use them to
give a general idea of how a command or code snippet can be used, e. g. to explain the meaning of
some command argument:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@login$<span class="w"> </span>sacct<span class="w"> </span>-j<span class="w"> </span>&lt;job<span class="w"> </span>id&gt;
</pre></div>
</div>
<p>Here, a placeholder explains the intention better than just a specific value:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>sacct<span class="w"> </span>-j<span class="w"> </span><span class="m">4041337</span>
</pre></div>
</div>
<p>Please be aware, that a reader often understands placeholders easier if you also give an example.
Therefore, always add an example!</p>
</section>
<section id="mark-omissions">
<h4>Mark Omissions<a class="headerlink" href="#mark-omissions" title="Permalink to this heading">#</a></h4>
<p>If showing only a snippet of a long output, omissions are marked with <code class="docutils literal notranslate"><span class="pre">[...]</span></code>.</p>
</section>
<section id="code-styling-rules">
<h4>Code Styling Rules<a class="headerlink" href="#code-styling-rules" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Stick to the Unix rules on optional and required arguments, and selection of item sets:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;required</span> <span class="pre">argument</span> <span class="pre">or</span> <span class="pre">value&gt;</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[optional</span> <span class="pre">argument</span> <span class="pre">or</span> <span class="pre">value]</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">{choice1|choice2|choice3}</span></code></p></li>
</ul>
</li>
<li><p>Please use following style guidelines while writing code blocks:</p>
<ul>
<li><p>Shell: <a class="reference external" href="https://google.github.io/styleguide/shellguide.html">Shell style guide</a></p></li>
<li><p>Python: <a class="reference external" href="https://peps.python.org/pep-0008/">PEP-0008 style guide</a></p></li>
<li><p>MATLAB: <a class="reference external" href="https://www.researchgate.net/publication/316479241_Best_practices_for_scientific_computing_and_MATLAB_programming_style_guidelines">MATLAB programming style guide</a></p></li>
<li><p>R: <a class="reference external" href="https://google.github.io/styleguide/Rguide.html">R style guide</a></p></li>
<li><p>C++: <a class="reference external" href="https://google.github.io/styleguide/cppguide.html">C++ style guide</a></p></li>
<li><p>Java: <a class="reference external" href="https://google.github.io/styleguide/javaguide.html">Java style guide</a></p></li>
</ul>
</li>
</ul>
</section>
<section id="list-of-prompts">
<h4>List of Prompts<a class="headerlink" href="#list-of-prompts" title="Permalink to this heading">#</a></h4>
<p>We follow these rules regarding prompts to make clear where a certain command or example is executed.
This should help to avoid errors.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Host/Partition</p></th>
<th class="head"><p>Prompt</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Localhost</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">marie&#64;local$</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Login nodes</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">marie&#64;login$</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Arbitrary compute node</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">marie&#64;compute$</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Compute node <code class="docutils literal notranslate"><span class="pre">Capella</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">marie&#64;capella$</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Login node <code class="docutils literal notranslate"><span class="pre">Capella</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">marie&#64;login.capella$</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Compute node <code class="docutils literal notranslate"><span class="pre">Barnard</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">marie&#64;barnard$</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Login node <code class="docutils literal notranslate"><span class="pre">Barnard</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">marie&#64;login.barnard$</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Compute node <code class="docutils literal notranslate"><span class="pre">Alpha</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">marie&#64;alpha$</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Login node <code class="docutils literal notranslate"><span class="pre">Alpha</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">marie&#64;login.alpha$</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Node <code class="docutils literal notranslate"><span class="pre">Julia</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">marie&#64;julia$</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Compute node <code class="docutils literal notranslate"><span class="pre">Romeo</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">marie&#64;romeo$</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Login node <code class="docutils literal notranslate"><span class="pre">Romeo</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">marie&#64;login.romeo$</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Compute node <code class="docutils literal notranslate"><span class="pre">Power9</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">marie&#64;power9$</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Login node <code class="docutils literal notranslate"><span class="pre">Power9</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">marie&#64;login.power9$</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Partition <code class="docutils literal notranslate"><span class="pre">dcv</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">marie&#64;dcv$</span></code></p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p><strong>Always use a prompt</strong>, even if there is no output provided for the shown command.</p></li>
<li><p>All code blocks which specify some general command templates, e.g. containing <code class="docutils literal notranslate"><span class="pre">&lt;</span></code> and <code class="docutils literal notranslate"><span class="pre">&gt;</span></code>
(see <span class="xref myst">placeholders</span> and <span class="xref myst">Code Styling Rules</span>), should use
<code class="docutils literal notranslate"><span class="pre">bash</span></code> for the code block. Additionally, an example invocation, perhaps with output, should be
given with the normal <code class="docutils literal notranslate"><span class="pre">console</span></code> code block. See also
<span class="xref myst">Code Block description below</span>.</p></li>
<li><p>Using some magic, the prompt as well as the output is identified and will not be copied!</p></li>
<li><p>Stick to the <span class="xref myst">generic user name</span> <code class="docutils literal notranslate"><span class="pre">marie</span></code>.</p></li>
</ul>
</section>
<section id="long-options">
<h4>Long Options<a class="headerlink" href="#long-options" title="Permalink to this heading">#</a></h4>
<p>The general rule is to provide long over short parameter names where possible to ease
understanding. This holds especially for Slurm options, but also other commands.</p>
<p>??? example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>| Do | Don&#39;t |
|----|-------|
| `srun --nodes=2 --ntasks-per-node=4 [...]`| `srun -N 2 -n 4 [...]` |
| `module load [...]` | `ml [...]` |
</pre></div>
</div>
</section>
<section id="equal-signs-in-command-line-options">
<h4>Equal Signs in Command-Line Options<a class="headerlink" href="#equal-signs-in-command-line-options" title="Permalink to this heading">#</a></h4>
<p>Some tools with CLI (command-line interface) prefer specification of the argument with an equal
sign (<code class="docutils literal notranslate"><span class="pre">=</span></code>) between the option name and the value, e.g. <code class="docutils literal notranslate"><span class="pre">--long_option=value</span></code>. Others prefer a
whitespace, e.g. <code class="docutils literal notranslate"><span class="pre">--long_option</span> <span class="pre">value</span></code>. We respect the design decisions of the tool
developers and document the desired mimic for <span class="xref myst">long options</span>. If you are in doubt,
calling <code class="docutils literal notranslate"><span class="pre">tool</span> <span class="pre">--help</span></code> might provide the answer.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Tool</p></th>
<th class="head"><p>Preference</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Slurm</p></td>
<td><p>w/ Equal sign</p></td>
</tr>
<tr class="row-odd"><td><p>HPC-Workspace</p></td>
<td><p>w/o equal sign</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="customize-search">
<h3>Customize Search<a class="headerlink" href="#customize-search" title="Permalink to this heading">#</a></h3>
<p>The
<a class="reference external" href="https://squidfunk.github.io/mkdocs-material/setup/setting-up-site-search/">documentation for the search plugin</a>
of the material theme is quite comprehensive. The search is realized as client-side search using the
open-source tool on <a class="reference external" href="https://lunrjs.com/">lunr</a>. The ranking of pages in search results bases on
so-called scoring. Please refer to
<a class="reference external" href="https://lunrjs.com/guides/searching.html#scoring">lunrjs documentation</a> for details.</p>
<p>From time to time it might be necessary to <strong>tweak the search priority of certain pages</strong>.
For example, pages from the archive section should be ranked very low in search results. This can be
achieved by adding the front matter <code class="docutils literal notranslate"><span class="pre">search.boost</span></code> property added to the top of the Markdown file of
interest:</p>
<div class="highlight-Markdown notranslate"><div class="highlight"><pre><span></span>---
search:
<span class="gu">  boost: 2</span>
<span class="gu">---</span>

<span class="gh"># Document Title</span>

[...]
</pre></div>
</div>
<p>The documentation of this plugin gives no range for the boost values. We recommend to use this
feature carefully starting with low values.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="contribute-via-browser">
<h1>Contribute via Browser<a class="headerlink" href="#contribute-via-browser" title="Permalink to this heading">#</a></h1>
<p>In the following, it is outlined how to contribute to the
<a class="reference external" href="https://compendium.hpc.tu-dresden.de/">HPC documentation</a> of
<a class="reference external" href="https://tu-dresden.de/zih/">TU Dresden/ZIH</a> by means of GitLab‚Äôs web interface using a standard web
browser only.</p>
<section id="preparation">
<h2>Preparation<a class="headerlink" href="#preparation" title="Permalink to this heading">#</a></h2>
<p>First of all, you need an account on <a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de">gitlab.hrz.tu-chemnitz.de</a>.
Secondly, you need access to the project
<a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/zih/hpcsupport/hpc-compendium">ZIH/hpcsupport/hpc-compendium</a>.</p>
<p>The project is publicly visible, i.e., it is open to the world and any signed-in user has the
<a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/help/user/permissions.md">Guest role</a> on this repository. Guests
have only very
<a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/help/user/permissions.md#project-members-permissions">limited permissions</a>.
In particular, as guest, you can contribute to the documentation by
<span class="xref myst">creating issues</span>, but you cannot edit files and create
new branches.</p>
<p>To be granted the role <strong>Developer</strong>, please request access by clicking the corresponding button.</p>
<p><img alt="Request access to the repository" src="63_chat_with_docs/misc/request_access.png" /></p>
<p>Once you are granted the developer role, choose ‚ÄúZIH/hpcsupport/hpc-compendium‚Äù in your project list.</p>
<p>!!! hint ‚ÄúGit basics‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you are not familiar with the basics of Git-based document revision control yet, please have
a look at [GitLab tutorials](https://docs.gitlab.com/ee/tutorials/).
</pre></div>
</div>
</section>
<section id="create-a-branch">
<h2>Create a Branch<a class="headerlink" href="#create-a-branch" title="Permalink to this heading">#</a></h2>
<p>Your contribution starts by creating your own branch of the repository that will hold your edits and
additions. Create your branch by clicking on ‚Äú+‚Äù near ‚Äúpreview-&gt;hpc-compendium/‚Äù as depicted in
the figure and click ‚ÄúNew branch‚Äù.</p>
<p><img alt="create new branch" src="63_chat_with_docs/misc/cb_create_new_branch.png" /></p>
<p>By default, the new branch should be created from the <code class="docutils literal notranslate"><span class="pre">preview</span></code> branch, as pre-selected.</p>
<p>Define a branch name that briefly describes what you plan to change, e.g., <code class="docutils literal notranslate"><span class="pre">edits-in-document-xyz</span></code>.
Then, click on ‚ÄúCreate branch‚Äù as depicted in this figure:</p>
<p><img alt="set branch name" src="63_chat_with_docs/misc/cb_set_branch_name.png" /></p>
<p>As a result, you should now see your branch‚Äôs name on top of your list of repository files as
depicted here:</p>
<p><img alt="branch indicator" src="63_chat_with_docs/misc/cb_branch_indicator.png" /></p>
</section>
<section id="editing-existing-articles">
<h2>Editing Existing Articles<a class="headerlink" href="#editing-existing-articles" title="Permalink to this heading">#</a></h2>
<p>Navigate the depicted document hierarchy under <code class="docutils literal notranslate"><span class="pre">doc.zih.tu-dresden.de/docs</span></code> until you find the
article to be edited. A click on the article‚Äôs name opens a textual representation of the article.
In the top right corner of it, you find the button ‚ÄúEdit‚Äù to be clicked in order to make changes.
Once you completed your changes, click on ‚ÄúCommit changes‚Äù. Please add meaningful comment about the
changes you made under ‚ÄúCommit message‚Äù. Feel free to do as many changes and commits as you wish in
your branch of the repository.</p>
</section>
<section id="adding-new-article">
<h2>Adding New Article<a class="headerlink" href="#adding-new-article" title="Permalink to this heading">#</a></h2>
<p>Navigate the depicted document hierarchy under <code class="docutils literal notranslate"><span class="pre">doc.zih.tu-dresden.de/docs</span></code> to find a topic that
fits best to your article. To start a completely new article, click on ‚Äú+ New file‚Äù as depicted
here:</p>
<p><img alt="create new file" src="63_chat_with_docs/misc/cb_create_new_file.png" /></p>
<p>Set a file name that corresponds well to your article like <code class="docutils literal notranslate"><span class="pre">application_xyz.md</span></code>.
(The file name should follow the pattern <code class="docutils literal notranslate"><span class="pre">fancy_title_and_more.md</span></code>.)
Once you completed your initial edits, click on ‚Äúcommit‚Äù.</p>
<p><img alt="commit new file" src="63_chat_with_docs/misc/cb_commit_file.png" /></p>
<p>Finally, the new article needs to be added to the navigation section of the configuration file
<code class="docutils literal notranslate"><span class="pre">doc.zih.tu-dresden.de/mkdocs.yaml</span></code>.</p>
</section>
<section id="submitting-articles-for-publication">
<h2>Submitting Articles for Publication<a class="headerlink" href="#submitting-articles-for-publication" title="Permalink to this heading">#</a></h2>
<p>Once you are satisfied with your edits, you are ready for publication.
Therefore, your edits need to undergo an internal review process and pass the CI/CD pipeline tests.
This process is triggered by creating a ‚Äúmerge request‚Äù, which serves the purpose of merging your edits
into the <code class="docutils literal notranslate"><span class="pre">preview</span></code> branch of the repository.</p>
<ul class="simple">
<li><p>Click on ‚ÄúMerge requests‚Äù (in the menu to the left) as depicted below.</p></li>
<li><p>Then, click on the button ‚ÄúNew merge request‚Äù.</p></li>
<li><p>Select your source branch (for example <code class="docutils literal notranslate"><span class="pre">edits-in-document-xyz</span></code>) and click on ‚ÄúCompare branches and
continue‚Äù. (The target branch is always <code class="docutils literal notranslate"><span class="pre">preview</span></code>. This is pre-selected - do not change!)</p></li>
<li><p>The next screen will give you an overview of your changes. Please provide a meaningful
description of the contributions. Once you checked them, click on ‚ÄúCreate merge request‚Äù.</p></li>
</ul>
<p><img alt="new merge request" src="63_chat_with_docs/misc/cb_new_merge_request.png" /></p>
</section>
<section id="revision-of-articles">
<h2>Revision of Articles<a class="headerlink" href="#revision-of-articles" title="Permalink to this heading">#</a></h2>
<p>As stated earlier, all changes undergo a review process.
This covers automated checks contained in the CI/CD pipeline and the review by a maintainer.
This is to ensure the quality of all contributions, e. g. by checking our
<span class="xref myst">content rules</span>.
You can follow this process under
<a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/zih/hpcsupport/hpc-compendium/-/merge_requests">Merge requests</a>
(where you initiated your merge request).
If you are asked to make corrections or changes, follow the directions as indicated.
Once your merge request has been accepted, the merge request will be closed and the branch will be deleted.
At this point, there is nothing else to do for you.
Except probably for waiting a little while until your changes become visible on the official web site.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="contribute-via-local-clone">
<h1>Contribute via Local Clone<a class="headerlink" href="#contribute-via-local-clone" title="Permalink to this heading">#</a></h1>
<p>In the following, it is outlined how to contribute to the
<a class="reference external" href="https://compendium.hpc.tu-dresden.de/">HPC documentation</a> of
<a class="reference external" href="https://tu-dresden.de/zih/">TU Dresden/ZIH</a> via a local clone of the Git repository. Although, this
document might seem very long describing complex steps, contributing is quite easy - trust us.</p>
<section id="initial-setup-of-your-local-clone">
<h2>Initial Setup of your Local Clone<a class="headerlink" href="#initial-setup-of-your-local-clone" title="Permalink to this heading">#</a></h2>
<p>Please follow this standard Git procedure for working with a local clone:</p>
<ol class="arabic simple">
<li><p>Fork the project on
<a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/zih/hpcsupport/hpc-compendium">https://gitlab.hrz.tu-chemnitz.de/zih/hpcsupport/hpc-compendium</a>
or request access to the project.</p></li>
<li><p>Change to a local (unencrypted) filesystem. (We have seen problems running the container on an
ecryptfs filesystem. So you might want to use e.g. <code class="docutils literal notranslate"><span class="pre">/tmp</span></code> as the start directory.)</p></li>
<li><p>Clone the Git repository:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">clone</span> <span class="pre">git&#64;gitlab.hrz.tu-chemnitz.de:zih/hpcsupport/hpc-compendium.git</span></code></p></li>
<li><p>If you forked the repository, instead use:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">clone</span> <span class="pre">git&#64;gitlab.hrz.tu-chemnitz.de:&lt;YOUR_LOGIN&gt;/hpc-compendium.git</span></code></p></li>
</ul>
</li>
</ol>
</li>
<li><p>Change into the new directory:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cd</span> <span class="pre">hpc-compendium</span></code></p></li>
</ul>
</li>
<li><p>If you forked the repository, add the original repository as a so-called remote:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">remote</span> <span class="pre">add</span> <span class="pre">upstream-zih</span> <span class="pre">git&#64;gitlab.hrz.tu-chemnitz.de:zih/hpcsupport/hpc-compendium.git</span></code></p></li>
</ul>
</li>
</ol>
</section>
<section id="working-with-your-local-clone">
<h2>Working with your Local Clone<a class="headerlink" href="#working-with-your-local-clone" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Whenever you start working on an issue, first make sure that your local data is up to date:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">checkout</span> <span class="pre">preview</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">pull</span> <span class="pre">origin</span> <span class="pre">preview</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">pull</span> <span class="pre">upstream-zih</span> <span class="pre">preview</span></code> (only required when you forked the project)</p></li>
</ol>
</li>
<li><p>Create a new feature branch for you to work in. Ideally, name it like the file you want to
modify or the issue you want to work on, e.g.:
<code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">checkout</span> <span class="pre">-b</span> <span class="pre">174-check-contribution-documentation</span></code> for issue 174 with title ‚ÄúCheck contribution
documentation‚Äù. (If you are uncertain about the name of a file, please look into <code class="docutils literal notranslate"><span class="pre">mkdocs.yaml</span></code>.)</p></li>
<li><p>Improve the documentation with your preferred editor, i.e. add new files and correct mistakes.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">add</span> <span class="pre">&lt;FILE&gt;</span></code> to select your improvements for the next commit.</p></li>
<li><p>Commit the changes with <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">commit</span> <span class="pre">-m</span> <span class="pre">&quot;&lt;DESCRIPTION&gt;&quot;</span></code>. The description should be a meaningful
description of your changes. If you work on an issue, please also add ‚ÄúCloses 174‚Äù (for issue 174).</p></li>
<li><p>Push the local changes to the GitLab server, e.g. with
<code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">push</span> <span class="pre">origin</span> <span class="pre">174-check-contribution-documentation</span></code>.</p></li>
<li><p>As an output you get a link to create a merge request against the preview branch.</p></li>
<li><p>When the merge request is created, a continuous integration (CI) pipeline automatically checks
your contributions. If you forked the repository, these automatic checks are not available, but you
can <span class="xref myst">run checks locally</span>.</p></li>
</ol>
<p>!!! tip</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>When you contribute, please follow our [content rules](content_rules.md) to make incorporating
your changes easy. We also check these rules via continuous integration checks and/or reviews.
You can find the details and commands to [preview your changes](#start-the-local-web-server) and
[apply checks](#run-the-proposed-checks-inside-container).
</pre></div>
</div>
</section>
<section id="merging-of-forked-repositories">
<h2>Merging of Forked Repositories<a class="headerlink" href="#merging-of-forked-repositories" title="Permalink to this heading">#</a></h2>
<p>When you have forked the repository as mentioned above, the process for merging is a bit different
from internal merge requests. Because branches of forks are not automatically checked by CI,
someone with at least developer access needs to do some more steps to incorporate the changes of
your MR:</p>
<ol class="arabic simple">
<li><p>The developer informs you about the start of merging process.</p></li>
<li><p>The developer needs to review your changes to make sure that your changes are specific and don‚Äôt introduce
problems, such as changes in the Dockerfile or any script could.</p></li>
<li><p>The developer needs to create a branch in our repository. Let‚Äôs call this ‚Äúinternal MR branch‚Äù.</p></li>
<li><p>The developer needs to change the target branch of your MR from ‚Äúpreview‚Äù to ‚Äúinternal MR branch‚Äù.</p></li>
<li><p>The developer needs to merge it.</p></li>
<li><p>The developer needs to open another MR from ‚Äúinternal MR branch‚Äù to ‚Äúpreview‚Äù to check whether
the changes pass the CI checks.</p></li>
<li><p>The developer needs to fix things that were found by CI.</p></li>
<li><p>The developer informs you about the MR or asks for your support while fixing the CI.</p></li>
</ol>
<p>When you follow our <span class="xref myst">content rules</span> and
<span class="xref myst">run checks locally</span>, you are making this process
faster.</p>
</section>
<section id="tools-to-ensure-quality">
<h2>Tools to Ensure Quality<a class="headerlink" href="#tools-to-ensure-quality" title="Permalink to this heading">#</a></h2>
<p>Assuming you already have a working Docker installation and have cloned the repository as mentioned
above, a few more steps are necessary.</p>
<p>Build the Docker image. This might take a bit longer, as <code class="docutils literal notranslate"><span class="pre">mkdocs</span></code> and other necessary software
needs to be downloaded, but you have to run it only once in a while.
Building a container could be done with the following steps:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span><span class="nb">cd</span><span class="w"> </span>hpc-compendium
<span class="gp">marie@local$ </span>doc.zih.tu-dresden.de/util/download-newest-mermaid.js.sh
<span class="gp">marie@local$ </span>docker<span class="w"> </span>build<span class="w"> </span>-t<span class="w"> </span>hpc-compendium<span class="w"> </span>.
</pre></div>
</div>
<p>To avoid a lot of retyping, set the following Git aliases once inside your local Git clone:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>git<span class="w"> </span>config<span class="w"> </span>alias.wikiscript<span class="w"> </span><span class="s1">&#39;!docker run --name=hpc-compendium --rm -w /docs --mount src=${PWD},target=/docs,type=bind hpc-compendium&#39;</span>
<span class="gp">marie@local$ </span>git<span class="w"> </span>config<span class="w"> </span>alias.wiki<span class="w"> </span><span class="s1">&#39;!docker run --name=hpc-compendium -p 8000:8000 --rm -w /docs --mount src=${PWD}/doc.zih.tu-dresden.de,target=/docs,type=bind hpc-compendium&#39;</span>
</pre></div>
</div>
</section>
<section id="working-with-the-docker-container">
<h2>Working with the Docker Container<a class="headerlink" href="#working-with-the-docker-container" title="Permalink to this heading">#</a></h2>
<p>Here is a suggestion of a workflow which might be suitable for you.</p>
<section id="start-the-local-web-server">
<h3>Start the Local Web Server<a class="headerlink" href="#start-the-local-web-server" title="Permalink to this heading">#</a></h3>
<p>The command(s) to start the dockerized web server is this:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>git<span class="w"> </span>wiki<span class="w"> </span>mkdocs<span class="w"> </span>serve<span class="w"> </span>-a<span class="w"> </span><span class="m">0</span>.0.0.0:8000
</pre></div>
</div>
<p>You can view the documentation via <code class="docutils literal notranslate"><span class="pre">http://localhost:8000</span></code> in your browser, now.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>You can keep the local web server running in this shell to always have the opportunity to see
the result of your changes in the browser. Simply open another terminal window for other
commands.
If you cannot see the page in your browser, check if you can get the URL for your browser&#39;s
address bar from a different terminal window:

```console
marie@local$ echo http://$(docker inspect -f &quot;{{.NetworkSettings.IPAddress}}&quot; $(docker ps -qf &quot;name=hpc-compendium&quot;)):8000
```
</pre></div>
</div>
<p>You can now update the contents in you preferred editor. The running container automatically takes
care of file changes and rebuilds the documentation whenever you save a file.</p>
<p>With the details described below, it will then be easy to follow the guidelines for local
correctness checks before submitting your changes and requesting the merge.</p>
</section>
<section id="run-the-proposed-checks-inside-container">
<h3>Run the Proposed Checks Inside Container<a class="headerlink" href="#run-the-proposed-checks-inside-container" title="Permalink to this heading">#</a></h3>
<p>In our continuous integration (CI) pipeline, a merge request triggers the automated check of</p>
<ul class="simple">
<li><p>correct links,</p></li>
<li><p>correct spelling,</p></li>
<li><p>correct text format.</p></li>
</ul>
<p>These checks ensure a high quality and consistency of the content and follow our
<span class="xref myst">content rules</span>. If one of them fails, the merge request will not be accepted. To
prevent this, you can run these checks locally and adapt your files accordingly.</p>
<p>You are now ready to use the different checks, however we suggest to try the pre-commit hook.</p>
<section id="pre-commit-git-hook">
<h4>Pre-commit Git Hook<a class="headerlink" href="#pre-commit-git-hook" title="Permalink to this heading">#</a></h4>
<p>We have several checks on the Markdown sources to ensure for a consistent and high quality of the
documentation. We recommend to automatically run checks whenever you try to commit a change. In this
case, failing checks prevent commits (unless you use option <code class="docutils literal notranslate"><span class="pre">--no-verify</span></code>). This can be accomplished
by adding a pre-commit hook to your local clone of the repository. The following code snippet shows
how to do that:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>cp<span class="w"> </span>doc.zih.tu-dresden.de/util/pre-commit<span class="w"> </span>.git/hooks/
</pre></div>
</div>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The pre-commit hook only works, if you can use Docker without using `sudo`. If this is not
already the case, use the command `adduser $USER docker` to enable Docker commands without
`sudo` for the current user. Restart the Docker daemons afterwards.
</pre></div>
</div>
<p>Read on if you want to run a specific check.</p>
</section>
<section id="linter">
<h4>Linter<a class="headerlink" href="#linter" title="Permalink to this heading">#</a></h4>
<p>If you want to check whether the Markdown files are formatted properly, use the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>git<span class="w"> </span>wiki<span class="w"> </span>markdownlint<span class="w"> </span>docs
</pre></div>
</div>
</section>
<section id="spell-checker">
<h4>Spell Checker<a class="headerlink" href="#spell-checker" title="Permalink to this heading">#</a></h4>
<p>For spell-checking a single file, e.g.
<code class="docutils literal notranslate"><span class="pre">doc.zih.tu-dresden.de/docs/software/big_data_frameworks.md</span></code>, use:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>git<span class="w"> </span>wikiscript<span class="w"> </span>doc.zih.tu-dresden.de/util/check-spelling.sh<span class="w"> </span>doc.zih.tu-dresden.de/docs/software/big_data_frameworks.md
</pre></div>
</div>
<p>For spell-checking all files, use:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>git<span class="w"> </span>wikiscript<span class="w"> </span>doc.zih.tu-dresden.de/util/check-spelling.sh<span class="w"> </span>-a
</pre></div>
</div>
<p>This outputs all words of all files that are unknown to the spell checker.
To let the spell checker ‚Äúknow‚Äù a word, append it to
<code class="docutils literal notranslate"><span class="pre">doc.zih.tu-dresden.de/wordlist.aspell</span></code>.</p>
</section>
<section id="check-pages-structure">
<h4>Check Pages Structure<a class="headerlink" href="#check-pages-structure" title="Permalink to this heading">#</a></h4>
<p>The script <code class="docutils literal notranslate"><span class="pre">util/check-no-floating.sh</span></code> first checks the hierarchy depth of the pages structure and
the second check tests if every Markdown file is included in the navigation section of the
<code class="docutils literal notranslate"><span class="pre">mkdocs.yaml</span></code> file. Invoke it as follows:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>git<span class="w"> </span>wikiscript<span class="w"> </span>doc.zih.tu-dresden.de/util/check-no-floating.sh<span class="w"> </span>doc.zih.tu-dresden.de
</pre></div>
</div>
</section>
<section id="link-checker">
<h4>Link Checker<a class="headerlink" href="#link-checker" title="Permalink to this heading">#</a></h4>
<p>!!! quote ‚ÄúUnknown programmer‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>No one likes dead links.
</pre></div>
</div>
<p>Therefore, we check the internal and external links within the Markdown source files.
With the script <code class="docutils literal notranslate"><span class="pre">doc.zih.tu-dresden.de/util/check-links.sh</span></code>, you can either check
<span class="xref myst">a single file</span>, <span class="xref myst">all modified files</span> or
<span class="xref myst">all files</span> of the compendium.</p>
<section id="single-file">
<h5>Single File<a class="headerlink" href="#single-file" title="Permalink to this heading">#</a></h5>
<p>To check the links within a single file, e.g.
<code class="docutils literal notranslate"><span class="pre">doc.zih.tu-dresden.de/docs/software/big_data_frameworks.md</span></code>, use:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>git<span class="w"> </span>wikiscript<span class="w"> </span>doc.zih.tu-dresden.de/util/check-links.sh<span class="w"> </span>docs/software/big_data_frameworks.md
</pre></div>
</div>
</section>
<section id="all-modified-files">
<h5>All Modified Files<a class="headerlink" href="#all-modified-files" title="Permalink to this heading">#</a></h5>
<p>The script can also check the links in all modified files, i.e., Markdown files which are part
of the repository and different to the <code class="docutils literal notranslate"><span class="pre">preview</span></code> branch. Use this script before committing your
changes to make sure your commit passes the CI/CD pipeline.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>git<span class="w"> </span>wikiscript<span class="w"> </span>doc.zih.tu-dresden.de/util/check-links.sh<span class="w"> </span>-c
</pre></div>
</div>
</section>
<section id="all-files">
<h5>All Files<a class="headerlink" href="#all-files" title="Permalink to this heading">#</a></h5>
<p>Checking the links of all Markdown files takes a moment of time:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>git<span class="w"> </span>wikiscript<span class="w"> </span>doc.zih.tu-dresden.de/util/check-links.sh<span class="w"> </span>-a
</pre></div>
</div>
</section>
</section>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="how-to-contribute">
<h1>How-To Contribute<a class="headerlink" href="#how-to-contribute" title="Permalink to this heading">#</a></h1>
<p>!!! cite ‚ÄúChinese proverb‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Ink is better than the best memory.
</pre></div>
</div>
<p>In this section you will find information about the technical setup of this documentation, the
content rules that apply, the Git workflow, and specific ways to contribute.</p>
<p>Your contributions are highly welcome. This can range from fixing typos, improving the phrasing and
wording to adopting examples, command lines and adding new content. Our goal is to provide a
general, consistent and up to date documentation. Thus, it is by no means a static documentation.
Moreover, is is constantly reviewed and updated.</p>
<section id="technical-setup">
<h2>Technical Setup<a class="headerlink" href="#technical-setup" title="Permalink to this heading">#</a></h2>
<p>This documentation is written in Markdown and translated into static html pages using
<a class="reference external" href="https://www.mkdocs.org/">mkdocs</a>. The single configuration file <code class="docutils literal notranslate"><span class="pre">mkdocs.yml</span></code> contains the page
structure as well as the specification of the theme and extensions.</p>
<p>We manage all essential files (Markdown pages, graphics, configuration, theme, etc.) within a
<a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/zih/hpcsupport/hpc-compendium">public Git repository</a>,
allowing for collaborative working and revision control. GitLab‚Äôs features offer different
possibilities of contribution and ensure up-to-date and consistent content by including a review
process. There are three possible ways how you can contribute to this documentation.
These are described below.</p>
<p>!!! tip ‚ÄúBefore you start‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Before you start your very first commit, please make sure that you are familiar with our
[Git workflow](#git-workflow) and that you have at least skimmed through the
[Content Rules](content_rules.md).
</pre></div>
</div>
</section>
<section id="git-workflow">
<h2>Git Workflow<a class="headerlink" href="#git-workflow" title="Permalink to this heading">#</a></h2>
<p>We employ a so-called Git feature workflow with a development branch. In our case, the working branch
is called <code class="docutils literal notranslate"><span class="pre">preview</span></code> and is kept in parallel to the <code class="docutils literal notranslate"><span class="pre">main</span></code> branch.</p>
<p>All contributions, e.g., new content, improved wording, fixed typos, etc., are added to separate
feature branches which base on <code class="docutils literal notranslate"><span class="pre">preview</span></code>. If the contribution is ready, you will have to create a
merge request back to the <code class="docutils literal notranslate"><span class="pre">preview</span></code> branch. A member of the ZIH team will review the changes
(four-eyes principle) and finally merge your changes to <code class="docutils literal notranslate"><span class="pre">preview</span></code>. All contributions need to pass
through the CI pipeline consisting of several checks to ensure compliance with the content rules.
Please, don‚Äôt worry too much about the checks. The ZIH staff will help you with that. You can find
more information about the <span class="xref myst">CI/CD pipeline</span> in the eponymous subsection.</p>
<p>In order to publish the updates and make them visible in the compendium,
the changes on <code class="docutils literal notranslate"><span class="pre">preview</span></code> branch are either automatically merged into the <code class="docutils literal notranslate"><span class="pre">main</span></code> branch on every
Monday via a pipeline schedule, or manually by admin staff. Moreover, the <code class="docutils literal notranslate"><span class="pre">main</span></code> branch is deployed
to <a class="reference external" href="https://compendium.hpc.tu-dresden.de">https://compendium.hpc.tu-dresden.de</a> and always reflects
a production-ready state. Manual interventions are only necessary in case of merge conflicts.
This process is handled by the admins.</p>
<p>???+ note ‚ÄúGraphic on Git workflow‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The applied Git workflow is depicted in the following graphic. Here, two feature branches `foo`
and `bar` are created basing on `preview`. Three individual commits are added to branch `foo`
before it is ready and merged back to `preview`. The contributions on `bar` consist only one
commit. In the end, all contribution are merged to the `main` branch.

```mermaid
%% Issues:
%% - showCommitLabel: false does not work; workaround is to use `commit id: &quot; &quot;`%%
%% - Changing the theme does not effect the rendered output. %%
%%{init: { &#39;logLevel&#39;: &#39;debug&#39;, &#39;theme&#39;: &#39;base&#39;, &#39;gitGraph&#39;: {&#39;showCommitLabel&#39;: false} }%%
gitGraph
    commit
    branch preview
    checkout preview
    commit
    branch foo
    checkout foo
    commit
    commit
    checkout preview
    branch bar
    checkout bar
    commit
    checkout preview
    merge bar
    checkout foo
    commit
    checkout preview
    merge foo
    checkout main
    merge preview
```
</pre></div>
</div>
</section>
<section id="id5">
<h2>Content Rules<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h2>
<p>To ensure a high-quality and consistent documentation, and to make it easier for readers to
understand all content, we have established <span class="xref myst">Content rules</span>. Please follow
these rules regarding Markdown syntax and writing style when contributing! Furthermore, reviewing
your changes takes less time and your improvements appear faster on the official documentation.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you contribute, you are fully and solely responsible for the content you create and have to
ensure that you have the right to create it under applicable laws.
</pre></div>
</div>
</section>
<section id="contribute-via-issue">
<h2>Contribute via Issue<a class="headerlink" href="#contribute-via-issue" title="Permalink to this heading">#</a></h2>
<p>You can contribute to the documentation using
<a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/zih/hpcsupport/hpc-compendium/-/issues">GitLab‚Äôs issue tracking system</a>.
For that, open an issue to report typos and missing documentation or request for more precise
wording etc. ZIH staff will get in touch with you to resolve the issue and improve the
documentation.</p>
<p>??? tip ‚ÄúCreate an issue in GitLab‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>![GIF showing how to create an issue in GitLab](misc/create_gitlab_issue.gif)
{: align=center}
</pre></div>
</div>
<p>!!! warning ‚ÄúHPC support‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Non-documentation issues and requests need to be send as ticket to
[hpc-support@tu-dresden.de](mailto:hpc-support@tu-dresden.de).
</pre></div>
</div>
</section>
<section id="contribute-via-web-ide">
<h2>Contribute via Web IDE<a class="headerlink" href="#contribute-via-web-ide" title="Permalink to this heading">#</a></h2>
<p>If you have a web browser (most probably you are using it to read this page) and want to contribute
to the documentation, you are good to go. GitLab offers a rich and versatile web interface for
working with repositories. To start fixing typos and edit source files, you can find more
information on the page <span class="xref myst">Contributing via web browser</span>.</p>
</section>
<section id="id6">
<h2>Contribute via Local Clone<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h2>
<p>For experienced Git users, we provide a Docker container that includes all the checks of the CI
engine used in the backend. Using them should ensure that merge requests are not blocked due to
automatic checks.  The page <span class="xref myst">Contributing via local clone</span> provides you
with the details about how to set up and use your local clone of the repository.</p>
</section>
<section id="ci-cd-pipeline">
<h2>CI/CD Pipeline<a class="headerlink" href="#ci-cd-pipeline" title="Permalink to this heading">#</a></h2>
<p>All contributions need to pass through the CI pipeline which consists of various checks to ensure
that the <span class="xref myst">content rules</span> have been followed.</p>
<p>The stages of the CI/CD pipeline are defined in a <code class="docutils literal notranslate"><span class="pre">.gitlab.yaml</span></code> file. For security reasons, this
file is maintained in a second, private repository.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="sharing-data">
<h1>Sharing Data<a class="headerlink" href="#sharing-data" title="Permalink to this heading">#</a></h1>
<p>This page should provide you some commands to share your data with other users or projects.</p>
<section id="grant-access-on-some-file-or-directory-to-persons-in-your-project">
<h2>Grant access on some file or directory to persons in your project<a class="headerlink" href="#grant-access-on-some-file-or-directory-to-persons-in-your-project" title="Permalink to this heading">#</a></h2>
<p>If all persons that should be able to access your data are in the same project, you can give them
access to your workspace, e. g. <code class="docutils literal notranslate"><span class="pre">input-data</span></code> via the following commands:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>id<span class="w"> </span>--group<span class="w"> </span>--name
<span class="go">p_number_crunch</span>
<span class="gp">marie@login$ </span>chown<span class="w"> </span>-R<span class="w"> </span>marie:p_number_crunch<span class="w"> </span>/scratch/ws/1/marie-input-data
</pre></div>
</div>
<p>Now, everyone who is in project <code class="docutils literal notranslate"><span class="pre">p_number_crunch</span></code> should be able to access your data. If this is not
the case, you should check whether the file that your colleague wants to access is readable for the
group (<code class="docutils literal notranslate"><span class="pre">r</span></code> permission is set for the group) and every parent directory of that file is searchable
for the group (<code class="docutils literal notranslate"><span class="pre">x</span></code> permission is set for the group). For example, in the following case, a colleague
of <code class="docutils literal notranslate"><span class="pre">marie</span></code> cannot access <code class="docutils literal notranslate"><span class="pre">data-file</span></code> because the base directory <code class="docutils literal notranslate"><span class="pre">.</span></code> is not searchable for the group
as it does not have the <code class="docutils literal notranslate"><span class="pre">x</span></code> permission, even though the file has the permission <code class="docutils literal notranslate"><span class="pre">r</span></code> set for the
group. Thus, <code class="docutils literal notranslate"><span class="pre">marie</span></code> has to make the directory searchable by using <code class="docutils literal notranslate"><span class="pre">chmod</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ls<span class="w"> </span>-la<span class="w"> </span>/scratch/ws/1/marie-input-data
<span class="go">drwxr-----   4 marie    p_number_crunch   4096 27. Jun 17:13 .</span>
<span class="go">drwxr-xr-x 444 operator adm             151552 14. Jul 09:41 ..</span>
<span class="go">-rw-r-----   2 marie    p_number_crunch   4096 27. Jun 17:13 data-file</span>
<span class="gp">marie@login$ </span>chmod<span class="w"> </span>g+x<span class="w"> </span>/scratch/ws/1/marie-input-data
<span class="gp">marie@login$ </span>ls<span class="w"> </span>-la<span class="w"> </span>/scratch/ws/1/marie-input-data
<span class="go">drwxr-x---   4 marie    p_number_crunch   4096 27. Jun 17:13 .</span>
<span class="go">drwxr-xr-x 444 operator adm             151552 14. Jul 09:41 ..</span>
<span class="go">-rw-r-----   2 marie    p_number_crunch   4096 27. Jun 17:13 data-file</span>
</pre></div>
</div>
<p>!!! danger ‚ÄúNew file inherits group and permissions of the creator‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>When a user creates a file, the created file is associated to that user and inherits the user&#39;s
default group. If the user is in multiple groups/projects, he/she has to ensure, that the new
file is associated with the project&#39;s group. This can be done using `chown` and `chmod` as shown
above. Another possibility is to use an environment file `env.sh` with the following content:

```bash
newgrp p_number_crunch  # files should have this group by default
umask o-rwx             # prevent creating files that allow persons not in this group (a.k.a. others) to read, write or execute something
```

Before creating new files, users can now load this file using `source` in order to ensure that
new files automatically get the right group:

```console
marie@login$ cd /scratch/ws/1/marie-input-data
marie@login$ source /projects/p_number_crunch/env.sh
bash-4.2$ touch new-file    #create a new file
```
</pre></div>
</div>
<p>Read on, if you want to restrict access to specific persons outside of your group, but don‚Äôt want to
permit everyone to access your data.</p>
</section>
<section id="grant-access-on-some-file-or-directory-to-persons-from-various-projects">
<h2>Grant access on some file or directory to persons from various projects<a class="headerlink" href="#grant-access-on-some-file-or-directory-to-persons-from-various-projects" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Access-control_list">Access Control Lists</a> (ACLs) can be used, when
<code class="docutils literal notranslate"><span class="pre">chmod</span></code> is not sufficient anymore, e. g. because you want to permit accessing a particular file for
persons from your project and also some persons outside of your project, but not everyone.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>At the moment `setfacl` is only working on our Lustre filesystems (`/data/horse` and
`/data/walrus`).
</pre></div>
</div>
<p>The command <code class="docutils literal notranslate"><span class="pre">setfacl</span></code> is used to manage access rights for workspaces. To view the current access
rights, use the command <code class="docutils literal notranslate"><span class="pre">getfacl</span></code>. The following commands are used to grant a user access to the
workspace.</p>
<p>If you are unsure what your group/project is, you can use the following command to find out:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>id<span class="w"> </span>--group<span class="w"> </span>--name
<span class="go">p_number_crunch</span>
</pre></div>
</div>
<p>If you are in multiple projects, you could see all of them using <code class="docutils literal notranslate"><span class="pre">--groups</span></code> instead of <code class="docutils literal notranslate"><span class="pre">--group</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>id<span class="w"> </span>--groups<span class="w"> </span>--name
<span class="go">p_number_crunch</span>
</pre></div>
</div>
<p>!!! example ‚ÄúGrant a user full access to the workspace folder‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ setfacl --modify=u:&lt;username&gt;:rwx &lt;path_to_workspace&gt;
```

For example, if `marie` wants to give her colleague `martin` access to the workspace
`input-data` she has created, she would use the following command:

```console
marie@login$ setfacl --modify=u:martin:rwx /scratch/ws/1/marie-input-data
```
</pre></div>
</div>
<p>!!! example ‚ÄúInherit these same rights to all newly created files and folders‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ setfacl --modify=d:u:&lt;username&gt;:rwx &lt;path_to_workspace&gt;
```
</pre></div>
</div>
<p>!!! example ‚ÄúGrant a project full access to the workspace folder‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ setfacl --modify=g:&lt;projectname&gt;:rwx &lt;path_to_workspace&gt;
```

For example, if `marie` wants to give all colleagues in `martin`&#39;s project `p_long_computations`
access to the workspace `input-data` she has created, she would use the following command:

```console
marie@login$ setfacl --modify=g:p_long_computations:rwx /scratch/ws/1/marie-input-data
```
</pre></div>
</div>
<p>!!! example ‚ÄúInherit these same rights to all newly created files and folders‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ setfacl --modify=d:g:&lt;projectname&gt;:rwx &lt;path_to_workspace&gt;
```
</pre></div>
</div>
<p>If you already have files inside your workspace, remember to use the <code class="docutils literal notranslate"><span class="pre">-R</span></code> or <code class="docutils literal notranslate"><span class="pre">--recursive</span></code> options
to apply these ACL changes to all files.</p>
<p>!!! example ‚ÄúRemove access rights for a particular user‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you want to remove a user&#39;s access then use:

```console
marie@login$ setfacl --remove=u:&lt;username&gt; &lt;path_to_workspace&gt;
```

Remember to also remove the default access rights, if you added them previously:

```console
marie@login$ setfacl --remove=d:u:&lt;username&gt; &lt;path_to_workspace&gt;
```

For example, if `marie` wants to remove access to the workspace `input-data` she has given
`martin` earlier:

```console
marie@login$ setfacl --remove=u:martin /scratch/ws/1/marie-input-data
```

And just to be sure, she would also remove default access rights for him:

```console
marie@login$ setfacl --remove=d:u:martin /scratch/ws/1/marie-input-data
```
</pre></div>
</div>
<p>More details on ACLs can be found on the <a class="reference external" href="https://man.archlinux.org/man/setfacl.1">setfacl man page</a>.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="filesystems">
<h1>Filesystems<a class="headerlink" href="#filesystems" title="Permalink to this heading">#</a></h1>
<p>As soon as you have access to ZIH systems, you have to manage your data. Several filesystems are
available. Each filesystem serves for special purpose according to their respective capacity,
performance and permanence.</p>
<p>We differentiate between <strong>permanent filesystems</strong> and <strong>working filesystems</strong>:</p>
<ul class="simple">
<li><p>The <span class="xref myst">permanent filesystems</span>, i.e. <code class="docutils literal notranslate"><span class="pre">/home</span></code> and <code class="docutils literal notranslate"><span class="pre">/projects</span></code>, are meant to hold your
source code, configuration files, and other permanent data.</p></li>
<li><p>The <span class="xref myst">working filesystems</span>, i.e, <code class="docutils literal notranslate"><span class="pre">horse</span></code>, <code class="docutils literal notranslate"><span class="pre">walrus</span></code>, etc., are designed as scratch
filesystems holding your working and temporary data, e.g., input and output of your compute
jobs.</p></li>
</ul>
<section id="recommendations-for-filesystem-usage">
<h2>Recommendations for Filesystem Usage<a class="headerlink" href="#recommendations-for-filesystem-usage" title="Permalink to this heading">#</a></h2>
<p>To work as efficient as possible, consider the following points</p>
<ul class="simple">
<li><p>Save source code etc. in <code class="docutils literal notranslate"><span class="pre">/home</span></code> or <code class="docutils literal notranslate"><span class="pre">/projects</span></code></p></li>
<li><p>Store checkpoints and other temporary data in <span class="xref myst">workspaces</span> on <code class="docutils literal notranslate"><span class="pre">horse</span></code></p></li>
<li><p>Compilation should be executed in <code class="docutils literal notranslate"><span class="pre">/dev/shm</span></code> or <code class="docutils literal notranslate"><span class="pre">/tmp</span></code></p></li>
</ul>
<p>Getting high I/O-bandwidth</p>
<ul class="simple">
<li><p>Use many clients</p></li>
<li><p>Use many processes (writing in the same file at the same time is possible)</p></li>
<li><p>Use large I/O transfer blocks</p></li>
<li><p>Avoid reading many small files. Use data container e. g.
<span class="xref myst">ratarmount</span>
to bundle small files into one</p></li>
</ul>
</section>
<section id="cheat-sheet-for-debugging-filesystem-issues">
<h2>Cheat Sheet for Debugging Filesystem Issues<a class="headerlink" href="#cheat-sheet-for-debugging-filesystem-issues" title="Permalink to this heading">#</a></h2>
<p>Users can select from the following commands to get some idea about
their data.</p>
<section id="general">
<h3>General<a class="headerlink" href="#general" title="Permalink to this heading">#</a></h3>
<p>For the first view, you can use the command <code class="docutils literal notranslate"><span class="pre">df</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>df
</pre></div>
</div>
<p>Alternatively, you can use the command <code class="docutils literal notranslate"><span class="pre">findmnt</span></code>, which is also able to report space usage
by adding the parameter <code class="docutils literal notranslate"><span class="pre">-D</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>findmnt<span class="w"> </span>-D
</pre></div>
</div>
<p>Optionally, you can use the parameter <code class="docutils literal notranslate"><span class="pre">-t</span></code> to specify the filesystem type or the parameter <code class="docutils literal notranslate"><span class="pre">-o</span></code> to
alter the output.</p>
<p>!!! important</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Do **not** use the `du`-command for this purpose. It is able to cause issues
for other users, while reading data from the filesystem.
</pre></div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="long-term-preservation-of-research-data">
<h1>Long-Term Preservation of Research Data<a class="headerlink" href="#long-term-preservation-of-research-data" title="Permalink to this heading">#</a></h1>
<section id="why-should-research-data-be-preserved">
<h2>Why should research data be preserved?<a class="headerlink" href="#why-should-research-data-be-preserved" title="Permalink to this heading">#</a></h2>
<p>There are several reasons. On the one hand, research data should be preserved to make the results
reproducible. On the other hand research data could be used a second time for investigating another
question. In the latter case persistent identifiers (like DOI) are needed to make these data
findable and citable. In both cases it is important to add meta-data to the data.</p>
</section>
<section id="which-research-data-should-be-preserved">
<h2>Which research data should be preserved?<a class="headerlink" href="#which-research-data-should-be-preserved" title="Permalink to this heading">#</a></h2>
<p>Since large quantities of data are nowadays produced it is not possible to store everything. The
researcher needs to decide which data are worth and important to keep.</p>
<p>In case these data come from simulations, there are two possibilities: 1 Storing the result of the
simulations 1 Storing the software and the input-values</p>
<p>Which of these possibilities is preferable depends on the time the simulations need and on the size
of the result of the calculations. Here one needs to estimate, which possibility is cheaper.</p>
<p><strong>This is, what DFG says</strong> (translated from
<a class="reference external" href="http://www.dfg.de/download/pdf/foerderung/programme/lis/ua_inf_empfehlungen_200901.pdf">http://www.dfg.de/download/pdf/foerderung/programme/lis/ua_inf_empfehlungen_200901.pdf</a>, page 2):</p>
<p><em>Primary research data are data, which were created in the course</em> <em>of studies of sources,
experiments, measurements or surveys. They are the</em> <em>basis of scholarly publications</em>. <em>The
definition of primary research data depends on the subject</em>. <em>Each community of researchers should
decide by itself, if raw data are</em> <em>already primary research data or at which degree of aggregation
data</em> <em>should be preserved. Further it should be agreed upon the granularity</em> <em>of research data: how
many data yield one set of data, which will be</em> <em>given a persistent identifier</em>.</p>
</section>
<section id="why-should-i-add-meta-data-to-my-data">
<h2>Why should I add Meta-Data to my data?<a class="headerlink" href="#why-should-i-add-meta-data-to-my-data" title="Permalink to this heading">#</a></h2>
<p>Many researchers think, that adding meta-data is time-consuming and senseless but that isn‚Äôt true.
On the contrary, adding meta-data is very important, since they should enable other researchers to
know, how and in which circumstances these data are created, in which format they are saved, and
which software in which version is needed to view the data, and so on, so that other researchers can
reproduce these data or use them for new investigations. Last but not least meta-data should enable
you in ten years time to know what your data describe, which you created such a long time ago.</p>
</section>
<section id="what-are-meta-data">
<h2>What are Meta-Data?<a class="headerlink" href="#what-are-meta-data" title="Permalink to this heading">#</a></h2>
<p>Meta-data means data about data. Meta-data are information about the stored file. There can be
administrative meta-data, descriptive meta-data, technical meta-data and so on. Often meta-data are
stored in XML-format but free text is also possible. There are some meta-data standards like
<a class="reference external" href="http://dublincore.org/">Dublin Core</a> or
<a class="reference external" href="https://www.dnb.de/DE/Professionell/Standardisierung/Standards/_content/lmer_uof.html">LMER</a>
Below are some examples:</p>
<ul class="simple">
<li><p>possible meta-data for a book would be:</p>
<ul>
<li><p>Title</p></li>
<li><p>Author</p></li>
<li><p>Publisher</p></li>
<li><p>Publication</p></li>
<li><p>year</p></li>
<li><p>ISBN</p></li>
</ul>
</li>
<li><p>possible meta-data for an electronically saved image would be:</p>
<ul>
<li><p>resolution of the image</p></li>
<li><p>information about the color depth of the picture</p></li>
<li><p>file format (jpg or tiff or ‚Ä¶)</p></li>
<li><p>file size how was this image created (digital camera, scanner, ‚Ä¶)</p></li>
<li><p>description of what the image shows</p></li>
<li><p>creation date of the picture</p></li>
<li><p>name of the person who made the picture</p></li>
</ul>
</li>
<li><p>meta-data for the result of a calculation/simulation could be:</p>
<ul>
<li><p>file format</p></li>
<li><p>file size</p></li>
<li><p>input data</p></li>
<li><p>which software in which version was used to calculate the result/to do the simulation</p></li>
<li><p>configuration of the software</p></li>
<li><p>date of the calculation/simulation (start/end or start/duration)</p></li>
<li><p>computer on which the calculation/simulation was done</p></li>
<li><p>name of the person who submitted the calculation/simulation</p></li>
<li><p>description of what was calculated/simulated</p></li>
</ul>
</li>
</ul>
</section>
<section id="where-can-i-get-more-information-about-management-of-research-data">
<h2>Where can I get more information about management of research data?<a class="headerlink" href="#where-can-i-get-more-information-about-management-of-research-data" title="Permalink to this heading">#</a></h2>
<p>Please visit the wiki <a class="reference external" href="https://www.forschungsdaten.org/en/">forschungsdaten.org</a> to learn more about
all of the different aspects of research data management.</p>
<p>For questions or individual consultations regarding research data management in general or any of
its certain aspects, you can contact the
<a class="reference external" href="https://tu-dresden.de/forschung-transfer/services-fuer-forschende/kontaktstelle-forschungsdaten?set_language=en">Service Center Research Data</a>
(Kontaktstelle Forschungsdaten) of TU Dresden.</p>
</section>
<section id="i-want-to-archive-my-research-data-at-zih-safely-how-can-i-do-that">
<h2>I want to archive my research data at ZIH safely. How can I do that?<a class="headerlink" href="#i-want-to-archive-my-research-data-at-zih-safely-how-can-i-do-that" title="Permalink to this heading">#</a></h2>
<p>For TU Dresden there exist two different services at ZIH for archiving research data. Both of
them ensure high data safety by duplicating data internally at two separate locations and
require some data preparation (e.g. packaging), but serve different use cases:</p>
<section id="storing-very-infrequently-used-data-during-the-course-of-the-project">
<h3>Storing very infrequently used data during the course of the project<a class="headerlink" href="#storing-very-infrequently-used-data-during-the-course-of-the-project" title="Permalink to this heading">#</a></h3>
<p>The intermediate archive is a tape storage easily accessible as a directory
(<code class="docutils literal notranslate"><span class="pre">/archiv/&lt;HRSK-project&gt;/</span></code> or <code class="docutils literal notranslate"><span class="pre">/archiv/&lt;login&gt;/</span></code>) using the
<span class="xref myst">Dataport Nodes</span>
and
<span class="xref myst">Datamover tools</span> to move your data to.
For detailed information please visit the
<a class="reference external" href="https://tu-dresden.de/zih/dienste/service-katalog/arbeitsumgebung/backup_archiv/archivierung_am_zih#section-2-1">ZIH intermediate archive documentation</a>.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The usage of the HRSK-project-related archive is preferable to the login-related archive, as
this enables assigning access rights and responsibility across multiple researchers, due to the
common staff turnover in research.
</pre></div>
</div>
<p>The use of the intermediate archive usually is limited by the end of the corresponding
research project. Afterwards data is required to be removed, tidied up and submitted to a
long-term repository (see next section).</p>
<p>The intermediate archive is the preferred service when you keep large, mostly unused data volumes
during the course of your research project; if you want or need to free storage capacities, but
you are still not able to define certain or relevant datasets for long-term archival.</p>
<p>If you are able to identify complete and final datasets, which you probably won‚Äôt use actively
anymore, then repositories as described in the next section may be the more appropriate selection.</p>
</section>
<section id="archiving-data-beyond-the-project-lifetime-for-10-years-and-above">
<h3>Archiving data beyond the project lifetime, for 10 years and above<a class="headerlink" href="#archiving-data-beyond-the-project-lifetime-for-10-years-and-above" title="Permalink to this heading">#</a></h3>
<p>According to good scientific practice (cf.
<a class="reference external" href="https://www.dfg.de/download/pdf/foerderung/rechtliche_rahmenbedingungen/gute_wissenschaftliche_praxis/kodex_gwp.pdf">DFG guidelines, #17</a>)
and
<a class="reference external" href="https://tu-dresden.de/tu-dresden/qualitaetsmanagement/ressourcen/dateien/wisprax/Leitlinien-fuer-den-Umgang-mit-Forschungsdaten-an-der-TU-Dresden.pdf">TU Dresden research data guidelines</a>,
relevant research data needs to be archived at least for 10 years. The
<a class="reference external" href="https://opara.zih.tu-dresden.de/xmlui/">OpARA service</a> (Open Access Repository and Archive) is the
joint research data repository service for Saxon universities to address this requirement.</p>
<p>Data can be uploaded and, to comply to the demands of long-term understanding of data, additional
metadata and description must be added. Large datasets may be optionally imported beforehand. In
this case, please contact the
<a class="reference external" href="mailto:servicedesk&#37;&#52;&#48;tu-dresden&#46;de?subject=OpARA:%20Data%20Import">TU Dresden Service Desk</a>.
Optionally, data can also be <strong>published</strong> by OpARA. To ensure data quality, data submissions
undergo a review process.</p>
<p>Beyond OpARA, it is also recommended to use discipline-specific data repositories for data
publications. Usually those are well known in a scientific community, and offer better fitting
options of data description and classification. Please visit <a class="reference external" href="https://re3data.org">re3data.org</a>
to look up a suitable one for your discipline.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="lustre">
<h1>Lustre<a class="headerlink" href="#lustre" title="Permalink to this heading">#</a></h1>
<section id="good-practices">
<h2>Good Practices<a class="headerlink" href="#good-practices" title="Permalink to this heading">#</a></h2>
<p>!!! hint ‚ÄúAvoid accessing metadata information‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Querying metadata information such as file and directory attributes is a resource intensive task
in Lustre filesystems. When these tasks are performed frequently or over large directories, it
can degrade the filesystem&#39;s performance and thus affect all users.
</pre></div>
</div>
<p>In this sense, you should minimize the usage of system calls querying or modifying file
and directory attributes, e.g. <code class="docutils literal notranslate"><span class="pre">stat()</span></code>, <code class="docutils literal notranslate"><span class="pre">statx()</span></code>, <code class="docutils literal notranslate"><span class="pre">open()</span></code>, <code class="docutils literal notranslate"><span class="pre">openat()</span></code> etc.</p>
<p>Please, also avoid commands basing on the above mentioned system calls such as <code class="docutils literal notranslate"><span class="pre">ls</span> <span class="pre">-l</span></code> and
<code class="docutils literal notranslate"><span class="pre">ls</span> <span class="pre">--color</span></code>. Instead, you should invoke <code class="docutils literal notranslate"><span class="pre">ls</span></code> or <code class="docutils literal notranslate"><span class="pre">ls</span> <span class="pre">-l</span> <span class="pre">&lt;filename&gt;</span></code> to reduce metadata operations.
This also holds for commands walking the filesystems recursively performing massive metadata
operations such as <code class="docutils literal notranslate"><span class="pre">ls</span> <span class="pre">-R</span></code>, <code class="docutils literal notranslate"><span class="pre">find</span></code>, <code class="docutils literal notranslate"><span class="pre">locate</span></code>, <code class="docutils literal notranslate"><span class="pre">du</span></code> and <code class="docutils literal notranslate"><span class="pre">df</span></code>.</p>
<p>Lustre offers a number of commands that are suited to its architecture.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Good</p></th>
<th class="head text-left"><p>Bad</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">lfs</span> <span class="pre">df</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">df</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">lfs</span> <span class="pre">find</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">find</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">ls</span> <span class="pre">-l</span> <span class="pre">&lt;filename&gt;</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">ls</span> <span class="pre">-l</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">ls</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">ls</span> <span class="pre">--color</span></code></p></td>
</tr>
</tbody>
</table>
<p>In case commands such as <code class="docutils literal notranslate"><span class="pre">du</span></code> are needed, for example to identify large
directories, these commands should be applied to as little data as
possible. You should not just query the main directory in general, you
should try to work in the sub directories first. The deeper in the
structure, the better.</p>
<section id="searching-the-directory-tree">
<h3>Searching the Directory Tree<a class="headerlink" href="#searching-the-directory-tree" title="Permalink to this heading">#</a></h3>
<p>The command <code class="docutils literal notranslate"><span class="pre">lfs</span> <span class="pre">find</span></code> searches the directory tree for files matching the specified parameters.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>lfs<span class="w"> </span>find<span class="w"> </span>&lt;root<span class="w"> </span>directory&gt;<span class="w"> </span><span class="o">[</span>options<span class="o">]</span>
</pre></div>
</div>
<p>If no option is provided, <code class="docutils literal notranslate"><span class="pre">lfs</span> <span class="pre">find</span></code> will efficiently list all files in a given directory and its
subdirectories, without fetching any file attributes.</p>
<p>Useful options:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--atime</span> <span class="pre">n</span></code> file was last accessed n*24 hours ago</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--ctime</span> <span class="pre">n</span></code> file was last changed n*24 hours ago</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--mtime</span> <span class="pre">n</span></code> file was last modified n*24 hours ago</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--maxdepth</span> <span class="pre">n</span></code> limits find to descend at most n levels of directory tree</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--print0|-0</span></code> print full file name to standard output if it matches the specified parameters,
followed by a NUL character.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--name</span> <span class="pre">arg</span></code> filename matches the given filename (supporting regular expression and wildcards)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--type</span> <span class="pre">[b|c|d|f|p|l|s]</span></code> file has type: <strong>b</strong>lock, <strong>c</strong>haracter, <strong>d</strong>irectory, <strong>f</strong>ile,
<strong>p</strong>ipe, sym<strong>l</strong>ink, or <strong>s</strong>ocket.</p></li>
</ul>
<p>??? example ‚ÄúExample: List files older than 30 days‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The follwing command will find and list all files older than 30 days in the workspace
`/scratch/ws/0/marie-number_crunch`:

```console
marie@login lfs find /scratch/ws/0/marie-number_crunch --mtime +30 --type f
/scratch/ws/0/marie-number_crunch/jobfile.sh
/scratch/ws/0/marie-number_crunch/0001.dat
/scratch/ws/0/marie-number_crunch/load_profile.sh
/scratch/ws/0/marie-number_crunch/mes0001
/scratch/ws/0/marie-number_crunch/d3dump01.0002
/scratch/ws/0/marie-number_crunch/mes0032
/scratch/ws/0/marie-number_crunch/dump01.0003
/scratch/ws/0/marie-number_crunch/slurm-1234567.log
```
</pre></div>
</div>
</section>
</section>
<section id="useful-commands-for-lustre">
<h2>Useful Commands for Lustre<a class="headerlink" href="#useful-commands-for-lustre" title="Permalink to this heading">#</a></h2>
<p>These commands work for Lustre filesystems <code class="docutils literal notranslate"><span class="pre">/data/horse</span></code> and <code class="docutils literal notranslate"><span class="pre">/data/walrus</span></code>. In order to hold this
documentation as general as possible we will use <code class="docutils literal notranslate"><span class="pre">&lt;filesystem&gt;</span></code> as a placeholder for the Lustre
filesystems. Just replace it when invoking the commands with the Lustre filesystem of interest.</p>
<p>Lustre‚Äôs <code class="docutils literal notranslate"><span class="pre">lfs</span></code> client utility provides several options for monitoring and configuring your Lustre
environment.</p>
<p><code class="docutils literal notranslate"><span class="pre">lfs</span></code> can be used in interactive and in command line mode. To enter the interactive mode, you just
call <code class="docutils literal notranslate"><span class="pre">lfs</span></code> and enter your commands. Since, both modes provide identical options, we use the command
line mode within this documentation.</p>
<p>!!! hint ‚ÄúFilesystem vs. Path‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you provide a path to the lfs commands instead of a filesystem, the lfs option is applied to
the filesystem this path is in. Thus, the passed information refers to the whole filesystem,
not the path.
</pre></div>
</div>
<p>You can retrieve a complete list of available options:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">marie@login lfs --list-commands</span>
<span class="go">setstripe           getstripe           setdirstripe        getdirstripe</span>
<span class="go">mkdir               rm_entry            pool_list           find</span>
<span class="go">check               osts                mdts                df</span>
<span class="go">[...]</span>
</pre></div>
</div>
<p>To get more information on a specific option, enter <code class="docutils literal notranslate"><span class="pre">help</span></code> followed by the option of interest:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">marie@login lfs help df</span>
<span class="go">df: report filesystem disk space usage or inodes usage of each MDS and all OSDs or a batch belonging to a specific pool.</span>
<span class="go">Usage: df [--inodes|-i] [--human-readable|-h] [--lazy|-l]</span>
<span class="go">          [--pool|-p &lt;fsname&gt;[.&lt;pool&gt;]] [path]</span>
</pre></div>
</div>
<p>More comprehensive documentation can be found in the man pages of lfs (<code class="docutils literal notranslate"><span class="pre">man</span> <span class="pre">lfs</span></code>).</p>
<section id="listing-disk-space-usage">
<h3>Listing Disk Space Usage<a class="headerlink" href="#listing-disk-space-usage" title="Permalink to this heading">#</a></h3>
<p>The command <code class="docutils literal notranslate"><span class="pre">lfs</span> <span class="pre">df</span></code> lists the filesystems disk space usage:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>lfs<span class="w"> </span>df<span class="w"> </span>-h<span class="w"> </span>&lt;filesystem&gt;
</pre></div>
</div>
<p>Useful options:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-h</span></code> outputs the units in human readable format.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-i</span></code> reports inode usage for each target and in summary.</p></li>
</ul>
<p>!!! example ‚ÄúExample disk space usage at <code class="docutils literal notranslate"><span class="pre">/scratch</span></code>‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>At one moment in time, the disk space usage of the Lustre filesystem `/scratch` was:

```console
lfs df -h /scratch
UUID                       bytes        Used   Available Use% Mounted on
scratch2-MDT0000_UUID        4.0T      502.8G        3.6T  13% /lustre/scratch2[MDT:0]
scratch2-MDT0001_UUID      408.0G      117.7G      290.3G  29% /lustre/scratch2[MDT:1]
scratch2-OST0000_UUID       28.9T       25.1T        3.7T  88% /lustre/scratch2[OST:0]
scratch2-OST0001_UUID       28.9T       24.7T        4.1T  86% /lustre/scratch2[OST:1]
scratch2-OST0002_UUID       28.9T       25.0T        3.9T  87% /lustre/scratch2[OST:2]
scratch2-OST0003_UUID       28.9T       25.1T        3.8T  87% /lustre/scratch2[OST:3]
[...]
scratch2-OST008d_UUID       28.9T       25.0T        3.8T  87% /lustre/scratch2[OST:141]
scratch2-OST008e_UUID       28.9T       24.9T        4.0T  87% /lustre/scratch2[OST:142]
scratch2-OST008f_UUID       28.9T       25.3T        3.6T  88% /lustre/scratch2[OST:143]

filesystem_summary:         4.1P        3.5P      571.8T  87% /lustre/scratch2
```

The disk space usage is displayed separately for each MDS and OST as well in total. You can see
that the usage is quite balanced between all MDSs and OSTs.

If very large files are not properly stripped across several OSTs, the filesystem might become
unbalanced with one server near 100% full.
</pre></div>
</div>
</section>
<section id="listing-personal-disk-usages-and-limits">
<h3>Listing Personal Disk Usages and Limits<a class="headerlink" href="#listing-personal-disk-usages-and-limits" title="Permalink to this heading">#</a></h3>
<p>To list your personal filesystem usage and limits (quota), invoke</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>lfs<span class="w"> </span>quota<span class="w"> </span>-h<span class="w"> </span>-u<span class="w"> </span><span class="nv">$USER</span><span class="w"> </span>&lt;filesystem&gt;
</pre></div>
</div>
<p>Useful options:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-h</span></code> outputs the units in human readable format.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-u|-g|-p</span> <span class="pre">&lt;arg&gt;</span></code> displays quota for specific user, group or project.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-v</span></code> displays the usage on each OST.</p></li>
</ul>
</section>
<section id="listing-osts">
<h3>Listing OSTs<a class="headerlink" href="#listing-osts" title="Permalink to this heading">#</a></h3>
<p>You can list all OSTs available in a particular Lustre filesystem using <code class="docutils literal notranslate"><span class="pre">lfs</span> <span class="pre">osts</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>lfs<span class="w"> </span>osts<span class="w"> </span>&lt;filesystem&gt;
</pre></div>
</div>
<p>If a path is specified, only OSTs belonging to the specified path are displayed.</p>
</section>
<section id="view-striping-information">
<h3>View Striping Information<a class="headerlink" href="#view-striping-information" title="Permalink to this heading">#</a></h3>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>lfs<span class="w"> </span>getstripe<span class="w"> </span>myfile
<span class="gp">marie@login$ </span>lfs<span class="w"> </span>getstripe<span class="w"> </span>-d<span class="w"> </span>mydirectory
</pre></div>
</div>
<p>The argument <code class="docutils literal notranslate"><span class="pre">-d</span></code> will also display striping for all files in the directory.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="data-life-cycle-management">
<h1>Data Life Cycle Management<a class="headerlink" href="#data-life-cycle-management" title="Permalink to this heading">#</a></h1>
<p>Correct organization of the structure of an HPC project is a straightforward way to the efficient
work of the whole team. There have to be rules and regulations that every member should follow. The
uniformity of the project can be achieved by taking into account and setting up correctly</p>
<ul class="simple">
<li><p>the same <strong>set of software</strong> (modules, compiler, packages, libraries, etc),</p></li>
<li><p>a defined <strong>data life cycle management</strong> including the same <strong>data storage</strong> or set of them,</p></li>
<li><p>and <strong>access rights</strong> to project data.</p></li>
</ul>
<p>The used set of software within an HPC project can be managed with environments on different
levels either defined by <span class="xref myst">modules</span>, <span class="xref myst">containers</span>
or by <span class="xref myst">Python virtual environments</span>.
In the following, a brief overview on relevant topics w.r.t. data life cycle management is provided.</p>
<section id="data-storage-and-management">
<h2>Data Storage and Management<a class="headerlink" href="#data-storage-and-management" title="Permalink to this heading">#</a></h2>
<p>In general, you should separate your data and store it on the appropriate storage and filesystem.
What is the appropriate storage and filesystem depends on the amount/volume of data and its kind,
and might differ over time. Please note the following rules of thumb:</p>
<ul class="simple">
<li><p>Use your personal <code class="docutils literal notranslate"><span class="pre">/home</span></code> directory for the limited amount of <em>personal data</em>, e.g., simple
examples and the results of calculations. Your <code class="docutils literal notranslate"><span class="pre">/home</span></code> directory is not a working directory!
However, <code class="docutils literal notranslate"><span class="pre">/home</span></code> filesystem is <span class="xref myst">backed up</span>. The section
<span class="xref myst">Global <code class="docutils literal notranslate"><span class="pre">/home</span></code> Filesystem</span> provides additional information.</p></li>
<li><p>Use your <code class="docutils literal notranslate"><span class="pre">/project</span></code> directory for project-related data. This directory enables collaboration by
sharing data with colleagues and project members. Please refer to the section
<span class="xref myst">Global <code class="docutils literal notranslate"><span class="pre">/projects</span></code> Filesystem</span> for further information.</p></li>
<li><p>Use <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">workspaces</span></code></span> as a place for your <em>working data</em> (i.e. data sets).
Recommendations of choosing the most suitable filesystem for your workspaces is presented on the
page <span class="xref myst">Working Filesystems</span>.</p></li>
<li><p>Use the <span class="xref myst">Intermediate Archive</span> and the
<span class="xref myst">Long-Term Archive</span> to store all kind of data that needs to be kept
for a long time, e.g. result data.</p></li>
</ul>
<section id="backup">
<h3>Backup<a class="headerlink" href="#backup" title="Permalink to this heading">#</a></h3>
<p>The backup is a crucial part of any project. Organize it at the beginning of the project. The
backup mechanism on ZIH systems covers <strong>only</strong> the filesystems <code class="docutils literal notranslate"><span class="pre">/home</span></code> and <code class="docutils literal notranslate"><span class="pre">/projects</span></code>. The section
<span class="xref myst">Backup</span> holds additional information.</p>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you accidentally delete your data in the &quot;no backup&quot; filesystems it **can not be restored**!
</pre></div>
</div>
</section>
<section id="folder-structure-and-organizing-data">
<h3>Folder Structure and Organizing Data<a class="headerlink" href="#folder-structure-and-organizing-data" title="Permalink to this heading">#</a></h3>
<p>Organizing of living data using the filesystem helps for consistency of the
project. We recommend following the rules for your work regarding:</p>
<ul class="simple">
<li><p>Organizing the data: Never change the original data; Automatize the organizing the data; Clearly
separate intermediate and final output in the filenames; Carry identifier and original name
along in your analysis pipeline; Make outputs clearly identifiable; Document your analysis
steps.</p></li>
<li><p>Naming Data: Keep short, but meaningful names; Keep standard file endings; File names
don‚Äôt replace documentation and metadata; Use standards of your discipline; Make rules for your
project, document and keep them (See the <span class="xref myst">README recommendations</span> below)</p></li>
</ul>
<p>This is the example of an organization (hierarchical) for the folder structure. Use it as a visual
illustration of the above:</p>
<p><img alt="Organizing_Data-using_file_systems.png" src="63_chat_with_docs/misc/Organizing_Data-using_file_systems.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>Keep in mind the <a class="reference external" href="https://en.wikipedia.org/wiki/IPO_model#Programming">input-process-output pattern</a>
for the folder structure within your projects.</p>
<section id="readme-recommendation">
<h4>README Recommendation<a class="headerlink" href="#readme-recommendation" title="Permalink to this heading">#</a></h4>
<p>In general, a <a class="reference external" href="https://en.wikipedia.org/wiki/README">README</a> file provides a brief and general
information on the software or project. A <code class="docutils literal notranslate"><span class="pre">README</span></code> file is used to explain the purpose of the
project and the <strong>structure</strong> of the project in a short way. We recommend providing a <code class="docutils literal notranslate"><span class="pre">README</span></code> file
for entire project as well as for every important folder in the project.</p>
<p>Example of the structure for the README: Think first: What is calculated why? (Description); What is
expected? (software and version)</p>
<p>!!! example ‚ÄúREADME‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```Bash
Title:
User:
Date:
Description:
Software:
Version:
Repo URL:
```
</pre></div>
</div>
</section>
</section>
<section id="metadata">
<h3>Metadata<a class="headerlink" href="#metadata" title="Permalink to this heading">#</a></h3>
<p>Another important aspect is the Metadata. It is sufficient to use
<span class="xref myst">Metadata</span> for your HPC project. Metadata
standards, i.e.,
<a class="reference external" href="http://dublincore.org/resources/metadata-basics/">Dublin core</a>,
<a class="reference external" href="https://www.openmicroscopy.org/">OME</a>,
will help to do it easier.</p>
</section>
<section id="data-hygiene">
<h3>Data Hygiene<a class="headerlink" href="#data-hygiene" title="Permalink to this heading">#</a></h3>
<p>Don‚Äôt forget about data hygiene: Classify your current data into critical (need it now), necessary
(need it later) or unnecessary (redundant, trivial or obsolete); Track and classify data throughout
its life cycle (from creation, storage and use to sharing, archiving and destruction); Erase the data
you don‚Äôt need throughout its life cycle.</p>
</section>
<section id="access-rights">
<h3>Access Rights<a class="headerlink" href="#access-rights" title="Permalink to this heading">#</a></h3>
<p>The concept of <strong>permissions</strong> and <strong>ownership</strong> is crucial in Linux. See the
<span class="xref myst">slides of HPC introduction</span> for understanding of the main concept.
Standard Linux changing permission command (i.e <code class="docutils literal notranslate"><span class="pre">chmod</span></code>) valid for ZIH systems as well. The
<strong>group</strong> access level contains members of your project group. Be careful with ‚Äòwrite‚Äô permission
and never allow to change the original data.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="permanent-filesystems">
<h1>Permanent Filesystems<a class="headerlink" href="#permanent-filesystems" title="Permalink to this heading">#</a></h1>
<p>!!! hint</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Do not use permanent filesystems as work directories:

- Even temporary files are kept in the snapshots and in the backup tapes over a long time,
senselessly filling the disks,
- By the sheer number and volume of work files, they may keep the backup from working efficiently.
</pre></div>
</div>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Filesystem Name</p></th>
<th class="head text-left"><p>Usable Directory</p></th>
<th class="head text-left"><p>Availability</p></th>
<th class="head text-left"><p>Type</p></th>
<th class="head text-left"><p>Quota</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Home</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/home</span></code></p></td>
<td class="text-left"><p>global</p></td>
<td class="text-left"><p>Lustre</p></td>
<td class="text-left"><p>per user: 50 GB</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Projects</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/projects</span></code></p></td>
<td class="text-left"><p>global</p></td>
<td class="text-left"><p>NFS</p></td>
<td class="text-left"><p>per project</p></td>
</tr>
</tbody>
</table>
<section id="global-home-filesystem">
<h2>Global /home Filesystem<a class="headerlink" href="#global-home-filesystem" title="Permalink to this heading">#</a></h2>
<p>Each user has 50 GiB in a <code class="docutils literal notranslate"><span class="pre">/home</span></code> directory independent of the granted capacity for the project.
The home directory is mounted with read-write permissions on all nodes of the ZIH system.</p>
<p>Hints for the usage of the global home directory:</p>
<ul class="simple">
<li><p>If you need distinct <code class="docutils literal notranslate"><span class="pre">.bashrc</span></code> files for each machine, you should
create separate files for them, named <code class="docutils literal notranslate"><span class="pre">.bashrc_&lt;machine_name&gt;</span></code></p></li>
</ul>
<p>If a user exceeds her/his quota (total size OR total number of files) she/he cannot
submit jobs into the batch system. Running jobs are not affected.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> We have no feasible way to get the contribution of
 a single user to a project&#39;s disk usage.
</pre></div>
</div>
<p>Some applications and frameworks are known to store cache or temporary data at places where quota
applies. You can change the default places using environment variables. We suggest to put such data
in <code class="docutils literal notranslate"><span class="pre">/tmp</span></code> or workspaces.
We cannot list all applications that do this, but some known ones are</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Application</p></th>
<th class="head text-left"><p>Environment variable</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Singularity</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">SINGULARITY_CACHEDIR</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>pip</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">PIP_CACHE_DIR</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Hugging Face</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">HF_HOME</span></code> and <code class="docutils literal notranslate"><span class="pre">TRANSFORMERS_CACHE</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Torch Extensions</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">TORCH_EXTENSIONS_DIR</span></code></p></td>
</tr>
</tbody>
</table>
<p>Python virtual environments and conda directories can grow quickly,
so they should also be placed inside workspaces.</p>
</section>
<section id="global-projects-filesystem">
<h2>Global /projects Filesystem<a class="headerlink" href="#global-projects-filesystem" title="Permalink to this heading">#</a></h2>
<p>For project data, we have a global project directory, that allows better collaboration between the
members of an HPC project.
Typically, all members of the project have read/write access to that directory.
It can only be written to on the login and export nodes.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>On compute nodes, `/projects` is mounted as read-only, because it must not be used as
work directory and heavy I/O.
</pre></div>
</div>
</section>
<section id="id7">
<h2>Backup<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h2>
<p>Just for the eventuality of a major filesystem crash, we keep tape-based backups of our
permanent filesystems for 180 days. Please send a
<a class="reference external" href="mailto:hpc-support&#37;&#52;&#48;tu-dresden&#46;de">ticket to the HPC support team</a> in case you need backuped data.</p>
</section>
<section id="quotas">
<h2>Quotas<a class="headerlink" href="#quotas" title="Permalink to this heading">#</a></h2>
<p>The quotas of the permanent filesystem are meant to help users to keep only data that is necessary.
Especially in HPC, it happens that millions of temporary files are created within hours. This is the
main reason for performance degradation of the filesystem.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If a quota is exceeded - project or home - (total size OR total number of files)
job submission is forbidden. Running jobs are not affected.
</pre></div>
</div>
<p>The following commands can be used for monitoring:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">show_resources</span></code> shows your projects‚Äô usage of the filesystem.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">quota</span> <span class="pre">-s</span> <span class="pre">-f</span> <span class="pre">/home</span></code> shows the user‚Äôs usage of the filesystem.</p></li>
</ul>
<p>In case a quota is above its limits:</p>
<ul class="simple">
<li><p>Remove core dumps and temporary data</p></li>
<li><p>Talk with your colleagues to identify unused or unnecessarily stored data</p></li>
<li><p>Check your workflow and use <code class="docutils literal notranslate"><span class="pre">/tmp</span></code> or the scratch filesystems for temporary files</p></li>
<li><p><em>Systematically</em> handle your important data:</p>
<ul>
<li><p>For later use (weeks‚Ä¶months) at the ZIH systems, build and zip tar
archives with meaningful names or IDs and store them, e.g., in a workspace in the
<span class="xref myst"><code class="docutils literal notranslate"><span class="pre">walrus</span></code> filesystem</span> or an <span class="xref myst">archive</span></p></li>
<li><p>Refer to the hints for <span class="xref myst">long-term preservation of research data</span></p></li>
</ul>
</li>
</ul>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="working-filesystems">
<h1>Working Filesystems<a class="headerlink" href="#working-filesystems" title="Permalink to this heading">#</a></h1>
<p>As soon as you have access to ZIH systems, you have to manage your data. Several filesystems are
available. Each filesystem serves for special purpose according to their respective capacity,
performance and permanence.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Filesystem Type</p></th>
<th class="head text-left"><p>Usable Directory</p></th>
<th class="head text-left"><p>Capacity</p></th>
<th class="head text-left"><p>Availability</p></th>
<th class="head text-left"><p>Remarks</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">Lustre</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/data/horse</span></code></p></td>
<td class="text-left"><p>20 PB</p></td>
<td class="text-left"><p>global</p></td>
<td class="text-left"><p>Only accessible via <span class="xref myst">Workspaces</span>. <strong>The(!)</strong> working directory to meet almost all demands</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">Lustre</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/data/walrus</span></code></p></td>
<td class="text-left"><p>20 PB</p></td>
<td class="text-left"><p>global</p></td>
<td class="text-left"><p>Only accessible via <span class="xref myst">Workspaces</span>. For moderately low bandwidth, low IOPS. Mounted read-only on compute nodes.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">WEKAio</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/data/weasel</span></code></p></td>
<td class="text-left"><p>1 PB</p></td>
<td class="text-left"><p>global (w/o Power)</p></td>
<td class="text-left"><p><em>Coming 2024!</em> For high IOPS</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">ext4</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/tmp</span></code></p></td>
<td class="text-left"><p>95 GB</p></td>
<td class="text-left"><p>node local</p></td>
<td class="text-left"><p>Systems: tbd. Is cleaned up after the job automatically.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">WEKAio</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/data/cat</span></code></p></td>
<td class="text-left"><p>1 PB</p></td>
<td class="text-left"><p>only Capella</p></td>
<td class="text-left"><p>For high IOPS. Only available on <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Capella</span></code></span>.</p></td>
</tr>
</tbody>
</table>
<section id="id8">
<h2>Recommendations for Filesystem Usage<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h2>
<p>To work as efficient as possible, consider the following points</p>
<ul class="simple">
<li><p>Save source code etc. in <code class="docutils literal notranslate"><span class="pre">/home</span></code> or <code class="docutils literal notranslate"><span class="pre">/projects/...</span></code></p></li>
<li><p>Store checkpoints and other temporary data in <span class="xref myst">workspaces</span> on <code class="docutils literal notranslate"><span class="pre">horse</span></code></p></li>
<li><p>Compilation in <code class="docutils literal notranslate"><span class="pre">/dev/shm</span></code> or <code class="docutils literal notranslate"><span class="pre">/tmp</span></code></p></li>
</ul>
<p>Getting high I/O-bandwidth</p>
<ul class="simple">
<li><p>Use many clients</p></li>
<li><p>Use many processes (writing in the same file at the same time is possible)</p></li>
<li><p>Use large I/O transfer blocks</p></li>
<li><p>Avoid reading many small files. Use data container e. g.
<span class="xref myst">ratarmount</span>
to bundle small files into one</p></li>
</ul>
</section>
<section id="id9">
<h2>Cheat Sheet for Debugging Filesystem Issues<a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h2>
<p>Users can select from the following commands to get some idea about their data.</p>
<section id="id10">
<h3>General<a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h3>
<p>For the first view, you can use the command <code class="docutils literal notranslate"><span class="pre">df</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>df
</pre></div>
</div>
<p>Alternatively, you can use the command <code class="docutils literal notranslate"><span class="pre">findmnt</span></code>, which is also able to report space usage
by adding the parameter <code class="docutils literal notranslate"><span class="pre">-D</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>findmnt<span class="w"> </span>-D
</pre></div>
</div>
<p>Optionally, you can use the parameter <code class="docutils literal notranslate"><span class="pre">-t</span></code> to specify the filesystem type or the parameter <code class="docutils literal notranslate"><span class="pre">-o</span></code> to
alter the output.</p>
<p>!!! important</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Do **not** use the `du`-command for this purpose. It is able to cause issues
for other users, while reading data from the filesystem.
</pre></div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="workspaces">
<h1>Workspaces<a class="headerlink" href="#workspaces" title="Permalink to this heading">#</a></h1>
<p>Storage systems differ in terms of capacity, streaming bandwidth, IOPS rate, etc. Price and
efficiency don‚Äôt allow to have it all in one. That is why fast parallel filesystems at ZIH have
restrictions with regards to <strong>lifetime</strong> and volume <strong><span class="xref myst">quota</span></strong>. The mechanism
of using <em>workspaces</em> enables you to better manage your HPC data. It is common and used at a large
number of HPC centers.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>A **workspace** is a directory, with an associated expiration date, created on behalf of a user
in a certain filesystem.
</pre></div>
</div>
<p>Once the workspace has reached its expiration date, it gets moved to a hidden directory and enters a
grace period. Once the grace period ends, the workspace is deleted permanently. The maximum lifetime
of a workspace depends on the storage system. All workspaces can be extended a certain amount of
times.</p>
<p>!!! tip</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Use the faster filesystems if you need to write temporary data in your computations, and use
the capacity oriented filesystems if you only need to read data for your computations. Please
keep track of your data and move it to a capacity oriented filesystem after the end of your
computations.
</pre></div>
</div>
<section id="workspace-management">
<h2>Workspace Management<a class="headerlink" href="#workspace-management" title="Permalink to this heading">#</a></h2>
<section id="workspace-lifetimes">
<h3>Workspace Lifetimes<a class="headerlink" href="#workspace-lifetimes" title="Permalink to this heading">#</a></h3>
<p>Since the workspace filesystems are intended for different use cases and thus differ in
performance, their granted timespans differ accordingly. The maximum lifetime and number of
renewals are provided in the following table.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Filesystem (use with parameter <code class="docutils literal notranslate"><span class="pre">--filesystem</span> <span class="pre">&lt;filesystem&gt;</span></code>)</p></th>
<th class="head text-right"><p>Max. Duration in Days</p></th>
<th class="head text-right"><p>Extensions</p></th>
<th class="head text-right"><p>Keeptime</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">horse</span></code></p></td>
<td class="text-right"><p>100</p></td>
<td class="text-right"><p>10</p></td>
<td class="text-right"><p>30</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">walrus</span></code></p></td>
<td class="text-right"><p>100</p></td>
<td class="text-right"><p>10</p></td>
<td class="text-right"><p>60</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">cat</span></code></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>30</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>{: summary=‚ÄùSettings for Workspace Filesystems.‚Äù}</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
</tr>
</tbody>
</table>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Currently, not all filesystems are available on all of our five clusters. The page
[Working Filesystems](working.md) provides the necessary information.
</pre></div>
</div>
</section>
<section id="list-available-filesystems">
<h3>List Available Filesystems<a class="headerlink" href="#list-available-filesystems" title="Permalink to this heading">#</a></h3>
<p>To list all available filesystems for using workspaces, you can either invoke <code class="docutils literal notranslate"><span class="pre">ws_list</span> <span class="pre">-l</span></code> or
<code class="docutils literal notranslate"><span class="pre">ws_find</span> <span class="pre">--list</span></code>. Since not all workspace filesystems are available on all HPC systems, the concrete
output differs depending on the system you are logged in. The page <span class="xref myst">Working Filesystems</span>
provides information which filesystem is available on which cluster.</p>
<p>=== ‚ÄúBarnard‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login.barnard$ ws_list -l
available filesystems:
horse (default)
walrus
```
</pre></div>
</div>
<p>=== ‚ÄúAlpha Centauri‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login.alpha$ ws_list -l
available filesystems:
horse (default)
walrus
```
</pre></div>
</div>
<p>=== ‚ÄúCapella‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login.capella$ ws_list -l
available filesystems:
horse
walrus
cat  (default)
```
</pre></div>
</div>
<p>=== ‚ÄúRomeo‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login.romeo$ ws_list -l
available filesystems:
horse (default)
walrus
```
</pre></div>
</div>
<p>!!! note ‚ÄúDefault filesystem‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The output of the commands `ws_find --list` and `ws_list -l` will indicate the
**default filesystem**. If you prefer another filesystem (cf. section
[List Available Filesystems](#list-available-filesystems)), you have to explictly
provide the option `--filesystem &lt;filesystem&gt;` to the workspace commands. If the default
filesystems is the one you want to work with, you can omit this option.
</pre></div>
</div>
</section>
<section id="list-current-workspaces">
<h3>List Current Workspaces<a class="headerlink" href="#list-current-workspaces" title="Permalink to this heading">#</a></h3>
<p>The command <code class="docutils literal notranslate"><span class="pre">ws_list</span></code> lists all your currently active (,i.e, not expired) workspaces, e.g.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ws_list
<span class="go">id: test-workspace</span>
<span class="go">    workspace directory  : /data/horse/ws/marie-test-workspace</span>
<span class="go">    remaining time       : 89 days 23 hours</span>
<span class="go">    creation time        : Wed Dec  6 14:46:12 2023</span>
<span class="go">    expiration date      : Tue Mar  5 14:46:12 2024</span>
<span class="go">    filesystem name      : horse</span>
<span class="go">    available extensions : 10</span>
</pre></div>
</div>
<p>The output of <code class="docutils literal notranslate"><span class="pre">ws_list</span></code> can be customized via several options. The following switch tab provides a
overview of some of these options. All available options can be queried by <code class="docutils literal notranslate"><span class="pre">ws_list</span> <span class="pre">--help</span></code>.</p>
<p>=== ‚ÄúCertain filesystem‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ ws_list --filesystem walrus
id: marie-numbercrunch
    workspace directory  : /data/walrus/ws/marie-numbercrunch
    remaining time       : 89 days 23 hours
    creation time        : Wed Dec  6 14:49:55 2023
    expiration date      : Tue Mar  5 14:49:55 2024
    filesystem name      : walrus
    available extensions : 2
```
</pre></div>
</div>
<p>=== ‚ÄúVerbose output‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ ws_list -v
id: test-workspace
    workspace directory  : /data/horse/ws/marie-test-workspace
    remaining time       : 89 days 23 hours
    creation time        : Wed Dec  6 14:46:12 2023
    expiration date      : Tue Mar  5 14:46:12 2024
    filesystem name      : scratch
    available extensions : 10
    acctcode             : p_number_crunch
    reminder             : Tue Feb 27 14:46:12 2024
    mailaddress          : marie@tu-dresden.de
```
</pre></div>
</div>
<p>=== ‚ÄúTerse output‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ ws_list -t
id: test-workspace
    workspace directory  : /data/horse/ws/marie-test-workspace
    remaining time       : 89 days 23 hours
    available extensions : 10
id: numbercrunch
    workspace directory  : /data/walrus/ws/marie-numbercrunch
    remaining time       : 89 days 23 hours
    available extensions : 2
```
</pre></div>
</div>
<p>=== ‚ÄúShow only names‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ ws_list -s
test-workspace
numbercrunch
```
</pre></div>
</div>
<p>=== ‚ÄúSort by remaining time‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>You can list your currently allocated workspace by remaining time. This is especially useful
for housekeeping tasks, such as extending soon expiring workspaces if necessary.

```
marie@login$ ws_list -R -t
id: test-workspace
     workspace directory  : /data/horse/ws/marie-test-workspace
     remaining time       : 89 days 23 hours
     available extensions : 10
id: marie-numbercrunch
    workspace directory  : /data/walrus/ws/marie-numbercrunch
    remaining time       : 89 days 23 hours
    available extensions : 2
```
</pre></div>
</div>
</section>
<section id="allocate-a-workspace">
<h3>Allocate a Workspace<a class="headerlink" href="#allocate-a-workspace" title="Permalink to this heading">#</a></h3>
<p>To allocate a workspace in one of the listed filesystems, use <code class="docutils literal notranslate"><span class="pre">ws_allocate</span></code>. It is necessary to
specify a unique name and the duration (in days) of the workspace.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">ws_allocate: [options] workspace_name duration</span>

<span class="go">Options:</span>
<span class="go">  -h [ --help]               produce help message</span>
<span class="go">  -V [ --version ]           show version</span>
<span class="go">  -d [ --duration ] arg (=1) duration in days</span>
<span class="go">  -n [ --name ] arg          workspace name</span>
<span class="go">  -F [ --filesystem ] arg    filesystem</span>
<span class="go">  -r [ --reminder ] arg      reminder to be sent n days before expiration</span>
<span class="go">  -m [ --mailaddress ] arg   mailaddress to send reminder to (works only with tu-dresden.de mails)</span>
<span class="go">  -x [ --extension ]         extend workspace</span>
<span class="go">  -u [ --username ] arg      username</span>
<span class="go">  -g [ --group ]             group workspace</span>
<span class="go">  -c [ --comment ] arg       comment</span>
</pre></div>
</div>
<p>!!! Note ‚ÄúName of a workspace‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The workspace name should help you to remember the experiment and data stored here. It has to
be unique on a certain filesystem. On the other hand it is possible to use the very same name
for workspaces on different filesystems.
</pre></div>
</div>
<p>=== ‚ÄúSimple allocation‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The simple way to allocate a workspace is calling `ws_allocate` command with two arguments,
where the first specifies the workspace name and the second the duration. This allocates a
workspace on the default filesystem with no e-mail reminder.

```console
marie@login$ ws_allocate test-workspace 90
Info: creating workspace.
/data/horse/ws/marie-test-workspace
remaining extensions  : 10
remaining time in days: 90
```
</pre></div>
</div>
<p>=== ‚ÄúSpecific filesystem‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>In order to allocate a workspace on a non-default filesystem, the option
`--filesystem &lt;filesystem&gt;` is required.

```console
marie@login$ ws_allocate --filesystem walrus test-workspace 99
Info: creating workspace.
/data/walrus/ws/marie-test-workspace
remaining extensions  : 2
remaining time in days: 99
```
</pre></div>
</div>
<p>=== ‚Äúwith e-mail reminder‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>This command will create a workspace with the name `test-workspace` on the `/horse` filesystem
(default)
with a duration of 99 days and send an e-mail reminder. The e-mail reminder will be sent every
day starting 7 days prior to expiration. We strongly recommend setting this e-mail reminder.

```console
marie@login$ ws_allocate --reminder 7 --mailaddress marie@tu-dresden.de test-workspace 99
Info: creating workspace.
/data/horse/ws/marie-test-workspace
remaining extensions  : 10
remaining time in days: 99
```
</pre></div>
</div>
<p>Please refer to the <span class="xref myst">section Cooperative Usage</span> for
group workspaces.</p>
</section>
<section id="extension-of-a-workspace">
<h3>Extension of a Workspace<a class="headerlink" href="#extension-of-a-workspace" title="Permalink to this heading">#</a></h3>
<p>The lifetime of a workspace is finite and different filesystems (storage systems) have different
maximum durations. The life time of a workspace can be adjusted multiple times, depending on the
filesystem. You can find the concrete values in the
<span class="xref myst">section settings for workspaces</span>.</p>
<p>Use the command <code class="docutils literal notranslate"><span class="pre">ws_extend</span> <span class="pre">[-F</span> <span class="pre">filesystem]</span> <span class="pre">workspace</span> <span class="pre">days</span></code> to extend your workspace:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ws_extend<span class="w"> </span>-F<span class="w"> </span>scratch<span class="w"> </span>test-workspace<span class="w"> </span><span class="m">100</span>
<span class="go">Info: extending workspace.</span>
<span class="go">/data/horse/ws/marie-test-workspace</span>
<span class="go">remaining extensions  : 1</span>
<span class="go">remaining time in days: 100</span>
</pre></div>
</div>
<p>E-mail reminder settings are retained. I.e., previously set e-mail alerts apply to the extended
workspace, too.</p>
<p>!!! attention</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>With the `ws_extend` command, a new duration for the workspace is set. The new duration is not
added to the remaining lifetime!
</pre></div>
</div>
<p>This means when you extend a workspace that expires in 90 days with the command</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ws_extend<span class="w"> </span>-F<span class="w"> </span>scratch<span class="w"> </span>test-workspace<span class="w"> </span><span class="m">40</span>
</pre></div>
</div>
<p>it will now expire in 40 days, <strong>not</strong> in 130 days!</p>
</section>
<section id="send-reminder-for-workspace-expiration-date">
<h3>Send Reminder for Workspace Expiration Date<a class="headerlink" href="#send-reminder-for-workspace-expiration-date" title="Permalink to this heading">#</a></h3>
<p>We strongly recommend using one of the two provided ways to ensure that the expiration date of a
workspace is not forgotten.</p>
<section id="send-daily-reminder">
<h4>Send Daily Reminder<a class="headerlink" href="#send-daily-reminder" title="Permalink to this heading">#</a></h4>
<p>An e-mail reminder can be set at workspace allocation using</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">ws_allocate --reminder &lt;N&gt; --mailaddress &lt;your.email&gt;@tu-dresden.de [...]</span>
</pre></div>
</div>
<p>This will send an e-mail every day starting <code class="docutils literal notranslate"><span class="pre">N</span></code> days prior to the expiration date.
See the <span class="xref myst">example above</span> for reference.</p>
<p>If you missed setting an e-mail reminder at workspace allocation, you can add a reminder later, e.g.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span># initial allocation
marie@login$ ws_allocate --name test-workspace --duration 17
[...]
# add e-mail reminder
marie@login$ ws_allocate --name test-workspace --duration 17 --reminder 7 --mailaddress &lt;your.email&gt;@tu-dresden.de
--extension
</pre></div>
</div>
<p>This will reallocate the workspace, which counts against your maximum number of reallocations (Note:
No data is deleted, but the database entry is modified).</p>
</section>
<section id="send-calendar-invitation">
<h4>Send Calendar Invitation<a class="headerlink" href="#send-calendar-invitation" title="Permalink to this heading">#</a></h4>
<p>The command <code class="docutils literal notranslate"><span class="pre">ws_send_ical</span></code> sends you an ical event on the expiration date of a specified workspace.
This calendar invitation can be further managed according to your personal preferences.
The syntax is as follows:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">ws_send_ical [--filesystem &lt;filesystem&gt;] --mail &lt;mail address&gt; --workspace &lt;workspace name&gt;</span>
</pre></div>
</div>
<p>E.g.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">ws_send_ical --filesystem horse --mail &lt;your.email&gt;@tu-dresden.de --workspace test-workspace</span>
</pre></div>
</div>
</section>
</section>
<section id="deletion-of-a-workspace">
<h3>Deletion of a Workspace<a class="headerlink" href="#deletion-of-a-workspace" title="Permalink to this heading">#</a></h3>
<p>There is an <span class="xref myst">Expire process</span> for every workspace filesystem running on a daily
basis. These processes check the lifetime of all workspaces and move expired workspaces into the
grace period.</p>
<p>In addition to this automatic process, you also have the option of <strong>explicitly releasing
workspaces</strong> using the <code class="docutils literal notranslate"><span class="pre">ws_release</span></code> command. It is mandatory to specify the name of the
workspace and the filesystem in which it is allocated:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ws_release<span class="w"> </span>--filesystem<span class="w"> </span>horse<span class="w"> </span>--name<span class="w"> </span>test-workspace
</pre></div>
</div>
<p>You can list your already released or expired workspaces using the <code class="docutils literal notranslate"><span class="pre">ws_restore</span> <span class="pre">--list</span></code> command.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ws_restore<span class="w"> </span>--list
<span class="go">horse:</span>
<span class="go">marie-test-workspace-1701873807</span>
<span class="go">    unavailable since Wed Dec  6 15:43:27 2023</span>
<span class="go">walrus:</span>
<span class="go">marie-numbercrunch-1701873907</span>
<span class="go">    unavailable since Wed Dec  6 15:45:07 2023</span>
</pre></div>
</div>
<p>In this example, the user <code class="docutils literal notranslate"><span class="pre">marie</span></code> has two inactive, i.e., expired, workspaces namely
<code class="docutils literal notranslate"><span class="pre">test-workspace</span></code> in <code class="docutils literal notranslate"><span class="pre">horse</span></code>, as well as <code class="docutils literal notranslate"><span class="pre">numbercrunch</span></code> in the <code class="docutils literal notranslate"><span class="pre">walrus</span></code> filesystem. The command
<code class="docutils literal notranslate"><span class="pre">ws_restore</span> <span class="pre">--list</span></code> lists the name of the workspace and its expiration date. As you can see, the
expiration date in Unix timestamp format is added to the workspace name.</p>
<p>!!! hint ‚ÄúDeleting data in an expired workspace‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you are short on quota, you might want to delete data in expired workspaces since it counts
to your quota. Expired workspaces are moved to a hidden directory named `.removed`. The access
rights remain unchanged. I.e., you can delete the data inside the workspace directory but you
must not delete the workspace directory itself!
</pre></div>
</div>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>When you release a workspace **manually**, it will not receive a grace period and be
**permanently deleted** the **next day**. The advantage of this design is that you can create
and release workspaces inside jobs and not pollute the filesystem with data no one needs anymore
in the hidden directories (when workspaces are in the grace period).
</pre></div>
</div>
<section id="expire-process">
<h4>Expire Process<a class="headerlink" href="#expire-process" title="Permalink to this heading">#</a></h4>
<p>The clean up process of expired workspaces is automatically handled by a so-called expirer process.
It performs the following steps once per day and filesystem:</p>
<ul class="simple">
<li><p>Check for remaining life time of all workspaces.</p>
<ul>
<li><p>If the workspaces expired, move it to a hidden directory so that it becomes inactive.</p></li>
</ul>
</li>
<li><p>Send reminder e-mails to users if the reminder functionality was configured for their particular
workspaces.</p></li>
<li><p>Scan through all workspaces in grace period.</p>
<ul>
<li><p>If a workspace exceeded the grace period, the workspace and its data are permanently deleted.</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="restoring-expired-workspaces">
<h3>Restoring Expired Workspaces<a class="headerlink" href="#restoring-expired-workspaces" title="Permalink to this heading">#</a></h3>
<p>At expiration time your workspace will be moved to a special, hidden directory. For a month,
you can still restore your data <strong>into an existing workspace</strong> using the command <code class="docutils literal notranslate"><span class="pre">ws_restore</span></code>.</p>
<p>The expired workspace has to be specified by its full name as listed by <code class="docutils literal notranslate"><span class="pre">ws_restore</span> <span class="pre">--list</span></code>,
including username prefix and timestamp suffix. Otherwise, it cannot be uniquely identified. The
target workspace, on the other hand, must be given with just its short name, as listed by <code class="docutils literal notranslate"><span class="pre">ws_list</span></code>,
without the username prefix.</p>
<p>Both workspaces must be on the <strong>very same filesystem</strong>. The data from the old workspace will be
moved into a directory in the new workspace with the name of the old one. This means a newly
allocated workspace works as well as a workspace that already contains data.</p>
<p>!!! note ‚ÄúSteps for restoring a workspace‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1. Use `ws_restore --list` to list all your expired workspaces and get the correct identifier
   string for the expired workspace. The identifier string of an expired and an active workspace
   are different!
1. (Optional) Allocate a new workspace on the very same filesystem using `ws_allocate`.
1. Then, you can invoke `ws_restore &lt;workspace_name&gt; &lt;target_name&gt;` to restore the expired
   workspace into the active workspace.
</pre></div>
</div>
<p>??? example ‚ÄúRestore workspace <code class="docutils literal notranslate"><span class="pre">number_crunch</span></code> into new workspace <code class="docutils literal notranslate"><span class="pre">long_computations</span></code>‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>This example depictes the necessary steps to restore the expired workspace `number_crunch` into
a newly allocated workspace named `long_computations.`

**First step**: List expired workspaces and retrieve correct identifier for the expired workspace.
In this example, `marie` has two expired workspaces, namely `test-workspace` and `number_crunch`
both in the `horse` filesystem. The identifier for the restore command is
`marie-number_crunch-1701873907`.

```console
marie@login$ ws_restore --list
horse:
marie-test-workspace-1701873807
    unavailable since Wed Dec  6 15:43:27 2023
marie-number_crunch-1701873907
    unavailable since Wed Dec  6 15:45:07 2023
walrus:
```

**Second step:** Allocate new workspace `long_compuations` on the very same filesystem. Please
refer to the documentation of the [`ws_allocate` command](#allocate-a-workspace) for
additional useful options.

```console
marie@login$ ws_allocate --filesystem horse --name long_computations --duration 60
```

**Third step:** Invoke the command `ws_restore`.

```console
marie@login$ ws_restore --filesystem horse marie-number_crunch-1701873907 long_computations
to verify that you are human, please type &#39;menunesarowo&#39;: menunesarowo
you are human
Info: restore successful, database entry removed.
```
</pre></div>
</div>
</section>
</section>
<section id="linking-workspaces-in-home">
<h2>Linking Workspaces in HOME<a class="headerlink" href="#linking-workspaces-in-home" title="Permalink to this heading">#</a></h2>
<p>It might be valuable to have links to personal workspaces within a certain directory, e.g., your
home directory. The command <code class="docutils literal notranslate"><span class="pre">ws_register</span> <span class="pre">DIR</span></code> will create and manage links to all personal
workspaces within in the directory <code class="docutils literal notranslate"><span class="pre">DIR</span></code>. Calling this command will do the following:</p>
<ul class="simple">
<li><p>The directory <code class="docutils literal notranslate"><span class="pre">DIR</span></code> will be created if necessary.</p></li>
<li><p>Links to all personal workspaces will be managed:</p>
<ul>
<li><p>Create links to all available workspaces if not already present.</p></li>
<li><p>Remove links to released workspaces.</p></li>
</ul>
</li>
</ul>
<p>!!! hint ‚ÄúAutomatic update of links‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>An automatic update of the workspace links can be invoked by putting the command
`ws_register DIR` in your personal `shell` configuration file (e.g., `.bashrc`).

When the filesystems are slow or even down, the command `ws_register` in your `.bashrc` can hang
preventing you from logging in to ZIH systems.
In order to make it failsafe, we recommend using `ws_register` in combination with a timeout.

```bash
ANSRED=$&#39;\e[41;1m&#39;
ANSRESET=$&#39;\e[0m&#39;
buf=&quot;$(timeout 10s ws_register $HOME/workspaces)&quot;
if test $? -eq 0; then
    echo &quot;${buf}&quot;
else
    echo &quot;${ANSRED} ws_register: timeout after 10 seconds.${ANSRESET}\n&quot;
fi
```
</pre></div>
</div>
</section>
<section id="how-to-use-workspaces">
<h2>How to use Workspaces<a class="headerlink" href="#how-to-use-workspaces" title="Permalink to this heading">#</a></h2>
<p>There are three typical options for the use of workspaces:</p>
<section id="per-job-storage">
<h3>Per-Job Storage<a class="headerlink" href="#per-job-storage" title="Permalink to this heading">#</a></h3>
<p>The idea of a ‚Äúworkspace per-job storage‚Äù addresses the need of a batch job for a directory for
temporary data which can be deleted afterwards. To help you to write your own
<span class="xref myst">(Slurm) job file</span>, suited to your needs, we came up with
the following example (which works <span class="xref myst">for the program g16</span>).</p>
<p>!!! hint</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Please do not blind copy the example, but rather take the essential idea and concept and adjust
it to your needs and workflow, e.g.

* adopt Slurm options for ressource specification,
* insert the path to your input file,
* specify what software you want to [load](../software/modules.md),
* and call the actual software to do your computation.
</pre></div>
</div>
<p>!!! example ‚ÄúUsing temporary workspaces for I/O intensive tasks‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash

#SBATCH --time=48:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1
## The optional constraint for the filesystem feature depends
## on the filesystem on which you want to use a workspace.
## Documentation here https://compendium.hpc.tu-dresden.de/jobs_and_resources/slurm/#filesystem-features
#SBATCH --constraint=local_disk
#SBATCH --cpus-per-task=24

# Load the software you need here
module purge
module load &lt;modules&gt;

# The path to where your input file is located
INPUTFILE=&quot;/path/to/my/inputfile.data&quot;
test ! -f &quot;${INPUTFILE}&quot; &amp;&amp; echo &quot;Error: Could not find the input file ${INPUTFILE}&quot; &amp;&amp; exit 1

# The workspace where results from multiple expirements will be saved for later analysis
RESULT_WSDIR=&quot;/path/to/workspace-experiments-results&quot;
test -z &quot;${RESULT_WSDIR}&quot; &amp;&amp; echo &quot;Error: Cannot find workspace ${RESULT_WSDIR}&quot; &amp;&amp; exit 1

# Allocate workspace for this job. Adjust time span to time limit of the job (--duration).
WSNAME=computation_$SLURM_JOB_ID
export WSDDIR=$(ws_allocate --filesystem horse --name ${WSNAME} --duration 2)
echo ${WSDIR}

# Check allocation
test -z &quot;${WSDIR}&quot; &amp;&amp; echo &quot;Error: Cannot allocate workspace ${WSDIR}&quot; &amp;&amp; exit 1

# Change to workspace directory
cd ${WSDIR}

# Adjust the following line to invoke the program you want to run
srun &lt;application&gt; &lt; &quot;${INPUTFILE}&quot; &gt; logfile.log

# Move result and log files of interest to directory named &#39;results&#39;. This directory and its
# content will be saved in another storage location for later analysis. All files and
# directories will be deleted right away at the end of this job file.
mkdir results
cp &lt;results and log files&gt; results/

# Save result files in a general workspace (RESULT_WSDIR, s.a.) holding results from several
# experiments.
# Compress results with bzip2 (which includes CRC32 Checksums).
bzip2 --compress --stdout -4 &quot;${WSDIR}/results&quot; &gt; ${RESULT_WSDIR}/gaussian_job-${SLURM_JOB_ID}.bz2
RETURN_CODE=$?
COMPRESSION_SUCCESS=&quot;$(if test ${RETURN_CODE} -eq 0; then echo &#39;TRUE&#39;; else echo &#39;FALSE&#39;; fi)&quot;

# Clean up workspace
if [ &quot;TRUE&quot; = ${COMPRESSION_SUCCESS} ]; then
    test -d ${WSDIR} &amp;&amp; rm -rf ${WSDIR}/*
    # Reduces grace period to 1 day!
    ws_release -F horse ${WSNAME}
else
    echo &quot;Error with compression and writing of results&quot;
    echo &quot;Please check the folder \&quot;${WSDIR}\&quot; for any partial(?) results.&quot;
    exit 1
fi
```
</pre></div>
</div>
</section>
<section id="data-for-a-campaign">
<h3>Data for a Campaign<a class="headerlink" href="#data-for-a-campaign" title="Permalink to this heading">#</a></h3>
<p>For a series of jobs or calculations that work on the same data, you should allocate a workspace
once, e.g., in <code class="docutils literal notranslate"><span class="pre">horse</span></code> for 100 days:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ws_allocate<span class="w"> </span>--filesystem<span class="w"> </span>horse<span class="w"> </span>my_scratchdata<span class="w"> </span><span class="m">100</span>
<span class="go">Info: creating workspace.</span>
<span class="go">/data/horse/ws/marie-my_scratchdata</span>
<span class="go">remaining extensions  : 10</span>
<span class="go">remaining time in days: 99</span>
</pre></div>
</div>
<p>You can grant your project group access rights:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>chmod<span class="w"> </span>g+wrx<span class="w"> </span>/data/horse/ws/marie-my_scratchdata
</pre></div>
</div>
<p>And verify it with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ls<span class="w"> </span>-la<span class="w"> </span>/data/horse/ws/marie-my_scratchdata
<span class="go">total 8</span>
<span class="go">drwxrwx--- 2 marie    hpcsupport 4096 Jul 10 09:03 .</span>
<span class="go">drwxr-xr-x 5 operator adm        4096 Jul 10 09:01 ..</span>
</pre></div>
</div>
</section>
<section id="mid-term-storage">
<h3>Mid-Term Storage<a class="headerlink" href="#mid-term-storage" title="Permalink to this heading">#</a></h3>
<!-- TODO: to be confirmed - is walrus really intended for this purpose? -->
<p>For data that rarely changes but consumes a lot of space, the <code class="docutils literal notranslate"><span class="pre">walrus</span></code> filesystem can be used. Note
that this is mounted read-only on the compute nodes, so you cannot use it as a work directory for
your jobs!</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ws_allocate<span class="w"> </span>--filesystem<span class="w"> </span>walrus<span class="w"> </span>my_inputdata<span class="w"> </span><span class="m">100</span>
<span class="go">/data/walrus/ws/marie-my_inputdata</span>
<span class="go">remaining extensions  : 2</span>
<span class="go">remaining time in days: 100</span>
</pre></div>
</div>
<!-- TODO to be confirmed for walrus / warm_archive replacement
!!!Attention

    The warm archive is not built for billions of files. There
    is a quota for 100.000 files per group. Please archive data.
-->
<!-- TODO command not found - not available yet for walrus?!
To see your active quota use

```console
marie@login$ qinfo quota /data/walrus/ws/
```

Note that the workspaces reside under the mountpoint `/warm_archive/ws/` and not `/warm_archive`
anymore.
-->
</section>
</section>
<section id="cooperative-usage-group-workspaces">
<h2>Cooperative Usage (Group Workspaces)<a class="headerlink" href="#cooperative-usage-group-workspaces" title="Permalink to this heading">#</a></h2>
<p>When a workspace is created with the option <code class="docutils literal notranslate"><span class="pre">-g,</span> <span class="pre">--group</span></code>, it gets a group workspace that is visible
to others (if in the same group) via <code class="docutils literal notranslate"><span class="pre">ws_list</span> <span class="pre">-g</span></code>.</p>
<p>!!! hint ‚ÄúChoose group‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you are member of multiple groups, then the group workspace is visible for your primary
group. You can list all groups you belong to via `groups`, and the first entry is your
primary group.

Nevertheless, you can create a group workspace for any of your groups following these two
steps:

1. Change to the desired group using `newgrp &lt;other-group&gt;`.
1. Create the group workspace as usual, i.e., `ws_allocate --group [...]`

The [page on Sharing Data](data_sharing.md) provides
information on how to grant access to certain colleagues and whole project groups.
</pre></div>
</div>
<p>!!! Example ‚ÄúAllocate and list group workspaces‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If Marie wants to share results and scripts in a workspace with all of her colleagues
in the project `p_number_crunch`, she can allocate a so-called group workspace.

```console
marie@login$ ws_allocate --group --name numbercrunch --duration 30
Info: creating workspace.
/data/horse/ws/marie-numbercrunch
remaining extensions  : 10
remaining time in days: 30
```

This workspace directory is readable for the group, e.g.,

```console
marie@login$ ls -ld /data/horse/ws/marie-numbercrunch
drwxr-x--- 2 marie p_number_crunch 4096 Mar  2 15:24 /data/horse/ws/marie-numbercrunch
```

All members of the project group `p_number_crunch` can now list this workspace using
`ws_list -g` and access the data (read-only).

```console
martin@login$ ws_list -g -t
id: numbercrunch
     workspace directory  : /data/horse/ws/marie-numbercrunch
     remaining time       : 29 days 23 hours
     available extensions : 10
```
</pre></div>
</div>
</section>
<section id="faq-and-troubleshooting">
<h2>FAQ and Troubleshooting<a class="headerlink" href="#faq-and-troubleshooting" title="Permalink to this heading">#</a></h2>
<p><strong>Q</strong>: I am getting the error <code class="docutils literal notranslate"><span class="pre">Error:</span> <span class="pre">could</span> <span class="pre">not</span> <span class="pre">create</span> <span class="pre">workspace</span> <span class="pre">directory!</span></code></p>
<p><strong>A</strong>: Please check the ‚Äúlocale‚Äù setting of your SSH client. Some clients (e.g. the one from Mac)
set values that are not valid on our ZIH systems. You should overwrite <code class="docutils literal notranslate"><span class="pre">LC_CTYPE</span></code> and set it to a
valid locale value like <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">LC_CTYPE=de_DE.UTF-8</span></code>.</p>
<p>A list of valid locales can be retrieved via <code class="docutils literal notranslate"><span class="pre">locale</span> <span class="pre">-a</span></code>.</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">language_CountryCode.UTF-8</span></code> (or plain) settings. Avoid ‚Äúiso‚Äù codepages!</p>
<p>Examples:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Language</p></th>
<th class="head"><p>Code</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Chinese - Simplified</p></td>
<td><p>zh_CN.UTF-8</p></td>
</tr>
<tr class="row-odd"><td><p>English</p></td>
<td><p>en_US.UTF-8</p></td>
</tr>
<tr class="row-even"><td><p>French</p></td>
<td><p>fr_FR.UTF-8</p></td>
</tr>
<tr class="row-odd"><td><p>German</p></td>
<td><p>de_DE.UTF-8</p></td>
</tr>
</tbody>
</table>
<hr class="docutils" />
<p><strong>Q</strong>: I am getting the error <code class="docutils literal notranslate"><span class="pre">Error:</span> <span class="pre">target</span> <span class="pre">workspace</span> <span class="pre">does</span> <span class="pre">not</span> <span class="pre">exist!</span></code> when trying to restore my
workspace.</p>
<p><strong>A</strong>: The workspace you want to restore into is either not on the same filesystem or you used the
wrong name. Use only the short name that is listed after <code class="docutils literal notranslate"><span class="pre">id:</span></code> when using <code class="docutils literal notranslate"><span class="pre">ws_list</span></code>.
See section <span class="xref myst">restoring expired workspaces</span>.</p>
<hr class="docutils" />
<p><strong>Q</strong>: I forgot to specify an e-mail reminder when allocating my workspace. How can I add the
e-mail alert functionality to an existing workspace?</p>
<p><strong>A</strong>: You can add the e-mail alert by ‚Äúoverwriting‚Äù the workspace settings via</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ws_allocate<span class="w"> </span>--extension<span class="w"> </span>--mailaddress<span class="w"> </span>&lt;mail<span class="w"> </span>address&gt;<span class="w"> </span>--reminder<span class="w"> </span>&lt;days&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">             </span>--name<span class="w"> </span>&lt;workspace-name&gt;<span class="w"> </span>--duration<span class="w"> </span>&lt;duration&gt;<span class="w"> </span>--filesystem<span class="w"> </span>&lt;filesystem&gt;
</pre></div>
</div>
<p>E.g.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ws_allocate<span class="w"> </span>--extension<span class="w"> </span>--mailaddress<span class="w"> </span>&lt;your.email&gt;@tu-dresden.de<span class="w"> </span>--reminder<span class="w"> </span><span class="m">7</span><span class="w"> </span><span class="se">\</span>
<span class="w">             </span>--name<span class="w"> </span>numbercrunch<span class="w"> </span>--duration<span class="w"> </span><span class="m">20</span><span class="w"> </span>--filesystem<span class="w"> </span>horse
</pre></div>
</div>
<p>This will lower the remaining extensions by one.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="transfer-data-inside-zih-systems-with-datamover">
<h1>Transfer Data Inside ZIH Systems with Datamover<a class="headerlink" href="#transfer-data-inside-zih-systems-with-datamover" title="Permalink to this heading">#</a></h1>
<p>With the <strong>Datamover</strong>, we provide special data transfer machines for transferring data between
the ZIH filesystems with best transfer speed. The Datamover machine is not accessible
through SSH as it is dedicated to data transfers. To move or copy files from one filesystem to
another, you have to use the following commands after logging in to any of the ZIH HPC systems:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dtcp</span></code>, <code class="docutils literal notranslate"><span class="pre">dtls</span></code>, <code class="docutils literal notranslate"><span class="pre">dtmv</span></code>, <code class="docutils literal notranslate"><span class="pre">dtrm</span></code>, <code class="docutils literal notranslate"><span class="pre">dtrsync</span></code>, <code class="docutils literal notranslate"><span class="pre">dttar</span></code>, and <code class="docutils literal notranslate"><span class="pre">dtwget</span></code></p></li>
</ul>
<p>These special commands submit a <span class="xref myst">batch job</span> to the data transfer
machines performing the selected command. Their syntax and behavior is the very same as the
well-known shell commands without the prefix <em><code class="docutils literal notranslate"><span class="pre">dt</span></code></em>, except for the following options.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Additional Option</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--account=ACCOUNT</span></code></p></td>
<td><p>Assign data transfer job to specified account.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--blocking</span>&#160;&#160;&#160;&#160;&#160;&#160; </code></p></td>
<td><p>Do not return until the data transfer job is complete. (default for <code class="docutils literal notranslate"><span class="pre">dtls</span></code>)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--time=TIME</span>&#160;&#160;&#160;&#160;&#160; </code></p></td>
<td><p>Job time limit (default: 18 h).</p></td>
</tr>
</tbody>
</table>
<section id="managing-transfer-jobs">
<h2>Managing Transfer Jobs<a class="headerlink" href="#managing-transfer-jobs" title="Permalink to this heading">#</a></h2>
<p>There are the commands <code class="docutils literal notranslate"><span class="pre">dtinfo</span></code>, <code class="docutils literal notranslate"><span class="pre">dtqueue</span></code>, <code class="docutils literal notranslate"><span class="pre">dtq</span></code>, and <code class="docutils literal notranslate"><span class="pre">dtcancel</span></code> to manage your transfer commands
and jobs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dtinfo</span></code> shows information about the nodes of the data transfer machine (like <code class="docutils literal notranslate"><span class="pre">sinfo</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dtqueue</span></code> and <code class="docutils literal notranslate"><span class="pre">dtq</span></code> show all your data transfer jobs (like <code class="docutils literal notranslate"><span class="pre">squeue</span> <span class="pre">--me</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dtcancel</span></code> signals data transfer jobs (like <code class="docutils literal notranslate"><span class="pre">scancel</span></code>).</p></li>
</ul>
<p>To identify the mount points of the different filesystems on the data transfer machine, use
<code class="docutils literal notranslate"><span class="pre">dtinfo</span></code>. It shows an output like this:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Directory on Datamover</p></th>
<th class="head text-left"><p>Mounting Clusters</p></th>
<th class="head text-left"><p>Directory on Cluster</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/home</span></code></p></td>
<td class="text-left"><p>Alpha,Barnard,Capella,Julia,Power9,Romeo</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/home</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/projects</span></code></p></td>
<td class="text-left"><p>Alpha,Barnard,Capella,Julia,Power9,Romeo</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/projects</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/data/horse</span></code></p></td>
<td class="text-left"><p>Alpha,Barnard,Capella,Julia,Power9,Romeo</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/data/horse</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/data/walrus</span></code></p></td>
<td class="text-left"><p>Alpha,Barnard,Capella,Julia,Power9</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/data/walrus</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/data/octopus</span></code></p></td>
<td class="text-left"><p>Alpha,Barnard,Capella,Power9,Romeo</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/data/octopus</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/data/cat</span></code></p></td>
<td class="text-left"><p>Capella</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/data/cat</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/data/archiv</span></code></p></td>
<td class="text-left"><p></p></td>
<td class="text-left"><p></p></td>
</tr>
</tbody>
</table>
</section>
<section id="usage-of-datamover">
<h2>Usage of Datamover<a class="headerlink" href="#usage-of-datamover" title="Permalink to this heading">#</a></h2>
<p>!!! example ‚ÄúCopy data from <code class="docutils literal notranslate"><span class="pre">/data/horse</span></code> to <code class="docutils literal notranslate"><span class="pre">/projects</span></code> filesystem.‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ dtcp -r /data/horse/ws/marie-workdata/results /projects/p_number_crunch/.
```
</pre></div>
</div>
<p>!!! example ‚ÄúMove data from <code class="docutils literal notranslate"><span class="pre">/data/horse</span></code> to <code class="docutils literal notranslate"><span class="pre">/data/walrus</span></code> filesystem.‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ dtmv /data/horse/ws/marie-workdata/results /data/walrus/ws/marie-archive/.
```
</pre></div>
</div>
<p>!!! example ‚ÄúArchive data from <code class="docutils literal notranslate"><span class="pre">/data/walrus</span></code> to <code class="docutils literal notranslate"><span class="pre">/archiv</span></code> filesystem.‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ dttar -czf /archiv/p_number_crunch/results.tgz /data/walrus/ws/marie-workdata/results
```
</pre></div>
</div>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Do not generate files in the `/archiv` filesystem much larger that 500 GB!
</pre></div>
</div>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The `projects` filesystem is not writable from within batch jobs.
However, you can store the data in the [`walrus` filesystem](../data_lifecycle/working.md)
using the Datamover nodes via `dt*` commands.
</pre></div>
</div>
</section>
<section id="transferring-files-between-zih-systems-and-group-drive">
<h2>Transferring Files Between ZIH Systems and Group Drive<a class="headerlink" href="#transferring-files-between-zih-systems-and-group-drive" title="Permalink to this heading">#</a></h2>
<p>In order to let the datamover have access to your group drive, copy your public SSH key from ZIH
system to <code class="docutils literal notranslate"><span class="pre">login1.zih.tu-dresden.de</span></code>, first.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ssh-copy-id<span class="w"> </span>-i<span class="w"> </span>~/.ssh/id_rsa.pub<span class="w"> </span>login1.zih.tu-dresden.de
<span class="gp"># </span>Export<span class="w"> </span>the<span class="w"> </span>name<span class="w"> </span>of<span class="w"> </span>your<span class="w"> </span>group<span class="w"> </span>drive<span class="w"> </span><span class="k">for</span><span class="w"> </span>reuse<span class="w"> </span>of<span class="w"> </span>example<span class="w"> </span>commands
<span class="gp">marie@login$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">GROUP_DRIVE_NAME</span><span class="o">=</span>&lt;my-drive-name&gt;
</pre></div>
</div>
<p>!!! example ‚ÄúCopy data from your group drive to <code class="docutils literal notranslate"><span class="pre">/data/horse</span></code> filesystem.‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ dtrsync -av dgw.zih.tu-dresden.de:/glw/${GROUP_DRIVE_NAME}/inputfile /data/horse/ws/marie-workdata/.
```
</pre></div>
</div>
<p>!!! example ‚ÄúCopy data from <code class="docutils literal notranslate"><span class="pre">/data/horse</span></code> filesystem to your group drive.‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ dtrsync -av /data/horse/ws/marie-workdata/resultfile dgw.zih.tu-dresden.de:/glw/${GROUP_DRIVE_NAME}/.
```
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="transfer-data-to-from-zih-systems-via-dataport-nodes">
<h1>Transfer Data to/from ZIH Systems via Dataport Nodes<a class="headerlink" href="#transfer-data-to-from-zih-systems-via-dataport-nodes" title="Permalink to this heading">#</a></h1>
<p>To copy large data to/from ZIH systems, the so-called <strong>dataport nodes</strong> should be used. While it is
possible to transfer small files directly via the login nodes, they are not intended to be used that
way. Furthermore, longer transfers will hit the CPU time limit on the login nodes, i.e. the process
get killed. The <strong>dataport nodes</strong> have a better uplink (10 GBit/s) allowing for higher bandwidth.
Note that you cannot log in via SSH to the dataport nodes, but only use
<code class="docutils literal notranslate"><span class="pre">scp</span></code>, <code class="docutils literal notranslate"><span class="pre">rsync</span></code> or <code class="docutils literal notranslate"><span class="pre">sftp</span></code> (incl. FTP-clients like e.g.
<a class="reference external" href="https://filezilla-project.org/">FileZilla</a>) on them.</p>
<p>The dataport nodes are reachable under the hostnames</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dataport1.hpc.tu-dresden.de</span></code> (IP: 141.30.73.4)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dataport2.hpc.tu-dresden.de</span></code> (IP: 141.30.73.5)</p></li>
</ul>
<p>Through the usage of these dataport nodes, you can bring your data to ZIH HPC systems or get data
from there - they have access to the different HPC
<span class="xref myst">filesystems</span>.
Please keep in mind that the different filesystems differ in capacity, IO-performance, and intended
use cases. Choose the one that matches your needs.</p>
<p>The following directories are accessible:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">/home</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">/projects</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">/data/horse</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">/data/walrus</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">/data/archiv</span></code></p></li>
</ul>
<section id="access-from-linux">
<h2>Access From Linux<a class="headerlink" href="#access-from-linux" title="Permalink to this heading">#</a></h2>
<p>There are at least three tools to exchange data between your local workstation and ZIH systems. They
are explained in the following section in more detail.</p>
<p>!!! important ‚ÄúPremise: SSH configuration‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The following explanations require that you have already set up your
[SSH configuration](../access/ssh_login.md#configuring-default-parameters-for-ssh).
</pre></div>
</div>
<section id="scp">
<h3>SCP<a class="headerlink" href="#scp" title="Permalink to this heading">#</a></h3>
<p>The tool <a class="reference external" href="https://www.man7.org/linux/man-pages/man1/scp.1.html"><code class="docutils literal notranslate"><span class="pre">scp</span></code></a>
(OpenSSH secure file copy) copies files between hosts on a network. To copy all files
in a directory, the option <code class="docutils literal notranslate"><span class="pre">-r</span></code> has to be specified.</p>
<p>??? example ‚ÄúExample: Copy a file from your workstation to ZIH systems‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
marie@local$ scp &lt;file&gt; dataport:&lt;target-location&gt;

# Add -r to copy whole directory
marie@local$ scp -r &lt;directory&gt; dataport:&lt;target-location&gt;
```

For example, if you want to copy your data file `mydata.csv` to the directory `input` in your
home directory, you would use the following:

```console
marie@local$ scp mydata.csv dataport:input/
```
</pre></div>
</div>
<p>??? example ‚ÄúExample: Copy a file from ZIH systems to your workstation‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
marie@local$ scp dataport:&lt;file&gt; &lt;target-location&gt;

# Add -r to copy whole directory
marie@local$ scp -r dataport:&lt;directory&gt; &lt;target-location&gt;
```

For example, if you have a directory named `output` in your home directory on ZIH systems and
you want to copy it to the directory `/tmp` on your workstation, you would use the following:

```console
marie@local$ scp -r dataport:output /tmp
```
</pre></div>
</div>
</section>
<section id="sftp">
<h3>SFTP<a class="headerlink" href="#sftp" title="Permalink to this heading">#</a></h3>
<p>The tool <a class="reference external" href="https://man7.org/linux/man-pages/man1/sftp.1.html"><code class="docutils literal notranslate"><span class="pre">sftp</span></code></a> (OpenSSH secure file transfer)
is a file transfer program, which performs all operations over an encrypted SSH transport. It may
use compression to increase performance.</p>
<p><code class="docutils literal notranslate"><span class="pre">sftp</span></code> is basically a virtual command line, which you could access and exit as follows.</p>
<p>!!! warning ‚ÄúNote‚Äù
It is important from which point in your directory tree you ‚Äòenter‚Äô <code class="docutils literal notranslate"><span class="pre">sftp</span></code>!
The current working directory (double ckeck with <code class="docutils literal notranslate"><span class="pre">pwd</span></code>) will be the target folder on your local
machine from/to which remote files from the ZIH system will be put/get by <code class="docutils literal notranslate"><span class="pre">sftp</span></code>.
The local folder might also be changed during a session with special commands.
During the <code class="docutils literal notranslate"><span class="pre">sftp</span></code> session, you can use regular commands like <code class="docutils literal notranslate"><span class="pre">ls</span></code>, <code class="docutils literal notranslate"><span class="pre">cd</span></code>, <code class="docutils literal notranslate"><span class="pre">pwd</span></code> etc.
But if you wish to access your local workstation, these must be prefixed with the letter <code class="docutils literal notranslate"><span class="pre">l</span></code>
(<code class="docutils literal notranslate"><span class="pre">l</span></code>ocal), e.g., <code class="docutils literal notranslate"><span class="pre">lls</span></code>, <code class="docutils literal notranslate"><span class="pre">lcd</span></code> or <code class="docutils literal notranslate"><span class="pre">lpwd</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>Enter<span class="w"> </span>virtual<span class="w"> </span><span class="nb">command</span><span class="w"> </span>line
<span class="gp">marie@local$ </span>sftp<span class="w"> </span>dataport
<span class="gp"># </span>Exit<span class="w"> </span>virtual<span class="w"> </span><span class="nb">command</span><span class="w"> </span>line
<span class="go">sftp&gt; exit</span>
<span class="gp"># </span>or
<span class="go">sftp&gt; &lt;Ctrl+D&gt;</span>
</pre></div>
</div>
<p>??? example ‚ÄúExample: Copy a file from your workstation to ZIH systems‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@local$ cd my/local/work
marie@local$ sftp dataport
# Copy file
sftp&gt; put &lt;file&gt;
# Copy directory
sftp&gt; put -r &lt;directory&gt;
```
</pre></div>
</div>
<p>??? example ‚ÄúExample: Copy a file from ZIH systems to your local workstation‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@local$ sftp dataport
# Copy file
sftp&gt; get &lt;file&gt;
# change local (target) directory
sftp&gt; lcd /my/local/work
# Copy directory
sftp&gt; get -r &lt;directory&gt;
```
</pre></div>
</div>
</section>
<section id="rsync">
<h3>Rsync<a class="headerlink" href="#rsync" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="https://man7.org/linux/man-pages/man1/rsync.1.html"><code class="docutils literal notranslate"><span class="pre">Rsync</span></code></a>, is a fast and extraordinarily
versatile file copying tool. It can copy locally, to/from another host over any remote shell, or
to/from a remote <code class="docutils literal notranslate"><span class="pre">rsync</span></code> daemon. It is famous for its delta-transfer algorithm, which reduces the
amount of data sent over the network by sending only the differences between the source files and
the existing files in the destination.</p>
<p>Type following commands in the terminal when you are in the directory of
the local machine.</p>
<p>??? example ‚ÄúExample: Copy a file from your workstation to ZIH systems‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
# Copy file
marie@local$ rsync &lt;file&gt; dataport:&lt;target-location&gt;
# Copy directory
marie@local$ rsync -r &lt;directory&gt; dataport:&lt;target-location&gt;
```
</pre></div>
</div>
<p>??? example ‚ÄúExample: Copy a file from ZIH systems to your local workstation‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
# Copy file
marie@local$ rsync dataport:&lt;file&gt; &lt;target-location&gt;
# Copy directory
marie@local$ rsync -r dataport:&lt;directory&gt; &lt;target-location&gt;
```
</pre></div>
</div>
</section>
</section>
<section id="access-from-windows">
<h2>Access From Windows<a class="headerlink" href="#access-from-windows" title="Permalink to this heading">#</a></h2>
<section id="command-line">
<h3>Command Line<a class="headerlink" href="#command-line" title="Permalink to this heading">#</a></h3>
<p>Windows 10 (1809 and higher) comes with a
<a class="reference external" href="https://docs.microsoft.com/en-us/windows-server/administration/openssh/openssh_overview">built-in OpenSSH support</a>
including the above described <!--[SCP](#scp) and --><span class="xref myst">SFTP</span>.</p>
</section>
<section id="gui-using-winscp">
<h3>GUI - Using WinSCP<a class="headerlink" href="#gui-using-winscp" title="Permalink to this heading">#</a></h3>
<p>First you have to install <a class="reference external" href="http://winscp.net/eng/download.php">WinSCP</a>.</p>
<p>Then you have to execute the WinSCP application and configure some
option as described below.</p>
<!-- screenshots will have to be updated-->
<p><img alt="Login - WinSCP" src="63_chat_with_docs/misc/WinSCP_001_new.PNG" />
{: align=‚Äùcenter‚Äù}</p>
<p><img alt="Save session as site" src="63_chat_with_docs/misc/WinSCP_002_new.PNG" />
{: align=‚Äùcenter‚Äù}</p>
<p><img alt="Login - WinSCP click Login" src="63_chat_with_docs/misc/WinSCP_003_new.PNG" />
{: align=‚Äùcenter‚Äù}</p>
<p><img alt="Enter password and click OK" src="63_chat_with_docs/misc/WinSCP_004_new.PNG" />
{: align=‚Äùcenter‚Äù}</p>
<p>After your connection succeeded, you can copy files from your local workstation to ZIH systems and
the other way around.</p>
<p><img alt="WinSCP document explorer" src="63_chat_with_docs/misc/WinSCP_005_new.PNG" />
{: align=‚Äùcenter‚Äù}</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="transfer-data-between-zih-systems-and-object-storage-s3">
<h1>Transfer Data between ZIH Systems and Object Storage (S3)<a class="headerlink" href="#transfer-data-between-zih-systems-and-object-storage-s3" title="Permalink to this heading">#</a></h1>
<p>Object Storage is an alternative to normal filesystem storage. It can be accessed via HTTPS and can
therefor be used where direct <code class="docutils literal notranslate"><span class="pre">scp</span></code> connections are prohibited, e.g. when one wants to copy data to
another data center. Access is provided on request via the corresponding
<a class="reference external" href="https://selfservice.tu-dresden.de/services/objectstorage/">self service page on object storage</a>.
The access key (<code class="docutils literal notranslate"><span class="pre">Zugriffsschl√ºssel</span></code>) and the secret key (<code class="docutils literal notranslate"><span class="pre">Geheimer</span> <span class="pre">Schl√ºssel</span></code>) are required later
when copying data to it.</p>
<p>Access to object storage is possible on ZIH systems via the module <code class="docutils literal notranslate"><span class="pre">rclone</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>rclone
</pre></div>
</div>
<section id="initial-configuration">
<h2>Initial Configuration<a class="headerlink" href="#initial-configuration" title="Permalink to this heading">#</a></h2>
<p>Before you use <code class="docutils literal notranslate"><span class="pre">rclone</span></code> for the first time, you have to configure it. This is done interactively as
shown below. Replace <code class="docutils literal notranslate"><span class="pre">REPLACE_ME_WITH_ACCESS_KEY</span></code> and <code class="docutils literal notranslate"><span class="pre">REPLACE_ME_WITH_SECRET_KEY</span></code> with the values
from the self service portal:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>rclone<span class="w"> </span>config
<span class="go">2023/03/22 09:35:55 NOTICE: Config file &quot;/home/marie/.config/rclone/rclone.conf&quot; not found - using defaults</span>
<span class="go">No remotes found, make a new one?</span>
<span class="go">n) New remote</span>
<span class="go">s) Set configuration password</span>
<span class="go">q) Quit config</span>
<span class="go">n/s/q&gt; n</span>

<span class="go">Enter name for new remote.</span>
<span class="go">name&gt; s3store</span>

<span class="go">Option Storage.</span>
<span class="go">Type of storage to configure.</span>
<span class="go">Choose a number from below, or type in your own value.</span>
<span class="go"> 1 / 1Fichier</span>
<span class="go">   \ (fichier)</span>
<span class="go"> 2 / Akamai NetStorage</span>
<span class="go">   \ (netstorage)</span>
<span class="go"> 3 / Alias for an existing remote</span>
<span class="go">   \ (alias)</span>
<span class="go"> 4 / Amazon Drive</span>
<span class="go">   \ (amazon cloud drive)</span>
<span class="go"> 5 / Amazon S3 Compliant Storage Providers including AWS, Alibaba, Ceph, China Mobile, Cloudflare, ArvanCloud, Digital Ocean, Dreamhost, Huawei OBS, IBM COS, IDrive e2, IONOS Cloud, Lyve Cloud, Minio, Netease, RackCorp, Scaleway, SeaweedFS, StackPath, Storj, Tencent COS, Qiniu and Wasabi</span>
<span class="go">   \ (s3)</span>
<span class="go"> 6 / Backblaze B2</span>
<span class="go">   \ (b2)</span>
<span class="go"> 7 / Better checksums for other remotes</span>
<span class="go">   \ (hasher)</span>
<span class="go"> 8 / Box</span>
<span class="go">   \ (box)</span>
<span class="go"> 9 / Cache a remote</span>
<span class="go">   \ (cache)</span>
<span class="go">10 / Citrix Sharefile</span>
<span class="go">   \ (sharefile)</span>
<span class="go">11 / Combine several remotes into one</span>
<span class="go">   \ (combine)</span>
<span class="go">12 / Compress a remote</span>
<span class="go">   \ (compress)</span>
<span class="go">13 / Dropbox</span>
<span class="go">   \ (dropbox)</span>
<span class="go">14 / Encrypt/Decrypt a remote</span>
<span class="go">   \ (crypt)</span>
<span class="go">15 / Enterprise File Fabric</span>
<span class="go">   \ (filefabric)</span>
<span class="go">16 / FTP</span>
<span class="go">   \ (ftp)</span>
<span class="go">17 / Google Cloud Storage (this is not Google Drive)</span>
<span class="go">   \ (google cloud storage)</span>
<span class="go">18 / Google Drive</span>
<span class="go">   \ (drive)</span>
<span class="go">19 / Google Photos</span>
<span class="go">   \ (google photos)</span>
<span class="go">20 / HTTP</span>
<span class="go">   \ (http)</span>
<span class="go">21 / Hadoop distributed file system</span>
<span class="go">   \ (hdfs)</span>
<span class="go">22 / HiDrive</span>
<span class="go">   \ (hidrive)</span>
<span class="go">23 / In memory object storage system.</span>
<span class="go">   \ (memory)</span>
<span class="go">24 / Internet Archive</span>
<span class="go">   \ (internetarchive)</span>
<span class="go">25 / Jottacloud</span>
<span class="go">   \ (jottacloud)</span>
<span class="go">26 / Koofr, Digi Storage and other Koofr-compatible storage providers</span>
<span class="go">   \ (koofr)</span>
<span class="go">27 / Local Disk</span>
<span class="go">   \ (local)</span>
<span class="go">28 / Mail.ru Cloud</span>
<span class="go">   \ (mailru)</span>
<span class="go">29 / Mega</span>
<span class="go">   \ (mega)</span>
<span class="go">30 / Microsoft Azure Blob Storage</span>
<span class="go">   \ (azureblob)</span>
<span class="go">31 / Microsoft OneDrive</span>
<span class="go">   \ (onedrive)</span>
<span class="go">32 / OpenDrive</span>
<span class="go">   \ (opendrive)</span>
<span class="go">33 / OpenStack Swift (Rackspace Cloud Files, Memset Memstore, OVH)</span>
<span class="go">   \ (swift)</span>
<span class="go">34 / Oracle Cloud Infrastructure Object Storage</span>
<span class="go">   \ (oracleobjectstorage)</span>
<span class="go">35 / Pcloud</span>
<span class="go">   \ (pcloud)</span>
<span class="go">36 / Put.io</span>
<span class="go">   \ (putio)</span>
<span class="go">37 / QingCloud Object Storage</span>
<span class="go">   \ (qingstor)</span>
<span class="go">38 / SMB / CIFS</span>
<span class="go">   \ (smb)</span>
<span class="go">39 / SSH/SFTP</span>
<span class="go">   \ (sftp)</span>
<span class="go">40 / Sia Decentralized Cloud</span>
<span class="go">   \ (sia)</span>
<span class="go">41 / Storj Decentralized Cloud Storage</span>
<span class="go">   \ (storj)</span>
<span class="go">42 / Sugarsync</span>
<span class="go">   \ (sugarsync)</span>
<span class="go">43 / Transparently chunk/split large files</span>
<span class="go">   \ (chunker)</span>
<span class="go">44 / Union merges the contents of several upstream fs</span>
<span class="go">   \ (union)</span>
<span class="go">45 / Uptobox</span>
<span class="go">   \ (uptobox)</span>
<span class="go">46 / WebDAV</span>
<span class="go">   \ (webdav)</span>
<span class="go">47 / Yandex Disk</span>
<span class="go">   \ (yandex)</span>
<span class="go">48 / Zoho</span>
<span class="go">   \ (zoho)</span>
<span class="go">49 / premiumize.me</span>
<span class="go">   \ (premiumizeme)</span>
<span class="go">50 / seafile</span>
<span class="go">   \ (seafile)</span>
<span class="go">Storage&gt; 5</span>

<span class="go">Option provider.</span>
<span class="go">Choose your S3 provider.</span>
<span class="go">Choose a number from below, or type in your own value.</span>
<span class="go">Press Enter to leave empty.</span>
<span class="go"> 1 / Amazon Web Services (AWS) S3</span>
<span class="go">   \ (AWS)</span>
<span class="go"> 2 / Alibaba Cloud Object Storage System (OSS) formerly Aliyun</span>
<span class="go">   \ (Alibaba)</span>
<span class="go"> 3 / Ceph Object Storage</span>
<span class="go">   \ (Ceph)</span>
<span class="go"> 4 / China Mobile Ecloud Elastic Object Storage (EOS)</span>
<span class="go">   \ (ChinaMobile)</span>
<span class="go"> 5 / Cloudflare R2 Storage</span>
<span class="go">   \ (Cloudflare)</span>
<span class="go"> 6 / Arvan Cloud Object Storage (AOS)</span>
<span class="go">   \ (ArvanCloud)</span>
<span class="go"> 7 / Digital Ocean Spaces</span>
<span class="go">   \ (DigitalOcean)</span>
<span class="go"> 8 / Dreamhost DreamObjects</span>
<span class="go">   \ (Dreamhost)</span>
<span class="go"> 9 / Huawei Object Storage Service</span>
<span class="go">   \ (HuaweiOBS)</span>
<span class="go">10 / IBM COS S3</span>
<span class="go">   \ (IBMCOS)</span>
<span class="go">11 / IDrive e2</span>
<span class="go">   \ (IDrive)</span>
<span class="go">12 / IONOS Cloud</span>
<span class="go">   \ (IONOS)</span>
<span class="go">13 / Seagate Lyve Cloud</span>
<span class="go">   \ (LyveCloud)</span>
<span class="go">14 / Minio Object Storage</span>
<span class="go">   \ (Minio)</span>
<span class="go">15 / Netease Object Storage (NOS)</span>
<span class="go">   \ (Netease)</span>
<span class="go">16 / RackCorp Object Storage</span>
<span class="go">   \ (RackCorp)</span>
<span class="go">17 / Scaleway Object Storage</span>
<span class="go">   \ (Scaleway)</span>
<span class="go">18 / SeaweedFS S3</span>
<span class="go">   \ (SeaweedFS)</span>
<span class="go">19 / StackPath Object Storage</span>
<span class="go">   \ (StackPath)</span>
<span class="go">20 / Storj (S3 Compatible Gateway)</span>
<span class="go">   \ (Storj)</span>
<span class="go">21 / Tencent Cloud Object Storage (COS)</span>
<span class="go">   \ (TencentCOS)</span>
<span class="go">22 / Wasabi Object Storage</span>
<span class="go">   \ (Wasabi)</span>
<span class="go">23 / Qiniu Object Storage (Kodo)</span>
<span class="go">   \ (Qiniu)</span>
<span class="go">24 / Any other S3 compatible provider</span>
<span class="go">   \ (Other)</span>
<span class="go">provider&gt; 24</span>

<span class="go">Option env_auth.</span>
<span class="go">Get AWS credentials from runtime (environment variables or EC2/ECS meta data if no env vars).</span>
<span class="go">Only applies if access_key_id and secret_access_key is blank.</span>
<span class="go">Choose a number from below, or type in your own boolean value (true or false).</span>
<span class="go">Press Enter for the default (false).</span>
<span class="go"> 1 / Enter AWS credentials in the next step.</span>
<span class="go">   \ (false)</span>
<span class="go"> 2 / Get AWS credentials from the environment (env vars or IAM).</span>
<span class="go">   \ (true)</span>
<span class="go">env_auth&gt; 1</span>

<span class="go">Option access_key_id.</span>
<span class="go">AWS Access Key ID.</span>
<span class="go">Leave blank for anonymous access or runtime credentials.</span>
<span class="go">Enter a value. Press Enter to leave empty.</span>
<span class="go">access_key_id&gt; REPLACE_ME_WITH_ACCESS_KEY</span>

<span class="go">Option secret_access_key.</span>
<span class="go">AWS Secret Access Key (password).</span>
<span class="go">Leave blank for anonymous access or runtime credentials.</span>
<span class="go">Enter a value. Press Enter to leave empty.</span>
<span class="go">secret_access_key&gt; REPLACE_ME_WITH_SECRET_KEY</span>

<span class="go">Option region.</span>
<span class="go">Region to connect to.</span>
<span class="go">Leave blank if you are using an S3 clone and you don&#39;t have a region.</span>
<span class="go">Choose a number from below, or type in your own value.</span>
<span class="go">Press Enter to leave empty.</span>
<span class="go">   / Use this if unsure.</span>
<span class="go"> 1 | Will use v4 signatures and an empty region.</span>
<span class="go">   \ ()</span>
<span class="go">   / Use this only if v4 signatures don&#39;t work.</span>
<span class="go"> 2 | E.g. pre Jewel/v10 CEPH.</span>
<span class="go">   \ (other-v2-signature)</span>
<span class="go">region&gt; 1</span>

<span class="go">Option endpoint.</span>
<span class="go">Endpoint for S3 API.</span>
<span class="go">Required when using an S3 clone.</span>
<span class="go">Enter a value. Press Enter to leave empty.</span>
<span class="go">endpoint&gt; s3.zih.tu-dresden.de</span>

<span class="go">Option location_constraint.</span>
<span class="go">Location constraint - must be set to match the Region.</span>
<span class="go">Leave blank if not sure. Used when creating buckets only.</span>
<span class="go">Enter a value. Press Enter to leave empty.</span>
<span class="go">location_constraint&gt; </span>

<span class="go">Option acl.</span>
<span class="go">Canned ACL used when creating buckets and storing or copying objects.</span>
<span class="go">This ACL is used for creating objects and if bucket_acl isn&#39;t set, for creating buckets too.</span>
<span class="go">For more info visit https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl</span>
<span class="go">Note that this ACL is applied when server-side copying objects as S3</span>
<span class="go">doesn&#39;t copy the ACL from the source but rather writes a fresh one.</span>
<span class="go">Choose a number from below, or type in your own value.</span>
<span class="go">Press Enter to leave empty.</span>
<span class="go">   / Owner gets FULL_CONTROL.</span>
<span class="go"> 1 | No one else has access rights (default).</span>
<span class="go">   \ (private)</span>
<span class="go">   / Owner gets FULL_CONTROL.</span>
<span class="go"> 2 | The AllUsers group gets READ access.</span>
<span class="go">   \ (public-read)</span>
<span class="go">   / Owner gets FULL_CONTROL.</span>
<span class="go"> 3 | The AllUsers group gets READ and WRITE access.</span>
<span class="go">   | Granting this on a bucket is generally not recommended.</span>
<span class="go">   \ (public-read-write)</span>
<span class="go">   / Owner gets FULL_CONTROL.</span>
<span class="go"> 4 | The AuthenticatedUsers group gets READ access.</span>
<span class="go">   \ (authenticated-read)</span>
<span class="go">   / Object owner gets FULL_CONTROL.</span>
<span class="go"> 5 | Bucket owner gets READ access.</span>
<span class="go">   | If you specify this canned ACL when creating a bucket, Amazon S3 ignores it.</span>
<span class="go">   \ (bucket-owner-read)</span>
<span class="go">   / Both the object owner and the bucket owner get FULL_CONTROL over the object.</span>
<span class="go"> 6 | If you specify this canned ACL when creating a bucket, Amazon S3 ignores it.</span>
<span class="go">   \ (bucket-owner-full-control)</span>
<span class="go">acl&gt; 1</span>

<span class="go">Edit advanced config?</span>
<span class="go">y) Yes</span>
<span class="go">n) No (default)</span>
<span class="go">y/n&gt; n</span>
</pre></div>
</div>
</section>
<section id="copying-data-from-to-object-storage">
<h2>Copying Data from/to Object Storage<a class="headerlink" href="#copying-data-from-to-object-storage" title="Permalink to this heading">#</a></h2>
<p>The following commands show how to create a bucket <code class="docutils literal notranslate"><span class="pre">mystorage</span></code> in your part of the object store:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>rclone
<span class="gp">marie@login$ </span>rclone<span class="w"> </span>mkdir<span class="w"> </span>s3store:mystorage
</pre></div>
</div>
<p>After these commands, you can copy a file, e. g. <code class="docutils literal notranslate"><span class="pre">largedata.tar.gz</span></code>, to it in a separate job with
the help of the <span class="xref myst">Datamover</span>. Adjust the parameters <code class="docutils literal notranslate"><span class="pre">time</span></code> and <code class="docutils literal notranslate"><span class="pre">account</span></code> as required:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>dtrclone<span class="w"> </span>--time<span class="o">=</span><span class="m">0</span>:10:00<span class="w"> </span>--account<span class="o">=</span>p_number_crunch<span class="w"> </span>copy<span class="w"> </span>--s3-acl<span class="w"> </span><span class="s2">&quot;public-read&quot;</span><span class="w"> </span>largedata.tar.gz<span class="w"> </span>s3store:mystorage
</pre></div>
</div>
<p>!!! warning ‚ÄúRestricted access‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you want to restrict access to your data, replace the last command with:

```console
marie@login$ dtrclone --time=0:10:00 --account=p_number_crunch copy largedata.tar.gz s3store:mystorage
```

Then, it is not possible to access your data without providing your credentials.
</pre></div>
</div>
<p>For small files, you can also directly copy data:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>rclone
<span class="gp">marie@login$ </span>rclone<span class="w"> </span>copy<span class="w"> </span>--s3-acl<span class="w"> </span><span class="s2">&quot;public-read&quot;</span><span class="w"> </span>largedata.tar.gz<span class="w"> </span>s3store:mystorage
</pre></div>
</div>
</section>
<section id="accessing-the-object-storage">
<h2>Accessing the Object Storage<a class="headerlink" href="#accessing-the-object-storage" title="Permalink to this heading">#</a></h2>
<p>The following commands show different possibilities to access a file from object storage.</p>
<section id="copying-a-file-from-object-storage-to-zih-systems">
<h3>Copying a File from Object Storage to ZIH systems<a class="headerlink" href="#copying-a-file-from-object-storage-to-zih-systems" title="Permalink to this heading">#</a></h3>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>dtrclone<span class="w"> </span>--time<span class="o">=</span><span class="m">0</span>:10:00<span class="w"> </span>--account<span class="o">=</span>p_number_crunch<span class="w"> </span>copy<span class="w"> </span>s3store:mystorage/largedata.tar.gz<span class="w"> </span>.
</pre></div>
</div>
</section>
<section id="copying-a-file-from-object-storage-to-your-workstation">
<h3>Copying a File from Object Storage to Your Workstation<a class="headerlink" href="#copying-a-file-from-object-storage-to-your-workstation" title="Permalink to this heading">#</a></h3>
<p>The following command assumes you have installed the command <code class="docutils literal notranslate"><span class="pre">s3cmd</span></code>, please also see the
<a class="reference external" href="https://tu-dresden.de/zih/dienste/service-katalog/arbeitsumgebung/datenspeicher/objektspeicher-s3">s3cmd Installation Instructions</a></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>s3cmd<span class="w"> </span>get<span class="w"> </span>s3://mystorage/largedata.tar.gz
</pre></div>
</div>
</section>
<section id="accessing-a-public-readable-file">
<h3>Accessing a Public-Readable File<a class="headerlink" href="#accessing-a-public-readable-file" title="Permalink to this heading">#</a></h3>
<p>It is possible to copy a public-readable file via <code class="docutils literal notranslate"><span class="pre">wget</span></code> or similar command line tools. Replace
<code class="docutils literal notranslate"><span class="pre">$USER</span></code> with your ZIH account.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@somewhere$ </span>wget<span class="w"> </span>https://s3.zih.tu-dresden.de/<span class="nv">$USER</span>:mystorage/largedata.tar.gz
</pre></div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="data-transfer">
<h1>Data Transfer<a class="headerlink" href="#data-transfer" title="Permalink to this heading">#</a></h1>
<section id="data-transfer-to-from-zih-systems-dataport-nodes">
<h2>Data Transfer to/from ZIH Systems: Dataport Nodes<a class="headerlink" href="#data-transfer-to-from-zih-systems-dataport-nodes" title="Permalink to this heading">#</a></h2>
<p>There are at least three tools for exchanging data between your local workstation and ZIH systems:
<code class="docutils literal notranslate"><span class="pre">scp</span></code>, <code class="docutils literal notranslate"><span class="pre">rsync</span></code>, and <code class="docutils literal notranslate"><span class="pre">sftp</span></code>. Please refer to the offline or online man pages of
<a class="reference external" href="https://www.man7.org/linux/man-pages/man1/scp.1.html">scp</a>,
<a class="reference external" href="https://man7.org/linux/man-pages/man1/rsync.1.html">rsync</a>, and
<a class="reference external" href="https://man7.org/linux/man-pages/man1/sftp.1.html">sftp</a> for detailed information.</p>
<p>No matter what tool you prefer, it is crucial that the <strong>dataport nodes</strong> are used as preferred way
to copy data to/from ZIH systems. Please follow the link to the documentation on <span class="xref myst">dataport
nodes</span> for further reference and examples.</p>
</section>
<section id="data-transfer-inside-zih-systems-datamover">
<h2>Data Transfer Inside ZIH Systems: Datamover<a class="headerlink" href="#data-transfer-inside-zih-systems-datamover" title="Permalink to this heading">#</a></h2>
<p>The recommended way for data transfer inside ZIH Systems is the <strong>Datamover</strong>. It is a special data
transfer machine that provides the best transfer speed. To load, move, copy etc. files from one
filesystem to another filesystem, you have to use commands prefixed with <code class="docutils literal notranslate"><span class="pre">dt</span></code>: <code class="docutils literal notranslate"><span class="pre">dtcp</span></code>, <code class="docutils literal notranslate"><span class="pre">dtwget</span></code>,
<code class="docutils literal notranslate"><span class="pre">dtmv</span></code>, <code class="docutils literal notranslate"><span class="pre">dtrm</span></code>, <code class="docutils literal notranslate"><span class="pre">dtrsync</span></code>, <code class="docutils literal notranslate"><span class="pre">dttar</span></code>, <code class="docutils literal notranslate"><span class="pre">dtls</span></code>. These commands submit a job to the data transfer
machines that execute the selected command.  Please refer to the detailed documentation regarding
the <span class="xref myst">Datamover</span>.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="gpu-cluster-alpha-centauri">
<h1>GPU Cluster Alpha Centauri<a class="headerlink" href="#gpu-cluster-alpha-centauri" title="Permalink to this heading">#</a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">#</a></h2>
<p>The multi-GPU cluster <code class="docutils literal notranslate"><span class="pre">Alpha</span> <span class="pre">Centauri</span></code> has been installed for AI-related computations (<a class="reference external" href="http://ScaDS.AI">ScaDS.AI</a>).</p>
</section>
<section id="hardware-specification">
<h2>Hardware Specification<a class="headerlink" href="#hardware-specification" title="Permalink to this heading">#</a></h2>
<p>The hardware specification is documented on the page
<span class="xref myst">HPC Resources</span>.</p>
</section>
<section id="id11">
<h2>Filesystems<a class="headerlink" href="#id11" title="Permalink to this heading">#</a></h2>
<p>Since 5th July 2024, <code class="docutils literal notranslate"><span class="pre">Alpha</span> <span class="pre">Centauri</span></code> is fully integrated in the InfiniBand infrastructure of
<code class="docutils literal notranslate"><span class="pre">Barnard</span></code>. With that, all <span class="xref myst">filesystems</span>
(<code class="docutils literal notranslate"><span class="pre">/home</span></code>, <code class="docutils literal notranslate"><span class="pre">/software</span></code>, <code class="docutils literal notranslate"><span class="pre">/data/horse</span></code>, <code class="docutils literal notranslate"><span class="pre">/data/walrus</span></code>, etc.) are available.</p>
</section>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this heading">#</a></h2>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The NVIDIA A100 GPUs may only be used with **CUDA 11** or later. Earlier versions do not
recognize the new hardware properly. Make sure the software you are using is built with CUDA11.
</pre></div>
</div>
<p>There is a total of 48 physical cores in each node. SMT is also active, so in total, 96 logical
cores are available per node.
Each node on the cluster <code class="docutils literal notranslate"><span class="pre">Alpha</span></code> has 2x AMD EPYC CPUs, 8x NVIDIA
A100-SXM4 GPUs, 1 TB RAM and 3.5 TB local space (<code class="docutils literal notranslate"><span class="pre">/tmp</span></code>) on an NVMe device.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Multithreading is disabled per default in a job.
See the [Slurm page](slurm.md) on how to enable it.
</pre></div>
</div>
<section id="modules">
<h3>Modules<a class="headerlink" href="#modules" title="Permalink to this heading">#</a></h3>
<p>The easiest way is using the <span class="xref myst">module system</span>.
All software available from the module system has been specifically build for the cluster <code class="docutils literal notranslate"><span class="pre">Alpha</span></code>
i.e., with optimization for Zen2 microarchitecture and CUDA-support enabled.</p>
<p>To check the available modules for <code class="docutils literal notranslate"><span class="pre">Alpha</span></code>, use the command</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login.alpha$ </span>module<span class="w"> </span>spider<span class="w"> </span>&lt;module_name&gt;
</pre></div>
</div>
<p>??? example ‚ÄúExample: Searching and loading PyTorch‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>For example, to check which `PyTorch` versions are available you can invoke

```console
marie@login.alpha$ module spider PyTorch
-------------------------------------------------------------------------------------------------------------------------
  PyTorch:
-------------------------------------------------------------------------------------------------------------------------
    Description:
      Tensors and Dynamic neural networks in Python with strong GPU acceleration. PyTorch is a deep learning framework
      that puts Python first.

     Versions:
        PyTorch/1.12.0
        PyTorch/1.12.1-CUDA-11.7.0
        PyTorch/1.12.1
[...]
```

Not all modules can be loaded directly. Most modules are build with a certain compiler or
toolchain that need to be loaded beforehand. Luckely, the module system can tell us, what we
need to do for a specific module or software version

```console
marie@login.alpha$ module spider PyTorch/1.12.1-CUDA-11.7.0

-------------------------------------------------------------------------------------------------------------------------
  PyTorch: PyTorch/1.12.1-CUDA-11.7.0
-------------------------------------------------------------------------------------------------------------------------
    Description:
      Tensors and Dynamic neural networks in Python with strong GPU acceleration. PyTorch is a deep learning framework
      that puts Python first.


    You will need to load all module(s) on any one of the lines below before the &quot;PyTorch/1.12.1&quot; module is available to load.

      release/23.04  GCC/11.3.0  OpenMPI/4.1.4
[...]
```

Finaly, the commandline to load the `PyTorch/1.12.1-CUDA-11.7.0` module is

```console
marie@login.alpha$ module load release/23.04  GCC/11.3.0  OpenMPI/4.1.4 PyTorch/1.12.1-CUDA-11.7.0
Module GCC/11.3.0, OpenMPI/4.1.4, PyTorch/1.12.1-CUDA-11.7.0 and 64 dependencies loaded.
```

Now, you can verify with the following command that the pytorch module is available

```console
marie@login.alpha$ python -c &quot;import torch; print(torch.__version__); print(torch.cuda.is_available())&quot;
1.12.1
True
```
</pre></div>
</div>
</section>
<section id="python-virtual-environments">
<h3>Python Virtual Environments<a class="headerlink" href="#python-virtual-environments" title="Permalink to this heading">#</a></h3>
<p><span class="xref myst">Virtual environments</span> allow you to install
additional Python packages and create an isolated runtime environment. We recommend using
<code class="docutils literal notranslate"><span class="pre">virtualenv</span></code> for this purpose.</p>
<p>!!! hint</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>We recommend to use [workspaces](../data_lifecycle/workspaces.md) for your virtual environments.
</pre></div>
</div>
<p>??? example ‚ÄúExample: Creating a virtual environment and installing <code class="docutils literal notranslate"><span class="pre">torchvision</span></code> package‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>As first step, you should create a workspace

```console
marie@login.alpha$ srun --nodes=1 --cpus-per-task=1 --gres=gpu:1 --time=01:00:00 --pty bash -l
marie@alpha$ ws_allocate --name python_virtual_environment --duration 1
Info: creating workspace.
/horse/ws/marie-python_virtual_environment
remaining extensions  : 2
remaining time in days: 1
```

Now, you can load the desired modules and create a virtual environment within the allocated
workspace.

```
marie@alpha$ module load release/23.04 GCCcore/11.3.0 GCC/11.3.0 OpenMPI/4.1.4 Python/3.10.4
Module GCC/11.3.0, OpenMPI/4.1.4, Python/3.10.4 and 21 dependencies loaded.
marie@alpha$ module load PyTorch/1.12.1-CUDA-11.7.0
Module PyTorch/1.12.1-CUDA-11.7.0 and 42 dependencies loaded.
marie@alpha$ which python
/software/rome/r23.04/Python/3.10.4-GCCcore-11.3.0/bin/python
marie@alpha$ pip list
[...]
marie@alpha$ virtualenv --system-site-packages /data/horse/ws/marie-python_virtual_environment/my-torch-env
created virtual environment CPython3.8.6.final.0-64 in 42960ms
  creator CPython3Posix(dest=/horse/.global1/ws/marie-python_virtual_environment/my-torch-env, clear=False, global=True)
  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=~/.local/share/virtualenv)
    added seed packages: pip==21.1.3, setuptools==57.2.0, wheel==0.36.2
  activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator
marie@alpha$ source /data/horse/ws/marie-python_virtual_environment/my-torch-env/bin/activate
(my-torch-env) marie@alpha$ pip install torchvision==0.13.1
[...]
Installing collected packages: torchvision
Successfully installed torchvision-0.13.1
[...]
(my-torch-env) marie@alpha$ python -c &quot;import torchvision; print(torchvision.__version__)&quot;
0.13.1+cu102
(my-torch-env) marie@alpha$ deactivate
```
</pre></div>
</div>
</section>
<section id="id12">
<h3>JupyterHub<a class="headerlink" href="#id12" title="Permalink to this heading">#</a></h3>
<p><span class="xref myst">JupyterHub</span> can be used to run Jupyter notebooks on Alpha Centauri
cluster. You can either use the
<span class="xref myst">standard profiles for Alpha</span> or use the advanced form
and define the resources for your JupyterHub job. The ‚ÄúAlpha GPU (NVIDIA Ampere A100)‚Äù preset
is a good starting configuration.</p>
</section>
<section id="containers">
<h3>Containers<a class="headerlink" href="#containers" title="Permalink to this heading">#</a></h3>
<p>Singularity containers enable users to have full control of their software environment.
For more information, see the <span class="xref myst">Singularity container details</span>.</p>
<p>Nvidia
<a class="reference external" href="https://developer.nvidia.com/blog/how-to-run-ngc-deep-learning-containers-with-singularity/">NGC</a>
containers can be used as an effective solution for machine learning related tasks. (Downloading
containers requires registration). Nvidia-prepared containers with software solutions for specific
scientific problems can simplify the deployment of deep learning workloads on HPC. NGC containers
have shown consistent performance compared to directly run code.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="nvidia-arm-hpc-developer-kit">
<h1>NVIDIA Arm HPC Developer Kit<a class="headerlink" href="#nvidia-arm-hpc-developer-kit" title="Permalink to this heading">#</a></h1>
<p>As part of the ZIH systems, we provide a NVIDIA Arm HPC Developer Kit to allow for experimentation
with Arm based systems.</p>
<section id="hardware">
<h2>Hardware<a class="headerlink" href="#hardware" title="Permalink to this heading">#</a></h2>
<p>This Arm HPC Developer kit offers:</p>
<ul class="simple">
<li><p>GIGABYTE G242-P32, 2U server</p></li>
<li><p>1x Ampere Altra Q80-30 (Arm processor)</p></li>
<li><p>512G DDR4 memory (8x 64G)</p></li>
<li><p>6TB SAS/ SATA 3.5‚Ä≥</p></li>
<li><p>2x NVIDIA A100 GPU</p></li>
<li><p>2x NVIDIA BlueField-2 E-Series DPU: 200GbE/HDR single-port, both connected to the InfiniBand network</p></li>
</ul>
</section>
<section id="further-information">
<h2>Further Information<a class="headerlink" href="#further-information" title="Permalink to this heading">#</a></h2>
<p>Further information about this new system can be found on the following websites:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://developer.nvidia.com/arm-hpc-devkit">NVIDIA product page</a></p></li>
<li><p><a class="reference external" href="https://github.com/arm-hpc-devkit/nvidia-arm-hpc-devkit-users-guide">link collection curated by NVIDIA</a></p></li>
</ul>
</section>
<section id="getting-access">
<h2>Getting Access<a class="headerlink" href="#getting-access" title="Permalink to this heading">#</a></h2>
<p>To get access to the developer kit, write a mail to
<a class="reference external" href="mailto:hpc-support&#37;&#52;&#48;tu-dresden&#46;de">the hpcsupport team</a>
with your ZIH login and a short description, what you want to use the developer kit for.</p>
<p>After you have gained access, you can log into the developer kit system via SSH from the login
nodes:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ssh<span class="w"> </span>a1.misc.hpc.tu-dresden.de
</pre></div>
</div>
</section>
<section id="running-applications">
<h2>Running Applications<a class="headerlink" href="#running-applications" title="Permalink to this heading">#</a></h2>
<p>!!! warning ‚ÄúNot under Slurm control‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>In contrast to all other compute resources, the ARM HPC Developer Kit is **not** managed by the
[Slurm batch system](../jobs_and_resources/slurm.md). To run your application just execute it.

For long running applications, we recommend using a session manager, for example
[tmux](../software/utilities.md#tmux).
</pre></div>
</div>
<p>!!! warning ‚ÄúNo shared filesystem available‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>This is a test system. For this reason the shared filesystems (e.g. Lustre or BeeGFS) are not
available.
</pre></div>
</div>
<p>The system supports the Arm v8.2+ architecture. Therefore, your application needs to be compiled
for the target architecture <code class="docutils literal notranslate"><span class="pre">aarch64</span></code> which is the 64-bit execution state of Arm v8. You can either
compile your application on the Developer Kit or cross compile for <code class="docutils literal notranslate"><span class="pre">aarch64</span></code> on another system.</p>
<section id="cross-compiling-for-the-arm-architecture">
<h3>Cross compiling for the Arm Architecture<a class="headerlink" href="#cross-compiling-for-the-arm-architecture" title="Permalink to this heading">#</a></h3>
<p>A compiler supporting the Arm architecture <code class="docutils literal notranslate"><span class="pre">aarch64</span></code> is required for cross compilation. You could
for example use the GCC compiler for <code class="docutils literal notranslate"><span class="pre">aarch64</span></code>. Most Linux distributions provide the compiler in
their package repositories, often the package is called <code class="docutils literal notranslate"><span class="pre">gcc-aarch64-linux-gnu</span></code>.</p>
<p>!!! note ‚ÄúNo cross compiler available on ZIH systems‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>On the ZIH systems is no cross compiler available. If you can&#39;t cross compile on your own
systems, compile your application on the Arm Developer Kit using the provided compiler, which
already builds for the `aarch64` target.
</pre></div>
</div>
<p>To cross compile your application run the compiler for the <code class="docutils literal notranslate"><span class="pre">aarch64</span></code> architecture instead of the
compiler you normally use.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>Instead<span class="w"> </span>of<span class="w"> </span>gcc
<span class="gp">marie@local$ </span>aarch64-linux-gnu-gcc<span class="w"> </span>-o<span class="w"> </span>application<span class="w"> </span>application.c

<span class="gp"># </span>When<span class="w"> </span>using<span class="w"> </span>make
<span class="gp">marie@local$ </span>make<span class="w"> </span><span class="nv">CC</span><span class="o">=</span>aarch64-linux-gnu-gcc
</pre></div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="binding-and-distribution-of-tasks">
<h1>Binding and Distribution of Tasks<a class="headerlink" href="#binding-and-distribution-of-tasks" title="Permalink to this heading">#</a></h1>
<p>Slurm provides several binding strategies to place and bind the tasks and/or threads of your job
to cores, sockets and nodes.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Keep in mind that the distribution method might have a direct impact on the execution time of
your application. The manipulation of the distribution can either speed up or slow down your
application.
</pre></div>
</div>
<section id="id13">
<h2>General<a class="headerlink" href="#id13" title="Permalink to this heading">#</a></h2>
<p>To specify a pattern the commands <code class="docutils literal notranslate"><span class="pre">--cpu_bind=&lt;cores|sockets&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">--distribution=&lt;block|cyclic&gt;</span></code>
are needed. The option <code class="docutils literal notranslate"><span class="pre">cpu_bind</span></code> defines the resolution in which the tasks will be allocated. While
<code class="docutils literal notranslate"><span class="pre">--distribution</span></code> determinate the order in which the tasks will be allocated to the CPUs. Keep in
mind that the allocation pattern also depends on your specification.</p>
<p>!!! example ‚ÄúExplicitly specify binding and distribution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash
#SBATCH --nodes=2                        # request 2 nodes
#SBATCH --cpus-per-task=4                # use 4 cores per task
#SBATCH --tasks-per-node=4               # allocate 4 tasks per node - 2 per socket

srun --ntasks 8 --cpus-per-task 4 --cpu_bind=cores --distribution=block:block ./application
```
</pre></div>
</div>
<p>In the following sections there are some selected examples of the combinations between <code class="docutils literal notranslate"><span class="pre">--cpu_bind</span></code>
and <code class="docutils literal notranslate"><span class="pre">--distribution</span></code> for different job types.</p>
</section>
<section id="openmp-strategies">
<h2>OpenMP Strategies<a class="headerlink" href="#openmp-strategies" title="Permalink to this heading">#</a></h2>
<p>The illustration below shows the default binding of a pure OpenMP job on a single node with 16 CPUs
on which 16 threads are allocated.</p>
<p><img alt="OpenMP" src="63_chat_with_docs/misc/openmp.png" />
{: align=center}</p>
<p>!!! example ‚ÄúDefault binding and default distribution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash
#SBATCH --nodes=1
#SBATCH --tasks-per-node=1
#SBATCH --cpus-per-task=16

export OMP_NUM_THREADS=16

srun --ntasks 1 --cpus-per-task $OMP_NUM_THREADS ./application
```
</pre></div>
</div>
</section>
<section id="mpi-strategies">
<h2>MPI Strategies<a class="headerlink" href="#mpi-strategies" title="Permalink to this heading">#</a></h2>
<section id="default-binding-and-distribution-pattern">
<h3>Default Binding and Distribution Pattern<a class="headerlink" href="#default-binding-and-distribution-pattern" title="Permalink to this heading">#</a></h3>
<p>The default binding uses <code class="docutils literal notranslate"><span class="pre">--cpu_bind=cores</span></code> in combination with <code class="docutils literal notranslate"><span class="pre">--distribution=block:cyclic</span></code>. The
default (as well as <code class="docutils literal notranslate"><span class="pre">block:cyclic</span></code>) allocation method will fill up one node after another, while
filling socket one and two in alternation. Resulting in only even ranks on the first socket of each
node and odd on each second socket of each node.</p>
<p><img alt="Default distribution" src="63_chat_with_docs/misc/mpi_default.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>!!! example ‚ÄúDefault binding and default distribution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash
#SBATCH --nodes=2
#SBATCH --tasks-per-node=16
#SBATCH --cpus-per-task=1

srun --ntasks 32 ./application
```
</pre></div>
</div>
</section>
<section id="core-bound">
<h3>Core Bound<a class="headerlink" href="#core-bound" title="Permalink to this heading">#</a></h3>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>With this command the tasks will be bound to a core for the entire runtime of your
application.
</pre></div>
</div>
<section id="distribution-block-block">
<h4>Distribution: block:block<a class="headerlink" href="#distribution-block-block" title="Permalink to this heading">#</a></h4>
<p>This method allocates the tasks linearly to the cores.</p>
<p><img alt="block:block distribution" src="63_chat_with_docs/misc/mpi_block_block.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>!!! example ‚ÄúBinding to cores and block:block distribution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash
#SBATCH --nodes=2
#SBATCH --tasks-per-node=16
#SBATCH --cpus-per-task=1

srun --ntasks 32 --cpu_bind=cores --distribution=block:block ./application
```
</pre></div>
</div>
</section>
<section id="distribution-cyclic-cyclic">
<h4>Distribution: cyclic:cyclic<a class="headerlink" href="#distribution-cyclic-cyclic" title="Permalink to this heading">#</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">--distribution=cyclic:cyclic</span></code> will allocate your tasks to the cores in a
round robin approach. It starts with the first socket of the first node,
then the first socket of the second node until one task is placed on
every first socket of every node. After that it will place a task on
every second socket of every node and so on.</p>
<p><img alt="cyclic:cyclic distribution" src="63_chat_with_docs/misc/mpi_cyclic_cyclic.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>!!! example ‚ÄúBinding to cores and cyclic:cyclic distribution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash
#SBATCH --nodes=2
#SBATCH --tasks-per-node=16
#SBATCH --cpus-per-task=1

srun --ntasks 32 --cpu_bind=cores --distribution=cyclic:cyclic ./application
```
</pre></div>
</div>
</section>
<section id="distribution-cyclic-block">
<h4>Distribution: cyclic:block<a class="headerlink" href="#distribution-cyclic-block" title="Permalink to this heading">#</a></h4>
<p>The cyclic:block distribution will allocate the tasks of your job in
alternation on node level, starting with first node filling the sockets
linearly.</p>
<p><img alt="cyclic:block distribution" src="63_chat_with_docs/misc/mpi_cyclic_block.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>!!! example ‚ÄúBinding to cores and cyclic:block distribution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash
#SBATCH --nodes=2
#SBATCH --tasks-per-node=16
#SBATCH --cpus-per-task=1

srun --ntasks 32 --cpu_bind=cores --distribution=cyclic:block ./application
```
</pre></div>
</div>
</section>
</section>
<section id="socket-bound">
<h3>Socket Bound<a class="headerlink" href="#socket-bound" title="Permalink to this heading">#</a></h3>
<p>The general distribution onto the nodes and sockets stays the same. The mayor difference between
socket- and CPU-bound lies within the ability of the OS to move tasks from one core to another
inside a socket while executing the application. These jumps can slow down the execution time of
your application.</p>
<section id="default-distribution">
<h4>Default Distribution<a class="headerlink" href="#default-distribution" title="Permalink to this heading">#</a></h4>
<p>The default distribution uses <code class="docutils literal notranslate"><span class="pre">--cpu_bind=sockets</span></code> with <code class="docutils literal notranslate"><span class="pre">--distribution=block:cyclic</span></code>. The default
allocation method (as well as <code class="docutils literal notranslate"><span class="pre">block:cyclic</span></code>) will fill up one node after another, while filling
socket one and two in alternation. Resulting in only even ranks on the first socket of each node and
odd on each second socket of each node.</p>
<p><img alt="Binding to sockets and block:cyclic distribution" src="63_chat_with_docs/misc/mpi_socket_block_cyclic.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>!!! example ‚ÄúBinding to sockets and block:cyclic distribution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash
#SBATCH --nodes=2
#SBATCH --tasks-per-node=16
#SBATCH --cpus-per-task=1

srun --ntasks 32 -cpu_bind=sockets ./application
```
</pre></div>
</div>
</section>
<section id="id14">
<h4>Distribution: block:block<a class="headerlink" href="#id14" title="Permalink to this heading">#</a></h4>
<p>This method allocates the tasks linearly to the cores.</p>
<p><img alt="Binding to sockets and block:block distribution" src="63_chat_with_docs/misc/mpi_socket_block_block.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>!!! example ‚ÄúBinding to sockets and block:block distribution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash
#SBATCH --nodes=2
#SBATCH --tasks-per-node=16
#SBATCH --cpus-per-task=1

srun --ntasks 32 --cpu_bind=sockets --distribution=block:block ./application
```
</pre></div>
</div>
</section>
<section id="distribution-block-cyclic">
<h4>Distribution: block:cyclic<a class="headerlink" href="#distribution-block-cyclic" title="Permalink to this heading">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">block:cyclic</span></code> distribution will allocate the tasks of your job in
alternation between the first node and the second node while filling the
sockets linearly.</p>
<p><img alt="Binding to sockets and block:cyclic distribution" src="63_chat_with_docs/misc/mpi_socket_block_cyclic.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>!!! example ‚ÄúBinding to sockets and block:cyclic distribution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash
#SBATCH --nodes=2
#SBATCh --tasks-per-node=16
#SBATCH --cpus-per-task=1

srun --ntasks 32 --cpu_bind=sockets --distribution=block:cyclic ./application
```
</pre></div>
</div>
</section>
</section>
</section>
<section id="hybrid-strategies">
<h2>Hybrid Strategies<a class="headerlink" href="#hybrid-strategies" title="Permalink to this heading">#</a></h2>
<section id="id15">
<h3>Default Binding and Distribution Pattern<a class="headerlink" href="#id15" title="Permalink to this heading">#</a></h3>
<p>The default binding pattern of hybrid jobs will split the cores allocated to a rank between the
sockets of a node. The example shows that Rank 0 has 4 cores at its disposal. Two of them on first
socket inside the first node and two on the second socket inside the first node.</p>
<p><img alt="sockets binding and block:block distribution" src="63_chat_with_docs/misc/hybrid.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>!!! example ‚ÄúBinding to sockets and block:block distribution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash
#SBATCH --nodes=2
#SBATCH --tasks-per-node=4
#SBATCH --cpus-per-task=4

export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
srun --ntasks 8 --cpus-per-task $OMP_NUM_THREADS ./application
```
</pre></div>
</div>
</section>
<section id="id16">
<h3>Core Bound<a class="headerlink" href="#id16" title="Permalink to this heading">#</a></h3>
<section id="id17">
<h4>Distribution: block:block<a class="headerlink" href="#id17" title="Permalink to this heading">#</a></h4>
<p>This method allocates the tasks linearly to the cores.</p>
<p><img alt="Binding to cores and block:block distribution" src="63_chat_with_docs/misc/hybrid_cores_block_block.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>!!! example ‚ÄúBinding to cores and block:block distribution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash
#SBATCH --nodes=2
#SBATCH --tasks-per-node=4
#SBATCH --cpus-per-task=4

export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
srun --ntasks 8 --cpus-per-task $OMP_NUM_THREADS --cpu_bind=cores --distribution=block:block ./application
```
</pre></div>
</div>
</section>
<section id="id18">
<h4>Distribution: cyclic:block<a class="headerlink" href="#id18" title="Permalink to this heading">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">cyclic:block</span></code> distribution will allocate the tasks of your job in alternation between the first
node and the second node while filling the sockets linearly.</p>
<p><img alt="binding to cores and cyclic:block distribution" src="63_chat_with_docs/misc/hybrid_cores_cyclic_block.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>!!! example ‚ÄúBinding to cores and cyclic:block distribution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash
#SBATCH --nodes=2
#SBATCH --tasks-per-node=4
#SBATCH --cpus-per-task=4

export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
srun --ntasks 8 --cpus-per-task $OMP_NUM_THREADS --cpu_bind=cores --distribution=cyclic:block ./application
```
</pre></div>
</div>
</section>
</section>
</section>
<section id="gpu">
<h2>GPU<a class="headerlink" href="#gpu" title="Permalink to this heading">#</a></h2>
<p>Currently with the Slurm version (20.11.9) used ZIH systems
it <strong>is not possible</strong> to bind tasks to GPUs. Is will be possible as soon as Slurm is updated at
least to version 21.08.0 (see <a class="reference external" href="https://slurm.schedmd.com/archive/slurm-21.08.0/gres.html#MIG_Management">GRES/MIG documentation in Slurm 21.08.0</a>).</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="gpu-cluster-capella">
<h1>GPU Cluster Capella<a class="headerlink" href="#gpu-cluster-capella" title="Permalink to this heading">#</a></h1>
<section id="id19">
<h2>Overview<a class="headerlink" href="#id19" title="Permalink to this heading">#</a></h2>
<p>The Lenovo multi-GPU cluster <code class="docutils literal notranslate"><span class="pre">Capella</span></code> has been installed by MEGWARE for
AI-related computations and traditional
HPC simulations. Capella is fully integrated into the ZIH HPC infrastructure.
Therefore, the usage should be similar to the other clusters.</p>
<p>In November 2024, Capella was ranked #51 in the <a class="reference external" href="https://top500.org/system/180298/">TOP500</a>,
which is #3 of German
systems, and #5 in the <a class="reference external" href="https://top500.org/lists/green500/list/2024/11/">GREEN500</a> lists of the
world‚Äôs fastest computers. Background information on how Capella reached these positions can be
found in this
<a class="reference external" href="https://www.golem.de/news/effiziente-grossrechner-wie-man-einen-supercomputer-in-die-green500-bekommt-2411-190925.html">Golem article</a>.</p>
</section>
<section id="hardware-specifications">
<h2>Hardware Specifications<a class="headerlink" href="#hardware-specifications" title="Permalink to this heading">#</a></h2>
<p>The hardware specification is documented on the page
<span class="xref myst">HPC Resources</span>.</p>
</section>
<section id="access-and-login-nodes">
<h2>Access and Login Nodes<a class="headerlink" href="#access-and-login-nodes" title="Permalink to this heading">#</a></h2>
<p>You use <code class="docutils literal notranslate"><span class="pre">login[1-2].capella.hpc.tu-dresden.de</span></code> to access the cluster <code class="docutils literal notranslate"><span class="pre">Capella</span></code> from the campus
(or VPN) network.
In order to verify the SSH fingerprints of the login nodes, please refer to the page
<span class="xref myst">Key Fingerprints</span>.</p>
<p>On the login nodes you have access to the same filesystems and the software stack
as on the compute node. GPUs are <strong>not</strong> available there.</p>
<p>In the subsections <span class="xref myst">Filesystems</span> and <span class="xref myst">Software and Modules</span> we
provide further information on these two topics.</p>
</section>
<section id="id20">
<h2>Filesystems<a class="headerlink" href="#id20" title="Permalink to this heading">#</a></h2>
<p>As with all other clusters, your <code class="docutils literal notranslate"><span class="pre">/home</span></code> directory is also available on <code class="docutils literal notranslate"><span class="pre">Capella</span></code>.
For reasons of convenience, the filesystems <code class="docutils literal notranslate"><span class="pre">horse</span></code> and <code class="docutils literal notranslate"><span class="pre">walrus</span></code> are also accessible.
Please note, that the filesystem <code class="docutils literal notranslate"><span class="pre">horse</span></code> <strong>should not be used</strong> as working
filesystem at the cluster <code class="docutils literal notranslate"><span class="pre">Capella</span></code> because we have something better.</p>
<section id="cluster-specific-filesystem-cat">
<h3>Cluster-Specific Filesystem <code class="docutils literal notranslate"><span class="pre">cat</span></code><a class="headerlink" href="#cluster-specific-filesystem-cat" title="Permalink to this heading">#</a></h3>
<p>With <code class="docutils literal notranslate"><span class="pre">Capella</span></code> comes the new filesystem <code class="docutils literal notranslate"><span class="pre">cat</span></code> designed to meet the high I/O requirements of AI
and ML workflows. It is a WEKAio filesystem and mounted under <code class="docutils literal notranslate"><span class="pre">/data/cat</span></code>. It is <strong>only available</strong>
on the cluster <code class="docutils literal notranslate"><span class="pre">Capella</span></code> and the <span class="xref myst">Datamover nodes</span>.</p>
<p>The filesystem <code class="docutils literal notranslate"><span class="pre">cat</span></code> should be used as the
main working filesystem and has to be used with <span class="xref myst">workspaces</span>.
Workspaces on the filesystem <code class="docutils literal notranslate"><span class="pre">cat</span></code> can only be created on the login and compute nodes, not on
the other clusters since <code class="docutils literal notranslate"><span class="pre">cat</span></code> is not available there.</p>
<p><code class="docutils literal notranslate"><span class="pre">cat</span></code> has only limited capacity, hence workspace duration is significantly shorter than
in other filesystems. We recommend that you only store actively used data there.
To transfer input and result data from and to the filesystems <code class="docutils literal notranslate"><span class="pre">horse</span></code> and <code class="docutils literal notranslate"><span class="pre">walrus</span></code>, respectively,
you will need to use the <span class="xref myst">Datamover nodes</span>. Regardless of the
direction of transfer, you should pack your data into archives (,e.g., using <code class="docutils literal notranslate"><span class="pre">dttar</span></code> command)
for the transfer.</p>
<p><strong>Do not</strong> invoke data transfer to the filesystems <code class="docutils literal notranslate"><span class="pre">horse</span></code> and <code class="docutils literal notranslate"><span class="pre">walrus</span></code> from login nodes.
Both login nodes are part of the cluster. Failures, reboots and other work
might affect your data transfer resulting in data corruption.</p>
<p>All other share <span class="xref myst">filesystems</span>
(<code class="docutils literal notranslate"><span class="pre">/home</span></code>, <code class="docutils literal notranslate"><span class="pre">/software</span></code>, <code class="docutils literal notranslate"><span class="pre">/data/horse</span></code>, <code class="docutils literal notranslate"><span class="pre">/data/walrus</span></code>, etc.) are also mounted.</p>
</section>
</section>
<section id="software-and-modules">
<h2>Software and Modules<a class="headerlink" href="#software-and-modules" title="Permalink to this heading">#</a></h2>
<p>The most straightforward method for utilizing the software is through the well-known
<span class="xref myst">module system</span>.
All software available from the module system has been <strong>specifically build</strong> for the cluster
<code class="docutils literal notranslate"><span class="pre">Capella</span></code> i.e., with optimization for Zen4 (Genoa) microarchitecture and CUDA-support enabled.</p>
<section id="id21">
<h3>Python Virtual Environments<a class="headerlink" href="#id21" title="Permalink to this heading">#</a></h3>
<p><span class="xref myst">Virtual environments</span> allow you to install
additional Python packages and create an isolated runtime environment. We recommend using
<code class="docutils literal notranslate"><span class="pre">venv</span></code> for this purpose.</p>
<p>!!! hint ‚ÄúVirtual environments in workspaces‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>We recommend to use [workspaces](../data_lifecycle/workspaces.md) for your virtual environments.
</pre></div>
</div>
</section>
</section>
<section id="batch-system">
<h2>Batch System<a class="headerlink" href="#batch-system" title="Permalink to this heading">#</a></h2>
<p>The batch system Slurm may be used as usual. Please refer to the page <span class="xref myst">Batch System Slurm</span>
for detailed information. In addition, the page <span class="xref myst">Job Examples with GPU</span>
provides examples on GPU allocation with Slurm.</p>
<p>You can find out about upcoming reservations (,e.g., for acceptance benchmarks) via <code class="docutils literal notranslate"><span class="pre">sinfo</span> <span class="pre">-T</span></code>.
Acceptance has priority, so your reservation requests can currently not be considered.</p>
<p>!!! note ‚ÄúSlurm limits and job runtime‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Although, each compute node is equipped with 64 CPU cores in total, only a **maximum of 56** can
be requested via Slurm
(cf. [Slurm Resource Limits Table](slurm_limits.md#slurm-resource-limits-table)).

The **maximum runtime** of jobs and interactive sessions is currently 24 hours. However, to
allow for greater fluctuation in testing, please make the jobs shorter if possible. You can use
[Chain Jobs](slurm_examples.md#chain-jobs) to split a long running job exceeding the batch queues
limits into parts and chain these parts. Applications with build-in check-point-restart
functionality are very suitable for this approach! If your application provides
check-point-restart, please use `/data/cat` for temporary data. Remove these data afterwards!
</pre></div>
</div>
<p>The partition <code class="docutils literal notranslate"><span class="pre">capella-interactive</span></code> can be used for your small tests and compilation of software.
In addition, JupyterHub instances that require low GPU utilization or only use GPUs for a short
period of time in their allocation are intended to use this partition.
You need to add <code class="docutils literal notranslate"><span class="pre">#SBATCH</span> <span class="pre">--partition=capella-interactive</span></code> to your job file and
<code class="docutils literal notranslate"><span class="pre">--partition=capella-interactive</span></code> to your <code class="docutils literal notranslate"><span class="pre">sbatch</span></code>, <code class="docutils literal notranslate"><span class="pre">srun</span></code> and <code class="docutils literal notranslate"><span class="pre">salloc</span></code> command line, respectively,
to address this partition.
The partition <code class="docutils literal notranslate"><span class="pre">capella-interactive</span></code> is configured to use <span class="xref myst">MIG</span> configuration of 1/7.</p>
</section>
<section id="virtual-gpus-mig">
<h2>Virtual GPUs-MIG<a class="headerlink" href="#virtual-gpus-mig" title="Permalink to this heading">#</a></h2>
<p>Starting with the Capella cluster, we introduce virtual GPUs. They are based on
<a class="reference external" href="https://www.nvidia.com/de-de/technologies/multi-instance-gpu/">Nvidia‚Äôs MIG technology</a>.
From an application point of view, each virtual GPU looks like a normal physical GPU, but offers
only a fraction of the compute resources and the maximum allocatable memory on the device.
We also only account you a fraction of a full GPU hour.
By using virtual GPUs, we expect to improve overall system utilization for jobs that cannot take
advantage of a full H100 GPU.
In addition, we can provide you with more resources and therefore shorter waiting times.
We intend to use these partitions for all applications that cannot use a full H100 GPU, such as
Jupyter-Notebooks.
Users can check the usage of compute and memory usage of the GPU with the help of
<span class="xref myst">job monitoring system PIKA</span>.
Since a GPU in the <code class="docutils literal notranslate"><span class="pre">Capella</span></code> cluster offers 3.2-3.5x more peak performance compared to an A100 GPU
in the cluster <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Alpha</span> <span class="pre">Centauri</span></code></span>, a 1/7 shard of a GPU in
Capella is about half the performance of a GPU in <code class="docutils literal notranslate"><span class="pre">Alpha</span> <span class="pre">Centauri</span></code>.</p>
<p>At the moment we only have a partitioning of 7 in the <code class="docutils literal notranslate"><span class="pre">capella-interactive</span></code> partition,
but we are free to create more configurations in the future.
For this, users‚Äô demands and expected high utilization of the smaller GPUS are essential.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Configuration Name</p></th>
<th class="head"><p>Compute Resources</p></th>
<th class="head"><p>Memory in GiB</p></th>
<th class="head"><p>Accounted GPU hour</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">capella-interactive</span></code></p></td>
<td><p>1 / 7</p></td>
<td><p>11</p></td>
<td><p>1/7</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="checkpoint-restart">
<h1>Checkpoint/Restart<a class="headerlink" href="#checkpoint-restart" title="Permalink to this heading">#</a></h1>
<p>At some point, every HPC system fails, e.g., a compute node or the network might crash causing
running jobs to crash, too. In order to prevent starting your crashed experiments and simulations
from the very beginning, you should be familiar with the concept of checkpointing.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Checkpointing saves the state of a running process to a checkpointing image file. Using this
file, the process can later be continued (restarted) from where it left off.
</pre></div>
</div>
<p>Another motivation is to use checkpoint/restart to split long running jobs into several shorter
ones. This might improve the overall job throughput, since shorter jobs can ‚Äúfill holes‚Äù in the job
queue.
Here is an extreme example from literature for the waste of large computing resources due to missing
checkpoints:</p>
<p>!!! cite ‚ÄúAdams, D. The Hitchhikers Guide Through the Galaxy‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Earth was a supercomputer constructed to find the question to the answer to the Life, the Universe,
and Everything by a race of hyper-intelligent pan-dimensional beings. Unfortunately 10 million years
later, and five minutes before the program had run to completion, the Earth was destroyed by
Vogons.
</pre></div>
</div>
<p>If you wish to do checkpointing, your first step should always be to check if your application
already has such capabilities built-in, as that is the most stable and safe way of doing it.
Applications that are known to have some sort of <strong>native checkpointing</strong> include:</p>
<p>Abaqus, Amber, Gaussian, GROMACS, LAMMPS, NAMD, NWChem, Quantum Espresso, STAR-CCM+, VASP</p>
<p>In case your program does not natively support checkpointing, there are attempts at creating generic
checkpoint/restart solutions that should work application-agnostic. One such project which we
recommend is <a class="reference external" href="http://dmtcp.sourceforge.net">Distributed Multi-Threaded Check-Pointing</a> (DMTCP).</p>
<p>DMTCP is available on ZIH systems after having loaded the <code class="docutils literal notranslate"><span class="pre">dmtcp</span></code> module</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>DMTCP
</pre></div>
</div>
<p>While our batch system <span class="xref myst">Slurm</span> also provides a checkpointing interface to the user,
unfortunately, it does not yet support DMTCP at this time. However, there are ongoing efforts of
writing a Slurm plugin that hopefully will change this in the near future. We will update this
documentation as soon as it becomes available.</p>
<p>In order to help with setting up checkpointing for your jobs, we have written a few scripts that
make it easier to utilize DMTCP together with Slurm.</p>
<section id="using-w-r-t-chain-jobs">
<h2>Using w.r.t. Chain Jobs<a class="headerlink" href="#using-w-r-t-chain-jobs" title="Permalink to this heading">#</a></h2>
<p>For long-running jobs that you wish to split into multiple shorter jobs
(<span class="xref myst">chain jobs</span>), thereby enabling the job scheduler to
fill the cluster much more efficiently and also providing some level of fault-tolerance, we have
written a script that automatically creates a number of jobs for your desired runtime and adds the
checkpoint/restart bits transparently to your batch script. You just have to specify the targeted
total runtime of your calculation and the interval in which you wish to do checkpoints. The latter
(plus the time it takes to write the checkpoint) will then be the runtime of the individual jobs.
This should be targeted at below 24 hours in order to be able to run on all
<span class="xref myst">partitions haswell64</span>. For
increased fault-tolerance, it can be chosen even shorter.</p>
<p>To use it, first add a <code class="docutils literal notranslate"><span class="pre">dmtcp_launch</span></code> before your application call in your batch script. In the case
of MPI applications, you have to add the parameters <code class="docutils literal notranslate"><span class="pre">--ib</span> <span class="pre">--rm</span></code> and put it between <code class="docutils literal notranslate"><span class="pre">srun</span></code> and your
application call, e.g.:</p>
<p>???+ example ‚ÄúExample my-dmtcp-script.sbatch‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
[...]

srun dmtcp_launch --ib --rm ./my-mpi-application
```
</pre></div>
</div>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>We have successfully tested checkpointing MPI applications with
the latest `Intel MPI` (module: intelmpi/2018.0.128). While it might
work with other MPI libraries, too, we have no experience in this
regard, so you should always try it out before using it for your
productive jobs.
</pre></div>
</div>
<p>Then just substitute your usual <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> call with <code class="docutils literal notranslate"><span class="pre">dmtcp_sbatch</span></code> and be sure to specify the <code class="docutils literal notranslate"><span class="pre">-t</span></code>
and <code class="docutils literal notranslate"><span class="pre">-i</span></code> parameters (don‚Äôt forget you need to have loaded the <code class="docutils literal notranslate"><span class="pre">dmtcp</span></code> module).</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>dmtcp_sbatch<span class="w"> </span>--time<span class="w"> </span><span class="m">2</span>-00:00:00<span class="w"> </span>--interval<span class="w"> </span><span class="m">28000</span>,800<span class="w"> </span>my-dmtcp-script.sbatch
</pre></div>
</div>
<p>With <code class="docutils literal notranslate"><span class="pre">-t,</span> <span class="pre">--time</span></code> you set the total runtime of your calculations. This will be replaced in the batch
script in order to shorten your individual jobs.</p>
<p>The parameter <code class="docutils literal notranslate"><span class="pre">-i,</span> <span class="pre">--interval</span></code> sets the time in seconds for your checkpoint intervals. It can
optionally include a timeout for writing out the checkpoint files, separated from the interval time
via comma (defaults to 10 minutes).</p>
<p>In the above example, there will be 6 jobs each running 8 hours, so
about 2 days in total.</p>
<p>!!! Hints</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- If you see your first job running into the time limit, that probably
means the timeout for writing out checkpoint files does not suffice
and should be increased. Our tests have shown that it takes
approximately 5 minutes to write out the memory content of a fully
utilized 64GB haswell node, so you should choose at least 10 minutes
there (better err on the side of caution). Your mileage may vary,
depending on how much memory your application uses. If your memory
content is rather incompressible, it might be a good idea to disable
the checkpoint file compression by setting: `export DMTCP_GZIP=0`
- Note that all jobs the script deems necessary for your chosen
time limit/interval values are submitted right when first calling the
script. If your applications take considerably less time than what
you specified, some of the individual jobs will be unnecessary. As
soon as one job does not find a checkpoint to resume from, it will
cancel all subsequent jobs for you.
- See `dmtcp_sbatch -h` for a list of available parameters and more help
</pre></div>
</div>
<p>What happens in your work directory?</p>
<ul class="simple">
<li><p>The script will create subdirectories named <code class="docutils literal notranslate"><span class="pre">ckpt_&lt;jobid&gt;</span></code> for each
individual job it puts into the queue</p></li>
<li><p>It will also create modified versions of your batch script, one for
the first job (<code class="docutils literal notranslate"><span class="pre">ckpt_launch.job</span></code>), one for the middle parts
(<code class="docutils literal notranslate"><span class="pre">ckpt_rstr.job</span></code>) and one for the final job (<code class="docutils literal notranslate"><span class="pre">cpkt_rstr_last.job</span></code>)</p></li>
<li><p>Inside the <code class="docutils literal notranslate"><span class="pre">ckpt_*</span></code> directories you will also find a file
(<code class="docutils literal notranslate"><span class="pre">job_ids</span></code>) containing all job ids that are related to this job
chain</p></li>
</ul>
<p>If you wish to restart manually from one of your checkpoints (e.g., if something went wrong in your
later jobs or the jobs vanished from the queue for some reason), you have to call <code class="docutils literal notranslate"><span class="pre">dmtcp_sbatch</span></code>
with the <code class="docutils literal notranslate"><span class="pre">-r,</span> <span class="pre">--resume</span></code> parameter, specifying a <code class="docutils literal notranslate"><span class="pre">cpkt_</span></code> directory to resume from.  Then it will use
the same parameters as in the initial run of this job chain. If you wish to adjust the time limit,
for instance, because you realized that your original limit was too short, just use the <code class="docutils literal notranslate"><span class="pre">-t,</span> <span class="pre">--time</span></code>
parameter again on resume.</p>
</section>
<section id="using-dmtcp-manually">
<h2>Using DMTCP Manually<a class="headerlink" href="#using-dmtcp-manually" title="Permalink to this heading">#</a></h2>
<p>If for some reason our automatic chain job script is not suitable for your use case, you could also
just use DMTCP on its own. In the following we will give you step-by-step instructions on how to
checkpoint your job manually:</p>
<ul class="simple">
<li><p>Load the DMTCP module: <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">load</span> <span class="pre">dmtcp</span></code></p></li>
<li><p>DMTCP usually runs an additional process that
manages the creation of checkpoints and such, the so-called <code class="docutils literal notranslate"><span class="pre">coordinator</span></code>. It must be started in
your batch script before the actual start of your application. To help you with this process, we
have created a bash function called <code class="docutils literal notranslate"><span class="pre">start_coordinator</span></code> that is available after sourcing
<code class="docutils literal notranslate"><span class="pre">$DMTCP_ROOT/bin/bash</span></code> in your script. The coordinator can take a handful of parameters, see <code class="docutils literal notranslate"><span class="pre">man</span> <span class="pre">dmtcp_coordinator</span></code>. Via <code class="docutils literal notranslate"><span class="pre">-i</span></code> you can specify an interval (in seconds) in which checkpoint files are
to be created automatically. With <code class="docutils literal notranslate"><span class="pre">--exit-after-ckpt</span></code> the application will be terminated after the
first checkpoint has been created, which can be useful if you wish to implement some sort of job
chaining on your own.</p></li>
<li><p>In front of your program call, you have to add the wrapper
script <code class="docutils literal notranslate"><span class="pre">dmtcp_launch</span></code>.  This will create a checkpoint automatically after 40 seconds and then
terminate your application and with it the job. If the job runs into its time limit (here: 60
seconds), the time to write out the checkpoint was probably not long enough. If all went well, you
should find <code class="docutils literal notranslate"><span class="pre">cpkt</span></code> files in your work directory together with a script called
<code class="docutils literal notranslate"><span class="pre">./dmtcp_restart_script.sh</span></code> that can be used to resume from the checkpoint.</p></li>
</ul>
<p>???+ example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#/bin/bash
#SBATCH --time=00:01:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=1500

source $DMTCP_ROOT/bin/bash start_coordinator -i 40 --exit-after-ckpt

dmtcp_launch ./my-application #for sequential/multithreaded applications
#or: srun dmtcp_launch --ib --rm ./my-mpi-application #for MPI
applications
```
</pre></div>
</div>
<ul class="simple">
<li><p>To restart your application, you need another batch file
(similar to the one above) where once again you first have to start the
DMTCP coordinator. The requested resources should match those of your
original job. If you do not wish to create another checkpoint in your
restarted run again, you can omit the <code class="docutils literal notranslate"><span class="pre">-i</span></code> and <code class="docutils literal notranslate"><span class="pre">--exit-after-ckpt</span></code>
parameters this time. Afterwards, the application must be run using the
restart script, specifying the host and port of the coordinator (they
have been exported by the <code class="docutils literal notranslate"><span class="pre">start_coordinator</span></code> function).</p></li>
</ul>
<p>???+ example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#/bin/bash
#SBATCH --time=00:01:00
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=1500

source $DMTCP_ROOT/bin/bash start_coordinator -i 40 --exit-after-ckpt

./dmtcp_restart_script.sh -h $DMTCP_COORD_HOST -p
$DMTCP_COORD_PORT
```
</pre></div>
</div>
</section>
<section id="signal-handler">
<h2>Signal Handler<a class="headerlink" href="#signal-handler" title="Permalink to this heading">#</a></h2>
<p>If for some reason your job is taking unexpectedly long and would be killed by Slurm
due to reaching its time limit, you can use <code class="docutils literal notranslate"><span class="pre">--signal=&lt;sig_num&gt;[&#64;sig_time]</span></code> to make
Slurm sent your processes a Unix signal <code class="docutils literal notranslate"><span class="pre">sig_time</span></code> seconds before.
Your application should take care of this signal and can write some checkpoints
or output intermediate results and terminate gracefully.
<code class="docutils literal notranslate"><span class="pre">sig_num</span></code> can be any numeric signal number or name, e.g. <code class="docutils literal notranslate"><span class="pre">10</span></code> and <code class="docutils literal notranslate"><span class="pre">USR1</span></code>. You will find a
comprehensive list of Unix signals including documentation in the
<a class="reference external" href="https://man7.org/linux/man-pages/man7/signal.7.html">signal man page</a>.
<code class="docutils literal notranslate"><span class="pre">sig_time</span></code> has to be an integer value between 0 and 65535 representing seconds
Slurm sends the signal before the time limit is reached. Due to resolution effects
the signal may be sent up to 60 seconds earlier than specified.</p>
<p>The command line</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>srun<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span><span class="w"> </span>--time<span class="o">=</span><span class="m">00</span>:05:00<span class="w"> </span>--signal<span class="o">=</span>USR1@120<span class="w"> </span>./signal-handler
</pre></div>
</div>
<p>makes Slurm send <code class="docutils literal notranslate"><span class="pre">./signal-handler</span></code> the signal <code class="docutils literal notranslate"><span class="pre">USR1</span></code> 120 seconds before
the time limit is reached. The following example provides a skeleton implementation of a
signal-aware application.</p>
<p>???+ example ‚ÄúExample signal-handler.c‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```C hl_lines=&quot;15&quot;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;signal.h&gt;

void sigfunc(int sig) {
    if(sig == SIGUSR1) {
        printf(&quot;Allocation&#39;s time limit reached. Saving checkpoint and exit\n&quot;);
        exit(EXIT_SUCCESS);
    }

    return;
}

int main(void) {
   signal(SIGUSR1, sigfunc);
   printf(&quot;do number crunching\n&quot;);
   while(1) {
       ;
   }

   return EXIT_SUCCESS;
}
```
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="hpc-resources">
<h1>HPC Resources<a class="headerlink" href="#hpc-resources" title="Permalink to this heading">#</a></h1>
<p>HPC resources in ZIH systems comprise the <em>High Performance Computing and Storage Complex</em> and its
extension <em>High Performance Computing ‚Äì Data Analytics</em>. In total it offers scientists
about 100,000 CPU cores and a peak performance of more than 1.5 quadrillion floating point
operations per second. The architecture specifically tailored to data-intensive computing, Big Data
analytics, and artificial intelligence methods with extensive capabilities for energy measurement
and performance monitoring provides ideal conditions to achieve the ambitious research goals of the
users and the ZIH.</p>
<section id="architectural-design">
<h2>Architectural Design<a class="headerlink" href="#architectural-design" title="Permalink to this heading">#</a></h2>
<p>Over the last decade we have been running our HPC system of high heterogeneity with a single
Slurm batch system. This made things very complicated, especially to inexperienced users. With
the replacement of the Taurus system by the cluster <span class="xref myst">Barnard</span> in 2023 we have a new
architectural design comprising <strong>six homogeneous clusters with their own Slurm instances and with
cluster specific login nodes</strong> running on the same CPU. Job submission is possible only from
within the corresponding cluster (compute or login node).</p>
<p>All clusters are integrated to the new InfiniBand fabric and have the same access to
the shared filesystems. You find a comprehensive documentation on the available working and
permanent filesystems on the page <span class="xref myst">Filesystems</span>.</p>
<p><img alt="Architecture overview 2023" src="jobs_and_resources/misc/architecture_2024.png" />
{: align=center}</p>
<p>HPC resources at ZIH comprise a total of <strong>six systems</strong>:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Year of Installation</p></th>
<th class="head"><p>DNS</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Capella</span></code></span></p></td>
<td><p>GPU cluster</p></td>
<td><p>2024</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">c[1-144].capella.hpc.tu-dresden.de</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Barnard</span></code></span></p></td>
<td><p>CPU cluster</p></td>
<td><p>2023</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">n[1001-1630].barnard.hpc.tu-dresden.de</span></code></p></td>
</tr>
<tr class="row-even"><td><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Alpha</span> <span class="pre">Centauri</span></code></span></p></td>
<td><p>GPU cluster</p></td>
<td><p>2021</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">i[8001-8037].alpha.hpc.tu-dresden.de</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Julia</span></code></span></p></td>
<td><p>Single SMP system</p></td>
<td><p>2021</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">julia.hpc.tu-dresden.de</span></code></p></td>
</tr>
<tr class="row-even"><td><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Romeo</span></code></span></p></td>
<td><p>CPU cluster</p></td>
<td><p>2020</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">i[7001-7186].romeo.hpc.tu-dresden.de</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Power9</span></code></span></p></td>
<td><p>IBM Power/GPU cluster</p></td>
<td><p>2018</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ml[1-29].power9.hpc.tu-dresden.de</span></code></p></td>
</tr>
</tbody>
</table>
<p>All clusters will run with their own <span class="xref myst">Slurm batch system</span> and job submission is possible
only from their respective login nodes.</p>
</section>
<section id="login-and-dataport-nodes">
<h2>Login and Dataport Nodes<a class="headerlink" href="#login-and-dataport-nodes" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Login-Nodes</p>
<ul>
<li><p>Individual for each cluster. See the specifics in each cluster chapter.</p></li>
</ul>
</li>
<li><p>2 Data-Transfer-Nodes</p>
<ul>
<li><p>2 servers without interactive login, only available via file transfer protocols
(<code class="docutils literal notranslate"><span class="pre">rsync</span></code>, <code class="docutils literal notranslate"><span class="pre">ftp</span></code>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dataport[3-4].hpc.tu-dresden.de</span></code></p></li>
<li><p>IPs: 141.30.73.[4,5]</p></li>
<li><p>Further information on the usage is documented on the site
<span class="xref myst">Dataport Nodes</span></p></li>
</ul>
</li>
</ul>
</section>
<section id="id22">
<h2>Barnard<a class="headerlink" href="#id22" title="Permalink to this heading">#</a></h2>
<p>The cluster <code class="docutils literal notranslate"><span class="pre">Barnard</span></code> is a general purpose cluster by Bull. It is based on Intel Sapphire Rapids CPUs.</p>
<ul class="simple">
<li><p>630 nodes, each with</p>
<ul>
<li><p>2 x Intel Xeon Platinum 8470 (52 cores) &#64; 2.00 GHz, Multithreading available</p></li>
<li><p>512 GB RAM (8 x 32 GB DDR5-4800 MT/s per socket)</p></li>
<li><p>12 nodes provide 1.8 TB local storage on NVMe device at <code class="docutils literal notranslate"><span class="pre">/tmp</span></code></p></li>
<li><p>All other nodes are diskless and have no or very limited local storage (i.e. <code class="docutils literal notranslate"><span class="pre">/tmp</span></code>)</p></li>
</ul>
</li>
<li><p>Login nodes: <code class="docutils literal notranslate"><span class="pre">login[1-4].barnard.hpc.tu-dresden.de</span></code></p></li>
<li><p>Hostnames: <code class="docutils literal notranslate"><span class="pre">n[1001-1630].barnard.hpc.tu-dresden.de</span></code></p></li>
<li><p>Operating system: Red Hat Enterprise Linux 8.9</p></li>
</ul>
</section>
<section id="id23">
<h2>Alpha Centauri<a class="headerlink" href="#id23" title="Permalink to this heading">#</a></h2>
<p>The cluster <code class="docutils literal notranslate"><span class="pre">Alpha</span> <span class="pre">Centauri</span></code> (short: <code class="docutils literal notranslate"><span class="pre">Alpha</span></code>) by NEC provides AMD Rome CPUs and NVIDIA A100 GPUs
and is designed for AI and ML tasks.</p>
<ul class="simple">
<li><p>37 nodes, each with</p>
<ul>
<li><p>8 x NVIDIA A100-SXM4 Tensor Core-GPUs (40 GB HBM2)</p></li>
<li><p>2 x AMD EPYC CPU 7352 (24 cores) &#64; 2.3 GHz, Multithreading available</p></li>
<li><p>1 TB RAM (16 x 32 GB DDR4-2933 MT/s per socket)</p></li>
<li><p>3.5 TB local storage on NVMe device at <code class="docutils literal notranslate"><span class="pre">/tmp</span></code></p></li>
</ul>
</li>
<li><p>Login nodes: <code class="docutils literal notranslate"><span class="pre">login[1-2].alpha.hpc.tu-dresden.de</span></code></p></li>
<li><p>Hostnames: <code class="docutils literal notranslate"><span class="pre">i[8001-8037].alpha.hpc.tu-dresden.de</span></code></p></li>
<li><p>Operating system: Rocky Linux 8.9</p></li>
<li><p>Further information on the usage is documented on the site <span class="xref myst">GPU Cluster Alpha Centauri</span></p></li>
</ul>
</section>
<section id="id24">
<h2>Capella<a class="headerlink" href="#id24" title="Permalink to this heading">#</a></h2>
<p>The cluster <code class="docutils literal notranslate"><span class="pre">Capella</span></code> by MEGWARE provides AMD Genoa CPUs and NVIDIA H100 GPUs
and is designed for AI and ML tasks.</p>
<ul class="simple">
<li><p>144 nodes, each with</p>
<ul>
<li><p>4 x NVIDIA H100-SXM5 Tensor Core-GPUs (94 GB HBM2e)</p></li>
<li><p>2 x AMD EPYC CPU 9334 (32 cores) &#64; 2.7 GHz, Multithreading disabled</p></li>
<li><p>768 GB RAM (12 x 32 GB DDR5-4800 MT/s per socket)</p></li>
<li><p>800 GB local storage on NVMe device at <code class="docutils literal notranslate"><span class="pre">/tmp</span></code></p></li>
</ul>
</li>
<li><p>Login nodes: <code class="docutils literal notranslate"><span class="pre">login[1-2].capella.hpc.tu-dresden.de</span></code></p></li>
<li><p>Hostnames: <code class="docutils literal notranslate"><span class="pre">c[1-144].capella.hpc.tu-dresden.de</span></code></p></li>
<li><p>Operating system: Alma Linux 9.4</p></li>
<li><p>Offers fractions of full GPUs via <span class="xref myst">Nvidia‚Äôs MIG mechanism</span></p></li>
<li><p>Further information on the usage is documented on the site <span class="xref myst">GPU Cluster Capella</span></p></li>
</ul>
</section>
<section id="id25">
<h2>Romeo<a class="headerlink" href="#id25" title="Permalink to this heading">#</a></h2>
<p>The cluster <code class="docutils literal notranslate"><span class="pre">Romeo</span></code> is a general purpose cluster by NEC based on AMD Rome CPUs.</p>
<ul class="simple">
<li><p>188 nodes, each with</p>
<ul>
<li><p>2 x AMD EPYC CPU 7702 (64 cores) &#64; 2.0 GHz, Multithreading available</p></li>
<li><p>512 GB RAM (8 x 32 GB DDR4-3200 MT/s per socket)</p></li>
<li><p>200 GB local storage on SSD at <code class="docutils literal notranslate"><span class="pre">/tmp</span></code></p></li>
</ul>
</li>
<li><p>Login nodes: <code class="docutils literal notranslate"><span class="pre">login[1-2].romeo.hpc.tu-dresden.de</span></code></p></li>
<li><p>Hostnames: <code class="docutils literal notranslate"><span class="pre">i[7001-7186].romeo.hpc.tu-dresden.de</span></code></p></li>
<li><p>Operating system: Rocky Linux 8.9</p></li>
<li><p>Further information on the usage is documented on the site <span class="xref myst">CPU Cluster Romeo</span></p></li>
</ul>
</section>
<section id="id26">
<h2>Julia<a class="headerlink" href="#id26" title="Permalink to this heading">#</a></h2>
<p>The cluster <code class="docutils literal notranslate"><span class="pre">Julia</span></code> is a large SMP (shared memory parallel) system by HPE based on Superdome Flex
architecture.</p>
<ul class="simple">
<li><p>1 node, with</p>
<ul>
<li><p>32 x Intel(R) Xeon(R) Platinum 8276M CPU &#64; 2.20 GHz (28 cores)</p></li>
<li><p>47 TB RAM (12 x 128 GB DDR4-2933 MT/s per socket)</p></li>
</ul>
</li>
<li><p>Configured as one single node</p></li>
<li><p>48 TB RAM (usable: 47 TB - one TB is used for cache coherence protocols)</p></li>
<li><p>370 TB of fast NVME storage available at <code class="docutils literal notranslate"><span class="pre">/nvme/&lt;projectname&gt;</span></code></p></li>
<li><p>Login node: <code class="docutils literal notranslate"><span class="pre">julia.hpc.tu-dresden.de</span></code></p></li>
<li><p>Hostname: <code class="docutils literal notranslate"><span class="pre">julia.hpc.tu-dresden.de</span></code></p></li>
<li><p>Operating system: Rocky Linux 8.7</p></li>
<li><p>Further information on the usage is documented on the site <span class="xref myst">SMP System Julia</span></p></li>
</ul>
</section>
<section id="id27">
<h2>Power9<a class="headerlink" href="#id27" title="Permalink to this heading">#</a></h2>
<p>The cluster <code class="docutils literal notranslate"><span class="pre">Power9</span></code> by IBM is based on Power9 CPUs and provides NVIDIA V100 GPUs.
<code class="docutils literal notranslate"><span class="pre">Power9</span></code> is specifically designed for machine learning (ML) tasks.</p>
<ul class="simple">
<li><p>32 nodes, each with</p>
<ul>
<li><p>2 x IBM Power9 CPU (2.80 GHz, 3.10 GHz boost, 22 cores)</p></li>
<li><p>256 GB RAM (8 x 16 GB DDR4-2666 MT/s per socket)</p></li>
<li><p>6 x NVIDIA V100-SXM2 GPUs (32 GB HBM2)</p></li>
<li><p>NVLINK bandwidth 150 GB/s between GPUs and host</p></li>
</ul>
</li>
<li><p>Login nodes: <code class="docutils literal notranslate"><span class="pre">login[1-2].power9.hpc.tu-dresden.de</span></code></p></li>
<li><p>Hostnames: <code class="docutils literal notranslate"><span class="pre">ml[1-29].power9.hpc.tu-dresden.de</span></code></p></li>
<li><p>Operating system: Alma Linux 8.7</p></li>
<li><p>Further information on the usage is documented on the site <span class="xref myst">GPU Cluster Power9</span></p></li>
</ul>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="smp-cluster-julia">
<h1>SMP Cluster Julia<a class="headerlink" href="#smp-cluster-julia" title="Permalink to this heading">#</a></h1>
<section id="id28">
<h2>Overview<a class="headerlink" href="#id28" title="Permalink to this heading">#</a></h2>
<p>The HPE Superdome Flex is a large shared memory node. It is especially well suited for data
intensive application scenarios, for example to process extremely large data sets completely in main
memory or in very fast NVMe memory.</p>
</section>
<section id="hardware-resources">
<h2>Hardware Resources<a class="headerlink" href="#hardware-resources" title="Permalink to this heading">#</a></h2>
<p>The hardware specification is documented on the page
<span class="xref myst">HPC Resources</span>.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>`Julia` has been partitioned at the end of October 2024. A quarter of the hardware ressources
(CPUs and memory) are now in exclusive operation for the
[DZA](https://www.deutscheszentrumastrophysik.de/).
</pre></div>
</div>
</section>
<section id="local-temporary-on-nvme-storage">
<h2>Local Temporary on NVMe Storage<a class="headerlink" href="#local-temporary-on-nvme-storage" title="Permalink to this heading">#</a></h2>
<p>There are 370 TB of NVMe devices installed. For immediate access for all projects, a volume of 87 TB
of fast NVMe storage is available at <code class="docutils literal notranslate"><span class="pre">/nvme/1/&lt;projectname&gt;</span></code>. A quota of
100 GB per project on this NVMe storage is set.</p>
<p>With a more detailed proposal to <a class="reference external" href="mailto:hpc-support&#37;&#52;&#48;tu-dresden&#46;de">hpc-support<span>&#64;</span>tu-dresden<span>&#46;</span>de</a>
on how this unique system (large shared memory + NVMe storage) can speed up their computations, a
project‚Äôs quota can be increased or dedicated volumes of up to the full capacity can be set up.</p>
</section>
<section id="hints-for-usage">
<h2>Hints for Usage<a class="headerlink" href="#hints-for-usage" title="Permalink to this heading">#</a></h2>
<ul>
<li><p>Granularity should be a socket (28 cores)</p></li>
<li><p>Can be used for OpenMP applications with large memory demands</p></li>
<li><p>To use Open MPI it is necessary to export the following environment
variables, so that Open MPI uses shared-memory instead of InfiniBand
for message transport:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">OMPI_MCA_pml</span><span class="o">=</span><span class="n">ob1</span>
<span class="n">export</span> <span class="n">OMPI_MCA_mtl</span><span class="o">=^</span><span class="n">mxm</span>
</pre></div>
</div>
</li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">I_MPI_FABRICS=shm</span></code> so that Intel MPI doesn‚Äôt even consider
using InfiniBand devices itself, but only shared-memory instead</p></li>
</ul>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="known-issues-with-mpi">
<h1>Known Issues with MPI<a class="headerlink" href="#known-issues-with-mpi" title="Permalink to this heading">#</a></h1>
<p>This pages holds known issues observed with MPI and concrete MPI implementations.</p>
<section id="open-mpi">
<h2>Open MPI<a class="headerlink" href="#open-mpi" title="Permalink to this heading">#</a></h2>
<section id="performance-loss-with-mpi-io-module-ompio">
<h3>Performance Loss with MPI-IO-Module OMPIO<a class="headerlink" href="#performance-loss-with-mpi-io-module-ompio" title="Permalink to this heading">#</a></h3>
<p>Open MPI v4.1.x introduced a couple of major enhancements, e.g., the <code class="docutils literal notranslate"><span class="pre">OMPIO</span></code> module is now the
default module for MPI-IO on <strong>all</strong> filesystems incl. Lustre (cf.
<a class="reference external" href="https://raw.githubusercontent.com/open-mpi/ompi/v4.1.x/NEWS">NEWS file in Open MPI source code</a>).
Prior to this, <code class="docutils literal notranslate"><span class="pre">ROMIO</span></code> was the default MPI-IO module for Lustre.</p>
<p>Colleagues of ZIH have found that some MPI-IO access patterns suffer a significant performance loss
using <code class="docutils literal notranslate"><span class="pre">OMPIO</span></code> as MPI-IO module with <code class="docutils literal notranslate"><span class="pre">OpenMPI/4.1.x</span></code> modules on ZIH systems. At the moment, the root
cause is unclear and needs further investigation.</p>
<p><strong>A workaround</strong> for this performance loss is to use the ‚Äúold‚Äù, i.e., <code class="docutils literal notranslate"><span class="pre">ROMIO</span></code> MPI-IO-module. This
is achieved by setting the environment variable <code class="docutils literal notranslate"><span class="pre">OMPI_MCA_io</span></code> before executing the application as
follows</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">OMPI_MCA_io</span><span class="o">=</span>^ompio
<span class="gp">marie@login$ </span>srun<span class="w"> </span><span class="o">[</span>...<span class="o">]</span>
</pre></div>
</div>
<p>or setting the option as argument, in case you invoke <code class="docutils literal notranslate"><span class="pre">mpirun</span></code> directly</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>mpirun<span class="w"> </span>--mca<span class="w"> </span>io<span class="w"> </span>^ompio<span class="w"> </span><span class="o">[</span>...<span class="o">]</span>
</pre></div>
</div>
</section>
<section id="mpirun-on-clusters-alpha-and-power9">
<h3>Mpirun on clusters <code class="docutils literal notranslate"><span class="pre">alpha</span></code> and <code class="docutils literal notranslate"><span class="pre">power9</span></code><a class="headerlink" href="#mpirun-on-clusters-alpha-and-power9" title="Permalink to this heading">#</a></h3>
<!-- laut max m√∂glich dass es nach dem update von alpha und power9 das problem nicht mehr relevant ist.-->
<p>Using <code class="docutils literal notranslate"><span class="pre">mpirun</span></code> on clusters <code class="docutils literal notranslate"><span class="pre">alpha</span></code> and <code class="docutils literal notranslate"><span class="pre">power</span></code> leads to wrong resource distribution when more than
one node is involved. This yields a strange distribution like e.g. <code class="docutils literal notranslate"><span class="pre">SLURM_NTASKS_PER_NODE=15,1</span></code>
even though <code class="docutils literal notranslate"><span class="pre">--tasks-per-node=8</span></code> was specified. Unless you really know what you‚Äôre doing (e.g.
use rank pinning via perl script), avoid using mpirun.</p>
<p>Another issue arises when using the Intel toolchain: mpirun calls a different MPI and caused a
8-9x slowdown in the PALM app in comparison to using srun or the GCC-compiled version of the app
(which uses the correct MPI).</p>
</section>
<section id="r-parallel-library-on-multiple-nodes">
<h3>R Parallel Library on Multiple Nodes<a class="headerlink" href="#r-parallel-library-on-multiple-nodes" title="Permalink to this heading">#</a></h3>
<p>Using the R parallel library on MPI clusters has shown problems when using more than a few compute
nodes. The error messages indicate that there are buggy interactions of R/Rmpi/Open MPI and UCX.
Disabling UCX has solved these problems in our experiments.</p>
<p>We invoked the R script successfully with the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>mpirun<span class="w"> </span>-mca<span class="w"> </span>btl_openib_allow_ib<span class="w"> </span><span class="nb">true</span><span class="w"> </span>--mca<span class="w"> </span>pml<span class="w"> </span>^ucx<span class="w"> </span>--mca<span class="w"> </span>osc<span class="w"> </span>^ucx<span class="w"> </span>-np<span class="w"> </span><span class="m">1</span><span class="w"> </span>Rscript<span class="w"> </span>--vanilla<span class="w"> </span>the-script.R
</pre></div>
</div>
<p>where the arguments <code class="docutils literal notranslate"><span class="pre">-mca</span> <span class="pre">btl_openib_allow_ib</span> <span class="pre">true</span> <span class="pre">--mca</span> <span class="pre">pml</span> <span class="pre">^ucx</span> <span class="pre">--mca</span> <span class="pre">osc</span> <span class="pre">^ucx</span></code> disable usage of
UCX.</p>
</section>
<section id="mpi-function-mpi-win-allocate">
<h3>MPI Function <code class="docutils literal notranslate"><span class="pre">MPI_Win_allocate</span></code><a class="headerlink" href="#mpi-function-mpi-win-allocate" title="Permalink to this heading">#</a></h3>
<p>The function <code class="docutils literal notranslate"><span class="pre">MPI_Win_allocate</span></code> is a one-sided MPI call that allocates memory and returns a window
object for RDMA operations (ref. <a class="reference external" href="https://www.open-mpi.org/doc/v3.0/man3/MPI_Win_allocate.3.php">man page</a>).</p>
<blockquote>
<div><p>Using MPI_Win_allocate rather than separate MPI_Alloc_mem + MPI_Win_create may allow the MPI
implementation to optimize the memory allocation. (Using advanced MPI)</p>
</div></blockquote>
<p>It was observed for at least for the <code class="docutils literal notranslate"><span class="pre">OpenMPI/4.0.5</span></code> module that using <code class="docutils literal notranslate"><span class="pre">MPI_Win_Allocate</span></code> instead of
<code class="docutils literal notranslate"><span class="pre">MPI_Alloc_mem</span></code> in conjunction with <code class="docutils literal notranslate"><span class="pre">MPI_Win_create</span></code> leads to segmentation faults in the calling
application. To be precise, the segfaults occurred at partition <code class="docutils literal notranslate"><span class="pre">romeo</span></code> when about 200 GB per node
where allocated. In contrast, the segmentation faults vanished when the implementation was
refactored to call the <code class="docutils literal notranslate"><span class="pre">MPI_Alloc_mem</span></code> + <code class="docutils literal notranslate"><span class="pre">MPI_Win_create</span></code> functions.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="nvme-storage">
<h1>NVMe Storage<a class="headerlink" href="#nvme-storage" title="Permalink to this heading">#</a></h1>
<p>90 NVMe storage nodes, each with</p>
<ul class="simple">
<li><p>8x Intel NVMe Datacenter SSD P4610, 3.2 TB</p></li>
<li><p>3.2 GB/s (8x 3.2 =25.6 GB/s)</p></li>
<li><p>2 InfiniBand EDR links, Mellanox MT27800, ConnectX-5, PCIe x16, 100
Gbit/s</p></li>
<li><p>2 sockets Intel Xeon E5-2620 v4 (16 cores, 2.10GHz)</p></li>
<li><p>64 GB RAM</p></li>
</ul>
<p>NVMe cards can saturate the HCAs</p>
<p><img alt="Configuration" src="63_chat_with_docs/misc/nvme.png" />
{: align=center}</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="introduction-hpc-resources-and-jobs">
<h1>Introduction HPC Resources and Jobs<a class="headerlink" href="#introduction-hpc-resources-and-jobs" title="Permalink to this heading">#</a></h1>
<p>ZIH operates high performance computing (HPC) systems with about 100.000 cores, 900 GPUs, and a
flexible storage hierarchy with about 40 PB total capacity. The HPC system provides an optimal
research environment especially in the area of data analytics, artificial intelligence methods and
machine learning as well as for processing extremely large data sets. Moreover it is also a perfect
platform for highly scalable, data-intensive and compute-intensive applications and has extensive
capabilities for energy measurement and performance monitoring. Therefore provides ideal conditions
to achieve the ambitious research goals of the users and the ZIH.</p>
<p>The HPC system consists of <span class="xref myst">six clusters</span>
with their own
<span class="xref myst">Slurm</span> instances and cluster specific
login nodes. The clusters share a number of different
<span class="xref myst">filesystems</span> which enable users to switch between the
components.</p>
<section id="selection-of-suitable-hardware">
<h2>Selection of Suitable Hardware<a class="headerlink" href="#selection-of-suitable-hardware" title="Permalink to this heading">#</a></h2>
<p>The six clusters
<span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Barnard</span></code></span>,
<span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Alpha</span> <span class="pre">Centauri</span></code></span>,
<span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Capella</span></code></span>,
<span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Romeo</span></code></span>,
<span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Power9</span></code></span> and
<span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Julia</span></code></span>
differ, among others, in number of nodes, cores per node, and GPUs and memory. The particular
<span class="xref myst">characteristica</span> qualify them for different applications.</p>
<section id="which-cluster-do-i-need">
<h3>Which Cluster Do I Need?<a class="headerlink" href="#which-cluster-do-i-need" title="Permalink to this heading">#</a></h3>
<p>The majority of the basic tasks can be executed on the conventional nodes like on <code class="docutils literal notranslate"><span class="pre">Barnard</span></code>. When
log in to ZIH systems, you are placed on a login node where you can execute short tests and compile
moderate projects. The login nodes cannot be used for real experiments and computations. Long and
extensive computational work and experiments have to be encapsulated into so called <strong>jobs</strong> and
scheduled to the compute nodes.</p>
<p>There is no such thing as free lunch at ZIH systems. Since compute nodes are operated in multi-user
node by default, jobs of several users can run at the same time at the very same node sharing
resources, like memory (but not CPU). On the other hand, a higher throughput can be achieved by
smaller jobs. Thus, restrictions w.r.t. <span class="xref myst">memory</span> and
<span class="xref myst">runtime limits</span> have to be respected when submitting jobs.</p>
<p>The following questions may help to decide which cluster to use</p>
<ul class="simple">
<li><p>my application</p>
<ul>
<li><p>is <span class="xref myst">interactive or a batch job</span>?</p></li>
<li><p>requires <span class="xref myst">parallelism</span>?</p></li>
<li><p>requires <span class="xref myst">multithreading (SMT)</span>?</p></li>
</ul>
</li>
<li><p>Do I need <span class="xref myst">GPUs</span>?</p></li>
<li><p>How much <span class="xref myst">run time</span> do I need?</p></li>
<li><p>How many <span class="xref myst">cores</span> do I need?</p></li>
<li><p>How much <span class="xref myst">memory</span> do I need?</p></li>
<li><p>Which <span class="xref myst">software</span> is required?</p></li>
</ul>
<!-- cluster_overview_table -->
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>DNS</p></th>
<th class="head text-left"><p>Nodes</p></th>
<th class="head text-right"><p># Nodes</p></th>
<th class="head text-right"><p>Cores per Node</p></th>
<th class="head text-right"><p>Threads per Core</p></th>
<th class="head text-right"><p>Memory per Node [in MB]</p></th>
<th class="head text-right"><p>Memory per Core [in MB]</p></th>
<th class="head text-right"><p>GPUs per Node</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Capella</strong><br><em>2024</em></p></td>
<td><p>GPU</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&lt;node&gt;.barnard.hpc.tu-dresden.de</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">c[1-144]</span></code></p></td>
<td class="text-right"><p>144</p></td>
<td class="text-right"><p>64</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>768,000</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>4</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Barnard</strong><br><em>2023</em></p></td>
<td><p>CPU</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&lt;node&gt;.barnard.hpc.tu-dresden.de</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">n[1001-1630]</span></code></p></td>
<td class="text-right"><p>630</p></td>
<td class="text-right"><p>104</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>515,000</p></td>
<td class="text-right"><p>12,000</p></td>
<td class="text-right"><p>0</p></td>
</tr>
<tr class="row-even"><td><p><strong>Alpha</strong><br><em>2021</em></p></td>
<td><p>GPU</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&lt;node&gt;.alpha.hpc.tu-dresden.de</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">i[8001-8037]</span></code></p></td>
<td class="text-right"><p>37</p></td>
<td class="text-right"><p>48</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>990,000</p></td>
<td class="text-right"><p>10,312</p></td>
<td class="text-right"><p>8</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Romeo</strong><br><em>2020</em></p></td>
<td><p>CPU</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&lt;node&gt;.romeo.hpc.tu-dresden.de</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">i[7001-7186]</span></code></p></td>
<td class="text-right"><p>186</p></td>
<td class="text-right"><p>128</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>505,000</p></td>
<td class="text-right"><p>1,972</p></td>
<td class="text-right"><p>0</p></td>
</tr>
<tr class="row-even"><td><p><strong>Julia</strong><br><em>2021</em></p></td>
<td><p>single SMP system</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">julia.hpc.tu-dresden.de</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">julia</span></code></p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>896</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>48,390,000</p></td>
<td class="text-right"><p>54,006</p></td>
<td class="text-right"><p>-</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Power9</strong><br><em>2018</em></p></td>
<td><p>IBM Power/GPU system</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&lt;node&gt;.power9.hpc.tu-dresden.de</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">ml[1-29]</span></code></p></td>
<td class="text-right"><p>29</p></td>
<td class="text-right"><p>44</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-right"><p>254,000</p></td>
<td class="text-right"><p>1,443</p></td>
<td class="text-right"><p>6</p></td>
</tr>
<tr class="row-even"><td><p>{: summary=‚Äùcluster overview table‚Äù align=‚Äùbottom‚Äù}</p></td>
<td><p></p></td>
<td><p></p></td>
<td class="text-left"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
</tr>
</tbody>
</table>
</section>
<section id="interactive-or-batch-mode">
<h3>Interactive or Batch Mode<a class="headerlink" href="#interactive-or-batch-mode" title="Permalink to this heading">#</a></h3>
<p><strong>Interactive jobs:</strong> An interactive job is the best choice for testing and development. See
<span class="xref myst">interactive-jobs</span>.
Slurm can forward your X11 credentials to the first node (or even all) for a job
with the <code class="docutils literal notranslate"><span class="pre">--x11</span></code> option. To use an interactive job you have to specify <code class="docutils literal notranslate"><span class="pre">-X</span></code> flag for the ssh login.</p>
<p>However, using <code class="docutils literal notranslate"><span class="pre">srun</span></code> directly on the Shell will lead to blocking and launch an interactive job.
Apart from short test runs, it is recommended to encapsulate your experiments and computational
tasks into batch jobs and submit them to the batch system. For that, you can conveniently put the
parameters directly into the job file which you can submit using <code class="docutils literal notranslate"><span class="pre">sbatch</span> <span class="pre">[options]</span> <span class="pre">&lt;job</span> <span class="pre">file&gt;</span></code>.</p>
</section>
<section id="parallel-jobs">
<h3>Parallel Jobs<a class="headerlink" href="#parallel-jobs" title="Permalink to this heading">#</a></h3>
<p><strong>MPI jobs:</strong> For MPI jobs typically allocates one core per task. Several nodes could be allocated
if it is necessary. The batch system <span class="xref myst">Slurm</span> will automatically find suitable hardware.</p>
<p><strong>OpenMP jobs:</strong> SMP-parallel applications can only run <strong>within a node</strong>, so it is necessary to
include the <span class="xref myst">batch system</span> options <code class="docutils literal notranslate"><span class="pre">--nodes=1</span></code> and <code class="docutils literal notranslate"><span class="pre">--tasks=1</span></code>. Using <code class="docutils literal notranslate"><span class="pre">--cpus-per-task=N</span></code>
Slurm will start one task and you will have <code class="docutils literal notranslate"><span class="pre">N</span></code> CPUs. The maximum number of processors for an
SMP-parallel program is 896 on cluster <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Julia</span></code></span> (be aware that the application has to be
developed with that large number of threads in mind).</p>
<p>Partitions with GPUs are best suited for <strong>repetitive</strong> and <strong>highly-parallel</strong> computing tasks. If
you have a task with potential <span class="xref myst">data parallelism</span> most likely that
you need the GPUs.  Beyond video rendering, GPUs excel in tasks such as machine learning, financial
simulations and risk modeling. Use the cluster <code class="docutils literal notranslate"><span class="pre">power</span></code> only if you need GPUs! Otherwise
using the x86-based partitions most likely would be more beneficial.</p>
</section>
<section id="multithreading">
<h3>Multithreading<a class="headerlink" href="#multithreading" title="Permalink to this heading">#</a></h3>
<p>Some cluster/nodes have Simultaneous Multithreading (SMT) enabled, e.g <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">alpha</span></code></span> You
request for this additional threads using the Slurm option <code class="docutils literal notranslate"><span class="pre">--hint=multithread</span></code> or by setting the
environment variable <code class="docutils literal notranslate"><span class="pre">SLURM_HINT=multithread</span></code>. Besides the usage of the threads to speed up the
computations, the memory of the other threads is allocated implicitly, too, and you will always get
<code class="docutils literal notranslate"><span class="pre">Memory</span> <span class="pre">per</span> <span class="pre">Core</span></code>*<code class="docutils literal notranslate"><span class="pre">number</span> <span class="pre">of</span> <span class="pre">threads</span></code> as memory pledge.</p>
</section>
<section id="what-do-i-need-a-cpu-or-gpu">
<h3>What do I need, a CPU or GPU?<a class="headerlink" href="#what-do-i-need-a-cpu-or-gpu" title="Permalink to this heading">#</a></h3>
<p>If an application is designed to run on GPUs this is normally announced unmistakable since the
efforts of adapting an existing software to make use of a GPU can be overwhelming.
And even if the software was listed in
<a class="reference external" href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/gpu-applications-catalog.pdf">NVIDIA‚Äôs list of GPU-Accelerated Applications</a>
only certain parts of the computations may run on the GPU.</p>
<p>To answer the question: The easiest way is to compare a typical computation
on a normal node and on a GPU node. (Make sure to eliminate the influence of different
CPU types and different number of cores.) If the execution time with GPU is better
by a significant factor then this might be the obvious choice.</p>
<p>??? note ‚ÄúDifference in Architecture‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The main difference between CPU and GPU architecture is that a CPU is designed to handle a wide
range of tasks quickly, but are limited in the concurrency of tasks that can be running.
While GPUs can process data much faster than a CPU due to massive parallelism
(but the amount of data which
a single GPU&#39;s core can handle is small), GPUs are not as versatile as CPUs.
</pre></div>
</div>
</section>
<section id="how-much-time-do-i-need">
<h3>How much time do I need?<a class="headerlink" href="#how-much-time-do-i-need" title="Permalink to this heading">#</a></h3>
<section id="runtime-limits">
<h4>Runtime limits<a class="headerlink" href="#runtime-limits" title="Permalink to this heading">#</a></h4>
<p>!!! warning ‚ÄúRuntime limits on login nodes‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>There is a time limit of 600 seconds set for processes on login nodes. Each process running
longer than this time limit is automatically killed. The login nodes are shared ressources
between all users of ZIH system and thus, need to be available and cannot be used for productive
runs.

```
CPU time limit exceeded
```

Please submit extensive application runs to the compute nodes using the [batch system](slurm.md).
</pre></div>
</div>
<p>!!! note ‚ÄúRuntime limits are enforced.‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>A job is canceled as soon as it exceeds its requested limit. Currently, the maximum run time
limit is 7 days.
</pre></div>
</div>
<p>Shorter jobs come with multiple advantages:</p>
<ul class="simple">
<li><p>lower risk of loss of computing time,</p></li>
<li><p>shorter waiting time for scheduling,</p></li>
<li><p>higher job fluctuation; thus, jobs with high priorities may start faster.</p></li>
</ul>
<p>To bring down the percentage of long running jobs we restrict the number of cores with jobs longer
than 2 days to approximately 50% and with jobs longer than 24 to 75% of the total number of cores.
(These numbers are subject to change.) As best practice we advise a run time of about 8h.</p>
<p>!!! hint ‚ÄúPlease always try to make a good estimation of your needed time limit.‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>For this, you can use a command line like this to compare the requested timelimit with the
elapsed time for your completed jobs that started after a given date:

```console
marie@login$ sacct -X -S 2021-01-01 -E now --format=start,JobID,jobname,elapsed,timelimit -s COMPLETED
```
</pre></div>
</div>
<p>Instead of running one long job, you should split it up into a chain job. Even applications that are
not capable of checkpoint/restart can be adapted. Please refer to the section
<span class="xref myst">Checkpoint/Restart</span> for further documentation.</p>
</section>
</section>
<section id="how-many-cores-do-i-need">
<h3>How many cores do I need?<a class="headerlink" href="#how-many-cores-do-i-need" title="Permalink to this heading">#</a></h3>
<p>ZIH systems are focused on data-intensive computing. They are meant to be used for highly
parallelized code. Please take that into account when migrating sequential code from a local machine
to our HPC systems. To estimate your execution time when executing your previously sequential
program in parallel, you can use <a class="reference external" href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl‚Äôs law</a>.
Think in advance about the parallelization strategy for your project and how to effectively use HPC
resources.</p>
<p>However, this is highly depending on the used software, investigate if your application supports a
parallel execution.</p>
</section>
<section id="how-much-memory-do-i-need">
<h3>How much memory do I need?<a class="headerlink" href="#how-much-memory-do-i-need" title="Permalink to this heading">#</a></h3>
<section id="memory-limits">
<h4>Memory Limits<a class="headerlink" href="#memory-limits" title="Permalink to this heading">#</a></h4>
<p>!!! note ‚ÄúMemory limits are enforced.‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Jobs which exceed their per-node memory limit are killed automatically by the batch system.
</pre></div>
</div>
<p>Memory requirements for your job can be specified via the <code class="docutils literal notranslate"><span class="pre">sbatch/srun</span></code> parameters:</p>
<p><code class="docutils literal notranslate"><span class="pre">--mem-per-cpu=&lt;MB&gt;</span></code> or <code class="docutils literal notranslate"><span class="pre">--mem=&lt;MB&gt;</span></code> (which is ‚Äúmemory per node‚Äù). The <strong>default limit</strong> regardless
of the partition it runs on is quite low at <strong>300 MB</strong> per CPU. If you need more memory, you need
to request it.</p>
<p>ZIH systems comprise different sets of nodes with different amount of installed memory which affect
where your job may be run. To achieve the shortest possible waiting time for your jobs, you should
be aware of the limits shown in the
<span class="xref myst">Slurm resource limits table</span>.</p>
<p>Follow the page <span class="xref myst">Slurm</span> for comprehensive documentation using the batch system at
ZIH systems. There is also a page with extensive set of <span class="xref myst">Slurm examples</span>.</p>
</section>
</section>
<section id="which-software-is-required">
<h3>Which software is required?<a class="headerlink" href="#which-software-is-required" title="Permalink to this heading">#</a></h3>
<section id="available-software">
<h4>Available software<a class="headerlink" href="#available-software" title="Permalink to this heading">#</a></h4>
<p>Pre-installed software on our HPC systems is managed via <span class="xref myst">modules</span>.
However, there are many different variants of these modules available. Each cluster has its own set
of installed modules, depending on their purpose.</p>
<p>Specific modules can be found with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>spider<span class="w"> </span>&lt;software_name&gt;
</pre></div>
</div>
</section>
</section>
</section>
<section id="processing-of-data-for-input-and-output">
<h2>Processing of Data for Input and Output<a class="headerlink" href="#processing-of-data-for-input-and-output" title="Permalink to this heading">#</a></h2>
<p>Pre-processing and post-processing of the data is a crucial part for the majority of data-dependent
projects. The quality of this work influence on the computations. However, pre- and post-processing
in many cases can be done completely or partially on a local system and then transferred to ZIH
systems. Please use ZIH systems primarily for the computation-intensive tasks.</p>
</section>
<section id="exclusive-reservation-of-hardware">
<h2>Exclusive Reservation of Hardware<a class="headerlink" href="#exclusive-reservation-of-hardware" title="Permalink to this heading">#</a></h2>
<p>If you need for some special reasons, e.g., for benchmarking, a project or paper deadline, parts of
our machines exclusively, we offer the opportunity to request and reserve these parts for your
project.</p>
<p>Please send your request <strong>7 working days</strong> before the reservation should start (as that‚Äôs our
maximum time limit for jobs and it is therefore not guaranteed that resources are available on
shorter notice) with the following information
<a class="reference external" href="mailto:support&#37;&#52;&#48;example&#46;com?subject=Exclusive%20Hardware%20Reservation%20Request&amp;body=Dear%20HPC%20support%2C%0A%0AI%20have%20the%20following%20request%20for%20an%20exclusive%20hardware%20reservation%3A%0A%0AProject%3A%0AReservation%20owner%3A%0ACluster%3A%0ANumber%20of%20nodes%3A%0AStart%20time%3A%20YYYY-MM-DDTHH%3AMM%0AEnd%20time%3A%20YYYY-MM-DDTHH%3AMM%0AReason%3A">via e-mail to the HPC Support</a></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Project:</span></code> <em>Which project will be credited for the reservation?</em></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Reservation</span> <span class="pre">owner:</span></code> <em>Who should be able to run jobs on the
reservation? I.e., name of an individual user or a group of users
within the specified project.</em></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Cluster:</span></code> <em>Which cluster should be used?</em></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Number</span> <span class="pre">of</span> <span class="pre">nodes:</span></code> <em>How many nodes do you need? (The number of GPUs will be scaled accordingly if
you request on a GPU cluster.)</em></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Start</span> <span class="pre">time:</span></code> <em>Start time of the reservation in the form <code class="docutils literal notranslate"><span class="pre">YYYY-MM-DDTHH:MM</span></code>, e.g.,
2020-05-21T09:00</em></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">End</span> <span class="pre">time:</span></code> <em>End time of the reservation in the form <code class="docutils literal notranslate"><span class="pre">YYYY-MM-DDTHH:MM</span></code></em></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Reason:</span></code> <em>Reason for the reservation.</em></p></li>
</ul>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Please note that your project CPU hour budget will be credited for the reserved hardware even if
you don&#39;t use it.
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="gpu-cluster-power9">
<h1>GPU Cluster Power9<a class="headerlink" href="#gpu-cluster-power9" title="Permalink to this heading">#</a></h1>
<section id="id29">
<h2>Overview<a class="headerlink" href="#id29" title="Permalink to this heading">#</a></h2>
<p>The multi-GPU cluster <code class="docutils literal notranslate"><span class="pre">Power9</span></code> was installed in 2018. Until the end of 2023, it was available as
partition <code class="docutils literal notranslate"><span class="pre">power</span></code> within the now decommissioned <code class="docutils literal notranslate"><span class="pre">Taurus</span></code> system. With the decommission of <code class="docutils literal notranslate"><span class="pre">Taurus</span></code>,
<code class="docutils literal notranslate"><span class="pre">Power9</span></code> has been re-engineered and is now a homogeneous, standalone cluster with own
<span class="xref myst">Slurm batch system</span> and own login nodes.</p>
</section>
<section id="id30">
<h2>Hardware Resources<a class="headerlink" href="#id30" title="Permalink to this heading">#</a></h2>
<p>The hardware specification of the cluster <code class="docutils literal notranslate"><span class="pre">Power9</span></code> is documented on the page
<span class="xref myst">HPC Resources</span>.</p>
<p>We provide additional architectural information in the following.
The compute nodes of the cluster <code class="docutils literal notranslate"><span class="pre">Power9</span></code> are built on the base of
<a class="reference external" href="https://www.ibm.com/it-infrastructure/power/power9">Power9 architecture</a> from IBM.
The system was created for AI challenges, analytics and working with data-intensive workloads and
accelerated databases.</p>
<p>The main feature of the nodes is the ability to work with the
<a class="reference external" href="https://www.nvidia.com/en-gb/data-center/tesla-v100/">NVIDIA Tesla V100</a> GPU with <strong>NV-Link</strong>
support that allows a total bandwidth with up to 300 GB/s. Each node on the
cluster <code class="docutils literal notranslate"><span class="pre">Power9</span></code> has six Tesla V100 GPUs. You can find a detailed specification of the cluster in our
<span class="xref myst">Power9 documentation</span>.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The cluster `Power9` is based on the PPC64 architecture, which means that the software built
for x86_64 will not work on this cluster.
</pre></div>
</div>
</section>
<section id="id31">
<h2>Usage<a class="headerlink" href="#id31" title="Permalink to this heading">#</a></h2>
<section id="id32">
<h3>Containers<a class="headerlink" href="#id32" title="Permalink to this heading">#</a></h3>
<p>If you want to use containers on <code class="docutils literal notranslate"><span class="pre">Power9</span></code>, please refer to the page
<span class="xref myst">Singularity for Power9 Architecture</span>.</p>
</section>
<section id="power-ai">
<h3>Power AI<a class="headerlink" href="#power-ai" title="Permalink to this heading">#</a></h3>
<p>There are tools provided by IBM, that work on cluster <code class="docutils literal notranslate"><span class="pre">Power9</span></code> and are related to AI tasks.
For more information see our <span class="xref myst">Power AI documentation</span>.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="cpu-cluster-romeo">
<h1>CPU Cluster Romeo<a class="headerlink" href="#cpu-cluster-romeo" title="Permalink to this heading">#</a></h1>
<section id="id33">
<h2>Overview<a class="headerlink" href="#id33" title="Permalink to this heading">#</a></h2>
<p>The HPC system <code class="docutils literal notranslate"><span class="pre">Romeo</span></code> is a general purpose cluster based on AMD Rome CPUs. From 2019 till the end
of 2023, it was available as partition <code class="docutils literal notranslate"><span class="pre">romeo</span></code> within <code class="docutils literal notranslate"><span class="pre">Taurus</span></code>. With the decommission of <code class="docutils literal notranslate"><span class="pre">Taurus</span></code>,
<code class="docutils literal notranslate"><span class="pre">Romeo</span></code> has been re-engineered and is now a homogeneous, standalone cluster with own
<span class="xref myst">Slurm batch system</span> and own login nodes.</p>
</section>
<section id="id34">
<h2>Hardware Resources<a class="headerlink" href="#id34" title="Permalink to this heading">#</a></h2>
<p>The hardware specification is documented on the page
<span class="xref myst">HPC Resources</span>.</p>
</section>
<section id="id35">
<h2>Usage<a class="headerlink" href="#id35" title="Permalink to this heading">#</a></h2>
<p>There is a total of 128 physical cores in each node. SMT is also active, so in total, 256 logical
cores are available per node.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Multithreading is disabled per default in a job. To make use of it include the Slurm parameter
`--hint=multithread` in your job script or command line, or set the environment variable
`SLURM_HINT=multithread` before job submission.
</pre></div>
</div>
<p>Each node brings 512 GB of main memory, so you can request roughly 1972 MB per logical core (using
<code class="docutils literal notranslate"><span class="pre">--mem-per-cpu</span></code>). Note that you will always get the memory for the logical core sibling too, even if
you do not intend to use SMT.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you are running a job here with only ONE process (maybe multiple cores), please explicitly
set the option `-n 1`!
</pre></div>
</div>
<p>Be aware that software built with Intel compilers and <code class="docutils literal notranslate"><span class="pre">-x*</span></code> optimization flags will not run on those
AMD processors! That‚Äôs why most older modules built with Intel toolchains are not available on
partition <code class="docutils literal notranslate"><span class="pre">romeo</span></code>.</p>
<p>We provide the script <code class="docutils literal notranslate"><span class="pre">ml_arch_avail</span></code> that can be used to check if a certain module is available on
<code class="docutils literal notranslate"><span class="pre">rome</span></code> architecture.</p>
</section>
<section id="example-running-cp2k-on-rome">
<h2>Example, running CP2K on Rome<a class="headerlink" href="#example-running-cp2k-on-rome" title="Permalink to this heading">#</a></h2>
<p>First, check what CP2K modules are available in general:
<code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">spider</span> <span class="pre">CP2K</span></code> or <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">avail</span> <span class="pre">CP2K</span></code>.</p>
<p>You will see that there are several different CP2K versions avail, built with different toolchains.
Now let‚Äôs assume you have to decided you want to run CP2K version 6 at least, so to check if those
modules are built for rome, use:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ml_arch_avail<span class="w"> </span>CP2K/6
<span class="go">CP2K/6.1-foss-2019a: haswell, rome</span>
<span class="go">CP2K/6.1-foss-2019a-spglib: haswell, rome</span>
<span class="go">CP2K/6.1-intel-2018a: sandy, haswell</span>
<span class="go">CP2K/6.1-intel-2018a-spglib: haswell</span>
</pre></div>
</div>
<p>There you will see that only the modules built with toolchain <code class="docutils literal notranslate"><span class="pre">foss</span></code> are available on architecture
<code class="docutils literal notranslate"><span class="pre">rome</span></code>, not the ones built with <code class="docutils literal notranslate"><span class="pre">intel</span></code>. So you can load, e.g. <code class="docutils literal notranslate"><span class="pre">ml</span> <span class="pre">CP2K/6.1-foss-2019a</span></code>.</p>
<p>Then, when writing your batch script, you have to specify the partition <code class="docutils literal notranslate"><span class="pre">romeo</span></code>. Also, if e.g. you
wanted to use an entire ROME node (no SMT) and fill it with MPI ranks, it could look like this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --partition=romeo</span>
<span class="c1">#SBATCH --ntasks-per-node=128</span>
<span class="c1">#SBATCH --nodes=1</span>
<span class="c1">#SBATCH --mem-per-cpu=1972</span>

srun<span class="w"> </span>cp2k.popt<span class="w"> </span>input.inp
</pre></div>
</div>
</section>
<section id="using-the-intel-toolchain-on-rome">
<h2>Using the Intel Toolchain on Rome<a class="headerlink" href="#using-the-intel-toolchain-on-rome" title="Permalink to this heading">#</a></h2>
<p>Currently, we have only newer toolchains starting at <code class="docutils literal notranslate"><span class="pre">intel/2019b</span></code> installed for the Rome nodes.
Even though they have AMD CPUs, you can still use the Intel compilers on there and they don‚Äôt even
create bad-performing code. When using the Intel Math Kernel Library (MKL) up to version 2019,
though, you should set the following environment variable to make sure that AVX2 is used:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MKL_DEBUG_CPU_TYPE</span><span class="o">=</span><span class="m">5</span>
</pre></div>
</div>
<p>Without it, the MKL does a CPUID check and disables AVX2/FMA on non-Intel CPUs, leading to much
worse performance.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>In version 2020 and above, Intel has removed this environment variable and added separate Zen codepaths
to the library. However, they are still incomplete and do not cover every BLAS function. Also, the
Intel AVX2 codepaths still seem to provide somewhat better performance, so a new workaround
would be to overwrite the `mkl_serv_intel_cpu_true` symbol with a custom function:
</pre></div>
</div>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">mkl_serv_intel_cpu_true</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>and preloading this in a library:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>gcc<span class="w"> </span>-shared<span class="w"> </span>-fPIC<span class="w"> </span>-o<span class="w"> </span>libfakeintel.so<span class="w"> </span>fakeintel.c
<span class="gp">marie@login$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">LD_PRELOAD</span><span class="o">=</span>libfakeintel.so
</pre></div>
</div>
<p>As for compiler optimization flags, <code class="docutils literal notranslate"><span class="pre">-xHOST</span></code> does not seem to produce best-performing code in every
case on Rome. You might want to try <code class="docutils literal notranslate"><span class="pre">-mavx2</span> <span class="pre">-fma</span></code> instead.</p>
<section id="intel-mpi">
<h3>Intel MPI<a class="headerlink" href="#intel-mpi" title="Permalink to this heading">#</a></h3>
<p>We have seen only half the theoretical peak bandwidth via InfiniBand between two nodes, whereas
Open MPI got close to the peak bandwidth, so you might want to avoid using Intel MPI on partition
<code class="docutils literal notranslate"><span class="pre">rome</span></code> if your application heavily relies on MPI communication until this issue is resolved.</p>
</section>
</section>
<hr class="docutils" />
<section id="search-boost-2-0">
<h2>search:
boost: 2.0<a class="headerlink" href="#search-boost-2-0" title="Permalink to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="batch-system-slurm">
<h1>Batch System Slurm<a class="headerlink" href="#batch-system-slurm" title="Permalink to this heading">#</a></h1>
<p>ZIH uses the batch system Slurm for resource management and job scheduling. Compute nodes are not
accessed directly, but addressed through Slurm. You specify the needed resources
(cores, memory, GPU, time, ‚Ä¶) and Slurm will schedule your job for execution.</p>
<p>When logging in to ZIH systems, you are placed on a login node. There, you can manage your
<span class="xref myst">data life cycle</span>,
setup experiments, and
edit and prepare jobs. The login nodes are not suited for computational work! From the login nodes,
you can interact with the batch system, e.g., submit and monitor your jobs.</p>
<p>??? note ‚ÄúBatch System‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The batch system is the central organ of every HPC system users interact with its compute
resources. The batch system finds an adequate compute system (partition) for your compute jobs.
It organizes the queueing and messaging, if all resources are in use. If resources are available
for your job, the batch system allocates and connects to these resources, transfers runtime
environment, and starts the job.

A workflow could look like this:

```mermaid
sequenceDiagram
    user -&gt;&gt;+ login node: run programm
    login node -&gt;&gt; login node: kill after 5 min
    login node -&gt;&gt;- user: Killed!
    user -&gt;&gt; login node: salloc [...]
    login node -&gt;&gt; Slurm: Request resources
    Slurm -&gt;&gt; user: resources
    user -&gt;&gt;+ allocated resources: srun [options] [command]
    allocated resources -&gt;&gt; allocated resources: run command (on allocated nodes)
    allocated resources -&gt;&gt;- user: program finished
    user -&gt;&gt;+ allocated resources: srun [options] [further_command]
    allocated resources -&gt;&gt; allocated resources: run further command
    allocated resources -&gt;&gt;- user: program finished
    user -&gt;&gt;+ allocated resources: srun [options] [further_command]
    allocated resources -&gt;&gt; allocated resources: run further command
    Slurm -&gt;&gt; allocated resources: Job limit reached/exceeded
    allocated resources -&gt;&gt;- user: Job limit reached
```
</pre></div>
</div>
<p>??? note ‚ÄúBatch Job‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>At HPC systems, computational work and resource requirements are encapsulated into so-called
jobs. In order to allow the batch system an efficient job placement it needs these
specifications:

* requirements: number of nodes and cores, memory per core, additional resources (GPU)
* maximum run-time
* HPC project for accounting
* who gets an email on which occasion

Moreover, the [runtime environment](../software/overview.md) as well as the executable and
certain command-line arguments have to be specified to run the computational work.
</pre></div>
</div>
<p>This page provides a brief overview on</p>
<ul class="simple">
<li><p><span class="xref myst">Slurm options</span> to specify resource requirements,</p></li>
<li><p>how to submit <span class="xref myst">interactive</span> and <span class="xref myst">batch jobs</span>,</p></li>
<li><p>how to <span class="xref myst">write job files</span>,</p></li>
<li><p>how to <span class="xref myst">manage and control your jobs</span>.</p></li>
</ul>
<p>If you are are already familiar with Slurm, you might be more interested in our collection of
<span class="xref myst">job examples</span> and <span class="xref myst">job examples for GPU usage</span>.
There is also a ton of external resources regarding Slurm. We recommend these links for detailed
information:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://slurm.schedmd.com/">slurm.schedmd.com</a> provides the official documentation comprising
manual pages, tutorials, examples, etc.</p></li>
<li><p><a class="reference external" href="https://www.schedmd.com/slurmdocs/rosetta.html">Comparison with other batch systems</a></p></li>
</ul>
<section id="job-submission">
<h2>Job Submission<a class="headerlink" href="#job-submission" title="Permalink to this heading">#</a></h2>
<p>There are three basic Slurm commands for job submission and execution:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">srun</span></code>: Run a parallel application (and, if necessary, allocate resources first).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sbatch</span></code>: Submit a batch script to Slurm for later execution.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">salloc</span></code>: Obtain a Slurm job allocation (i.e., resources like CPUs, nodes and GPUs) for
interactive use. Release the allocation when finished.</p></li>
</ol>
<p>Executing a program with <code class="docutils literal notranslate"><span class="pre">srun</span></code> directly on the shell will be blocking and launch an
<span class="xref myst">interactive job</span>. Apart from short test runs, it is recommended to submit your
jobs to Slurm for later execution by using <span class="xref myst">batch jobs</span>. For that, you can conveniently
put the parameters in a <span class="xref myst">job file</span>, which you can submit using <code class="docutils literal notranslate"><span class="pre">sbatch</span> <span class="pre">[options]</span> <span class="pre">&lt;job</span> <span class="pre">file&gt;</span></code>.</p>
<p>After submission, your job gets a unique job ID, which is stored in the environment variable
<code class="docutils literal notranslate"><span class="pre">SLURM_JOB_ID</span></code> at job runtime. The command <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> outputs the job ID to stderr. Furthermore, you
can find it via <code class="docutils literal notranslate"><span class="pre">squeue</span> <span class="pre">--me</span></code>. The job ID allows you to
<span class="xref myst">manage and control</span> your jobs.</p>
<p>!!! warning ‚Äúsrun vs. mpirun‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>On ZIH systems, `srun` is used to run your parallel application. The use of `mpirun` is provenly
broken on clusters `Power9` and `Alpha` for jobs requiring more than one node. Especially when
using code from github projects, double-check its configuration by looking for a line like
&#39;submit command  mpirun -n $ranks ./app&#39; and replace it with &#39;srun ./app&#39;.

Otherwise, this may lead to wrong resource distribution and thus job failure, or tremendous
slowdowns of your application.
</pre></div>
</div>
</section>
<section id="options">
<h2>Options<a class="headerlink" href="#options" title="Permalink to this heading">#</a></h2>
<p>The following table contains the most important options for <code class="docutils literal notranslate"><span class="pre">srun</span></code>, <code class="docutils literal notranslate"><span class="pre">sbatch</span></code>, <code class="docutils literal notranslate"><span class="pre">salloc</span></code> to specify
resource requirements and control communication.</p>
<p>??? tip ‚ÄúOptions Table (see <code class="docutils literal notranslate"><span class="pre">man</span> <span class="pre">sbatch</span></code> for all available options)‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>| Slurm Option               | Description |
|:---------------------------|:------------|
| `-n, --ntasks=&lt;N&gt;`         | Total number of (MPI) tasks (default: 1) |
| `-N, --nodes=&lt;N&gt;`          | Number of compute nodes |
| `--ntasks-per-node=&lt;N&gt;`    | Number of tasks per allocated node to start (default: 1) |
| `-c, --cpus-per-task=&lt;N&gt;`  | Number of CPUs per task; needed for multithreaded (e.g. OpenMP) jobs; typically `N` should be equal to `OMP_NUM_THREADS` |
| `--mem-per-cpu=&lt;size&gt;`     | Memory need per allocated CPU in MB |
| `-t, --time=&lt;HH:MM:SS&gt;`    | Maximum runtime of the job |
| `--mail-user=&lt;your email&gt;` | Get updates about the status of the jobs |
| `--mail-type=ALL`          | For what type of events you want to get a mail; valid options: `ALL`, `BEGIN`, `END`, `FAIL`, `REQUEUE` |
| `-J, --job-name=&lt;name&gt;`    | Name of the job shown in the queue and in mails (cut after 24 chars) |
| `--no-requeue`             | Disable requeueing of the job in case of node failure (default: enabled) |
| `--exclusive`              | Exclusive usage of compute nodes; you will be charged for all CPUs/cores on the node |
| `-A, --account=&lt;project&gt;`  | Charge resources used by this job to the specified project |
| `-o, --output=&lt;filename&gt;`  | File to save all normal output (stdout) (default: `slurm-%j.out`) |
| `-e, --error=&lt;filename&gt;`   | File to save all error output (stderr)  (default: `slurm-%j.out`) |
| `-a, --array=&lt;arg&gt;`        | Submit an array job ([examples](slurm_examples.md#array-jobs)) |
| `-w &lt;node1&gt;,&lt;node2&gt;,...`   | Restrict job to run on specific nodes only |
| `-x &lt;node1&gt;,&lt;node2&gt;,...`   | Exclude specific nodes from job |
| `--switches=&lt;count&gt;[@max-time]` | Optimum switches and max time to wait for optimum |
| `--signal=&lt;sig_num&gt;[@sig_time]` | Send signal `sig_num` to job `sig_time` before time limit (see [Checkoint/Restart page](checkpoint_restart.md#signal-handler)) |
| `--test-only`              | Retrieve estimated start time of a job considering the job queue; does not actually submit the job nor run the application |
</pre></div>
</div>
<p>!!! note ‚ÄúOutput and Error Files‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>When redirecting stderr and stderr into a file using `--output=&lt;filename&gt;` and
`--stderr=&lt;filename&gt;`, make sure the target path is writeable on the
compute nodes, i.e., it may not point to a read-only mounted
[filesystem](../data_lifecycle/overview.md) like `/projects.`
</pre></div>
</div>
<p>!!! note ‚ÄúNo free lunch‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Runtime and memory limits are enforced. Please refer to the page
[Slurm resource limits](slurm_limits.md) for a detailed overview.
</pre></div>
</div>
<section id="host-list">
<h3>Host List<a class="headerlink" href="#host-list" title="Permalink to this heading">#</a></h3>
<p>If you want to place your job onto specific nodes, use <code class="docutils literal notranslate"><span class="pre">-w,</span> <span class="pre">--nodelist=&lt;host1,host2,..&gt;</span></code> with a
list of hosts that will work for you.</p>
</section>
<section id="number-of-switches">
<h3>Number of Switches<a class="headerlink" href="#number-of-switches" title="Permalink to this heading">#</a></h3>
<p>You can fine tune your job by specifying the number of switches desired for the job allocation and
optionally the maximum time to wait for that number of switches. The corresponding option to
<code class="docutils literal notranslate"><span class="pre">sbatch</span></code> is <code class="docutils literal notranslate"><span class="pre">--switches=&lt;count&gt;[&#64;max-time]</span></code>. The job remains pending until it either finds an
allocation with desired switch count or the time limit expires. Acceptable time formats include
‚Äúminutes‚Äù, ‚Äúminutes:seconds‚Äù, ‚Äúhours:minutes:seconds‚Äù, ‚Äúdays-hours‚Äù, ‚Äúdays-hours:minutes‚Äù and
‚Äúdays-hours:minutes:seconds‚Äù. For a detailed explanation, please refer to the
<a class="reference external" href="https://slurm.schedmd.com/sbatch.html#OPT_switches">sbatch online documentation</a>.</p>
</section>
</section>
<section id="interactive-jobs">
<h2>Interactive Jobs<a class="headerlink" href="#interactive-jobs" title="Permalink to this heading">#</a></h2>
<p>Interactive activities like editing, compiling, preparing experiments etc. are normally limited to
the login nodes. For longer interactive sessions, you can allocate resources on the compute node
with the command <code class="docutils literal notranslate"><span class="pre">salloc</span></code>. It takes the same options as <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> to specify the required resources.</p>
<p><code class="docutils literal notranslate"><span class="pre">salloc</span></code> returns a new shell on the node where you submitted the job. You need to use the command
<code class="docutils literal notranslate"><span class="pre">srun</span></code> in front of the following commands to have these commands executed on the allocated
resources. If you request for  more than one task, please be aware that <code class="docutils literal notranslate"><span class="pre">srun</span></code> will run the command
on each allocated task by default! To release the allocated resources, invoke the command <code class="docutils literal notranslate"><span class="pre">exit</span></code> or
<code class="docutils literal notranslate"><span class="pre">scancel</span> <span class="pre">&lt;jobid&gt;</span></code>.</p>
<p>!!! example ‚ÄúExample: Interactive allocation using <code class="docutils literal notranslate"><span class="pre">salloc</span></code>‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The following code listing depicts the allocation of two nodes with two tasks on each node with a
time limit of one hour on the cluster `Barnard` for interactive usage.

```console linenums=&quot;1&quot;
marie@login.barnard$ salloc --nodes=2 --ntasks-per-node=2 --time=01:00:00
salloc: Pending job allocation 1234567
salloc: job 1234567 queued and waiting for resources
salloc: job 1234567 has been allocated resources
salloc: Granted job allocation 1234567
salloc: Waiting for resource configuration
salloc: Nodes n[1184,1223] are ready for job
[...]
marie@login.barnard$ hostname
login1
marie@login.barnard$ srun hostname
n1184
n1184
n1223
n1223
marie@login.barnard$ exit # ending the resource allocation
```

After Slurm successfully allocated resources for the job, a new shell is created on the submit
host (cf. lines 9-10).

In order to use the allocated resources, you need to invoke your commands with `srun` (cf. lines
11 ff).
</pre></div>
</div>
<p>The command <code class="docutils literal notranslate"><span class="pre">srun</span></code> also creates an allocation, if it is running outside any <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> or <code class="docutils literal notranslate"><span class="pre">salloc</span></code>
allocation.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>srun<span class="w"> </span>--pty<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">4</span><span class="w"> </span>--time<span class="o">=</span><span class="m">1</span>:00:00<span class="w"> </span>--mem-per-cpu<span class="o">=</span><span class="m">1700</span><span class="w"> </span>bash<span class="w"> </span>-l
<span class="go">srun: job 13598400 queued and waiting for resources</span>
<span class="go">srun: job 13598400 has been allocated resources</span>
<span class="gp">marie@compute$ # </span>Now,<span class="w"> </span>you<span class="w"> </span>can<span class="w"> </span>start<span class="w"> </span>interactive<span class="w"> </span>work<span class="w"> </span>with<span class="w"> </span>e.g.<span class="w"> </span><span class="m">4</span><span class="w"> </span>cores
</pre></div>
</div>
<p>Since Slurm 20.11 <code class="docutils literal notranslate"><span class="pre">--exclusive</span></code> is the default for <code class="docutils literal notranslate"><span class="pre">srun</span></code> as a step, that means you have to
use <code class="docutils literal notranslate"><span class="pre">--overlap</span></code>, if you want to run <code class="docutils literal notranslate"><span class="pre">srun</span></code> within a <code class="docutils literal notranslate"><span class="pre">srun</span></code> allocation.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>srun<span class="w"> </span>--pty<span class="w"> </span>bash<span class="w"> </span>-l
<span class="go">srun: job 27410688 queued and waiting for resources</span>
<span class="go">srun: job 27410688 has been allocated resources</span>
<span class="gp">marie@compute$ </span>srun<span class="w"> </span>--overlap<span class="w"> </span>hostname
<span class="go">taurusi6604.taurus.hrsk.tu-dresden.de</span>
</pre></div>
</div>
<p>!!! note ‚ÄúUsing <code class="docutils literal notranslate"><span class="pre">module</span></code> commands in interactive mode‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The [module commands](../software/modules.md) are made available by sourcing the files
`/etc/profile` and `~/.bashrc`. This is done automatically by passing the parameter `-l` to your
shell, as shown in the example above. If you missed adding `-l` at submitting the interactive
session, no worry, you can source this files also later on manually (`source /etc/profile`).
</pre></div>
</div>
<section id="interactive-x11-gui-jobs">
<h3>Interactive X11/GUI Jobs<a class="headerlink" href="#interactive-x11-gui-jobs" title="Permalink to this heading">#</a></h3>
<p>Slurm will forward your X11 credentials to the first (or even all) node for a job with the
(undocumented) <code class="docutils literal notranslate"><span class="pre">--x11</span></code> option.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>srun<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span><span class="w"> </span>--pty<span class="w"> </span>--x11<span class="o">=</span>first<span class="w"> </span>xeyes
</pre></div>
</div>
<p>!!! hint ‚ÄúX11 error‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you are getting the error:

```Bash
srun: error: x11: unable to connect node taurusiXXXX
```

that probably means you still have an old host key for the target node in your
`~.ssh/known_hosts` file (e.g. from pre-SCS5). This can be solved either by removing the entry
from your `known_hosts` or by simply deleting the `known_hosts` file altogether if you don&#39;t have
important other entries in it.
</pre></div>
</div>
</section>
</section>
<section id="batch-jobs">
<h2>Batch Jobs<a class="headerlink" href="#batch-jobs" title="Permalink to this heading">#</a></h2>
<p>Working interactively using <code class="docutils literal notranslate"><span class="pre">srun</span></code> and <code class="docutils literal notranslate"><span class="pre">salloc</span></code> is a good starting point for testing and compiling.
But, as soon as you leave the testing stage, we highly recommend to use batch jobs.
Batch jobs are encapsulated within <span class="xref myst">job files</span> and submitted to the batch system using
<code class="docutils literal notranslate"><span class="pre">sbatch</span></code> for later execution. A job file is basically a script holding the resource requirements,
environment settings and the commands for executing the application. Using batch jobs and job files
has multiple advantages*:</p>
<ul class="simple">
<li><p>You can reproduce your experiments and work, because all steps are saved in a file.</p></li>
<li><p>You can easily share your settings and experimental setup with colleagues.</p></li>
</ul>
<p>*) If job files are version controlled or environment <code class="docutils literal notranslate"><span class="pre">env</span></code> is saved along with Slurm output.</p>
<p>!!! hint ‚ÄúSyntax: Submitting a batch job‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ sbatch [options] &lt;job_file&gt;
```
</pre></div>
</div>
<section id="job-files">
<h3>Job Files<a class="headerlink" href="#job-files" title="Permalink to this heading">#</a></h3>
<p>Job files have to be written with the following structure.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1"># ^Batch script starts with shebang line</span>

<span class="c1">#SBATCH --ntasks=24                   # #SBATCH lines request resources and</span>
<span class="c1">#SBATCH --time=01:00:00               # specify Slurm options</span>
<span class="c1">#SBATCH --account=&lt;KTR&gt;               #</span>
<span class="c1">#SBATCH --job-name=fancyExp           # All #SBATCH lines have to follow uninterrupted</span>
<span class="c1">#SBATCH --output=simulation-%j.out    # after the shebang line</span>
<span class="c1">#SBATCH --error=simulation-%j.err     # Comments start with # and do not count as interruptions</span>

module<span class="w"> </span>purge<span class="w">                          </span><span class="c1"># Set up environment, e.g., clean/switch modules environment</span>
module<span class="w"> </span>load<span class="w"> </span>&lt;module1<span class="w"> </span>module2&gt;<span class="w">         </span><span class="c1"># and load necessary modules</span>

srun<span class="w"> </span>./application<span class="w"> </span><span class="o">[</span>options<span class="o">]</span><span class="w">          </span><span class="c1"># Execute parallel application with srun</span>
</pre></div>
</div>
<p>The following two examples show the basic resource specifications for a pure OpenMP application and
a pure MPI application, respectively. Within the section <span class="xref myst">Job Examples</span>, we
provide a comprehensive collection of job examples.</p>
<p>??? example ‚ÄúJob file OpenMP‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash

#SBATCH --nodes=1
#SBATCH --tasks-per-node=1
#SBATCH --cpus-per-task=64
#SBATCH --time=01:00:00
#SBATCH --account=&lt;account&gt;

module purge
module load &lt;modules&gt;

export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
srun ./path/to/openmp_application
```

* Submisson: `marie@login$ sbatch batch_script.sh`
* Run with fewer CPUs: `marie@login$ sbatch --cpus-per-task=14 batch_script.sh`
</pre></div>
</div>
<p>??? example ‚ÄúJob file MPI‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash

#SBATCH --ntasks=64
#SBATCH --time=01:00:00
#SBATCH --account=&lt;account&gt;

module purge
module load &lt;modules&gt;

srun ./path/to/mpi_application
```

* Submisson: `marie@login$ sbatch batch_script.sh`
* Run with fewer MPI tasks: `marie@login$ sbatch --ntasks=14 batch_script.sh`
</pre></div>
</div>
</section>
</section>
<section id="using-simultaneous-multithreading-smt">
<h2>Using Simultaneous Multithreading (SMT)<a class="headerlink" href="#using-simultaneous-multithreading-smt" title="Permalink to this heading">#</a></h2>
<p>Most modern architectures offer simultaneous multithreading (SMT), where physical cores of a CPU are
split into virtual cores (aka. threads). This technique allows to run two instruction streams per
physical core in parallel.</p>
<p>At ZIH systems, SMT is available at the partitions <code class="docutils literal notranslate"><span class="pre">rome</span></code> and <code class="docutils literal notranslate"><span class="pre">alpha</span></code>. It is deactivated by
default, because the environment variable <code class="docutils literal notranslate"><span class="pre">SLURM_HINT</span></code> is set to <code class="docutils literal notranslate"><span class="pre">nomultithread</span></code>.
If you wish to make use of the SMT cores, you need to explicitly activate it.
In principle, there are two different ways:</p>
<ol class="arabic simple">
<li><p>Change the value of the environment variable via <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">SLURM_HINT=multithread</span></code> in your current
shell and submit your job file, or invoke your <code class="docutils literal notranslate"><span class="pre">srun</span></code> or <code class="docutils literal notranslate"><span class="pre">salloc</span></code> command line.</p></li>
<li><p>Clear the environment variable via <code class="docutils literal notranslate"><span class="pre">unset</span> <span class="pre">SLURM_HINT</span></code> and provide the option <code class="docutils literal notranslate"><span class="pre">--hint=multithread</span></code>
to <code class="docutils literal notranslate"><span class="pre">sbatch</span></code>, <code class="docutils literal notranslate"><span class="pre">srun</span></code> or <code class="docutils literal notranslate"><span class="pre">salloc</span></code> command line.</p></li>
</ol>
<p>??? warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> If you like to activate SMT via the directive
 ```
 #SBATCH --hint=multithread
 ```
 within your job file, you also have to clear the environment variable `SLURM_HINT` before
 submitting the job file. Otherwise, the environment varibale `SLURM_HINT` takes precedence.
</pre></div>
</div>
</section>
<section id="heterogeneous-jobs">
<h2>Heterogeneous Jobs<a class="headerlink" href="#heterogeneous-jobs" title="Permalink to this heading">#</a></h2>
<p>A heterogeneous job consists of several job components, all of which can have individual job
options. In particular, different components can use resources from different Slurm partitions.
One example for this setting is an MPI application consisting of a master process with a huge memory
footprint and worker processes requiring GPU support.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">salloc</span></code>, <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> and <code class="docutils literal notranslate"><span class="pre">srun</span></code> commands can all be used to submit heterogeneous jobs. Resource
specifications for each component of the heterogeneous job should be separated with ‚Äú:‚Äù character.
Running a job step on a specific component is supported by the option <code class="docutils literal notranslate"><span class="pre">--het-group</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>salloc<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">4</span><span class="w"> </span>--partition<span class="w"> </span>&lt;partition&gt;<span class="w"> </span>--mem<span class="o">=</span>200G<span class="w"> </span>:<span class="w"> </span><span class="se">\</span>
<span class="w">                    </span>--ntasks<span class="o">=</span><span class="m">8</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">1</span><span class="w"> </span>--gres<span class="o">=</span>gpu:8<span class="w"> </span>--mem<span class="o">=</span>80G<span class="w"> </span>--partition<span class="w"> </span>&lt;partition&gt;
<span class="go">[...]</span>
<span class="gp">marie@login$ </span>srun<span class="w"> </span>./my_application<span class="w"> </span>&lt;args<span class="w"> </span><span class="k">for</span><span class="w"> </span>master<span class="w"> </span>tasks&gt;<span class="w"> </span>:<span class="w"> </span>./my_application<span class="w"> </span>&lt;args<span class="w"> </span><span class="k">for</span><span class="w"> </span>worker<span class="w"> </span>tasks&gt;
</pre></div>
</div>
<p>Heterogeneous jobs can also be defined in job files. There, it is required to separate multiple
components by a line containing the directive <code class="docutils literal notranslate"><span class="pre">#SBATCH</span> <span class="pre">hetjob</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>

<span class="c1">#SBATCH --ntasks=1</span>
<span class="c1">#SBATCH --cpus-per-task=4</span>
<span class="c1">#SBATCH --partition=&lt;partition&gt;</span>
<span class="c1">#SBATCH --mem=200G</span>
<span class="c1">#SBATCH hetjob # required to separate groups</span>
<span class="c1">#SBATCH --ntasks=8</span>
<span class="c1">#SBATCH --cpus-per-task=1</span>
<span class="c1">#SBATCH --gres=gpu:8</span>
<span class="c1">#SBATCH --mem=80G</span>
<span class="c1">#SBATCH --partition=&lt;partition&gt;</span>

srun<span class="w"> </span>./my_application<span class="w"> </span>&lt;args<span class="w"> </span><span class="k">for</span><span class="w"> </span>master<span class="w"> </span>tasks&gt;<span class="w"> </span>:<span class="w"> </span>./my_application<span class="w"> </span>&lt;args<span class="w"> </span><span class="k">for</span><span class="w"> </span>worker<span class="w"> </span>tasks&gt;

<span class="c1"># or as an alternative</span>
srun<span class="w"> </span>./my_application<span class="w"> </span>&lt;args<span class="w"> </span><span class="k">for</span><span class="w"> </span>master<span class="w"> </span>tasks&gt;<span class="w"> </span><span class="p">&amp;</span>
srun<span class="w"> </span>--het-group<span class="o">=</span><span class="m">1</span><span class="w"> </span>./my_application<span class="w"> </span>&lt;args<span class="w"> </span><span class="k">for</span><span class="w"> </span>worker<span class="w"> </span>tasks&gt;<span class="w"> </span><span class="p">&amp;</span>
<span class="nb">wait</span>
</pre></div>
</div>
<section id="limitations">
<h3>Limitations<a class="headerlink" href="#limitations" title="Permalink to this heading">#</a></h3>
<p>Due to the way scheduling algorithm works it is required that each component has to be allocated on
a different node. Furthermore, job arrays of heterogeneous jobs are not supported.</p>
</section>
</section>
<section id="manage-and-control-jobs">
<h2>Manage and Control Jobs<a class="headerlink" href="#manage-and-control-jobs" title="Permalink to this heading">#</a></h2>
<section id="job-and-slurm-monitoring">
<h3>Job and Slurm Monitoring<a class="headerlink" href="#job-and-slurm-monitoring" title="Permalink to this heading">#</a></h3>
<p>On the command line, use <code class="docutils literal notranslate"><span class="pre">squeue</span></code> to watch the scheduling queue.</p>
<p>!!! tip ‚ÄúShow your jobs‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Invoke `squeue --me` to list only your jobs.
</pre></div>
</div>
<p>In its last column, the <code class="docutils literal notranslate"><span class="pre">squeue</span></code> command will also tell why a job is not running.
Possible reasons and their detailed descriptions are listed in the following table.
More information about job parameters can be obtained with <code class="docutils literal notranslate"><span class="pre">scontrol</span> <span class="pre">-d</span> <span class="pre">show</span> <span class="pre">job</span> <span class="pre">&lt;jobid&gt;</span></code>.</p>
<p>??? tip ‚ÄúReason Table‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>| Reason             | Long Description  |
|:-------------------|:------------------|
| `Dependency`         | This job is waiting for a dependent job to complete. |
| `None`               | No reason is set for this job. |
| `PartitionDown`      | The partition required by this job is in a down state. |
| `PartitionNodeLimit` | The number of nodes required by this job is outside of its partitions current limits. Can also indicate that required nodes are down or drained. |
| `PartitionTimeLimit` | The jobs time limit exceeds its partitions current time limit. |
| `Priority`           | One or higher priority jobs exist for this partition. |
| `Resources`          | The job is waiting for resources to become available. |
| `NodeDown`           | A node required by the job is down. |
| `BadConstraints`     | The jobs constraints can not be satisfied. |
| `SystemFailure`      | Failure of the Slurm system, a filesystem, the network, etc. |
| `JobLaunchFailure`   | The job could not be launched. This may be due to a filesystem problem, invalid program name, etc. |
| `NonZeroExitCode`    | The job terminated with a non-zero exit code. |
| `TimeLimit`          | The job exhausted its time limit. |
| `InactiveLimit`      | The job reached the system inactive limit. |
</pre></div>
</div>
<p>For detailed information on why your submitted job has not started yet, you can use the command</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>whypending<span class="w"> </span>&lt;jobid&gt;
</pre></div>
</div>
</section>
<section id="editing-jobs">
<h3>Editing Jobs<a class="headerlink" href="#editing-jobs" title="Permalink to this heading">#</a></h3>
<p>Jobs that have not yet started can be altered. By using <code class="docutils literal notranslate"><span class="pre">scontrol</span> <span class="pre">update</span> <span class="pre">timelimit=4:00:00</span> <span class="pre">jobid=&lt;jobid&gt;</span></code>, it is for example possible to modify the maximum runtime. <code class="docutils literal notranslate"><span class="pre">scontrol</span></code> understands
many different options, please take a look at the
<a class="reference external" href="https://slurm.schedmd.com/scontrol.html">scontrol documentation</a> for more details.</p>
</section>
<section id="canceling-jobs">
<h3>Canceling Jobs<a class="headerlink" href="#canceling-jobs" title="Permalink to this heading">#</a></h3>
<p>The command <code class="docutils literal notranslate"><span class="pre">scancel</span> <span class="pre">&lt;jobid&gt;</span></code> kills a single job and removes it from the queue. By using <code class="docutils literal notranslate"><span class="pre">scancel</span> <span class="pre">-u</span> <span class="pre">&lt;username&gt;</span></code>, you can send a canceling signal to all of your jobs at once.</p>
</section>
<section id="evaluating-jobs">
<h3>Evaluating Jobs<a class="headerlink" href="#evaluating-jobs" title="Permalink to this heading">#</a></h3>
<p>The Slurm command <code class="docutils literal notranslate"><span class="pre">sacct</span></code> provides job statistics like memory usage, CPU time, energy usage etc.
as table-formatted output on the command line.</p>
<p>The job monitor <span class="xref myst">PIKA</span> provides web-based graphical performance statistics
at no extra cost.</p>
<p>!!! hint ‚ÄúLearn from old jobs‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>We highly encourage you to inspect your previous jobs in order to better
estimate the requirements, e.g., runtime, for future jobs.
With PIKA, it is e.g. easy to check whether a job is hanging, idling,
or making good use of the resources.
</pre></div>
</div>
<p>??? tip ‚ÄúUsing sacct (see also <code class="docutils literal notranslate"><span class="pre">man</span> <span class="pre">sacct</span></code>)‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>`sacct` outputs the following fields by default.

```console
# show all own jobs contained in the accounting database
marie@login$ sacct
    JobID    JobName  Partition    Account  AllocCPUS      State ExitCode
------------ ---------- ---------- ---------- ---------- ---------- --------
[...]
```

We&#39;d like to point your attention to the following options to gain insight in your jobs.

??? example &quot;Show specific job&quot;

    ```console
    marie@login$ sacct --jobs=&lt;JOBID&gt;
    ```

??? example &quot;Show all fields for a specific job&quot;

    ```console
    marie@login$ sacct --jobs=&lt;JOBID&gt; --format=All
    ```

??? example &quot;Show specific fields&quot;

    ```console
    marie@login$ sacct --jobs=&lt;JOBID&gt; --format=JobName,MaxRSS,MaxVMSize,CPUTime,ConsumedEnergy
    ```

The manual page (`man sacct`) and the [sacct online reference](https://slurm.schedmd.com/sacct.html)
provide a comprehensive documentation regarding available fields and formats.

!!! hint &quot;Time span&quot;

    By default, `sacct` only shows data of the last day. If you want to look further into the past
    without specifying an explicit job id, you need to provide a start date via the option
    `--starttime` (or short: `-S`). A certain end date is also possible via `--endtime` (or `-E`).

??? example &quot;Show all jobs since the beginning of year 2021&quot;

    ```console
    marie@login$ sacct --starttime 2021-01-01 [--endtime now]
    ```
</pre></div>
</div>
</section>
</section>
<section id="jobs-at-reservations">
<h2>Jobs at Reservations<a class="headerlink" href="#jobs-at-reservations" title="Permalink to this heading">#</a></h2>
<p>Within a reservation, you have privileged access to HPC resources.
How to ask for a reservation is described in the section
<span class="xref myst">reservations</span>.
After we agreed with your requirements, we will send you an e-mail with your reservation name. Then,
you could see more information about your reservation with the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>scontrol<span class="w"> </span>show<span class="w"> </span><span class="nv">res</span><span class="o">=</span>&lt;reservation<span class="w"> </span>name&gt;
<span class="gp"># </span>e.g.<span class="w"> </span>scontrol<span class="w"> </span>show<span class="w"> </span><span class="nv">res</span><span class="o">=</span>hpcsupport_123
</pre></div>
</div>
<p>If you want to use your reservation, you have to add the parameter
<code class="docutils literal notranslate"><span class="pre">--reservation=&lt;reservation</span> <span class="pre">name&gt;</span></code> either in your job script or to your <code class="docutils literal notranslate"><span class="pre">srun</span></code> or <code class="docutils literal notranslate"><span class="pre">salloc</span></code> command.</p>
</section>
<section id="node-local-storage-in-jobs">
<h2>Node-Local Storage in Jobs<a class="headerlink" href="#node-local-storage-in-jobs" title="Permalink to this heading">#</a></h2>
<p>For some workloads and applications, it is valuable to use node-local storage in order to reduce or
even completely omit usage of the <span class="xref myst">parallel filesystems</span>.</p>
<p>The availability and the capacity of local storage differ between the clusters, as depicted in the
following table.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Cluster</p></th>
<th class="head"><p>Number of  Nodes</p></th>
<th class="head"><p>Local Storage</p></th>
<th class="head"><p>Mountpoint</p></th>
<th class="head"><p>Request</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Alpha</span> <span class="pre">Centauri</span></code></span></p></td>
<td><p>All compute nodes</p></td>
<td><p>3.5 TB on NVMe device</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/tmp</span></code></p></td>
<td><p>Always present, no action needed</p></td>
</tr>
<tr class="row-odd"><td><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Barnard</span></code></span></p></td>
<td><p>12 nodes</p></td>
<td><p>1.8 TB on NVMe device</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/tmp</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">--constraint=local_disk</span></code> option to <code class="docutils literal notranslate"><span class="pre">sbatch</span></code>, <code class="docutils literal notranslate"><span class="pre">salloc</span></code>, and <code class="docutils literal notranslate"><span class="pre">srun</span></code></p></td>
</tr>
<tr class="row-even"><td><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Capella</span></code></span></p></td>
<td><p>All compute nodes</p></td>
<td><p>800 GB</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/tmp</span></code></p></td>
<td><p>Always present, no action needed</p></td>
</tr>
<tr class="row-odd"><td><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Romeo</span></code></span></p></td>
<td><p>All compute nodes</p></td>
<td><p>200 GB</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/tmp</span></code></p></td>
<td><p>Always present, no action needed</p></td>
</tr>
</tbody>
</table>
<p>!!! hint ‚ÄúClusters <code class="docutils literal notranslate"><span class="pre">Power9</span></code> and <code class="docutils literal notranslate"><span class="pre">Julia</span></code>‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Node-local storage is not available on the two clusters [`Power9`](hardware_overview.md#power9)
and [`Julia`](julia.md).
</pre></div>
</div>
<p>!!! hint Request nodes with local storage on <code class="docutils literal notranslate"><span class="pre">Barnard</span></code></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Note that most nodes on `Barnard` don&#39;t have a local disk and space in `/tmp` is **very**
limited. If you need a local disk request this with the
[Slurm feature](slurm.md#node-local-storage-in-jobs) `--constraint=local_disk` to
`sbatch`, `salloc`, and `srun`.
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="job-examples">
<h1>Job Examples<a class="headerlink" href="#job-examples" title="Permalink to this heading">#</a></h1>
<section id="id36">
<h2>Parallel Jobs<a class="headerlink" href="#id36" title="Permalink to this heading">#</a></h2>
<p>For submitting parallel jobs, a few rules have to be understood and followed. In general, they
depend on the type of parallelization and architecture.</p>
<section id="openmp-jobs">
<h3>OpenMP Jobs<a class="headerlink" href="#openmp-jobs" title="Permalink to this heading">#</a></h3>
<p>An SMP-parallel job can only run within a node, so it is necessary to include the options <code class="docutils literal notranslate"><span class="pre">--node=1</span></code>
and <code class="docutils literal notranslate"><span class="pre">--ntasks=1</span></code>. The maximum number of processors for an SMP-parallel program is 896 on the cluster
<span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Julia</span></code></span> as described in the
<span class="xref myst">section on memory limits</span>. Using the option
<code class="docutils literal notranslate"><span class="pre">--cpus-per-task=&lt;N&gt;</span></code> Slurm will start one task and you will have <code class="docutils literal notranslate"><span class="pre">N</span></code> CPUs available for your job.
An example job file would look like:</p>
<p>!!! example ‚ÄúJob file for OpenMP application‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```Bash
#!/bin/bash
#SBATCH --nodes=1
#SBATCH --tasks-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --time=08:00:00
#SBATCH --mail-type=start,end
#SBATCH --mail-user=&lt;your.email&gt;@tu-dresden.de

export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
./path/to/binary
```
</pre></div>
</div>
</section>
<section id="mpi-jobs">
<h3>MPI Jobs<a class="headerlink" href="#mpi-jobs" title="Permalink to this heading">#</a></h3>
<p>For MPI-parallel jobs one typically allocates one core per task that has to be started.</p>
<p>!!! warning ‚ÄúMPI libraries‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>There are different MPI libraries on ZIH systems for the different micro architectures. Thus,
you have to compile the binaries specifically for the target architecture of the cluster of
interest. Please refer to the sections [building software](../software/building_software.md) and
[module environments](../software/modules.md#module-environments) for detailed information.
</pre></div>
</div>
<p>!!! example ‚ÄúJob file for MPI application‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```Bash
#!/bin/bash
#SBATCH --ntasks=864
#SBATCH --time=08:00:00
#SBATCH --job-name=Science1
#SBATCH --mail-type=end
#SBATCH --mail-user=&lt;your.email&gt;@tu-dresden.de

srun ./path/to/binary
```
</pre></div>
</div>
</section>
<section id="multiple-programs-running-simultaneously-in-a-job">
<h3>Multiple Programs Running Simultaneously in a Job<a class="headerlink" href="#multiple-programs-running-simultaneously-in-a-job" title="Permalink to this heading">#</a></h3>
<p>In this short example, our goal is to run four instances of a program concurrently in a <strong>single</strong>
batch script. Of course, we could also start a batch script four times with <code class="docutils literal notranslate"><span class="pre">sbatch</span></code>, but this is
not what we want to do here. However, you can also find an example about
<span class="xref myst">how to run GPU programs simultaneously in a single job</span></p>
<p>!!! example ‚Äù ‚Äú</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```Bash
#!/bin/bash
#SBATCH --ntasks=4
#SBATCH --cpus-per-task=1
#SBATCH --time=01:00:00
#SBATCH --job-name=PseudoParallelJobs
#SBATCH --mail-type=end
#SBATCH --mail-user=&lt;your.email&gt;@tu-dresden.de

# The following sleep command was reported to fix warnings/errors with srun by users (feel free to uncomment).
#sleep 5
srun --exclusive --ntasks=1 ./path/to/binary &amp;

#sleep 5
srun --exclusive --ntasks=1 ./path/to/binary &amp;

#sleep 5
srun --exclusive --ntasks=1 ./path/to/binary &amp;

#sleep 5
srun --exclusive --ntasks=1 ./path/to/binary &amp;

echo &quot;Waiting for parallel job steps to complete...&quot;
wait
echo &quot;All parallel job steps completed!&quot;
```
</pre></div>
</div>
</section>
<section id="request-resources-for-parallel-make">
<h3>Request Resources for Parallel Make<a class="headerlink" href="#request-resources-for-parallel-make" title="Permalink to this heading">#</a></h3>
<p>From time to time, you want to build and compile software and applications on a compute node.
But, do you need to request tasks or CPUs from Slurm in order to provide resources for the parallel
<code class="docutils literal notranslate"><span class="pre">make</span></code> command?  The answer is ‚ÄúCPUs‚Äù.</p>
<p>!!! example ‚ÄúInteractive allocation for parallel <code class="docutils literal notranslate"><span class="pre">make</span></code> command‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ srun --ntasks=1 --cpus-per-task=16 --mem=16G --time=01:00:00 --pty bash --login
[...]
marie@compute$ # prepare the source code for building using configure, cmake or so
marie@compute$ make -j 16
```
</pre></div>
</div>
</section>
</section>
<section id="exclusive-jobs-for-benchmarking">
<h2>Exclusive Jobs for Benchmarking<a class="headerlink" href="#exclusive-jobs-for-benchmarking" title="Permalink to this heading">#</a></h2>
<p>Jobs on ZIH systems run, by default, in shared-mode, meaning that multiple jobs (from different
users) can run at the same time on the same compute node. Sometimes, this behavior is not desired
(e.g. for benchmarking purposes). You can request for exclusive usage of resources using the Slurm
parameter <code class="docutils literal notranslate"><span class="pre">--exclusive</span></code>.</p>
<p>!!! note ‚ÄúExclusive does not allocate all available resources‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Setting `--exclusive` **only** makes sure that there will be **no other jobs running on your
nodes**.  It does not, however, mean that you automatically get access to all the resources
which the node might provide without explicitly requesting them.

E.g. you still have to request for a GPU via the generic resources parameter (`gres`) on the GPU
cluster. On the other hand, you also have to request all cores of a node if you need them.
</pre></div>
</div>
<p>CPU cores can either to be used for a task (<code class="docutils literal notranslate"><span class="pre">--ntasks</span></code>) or for multi-threading within the same task
(<code class="docutils literal notranslate"><span class="pre">--cpus-per-task</span></code>). Since those two options are semantically different (e.g., the former will
influence how many MPI processes will be spawned by <code class="docutils literal notranslate"><span class="pre">srun</span></code> whereas the latter does not), Slurm
cannot determine automatically which of the two you might want to use. Since we use cgroups for
separation of jobs, your job is not allowed to use more resources than requested.</p>
<p>Here is a short example to ensure that a benchmark is not spoiled by other jobs, even if it doesn‚Äôt
use up all resources of the nodes:</p>
<p>!!! example ‚ÄúJob file with exclusive resources‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```Bash
#!/bin/bash
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=2
#SBATCH --cpus-per-task=8
#SBATCH --exclusive            # ensure that nobody spoils my measurement on 2 x 2 x 8 cores
#SBATCH --time=00:10:00
#SBATCH --job-name=benchmark
#SBATCH --mail-type=start,end
#SBATCH --mail-user=&lt;your.email&gt;@tu-dresden.de

srun ./my_benchmark
```
</pre></div>
</div>
</section>
<section id="array-jobs">
<h2>Array Jobs<a class="headerlink" href="#array-jobs" title="Permalink to this heading">#</a></h2>
<p>Array jobs can be used to create a sequence of jobs that share the same executable and resource
requirements, but have different input files, to be submitted, controlled, and monitored as a single
unit. The option is <code class="docutils literal notranslate"><span class="pre">-a,</span> <span class="pre">--array=&lt;indexes&gt;</span></code> where the parameter <code class="docutils literal notranslate"><span class="pre">indexes</span></code> specifies the array
indices. The following specifications are possible</p>
<ul class="simple">
<li><p>comma separated list, e.g., <code class="docutils literal notranslate"><span class="pre">--array=0,1,2,17</span></code>,</p></li>
<li><p>range based, e.g., <code class="docutils literal notranslate"><span class="pre">--array=0-42</span></code>,</p></li>
<li><p>step based, e.g., <code class="docutils literal notranslate"><span class="pre">--array=0-15:4</span></code>,</p></li>
<li><p>mix of comma separated and range base, e.g., <code class="docutils literal notranslate"><span class="pre">--array=0,1,2,16-42</span></code>.</p></li>
</ul>
<p>A maximum number of simultaneously running tasks from the job array may be specified using the <code class="docutils literal notranslate"><span class="pre">%</span></code>
separator. The specification <code class="docutils literal notranslate"><span class="pre">--array=0-23%8</span></code> limits the number of simultaneously running tasks from
this job array to 8.</p>
<p>Within the job you can read the environment variables <code class="docutils literal notranslate"><span class="pre">SLURM_ARRAY_JOB_ID</span></code> and
<code class="docutils literal notranslate"><span class="pre">SLURM_ARRAY_TASK_ID</span></code> which is set to the first job ID of the array and set individually for each
step, respectively.</p>
<p>Within an array job, you can use <code class="docutils literal notranslate"><span class="pre">%a</span></code> and <code class="docutils literal notranslate"><span class="pre">%A</span></code> in addition to <code class="docutils literal notranslate"><span class="pre">%j</span></code> and <code class="docutils literal notranslate"><span class="pre">%N</span></code> to make the output file
name specific to the job:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">%A</span></code> will be replaced by the value of <code class="docutils literal notranslate"><span class="pre">SLURM_ARRAY_JOB_ID</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%a</span></code> will be replaced by the value of <code class="docutils literal notranslate"><span class="pre">SLURM_ARRAY_TASK_ID</span></code></p></li>
</ul>
<p>!!! example ‚ÄúJob file using job arrays‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```Bash
#!/bin/bash
#SBATCH --array=0-9
#SBATCH --output=arraytest-%A_%a.out
#SBATCH --error=arraytest-%A_%a.err
#SBATCH --ntasks=864
#SBATCH --time=08:00:00
#SBATCH --job-name=Science1
#SBATCH --mail-type=end
#SBATCH --mail-user=&lt;your.email&gt;@tu-dresden.de

echo &quot;Hi, I am step $SLURM_ARRAY_TASK_ID in this array job $SLURM_ARRAY_JOB_ID&quot;
```
</pre></div>
</div>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you submit a large number of jobs doing heavy I/O in the Lustre filesystems you should limit
the number of your simultaneously running job with a second parameter like:

```Bash
#SBATCH --array=1-100000%100
```
</pre></div>
</div>
<p>Please read the Slurm documentation at <a class="reference external" href="https://slurm.schedmd.com/sbatch.html">https://slurm.schedmd.com/sbatch.html</a> for further details.</p>
</section>
<section id="chain-jobs">
<h2>Chain Jobs<a class="headerlink" href="#chain-jobs" title="Permalink to this heading">#</a></h2>
<p>You can use chain jobs to <strong>create dependencies between jobs</strong>. This is often useful if a job
relies on the result of one or more preceding jobs. Chain jobs can also be used to split a long
running job exceeding the batch queues limits into parts and chain these parts. Slurm has an option
<code class="docutils literal notranslate"><span class="pre">-d,</span> <span class="pre">--dependency=&lt;dependency_list&gt;</span></code> that allows to specify that a job is only allowed to start if
another job finished.</p>
<p>In the following we provide two examples for scripts that submit chain jobs.</p>
<p>??? example ‚ÄúScaling experiment using chain jobs‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>This scripts submits the very same job file `myjob.sh` four times, which will be executed one
after each other. The number of tasks is increased from job to job making this submit script a
good starting point for (strong) scaling experiments.

```Bash title=&quot;submit_scaling.sh&quot;
#!/bin/bash

task_numbers=&quot;1 2 4 8&quot;
dependency=&quot;&quot;
job_file=&quot;myjob.sh&quot;

for tasks in ${task_numbers} ; do
    job_cmd=&quot;sbatch --ntasks=${tasks}&quot;
    if [ -n &quot;${dependency}&quot; ] ; then
        job_cmd=&quot;${job_cmd} --dependency=afterany:${dependency}&quot;
    fi
    job_cmd=&quot;${job_cmd} ${job_file}&quot;
    echo -n &quot;Running command: ${job_cmd}  &quot;
    out=&quot;$(${job_cmd})&quot;
    echo &quot;Result: ${out}&quot;
    dependency=$(echo &quot;${out}&quot; | awk &#39;{print $4}&#39;)
done
```

The output looks like:
```console
marie@login$ sh submit_scaling.sh
Running command: sbatch --ntasks=1 myjob.sh  Result: Submitted batch job 2963822
Running command: sbatch --ntasks=2 --dependency afterany:32963822 myjob.sh  Result: Submitted batch job 2963823
Running command: sbatch --ntasks=4 --dependency afterany:32963823 myjob.sh  Result: Submitted batch job 2963824
Running command: sbatch --ntasks=8 --dependency afterany:32963824 myjob.sh  Result: Submitted batch job 2963825
```
</pre></div>
</div>
<p>??? example ‚ÄúExample to submit job chain via script‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>This script submits three different job files, which will be executed one after each other. Of
course, the dependency reasons can be adopted.

```bash title=&quot;submit_job_chain.sh&quot;
#!/bin/bash

declare -a job_names=(&quot;jobfile_a.sh&quot; &quot;jobfile_b.sh&quot; &quot;jobfile_c.sh&quot;)
dependency=&quot;&quot;
arraylength=${#job_names[@]}

for (( i=0; i&lt;arraylength; i++ )) ; do
  job_nr=$((i + 1))
  echo &quot;Job ${job_nr}/${arraylength}: ${job_names[$i]}&quot;
  if [ -n &quot;${dependency}&quot; ] ; then
      echo &quot;Dependency: after job ${dependency}&quot;
      dependency=&quot;--dependency=afterany:${dependency}&quot;
  fi
  job=&quot;sbatch ${dependency} ${job_names[$i]}&quot;
  out=$(${job})
  dependency=$(echo &quot;${out}&quot; | awk &#39;{print $4}&#39;)
done
```

The output looks like:
```console
marie@login$ sh submit_job_chains.sh
Job 1/3: jobfile_a.sh
Job 2/3: jobfile_b.sh
Dependency: after job 2963708
Job 3/3: jobfile_c.sh
Dependency: after job 2963709
```
</pre></div>
</div>
</section>
<section id="requesting-gpus">
<h2>Requesting GPUs<a class="headerlink" href="#requesting-gpus" title="Permalink to this heading">#</a></h2>
<p>Examples of jobs that require the use of GPUs can be found in the
<span class="xref myst">Job Examples with GPU</span> section.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="job-examples-with-gpu">
<h1>Job Examples with GPU<a class="headerlink" href="#job-examples-with-gpu" title="Permalink to this heading">#</a></h1>
<p>General information on how to request resources via the Slurm batch system can be found in the
<span class="xref myst">Job Examples</span> section.</p>
<section id="id37">
<h2>Requesting GPUs<a class="headerlink" href="#id37" title="Permalink to this heading">#</a></h2>
<p>Slurm will allocate one or many GPUs for your job if requested.
Please note that GPUs are only available in the GPU clusters, like
<span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Alpha</span></code></span>, <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Capella</span></code></span>
and <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Power9</span></code></span>.
The option for <code class="docutils literal notranslate"><span class="pre">sbatch/srun</span></code> in this case is <code class="docutils literal notranslate"><span class="pre">--gres=gpu:[NUM_PER_NODE]</span></code>,
where <code class="docutils literal notranslate"><span class="pre">NUM_PER_NODE</span></code> is the number of GPUs <strong>per node</strong> that will be used for the job.</p>
<p>!!! example ‚ÄúJob file to request a GPU‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```Bash
#!/bin/bash
#SBATCH --nodes=2              # request 2 nodes
#SBATCH --mincpus=1            # allocate one task per node...
#SBATCH --ntasks=2             # ...which means 2 tasks in total (see note below)
#SBATCH --cpus-per-task=6      # use 6 threads per task
#SBATCH --gres=gpu:1           # use 1 GPU per node (i.e. use one GPU per task)
#SBATCH --time=01:00:00        # run for 1 hour
#SBATCH --account=p_number_crunch      # account CPU time to project p_number_crunch

srun ./your/cuda/application   # start you application (probably requires MPI to use both nodes)
```
</pre></div>
</div>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Due to an unresolved issue concerning the Slurm job scheduling behavior, it is currently not
practical to use `--ntasks-per-node` together with GPU jobs. If you want to use multiple nodes,
please use the parameters `--ntasks` and `--mincpus` instead. The values of `mincpus`*`nodes`
has to equal `ntasks` in this case.
</pre></div>
</div>
<section id="limitations-of-gpu-job-allocations">
<h3>Limitations of GPU Job Allocations<a class="headerlink" href="#limitations-of-gpu-job-allocations" title="Permalink to this heading">#</a></h3>
<p>The number of cores per node that are currently allowed to be allocated for GPU jobs is limited
depending on how many GPUs are being requested.
This is because we do not wish that GPUs become unusable due to all cores on a node being used by
a single job which does not, at the same time, request all GPUs.</p>
<p>E.g., if you specify <code class="docutils literal notranslate"><span class="pre">--gres=gpu:2</span></code>, your total number of cores per node (meaning:
<code class="docutils literal notranslate"><span class="pre">ntasks</span></code>*<code class="docutils literal notranslate"><span class="pre">cpus-per-task</span></code>) may not exceed 12 on <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Alpha</span></code></span> or on
<span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Capella</span></code></span>.</p>
<p>Note that this also has implications for the use of the <code class="docutils literal notranslate"><span class="pre">--exclusive</span></code> parameter.
Since this sets the number of allocated cores to the maximum, you also <strong>must</strong> request all GPUs
otherwise your job will not start.
In the case of <code class="docutils literal notranslate"><span class="pre">--exclusive</span></code>, it won‚Äôt be denied on submission,
because this is evaluated in a later scheduling step.
Jobs that directly request too many cores per GPU will be denied with the error message:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Batch job submission failed: Requested node configuration is not available</span>
</pre></div>
</div>
<p>Similar it is not allowed to start CPU-only jobs on the GPU cluster.
I.e. you must request at least one GPU there, or you will get this error message:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">srun: error: QOSMinGRES</span>
<span class="go">srun: error: Unable to allocate resources: Job violates accounting/QOS policy (job submit limit, user&#39;s size and/or time limits)</span>
</pre></div>
</div>
</section>
<section id="running-multiple-gpu-applications-simultaneously-in-a-batch-job">
<h3>Running Multiple GPU Applications Simultaneously in a Batch Job<a class="headerlink" href="#running-multiple-gpu-applications-simultaneously-in-a-batch-job" title="Permalink to this heading">#</a></h3>
<p>Our starting point is a (serial) program that needs a single GPU and four CPU cores to perform its
task (e.g. TensorFlow). The following batch script shows how to run such a job on any of
the GPU clusters <code class="docutils literal notranslate"><span class="pre">Power9</span></code>, <code class="docutils literal notranslate"><span class="pre">Alpha</span></code> or <code class="docutils literal notranslate"><span class="pre">Capella</span></code>.</p>
<p>!!! example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --gres=gpu:1
#SBATCH --gpus-per-task=1
#SBATCH --time=01:00:00
#SBATCH --mem-per-cpu=1443

srun some-gpu-application
```
</pre></div>
</div>
<p>When <code class="docutils literal notranslate"><span class="pre">srun</span></code> is used within a submission script, it inherits parameters from <code class="docutils literal notranslate"><span class="pre">sbatch</span></code>, including
<code class="docutils literal notranslate"><span class="pre">--ntasks=1</span></code>, <code class="docutils literal notranslate"><span class="pre">--cpus-per-task=4</span></code>, etc. So we actually implicitly run the following</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>srun<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="o">[</span>...<span class="o">]</span><span class="w"> </span>some-gpu-application
</pre></div>
</div>
<p>Now, our goal is to run four instances of this program concurrently in a single batch script. Of
course we could also start the above script multiple times with <code class="docutils literal notranslate"><span class="pre">sbatch</span></code>, but this is not what we
want to do here.</p>
<section id="solution">
<h4>Solution<a class="headerlink" href="#solution" title="Permalink to this heading">#</a></h4>
<p>In order to run multiple programs concurrently in a single batch script/allocation we have to do
three things:</p>
<ol class="arabic simple">
<li><p>Allocate enough resources to accommodate multiple instances of our program. This can be achieved
with an appropriate batch script header (see below).</p></li>
<li><p>Start job steps with <code class="docutils literal notranslate"><span class="pre">srun</span></code> as background processes. This is achieved by adding an ampersand at
the end of the <code class="docutils literal notranslate"><span class="pre">srun</span></code> command.</p></li>
<li><p>Make sure that each background process gets its private resources. We need to set the resource
fraction needed for a single run in the corresponding <code class="docutils literal notranslate"><span class="pre">srun</span></code> command. The total aggregated
resources of all job steps must fit in the allocation specified in the batch script header.
Additionally, the option <code class="docutils literal notranslate"><span class="pre">--exclusive</span></code> is needed to make sure that each job step is provided with
its private set of CPU and GPU resources.  The following example shows how four independent
instances of the same program can be run concurrently from a single batch script. Each instance
(task) is equipped with 4 CPUs (cores) and one GPU.</p></li>
</ol>
<p>!!! example ‚ÄúJob file simultaneously executing four independent instances of the same program‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```Bash
#!/bin/bash
#SBATCH --ntasks=4
#SBATCH --cpus-per-task=4
#SBATCH --gres=gpu:4
#SBATCH --gpus-per-task=1
#SBATCH --time=01:00:00
#SBATCH --mem-per-cpu=1443

srun --exclusive --gres=gpu:1 --ntasks=1 --cpus-per-task=4 --gpus-per-task=1 --mem-per-cpu=1443 some-gpu-application &amp;
srun --exclusive --gres=gpu:1 --ntasks=1 --cpus-per-task=4 --gpus-per-task=1 --mem-per-cpu=1443 some-gpu-application &amp;
srun --exclusive --gres=gpu:1 --ntasks=1 --cpus-per-task=4 --gpus-per-task=1 --mem-per-cpu=1443 some-gpu-application &amp;
srun --exclusive --gres=gpu:1 --ntasks=1 --cpus-per-task=4 --gpus-per-task=1 --mem-per-cpu=1443 some-gpu-application &amp;

echo &quot;Waiting for all job steps to complete...&quot;
wait
echo &quot;All jobs completed!&quot;
```
</pre></div>
</div>
<p>In practice, it is possible to leave out resource options in <code class="docutils literal notranslate"><span class="pre">srun</span></code> that do not differ from the ones
inherited from the surrounding <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> context. The following line would be sufficient to do the
job in this example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>srun<span class="w"> </span>--exclusive<span class="w"> </span>--gres<span class="o">=</span>gpu:1<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span><span class="w"> </span>some-gpu-application<span class="w"> </span><span class="p">&amp;</span>
</pre></div>
</div>
<p>Yet, it adds some extra safety to leave them in, enabling the Slurm batch system to complain if not
enough resources in total were specified in the header of the batch script.</p>
</section>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="slurm-job-file-generator">
<h1>Slurm Job File Generator<a class="headerlink" href="#slurm-job-file-generator" title="Permalink to this heading">#</a></h1>
<p>This page provides a generator for Slurm job files covering</p>
<ul class="simple">
<li><p>basic Slurm options for resource specification and job management,</p></li>
<li><p>data life cycle handling using workspaces,</p></li>
<li><p>and a skeleton for setting up the computational environment using modules.</p></li>
</ul>
<p>It is intended as a starting point for beginners and thus, does not cover all available Slurm
options.</p>
<p>If you are interested in providing this job file generator for your HPC users, you can find the
project at
<a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/zih/hpcsupport/slurm-jobfile-generator">https://gitlab.hrz.tu-chemnitz.de/zih/hpcsupport/slurm-jobfile-generator</a>.</p>
<!--
This file is part of sgen software.
Slurm Jobfile Generator

Copyright (c) 2022,
    Technische Universitaet Dresden, Germany

sgen is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

Foobar is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with sgen.  If not, see <http://www.gnu.org/licenses/>.
-->
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <!-- <meta name="viewport" content="width=device-width, initial-scale=1.0"> -->
    <title>Slurm-Job-Generator</title>
    <!-- <link type="text/css" href="../misc/style.css" rel="stylesheet"> -->
    <!-- <script src="jquery-3.6.0.min.js"> </script> -->
  </head>
  <body>
    <div class="header">
      <label class="header">TU Dresden Slurm Job Generator</label>
    </div>
    <button type="button" class="collapsible">General</button>
    <div class="content">
      <div class="row">
        <label class="cell-name">Job name (<tt>-J, --job-name</tt>) </label>
        <div class="cell-tooltip">
          <img id="job-name-info" class="info-img" src="../misc/info.png" title="help"
          alt="Information sign">
        </div>
        <input id="job-name" class="cell-input" type="text">
      </div>
      <div class="row">
        <label class="cell-name">Project (<tt>-A, --account</tt>)</label>
        <div class="cell-tooltip">
          <img id="account-info" class="info-img" src="../misc/info.png" title="help"
               alt="Information sign">
        </div>
        <input id="account" class="cell-input" type="text">
      </div>
      <div class="row">
        <label class="cell-name">Email (<tt>--mail-user, --mail-type</tt>)</label>
        <div class="cell-tooltip">
          <img id="mail-info" class="info-img" src="../misc/info.png" title="help" alt="Information sign">
        </div>
        <div class="cell-input">
          <input id="mail" class="mail" type="mail">
          <input id="mail-all" type="checkbox">
          <label for="all">All</label>
          <input id="mail-begin" type="checkbox">
          <label for="begin">Begin</label>
          <input id="mail-end" type="checkbox">
          <label for="end">End</label>
          <input id="mail-fail" type="checkbox">
          <label for="fail">Fail</label>
        </div>
      </div>
    </div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;button type=&quot;button&quot; class=&quot;collapsible&quot;&gt;Resources&lt;/button&gt;
&lt;div class=&quot;content&quot;&gt;
  &lt;div class=&quot;partition-input&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
      &lt;label class=&quot;cell-name&quot;&gt;Time limit (&lt;tt&gt;-t, --time&lt;/tt&gt;)&lt;/label&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;time-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;days-hours:minutes:seconds&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;input id=&quot;timelimit&quot; class=&quot;cell-input&quot; type=&quot;text&quot; placeholder=&quot;00-00:00:00&quot;&gt;
      &lt;label id=&quot;time-text&quot; class=&quot;limits cell-input&quot;&gt;&lt;/label&gt;
    &lt;/div&gt;
    &lt;div class=&quot;row&quot;&gt;
      &lt;label class=&quot;cell-name&quot;&gt;Partition (&lt;tt&gt;-p, --partition&lt;/tt&gt;)&lt;/label&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;partition-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;select id=&quot;partition&quot; class=&quot;cell-input&quot;&gt;&lt;/select&gt;
    &lt;/div&gt;
    &lt;div class=&quot;row&quot;&gt;
      &lt;label class=&quot;cell-name&quot;&gt;Nodes (&lt;tt&gt;-N, --nodes&lt;/tt&gt;)&lt;/label&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;nodes-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;input id=&quot;nodes&quot; class=&quot;cell-input&quot; type=&quot;text&quot;&gt;
      &lt;label id=&quot;nodes-text&quot; class=&quot;limits cell-input&quot;&gt;&lt;/label&gt;
    &lt;/div&gt;
    &lt;div class=&quot;row&quot;&gt;
      &lt;label class=&quot;cell-name&quot;&gt;Tasks (&lt;tt&gt;-n, --ntasks&lt;/tt&gt;)&lt;/label&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;tasks-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;input id=&quot;tasks&quot; class=&quot;cell-input&quot; type=&quot;text&quot;&gt;
      &lt;label id=&quot;tasks-text&quot; class=&quot;limits cell-input&quot;&gt;&lt;/label&gt;
    &lt;/div&gt;
    &lt;div class=&quot;row&quot;&gt;
      &lt;label class=&quot;cell-name&quot;&gt;Tasks per node (&lt;tt&gt;--tasks-per-node&lt;/tt&gt;)&lt;/label&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;tasks/node-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;input id=&quot;tasks/node&quot; class=&quot;cell-input&quot; type=&quot;text&quot;&gt;
      &lt;label id=&quot;tasks/node-text&quot; class=&quot;limits cell-input&quot;&gt;&lt;/label&gt;
    &lt;/div&gt;
    &lt;div class=&quot;row&quot;&gt;
      &lt;label class=&quot;cell-name&quot;&gt;CPUs per task (&lt;tt&gt;-c, --cpus-per-task&lt;/tt&gt;)&lt;/label&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;cpus-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;input id=&quot;cpus&quot; class=&quot;cell-input&quot; type=&quot;text&quot;&gt;
      &lt;label id=&quot;cpus-text&quot; class=&quot;limits cell-input&quot;&gt;&lt;/label&gt;
    &lt;/div&gt;
    &lt;div id=&quot;div-thread&quot; class=&quot;row&quot;&gt;
      &lt;span class=&quot;cell-name&quot;&gt;&lt;/span&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;nomultithread-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;div class=&quot;cell-input&quot;&gt;
        &lt;input id=&quot;nomultithread&quot; class=&quot;cell&quot; type=&quot;checkbox&quot;&gt;
        &lt;label for=&quot;nomultithread&quot;&gt;No Multithreading&lt;/label&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div id=&quot;div-gpu&quot; class=&quot;row&quot;&gt;
      &lt;label class=&quot;cell-name&quot;&gt;GPUs per node (&lt;tt&gt;--gpus-per-node&lt;/tt&gt;)&lt;/label&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;gpus-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;input id=&quot;gpus&quot; class=&quot;cell-input&quot; type=&quot;text&quot;&gt;
      &lt;label id=&quot;gpus-text&quot; class=&quot;limits cell-input&quot;&gt;&lt;/label&gt;
    &lt;/div&gt;
    &lt;div id=&quot;div-gpu/task&quot; class=&quot;row&quot;&gt;
      &lt;label class=&quot;cell-name&quot;&gt;GPUs per task (&lt;tt&gt;--gpus-per-task&lt;/tt&gt;)&lt;/label&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;gpus/task-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;input id=&quot;gpus/task&quot; class=&quot;cell-input&quot; type=&quot;text&quot;&gt;
      &lt;label id=&quot;gpus/task-text&quot; class=&quot;limits cell-input&quot;&gt;&lt;/label&gt;
    &lt;/div&gt;
    &lt;div class=&quot;row&quot;&gt;
      &lt;label class=&quot;cell-name&quot;&gt;Memory per CPU (&lt;tt&gt;--mem-per-cpu&lt;/tt&gt;)&lt;/label&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;mem-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;div class=&quot;cell-input&quot;&gt;
        &lt;input id=&quot;mem&quot; type=&quot;text&quot;&gt;
        &lt;select id=&quot;byte&quot;&gt;
          &lt;option value=&quot;M&quot; title=&quot;placeholder&quot; selected=&quot;selected&quot;&gt;MiB&lt;/option&gt;
          &lt;option value=&quot;G&quot; title=&quot;placeholder&quot;&gt;GiB&lt;/option&gt;
        &lt;/select&gt;
        &lt;label id=&quot;mem-text&quot; class=&quot;limits&quot;&gt;&lt;/label&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&quot;row&quot;&gt;
      &lt;label class=&quot;cell-name&quot;&gt;Reservation (&lt;tt&gt;--reservation&lt;/tt&gt;)&lt;/label&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;reservation-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;input id=&quot;reservation&quot; class=&quot;cell-input&quot; type=&quot;text&quot; alt=&quot;Information sign&quot;&gt;
    &lt;/div&gt;
    &lt;div class=&quot;row&quot;&gt;
      &lt;label class=&quot;cell-name&quot;&gt;Exclusive (&lt;tt&gt;--exclusive&lt;/tt&gt;)&lt;/label&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;exclusive-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;div class=&quot;cell-input&quot;&gt;
        &lt;input id=&quot;exclusive&quot; type=&quot;checkbox&quot;&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=&quot;partition-info&quot;&gt;
    &lt;pre id=&quot;info-panel-partition&quot; class=&quot;info-pre&quot;&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;button type=&quot;button&quot; class=&quot;collapsible&quot;&gt;Advanced&lt;/button&gt;
&lt;div class=&quot;content&quot;&gt;
  &lt;div class=&quot;row&quot;&gt;
    &lt;label class=&quot;cell-name&quot;&gt;Array (&lt;tt&gt;-a, --array&lt;/tt&gt;)&lt;/label&gt;
    &lt;div class=&quot;cell-tooltip&quot;&gt;
      &lt;img id=&quot;array-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
    &lt;/div&gt;
    &lt;input id=&quot;array&quot; class=&quot;cell-input&quot; type=&quot;text&quot; placeholder=&quot;1-5&quot;&gt;
  &lt;/div&gt;
  &lt;div class=&quot;row&quot;&gt;
    &lt;label class=&quot;cell-name&quot;&gt;Dependency (&lt;tt&gt;-d, --dependency&lt;/tt&gt;)&lt;/label&gt;
    &lt;div class=&quot;cell-tooltip&quot;&gt;
      &lt;img id=&quot;dependency-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
    &lt;/div&gt;
    &lt;div class=&quot;cell-input&quot;&gt;
      &lt;select id=&quot;type-depend&quot;&gt;
        &lt;option value=&quot;none&quot; title=&quot;placeholder&quot; selected=&quot;selected&quot;&gt;&lt;/option&gt;
        &lt;option value=&quot;after&quot; title=&quot;placeholder&quot;&gt;after&lt;/option&gt;
        &lt;option value=&quot;afterany&quot; title=&quot;placeholder&quot;&gt;afterany&lt;/option&gt;
        &lt;option value=&quot;afterburstbuffer&quot; title=&quot;placeholder&quot;&gt;afterburstbuffer&lt;/option&gt;
        &lt;option value=&quot;aftercorr&quot; title=&quot;placeholder&quot;&gt;aftercorr&lt;/option&gt;
        &lt;option value=&quot;afternotok&quot; title=&quot;placeholder&quot;&gt;afternotok&lt;/option&gt;
        &lt;option value=&quot;afterok&quot; title=&quot;placeholder&quot;&gt;afterok&lt;/option&gt;
        &lt;option value=&quot;singleton&quot; title=&quot;placeholder&quot;&gt;singleton&lt;/option&gt;
      &lt;/select&gt;
      &lt;input id=&quot;jobid&quot; class=&quot;hidden&quot; type=&quot;text&quot; placeholder=&quot;jobid&quot;&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;button type=&quot;button&quot; class=&quot;collapsible&quot;&gt;Log Files&lt;/button&gt;
&lt;div class=&quot;content&quot;&gt;
  &lt;div class=&quot;row&quot;&gt;
    &lt;label class=&quot;cell-name&quot;&gt;Single output file&lt;/label&gt;
    &lt;div class=&quot;cell-tooltip&quot;&gt;
      &lt;img id=&quot;one-output-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
    &lt;/div&gt;
    &lt;div class=&quot;cell-input&quot;&gt;
      &lt;input id=&quot;one-output&quot; type=&quot;checkbox&quot;&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=&quot;row&quot;&gt;
    &lt;label class=&quot;cell-name&quot;&gt;Output file (&lt;tt&gt;-o, --output&lt;/tt&gt;) &lt;/label&gt;
    &lt;div class=&quot;cell-tooltip&quot;&gt;
      &lt;img id=&quot;output-file-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
    &lt;/div&gt;
    &lt;input id=&quot;output-file&quot; class=&quot;cell-input&quot; type=&quot;text&quot; placeholder=&quot;slurm-%j.out&quot;&gt;
  &lt;/div&gt;
  &lt;div id=&quot;err-div&quot; class=&quot;row&quot;&gt;
    &lt;label class=&quot;cell-name&quot;&gt;Error file (&lt;tt&gt;-e, --error&lt;/tt&gt;) &lt;/label&gt;
    &lt;div class=&quot;cell-tooltip&quot;&gt;
      &lt;img id=&quot;error-file-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
    &lt;/div&gt;
    &lt;input id=&quot;error-file&quot; class=&quot;cell-input&quot; type=&quot;text&quot; placeholder=&quot;slurm-%j.out&quot;&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;button type=&quot;button&quot; class=&quot;collapsible&quot;&gt;Application&lt;/button&gt;
&lt;div class=&quot;content&quot;&gt;
  &lt;div class=&quot;row&quot;&gt;
    &lt;label class=&quot;cell-name&quot;&gt;Command (w. path and arguments) &lt;/label&gt;
    &lt;div class=&quot;cell-tooltip&quot;&gt;
      &lt;img id=&quot;executable-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
    &lt;/div&gt;
    &lt;input id=&quot;executable&quot; class=&quot;cell-input executable&quot; type=&quot;text&quot; placeholder=&quot;./a.out&quot;&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;button type=&quot;button&quot; class=&quot;collapsible&quot;&gt;Workspace&lt;/button&gt;
&lt;div class=&quot;content&quot;&gt;
  &lt;div class=&quot;partition-input&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
      &lt;label class=&quot;cell-name&quot;&gt;Allocate a workspace&lt;/label&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;ws-alloc-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;div class=&quot;cell-input&quot;&gt;
        &lt;input id=&quot;check-workspace&quot; type=&quot;checkbox&quot;&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&quot;row hidden&quot;&gt;
      &lt;label class=&quot;cell-name&quot;&gt;Filesystem&lt;/label&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;ws-filesystem-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;select id=&quot;workspace-filesystem&quot; class=&quot;cell-input&quot;&gt;&lt;/select&gt;
    &lt;/div&gt;
    &lt;div class=&quot;row hidden&quot;&gt;
      &lt;label class=&quot;cell-name&quot;&gt;Name&lt;/label&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;ws-name-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;input id=&quot;ws-name&quot; class=&quot;cell-input&quot; type=&quot;text&quot;&gt;
    &lt;/div&gt;
    &lt;div class=&quot;row hidden&quot;&gt;
      &lt;label class=&quot;cell-name&quot;&gt;Duration&lt;/label&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;ws-duration-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;div class=&quot;cell-input&quot;&gt;
        &lt;input id=&quot;duration&quot; type=&quot;text&quot; min=&quot;1&quot;&gt;
        &lt;label id=&quot;duration-text&quot; class=&quot;limits&quot;&gt;&lt;/label&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&quot;row hidden&quot;&gt;
      &lt;label class=&quot;cell-name&quot;&gt;Release workspace after job&lt;/label&gt;
      &lt;div class=&quot;cell-tooltip&quot;&gt;
        &lt;img id=&quot;ws-delete-info&quot; class=&quot;info-img&quot; src=&quot;../misc/info.png&quot; title=&quot;help&quot; alt=&quot;Information sign&quot;&gt;
      &lt;/div&gt;
      &lt;div class=&quot;cell-input&quot;&gt;
        &lt;input id=&quot;check-delete&quot; type=&quot;checkbox&quot;&gt;
      &lt;/div&gt;
      &lt;label for=&quot;check-delete&quot;&gt;Delete after job&lt;/label&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=&quot;partition-info&quot;&gt;
    &lt;pre id=&quot;info-panel-ws&quot; class=&quot;info-pre row hidden&quot;&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output&quot;&gt;
  &lt;button id=&quot;generate-button&quot; class=&quot;output&quot; type=&quot;button&quot;&gt;Generate&lt;/button&gt;
  &lt;div class=&quot;code&quot;&gt;
    &lt;label id=&quot;output-text&quot; class=&quot;limits&quot;&gt;Output requires update&lt;/label&gt;
    &lt;pre id=&quot;output&quot;&gt;&lt;/pre&gt;
  &lt;/div&gt;
  &lt;button id=&quot;copy-button&quot; class=&quot;output&quot; type=&quot;button&quot;&gt;Copy to Clipboard&lt;/button&gt;
  &lt;button id=&quot;save-button&quot; class=&quot;output&quot; type=&quot;button&quot;&gt;Save as File&lt;/button&gt;
&lt;/div&gt;

&lt;script&gt;
  // dictionary containing the limits for the different partitions
  const limitsPartition = {
    &#39;alpha&#39; : alpha = {
      &#39;MaxTime&#39;: &#39;INFINITE&#39;,
      &#39;DefaultTime&#39;: 480,
      &#39;Sockets&#39;: 2,
      &#39;CoresPerSocket&#39;: 24,
      &#39;ThreadsPerCore&#39;: 2,
      &#39;nodes&#39;: 37,
      &#39;GPU&#39;: 8,
      &#39;HTCores&#39;: 96,
      &#39;Cores&#39;: 48,
      &#39;MemoryPerNode&#39;: 990000,
      &#39;MemoryPerCore&#39;: 10312
    },
    &#39;haswell&#39; : haswell = {
      &#39;MaxTime&#39;: &#39;INFINITE&#39;,
      &#39;DefaultTime&#39;: 480,
      &#39;Sockets&#39;: 2,
      &#39;CoresPerSocket&#39;: 12,
      &#39;ThreadsPerCore&#39;: 1,
      &#39;nodes&#39;: 609,
      &#39;GPU&#39;: 0,
      &#39;HTCores&#39;: 24,
      &#39;Cores&#39;: 24,
      &#39;MemoryPerNode&#39;: 61000,
      &#39;MemoryPerCore&#39;: 2541
    },
    &#39;haswell64&#39; : haswell64 = {
      &#39;MaxTime&#39;: &#39;INFINITE&#39;,
      &#39;DefaultTime&#39;: 480,
      &#39;Sockets&#39;: 2,
      &#39;CoresPerSocket&#39;: 12,
      &#39;ThreadsPerCore&#39;: 1,
      &#39;nodes&#39;: 586,
      &#39;GPU&#39;: 0,
      &#39;HTCores&#39;: 24,
      &#39;Cores&#39;: 24,
      &#39;MemoryPerNode&#39;: 61000,
      &#39;MemoryPerCore&#39;: 2541
    },
    &#39;haswell256&#39; : haswell256 = {
      &#39;MaxTime&#39;: &#39;INFINITE&#39;,
      &#39;DefaultTime&#39;: 480,
      &#39;Sockets&#39;: 2,
      &#39;CoresPerSocket&#39;: 12,
      &#39;ThreadsPerCore&#39;: 1,
      &#39;nodes&#39;: 18,
      &#39;GPU&#39;: 0,
      &#39;HTCores&#39;: 24,
      &#39;Cores&#39;: 24,
      &#39;MemoryPerNode&#39;: 254000,
      &#39;MemoryPerCore&#39;: 10583
    },
    &#39;interactive&#39; : interactive = {
      &#39;MaxTime&#39;: 480,
      &#39;DefaultTime&#39;: 30,
      &#39;Sockets&#39;: 2,
      &#39;CoresPerSocket&#39;: 12,
      &#39;ThreadsPerCore&#39;: 1,
      &#39;nodes&#39;: 8,
      &#39;GPU&#39;: 0,
      &#39;HTCores&#39;: 24,
      &#39;Cores&#39;: 24,
      &#39;MemoryPerNode&#39;: 61000,
      &#39;MemoryPerCore&#39;: 2541
    },
    &#39;smp2&#39; : smp2 = {
      &#39;MaxTime&#39;: &#39;INFINITE&#39;,
      &#39;DefaultTime&#39;: 480,
      &#39;Sockets&#39;: 4,
      &#39;CoresPerSocket&#39;: 14,
      &#39;ThreadsPerCore&#39;: 1,
      &#39;nodes&#39;: 5,
      &#39;GPU&#39;: 0,
      &#39;HTCores&#39;: 56,
      &#39;Cores&#39;: 56,
      &#39;MemoryPerNode&#39;: 2044000,
      &#39;MemoryPerCore&#39;: 36500
    },
    &#39;hpdlf&#39; : hpdlf = {
      &#39;MaxTime&#39;: &#39;INFINITE&#39;,
      &#39;DefaultTime&#39;: 60,
      &#39;Sockets&#39;: 2,
      &#39;CoresPerSocket&#39;: 6,
      &#39;ThreadsPerCore&#39;: 1,
      &#39;nodes&#39;: 14,
      &#39;GPU&#39;: 3,
      &#39;HTCores&#39;: 12,
      &#39;Cores&#39;: 12,
      &#39;MemoryPerNode&#39;: 95000,
      &#39;MemoryPerCore&#39;: 7916
    },
    &#39;power9&#39; : power9 = {
      &#39;MaxTime&#39;: &#39;INFINITE&#39;,
      &#39;DefaultTime&#39;: 60,
      &#39;Sockets&#39;: 2,
      &#39;CoresPerSocket&#39;: 22,
      &#39;ThreadsPerCore&#39;: 4,
      &#39;nodes&#39;: 30,
      &#39;GPU&#39;: 6,
      &#39;HTCores&#39;: 176,
      &#39;Cores&#39;: 44,
      &#39;MemoryPerNode&#39;: 254000,
      &#39;MemoryPerCore&#39;: 1443
    },
    &#39;romeo&#39; : romeo = {
      &#39;MaxTime&#39;: &#39;INFINITE&#39;,
      &#39;DefaultTime&#39;: 480,
      &#39;Sockets&#39;: 2,
      &#39;CoresPerSocket&#39;: 64,
      &#39;ThreadsPerCore&#39;: 2,
      &#39;nodes&#39;: 190,
      &#39;GPU&#39;: 0,
      &#39;HTCores&#39;: 256,
      &#39;Cores&#39;: 128,
      &#39;MemoryPerNode&#39;: 505000,
      &#39;MemoryPerCore&#39;: 1972
    },
    &#39;romeo-interactive&#39;: {
      &#39;MaxTime&#39;: 480,
      &#39;DefaultTime&#39;: 10,
      &#39;Sockets&#39;: 2,
      &#39;CoresPerSocket&#39;: 64,
      &#39;ThreadsPerCore&#39;: 2,
      &#39;nodes&#39;: 2,
      &#39;GPU&#39;: 0,
      &#39;HTCores&#39;: 256,
      &#39;Cores&#39;: 128,
      &#39;MemoryPerNode&#39;: 505000,
      &#39;MemoryPerCore&#39;: 1972
    },
    &#39;julia&#39; : julia = {
      &#39;MaxTime&#39;: &#39;INFINITE&#39;,
      &#39;DefaultTime&#39;: 480,
      &#39;Sockets&#39;: 32,
      &#39;CoresPerSocket&#39;: 28,
      &#39;ThreadsPerCore&#39;: 1,
      &#39;nodes&#39;: 1,
      &#39;GPU&#39;: 0,
      &#39;HTCores&#39;: 896,
      &#39;Cores&#39;: 896,
      &#39;MemoryPerNode&#39;: 48390000,
      &#39;MemoryPerCore&#39;: 54006
    },
    &#39;alpha&#39; : alpha = {
      &#39;MaxTime&#39;: &#39;INFINITE&#39;,
      &#39;DefaultTime&#39;: 480,
      &#39;Sockets&#39;: 2,
      &#39;CoresPerSocket&#39;: 24,
      &#39;ThreadsPerCore&#39;: 2,
      &#39;nodes&#39;: 32,
      &#39;GPU&#39;: 8,
      &#39;HTCores&#39;: 96,
      &#39;Cores&#39;: 48,
      &#39;MemoryPerNode&#39;: 990000,
      &#39;MemoryPerCore&#39;: 10312
    },
    &#39;alpha-interactive&#39;: {
      &#39;MaxTime&#39;: &#39;INFINITE&#39;,
      &#39;DefaultTime&#39;: 480,
      &#39;Sockets&#39;: 2,
      &#39;CoresPerSocket&#39;: 24,
      &#39;ThreadsPerCore&#39;: 2,
      &#39;nodes&#39;: 2,
      &#39;GPU&#39;: 8,
      &#39;HTCores&#39;: 96,
      &#39;Cores&#39;: 48,
      &#39;MemoryPerNode&#39;: 990000,
      &#39;MemoryPerCore&#39;: 10312
    }      };

  // dictionary containing the limits for the different workspaces
  const limitsWorkspace = {
    &#39;scratch&#39; : scratch = {
      &#39;info&#39; : &#39;&#39;,
      &#39;duration&#39; : 100,
      &#39;extensions&#39; : 10
    },
    &#39;warm_archive&#39; : warm_archive = {
      &#39;info&#39; : &#39;&#39;,
      &#39;duration&#39; : 365,
      &#39;extensions&#39; : 2
    },
    &#39;ssd&#39; : ssd = {
      &#39;info&#39; : &#39;&#39;,
      &#39;duration&#39; : 30,
      &#39;extensions&#39; : 2
    },
    &#39;beegfs&#39; : beegfs = {
      &#39;info&#39; : &#39;&#39;,
      &#39;duration&#39; : 30,
      &#39;extensions&#39; : 2
    }
  };

  // dictionary containing the texts and link for the info icons
  const info = {
    &#39;job-name&#39;: {
      &#39;text&#39;: &#39;Specify a name for the job allocation. The specified name will appear along with the job id number when querying running jobs on the system. (default: name of the job file)&#39;,
      &#39;link&#39;: &#39;https://slurm.schedmd.com/sbatch.html#OPT_job-name&#39;
    },
    &#39;account&#39;: {
      &#39;text&#39;: &#39;Charge resources used by this job to specified project.&#39;,
      &#39;link&#39;: &#39;https://slurm.schedmd.com/sbatch.html#OPT_account&#39;
    },
    &#39;mail&#39;: {
      &#39;text&#39;: &#39;Specify which user is send a email notification of state changes as defined by --mail-type.&#39;,
      &#39;link&#39;: &#39;https://slurm.schedmd.com/sbatch.html#OPT_mail-user&#39;
    },
    &#39;time&#39;: {
      &#39;text&#39;: &#39;Set the total run time limit of the job allocation. When the time limit is reached, each task in each job step is sent SIGTERM followed by SIGKILL. The default time limit is the partition\&#39;s default time limit. (currently only supports ddd-hh:mm:ss and hh:mm:ss)&#39;,
      &#39;link&#39;: &#39;https://slurm.schedmd.com/sbatch.html#OPT_time&#39;
    },
    &#39;partition&#39;: {
      &#39;text&#39;: &#39;Request a specific partition for the resource allocation. If the job can use more than one partition, specify their names in a comma separate list and the one offering earliest initiation will be used with no regard given to the partition name ordering. (default: default paritition of the system)&#39;,
      &#39;link&#39;: &#39;https://slurm.schedmd.com/sbatch.html#OPT_partition&#39;
    },
    &#39;nodes&#39;: {
      &#39;text&#39;: &#39;Request that number of nodes be allocated to this job.&#39;,
      &#39;link&#39;: &#39;https://slurm.schedmd.com/sbatch.html#OPT_nodes&#39;
    },
    &#39;tasks&#39;: {
      &#39;text&#39;: &#39;Request that many MPI tasks (default: one task per node)&#39;,
      &#39;link&#39;: &#39;https://slurm.schedmd.com/sbatch.html#OPT_ntasks&#39;
    },
    &#39;tasks/node&#39;: {
      &#39;text&#39;: &#39;Allocate that many tasks per node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option.&#39;,
      &#39;link&#39;: &#39;https://slurm.schedmd.com/sbatch.html#OPT_ntasks-per-node&#39;
    },
    &#39;cpus&#39;: {
      &#39;text&#39;: &#39;Request that number of processors per MPI task. This is needed for multithreaded (e.g. OpenMP) jobs; typically &lt;N&gt; should be equal to OMP_NUM_THREADS&#39;,
      &#39;link&#39;: &#39;https://slurm.schedmd.com/sbatch.html#OPT_cpus-per-task&#39;
    },
    &#39;nomultithread&#39;: {
      &#39;text&#39;: &#39;[don\&#39;t] use extra threads with in-core multi-threading which can benefit communication intensive applications.&#39;,
      &#39;link&#39;: &#39;https://slurm.schedmd.com/sbatch.html#OPT_[no]multithread&#39;
    },
    &#39;gpus&#39;: {
      &#39;text&#39;: &#39;help text for gpus&#39;,
      &#39;link&#39;: &#39;https://slurm.schedmd.com/sbatch.html#OPT_gpus&#39;
    },
    &#39;gpus/task&#39;: {
      &#39;text&#39;: &#39;help text for gpus/task&#39;,
      &#39;link&#39;: &#39;test&#39;
    },
    &#39;mem&#39;: {
      &#39;text&#39;: &#39;Specify the real memory required per node.&#39;,
      &#39;link&#39;: &#39;https://slurm.schedmd.com/sbatch.html#OPT_output&#39;
    },
    &#39;reservation&#39;: {
      &#39;text&#39;: &#39;Allocate resources for the job from the named reservation.&#39;,
      &#39;link&#39;: &#39;https://slurm.schedmd.com/sbatch.html#OPT_reservation&#39;
    },
    &#39;exclusive&#39;: {
      &#39;text&#39;: &#39;The job allocation can not share nodes with other running job. Exclusive usage of compute nodes; you will be charged for all CPUs/cores on the node&#39;,
      &#39;link&#39;: &#39;https://slurm.schedmd.com/sbatch.html#OPT_exclusive&#39;
    },
    &#39;executable&#39;: {
      &#39;text&#39;: &#39;help text for executable&#39;,
      &#39;link&#39;: &#39;test&#39;
    },
    &#39;one-output&#39;: {
      &#39;text&#39;: &#39;help text for one-output&#39;,
      &#39;link&#39;: &#39;test&#39;
    },
    &#39;output-file&#39;: {
      &#39;text&#39;: &#39;File to save all normal output (stdout) (default: slurm-%j.out)&#39;,
      &#39;link&#39;: &#39;https://slurm.schedmd.com/sbatch.html#OPT_output&#39;
    },
    &#39;error-file&#39;: {
      &#39;text&#39;: &#39;File to save all error output (stderr) (default: slurm-%j.out)&#39;,
      &#39;link&#39;: &#39;https://slurm.schedmd.com/sbatch.html#OPT_error&#39;
    },
    &#39;array&#39;: {
      &#39;text&#39;: &#39;help text for array&#39;,
      &#39;link&#39;: &#39;test&#39;
    },
    &#39;dependency&#39;: {
      &#39;text&#39;: &#39;help text for dependency&#39;,
      &#39;link&#39;: &#39;test&#39;
    },
    &#39;ws-alloc&#39;: {
      &#39;text&#39;: &#39;help text for allocate workspace&#39;,
      &#39;link&#39;: &#39;test&#39;
    },
    &#39;ws-filesystem&#39;: {
      &#39;text&#39;: &#39;help text for filesystem&#39;,
      &#39;link&#39;: &#39;test&#39;
    },
    &#39;ws-name&#39;: {
      &#39;text&#39;: &#39;Valid characters for workspace names are only alphanumeric characters, -, ., and _. Workspace name has to start with an alphanumeric character.&#39;,
      &#39;link&#39;: &#39;test&#39;
    },
    &#39;ws-duration&#39;: {
      &#39;text&#39;: &#39;help text for duration&#39;,
      &#39;link&#39;: &#39;test&#39;
    },
    &#39;ws-delete&#39;: {
      &#39;text&#39;: &#39;help text for delete workspace&#39;,
      &#39;link&#39;: &#39;test&#39;
    }
  };

  // dictionary for the max values
  var maxValues = {
    &#39;nodes&#39; : 1,
    &#39;tasks&#39; : 1,
    &#39;tasks/node&#39; : 1,
    &#39;cpus&#39; : 1,
    &#39;gpus&#39; : 0,
    &#39;gpus/task&#39; : 0,
    &#39;mem&#39; : 1,
    &#39;duration&#39;: 1
  };

  // dictionary for the min values
  var minValues = {
    &#39;nodes&#39; : 1,
    &#39;tasks&#39; : 1,
    &#39;tasks/node&#39; : 1,
    &#39;cpus&#39; : 1,
    &#39;gpus&#39; : 0,
    &#39;gpus/task&#39; : 0,
    &#39;mem&#39; : 1,
    &#39;duration&#39;: 1
  };

  /**
   *  Function to generate the output text
   */
  var generateOutput = function() {
    let outputText = document.getElementById(&#39;output&#39;)
    outputText.innerText = &#39;#!/bin/bash\n&#39;;
    if (document.getElementById(&#39;job-name&#39;).value !== &#39;&#39;) {
      outputText.innerText += &#39;\n#SBATCH --job-name=\&quot;&#39;
      + document.getElementById(&#39;job-name&#39;).value + &#39;\&quot;&#39;;
    }
    if (document.getElementById(&#39;account&#39;).value !== &#39;&#39;) {
      outputText.innerText += &#39;\n#SBATCH --account=\&quot;&#39;
      + document.getElementById(&#39;account&#39;).value + &#39;\&quot;&#39;;
    }
    if (document.getElementById(&#39;mail&#39;).value !== &#39;&#39;) {
      outputText.innerText += &#39;\n#SBATCH --mail-user=&#39;
      + document.getElementById(&#39;mail&#39;).value;
      if (document.getElementById(&#39;mail-all&#39;).checked === true) {
        outputText.innerText += &#39;\n#SBATCH --mail-type=ALL&#39;;
      } else {
        let mailtype = &quot;&quot;
        let mailtype_wanted = false
        if (document.getElementById(&#39;mail-begin&#39;).checked === true) {
          mailtype_wanted = true
          mailtype = &quot;BEGIN&quot;
          // outputText.innerText += &#39;\n#SBATCH --mail-type=BEGIN&#39;;
        }
        if (document.getElementById(&#39;mail-end&#39;).checked === true) {
          if (mailtype_wanted === true) {
            mailtype += &quot;,END&quot;
          } else {
            mailtype += &quot;END&quot;
          }
          mailtype_wanted = true
          // outputText.innerText += &#39;\n#SBATCH --mail-type=END&#39;;
        }
        if (document.getElementById(&#39;mail-fail&#39;).checked === true) {
          if (mailtype_wanted === true) {
            mailtype += &quot;,FAIL&quot;
          } else {
            mailtype += &quot;FAIL&quot;
          }
          mailtype_wanted = true
          // outputText.innerText += &#39;\n#SBATCH --mail-type=FAIL&#39;;
        }
        if (mailtype_wanted === true) {
          outputText.innerText += &#39;\n#SBATCH --mail-type=&#39; + mailtype
        }
      }
    }
    if (document.getElementById(&#39;timelimit&#39;).value !== &#39;&#39;) {
      outputText.innerText += &#39;\n#SBATCH --time=&#39;
      + document.getElementById(&#39;timelimit&#39;).value;
    } else {
      outputText.innerText += &#39;\n#SBATCH --time=&#39;
      + limitsPartition[document.getElementById(&#39;partition&#39;).value][&#39;DefaultTime&#39;];
    }
    outputText.innerText += &#39;\n#SBATCH --partition=&#39;
    + document.getElementById(&#39;partition&#39;).value;
    if (document.getElementById(&#39;nodes&#39;).value !== &#39;&#39;) {
      outputText.innerText += &#39;\n#SBATCH --nodes=&#39; + document.getElementById(&#39;nodes&#39;).value;
    }
    if (document.getElementById(&#39;tasks&#39;).value !== &#39;&#39;) {
      outputText.innerText += &#39;\n#SBATCH --ntasks=&#39;
      + document.getElementById(&#39;tasks&#39;).value;
    }
    if (document.getElementById(&#39;tasks/node&#39;).value !== &#39;&#39; &amp;&amp; document.getElementById(&#39;gpus&#39;).value === &#39;&#39;) {
      outputText.innerText += &#39;\n#SBATCH --ntasks-per-node=&#39;
      + document.getElementById(&#39;tasks/node&#39;).value;
    } else if (document.getElementById(&#39;tasks/node&#39;).value !== &#39;&#39;) {
      outputText.innerText += &#39;\n#SBATCH --mincpus=&#39;
      + document.getElementById(&#39;tasks/node&#39;).value;
    }
    if (document.getElementById(&#39;cpus&#39;).value !== &#39;&#39;) {
      outputText.innerText += &#39;\n#SBATCH --cpus-per-task=&#39;
      + document.getElementById(&#39;cpus&#39;).value;
    }
    if (document.getElementById(&#39;gpus&#39;).value !== &#39;&#39;) {
      outputText.innerText += &#39;\n#SBATCH --gres=gpu:&#39;
      + document.getElementById(&#39;gpus&#39;).value;
    }
    if (document.getElementById(&#39;gpus/task&#39;).value !== &#39;&#39;) {
      outputText.innerText += &#39;\n#SBATCH --gpus-per-task=&#39;
      + document.getElementById(&#39;gpus/task&#39;).value;
    }
    if (document.getElementById(&#39;mem&#39;).value !== &#39;&#39;) {
      outputText.innerText += &#39;\n#SBATCH --mem-per-cpu=&#39;
      + document.getElementById(&#39;mem&#39;).value
      + document.getElementById(&#39;byte&#39;).value;
    }
    if (document.getElementById(&#39;reservation&#39;).value !== &#39;&#39;) {
      outputText.innerText += &#39;\n#SBATCH --reservation=&#39;
      + document.getElementById(&#39;reservation&#39;).value;
    }
    if (document.getElementById(&#39;exclusive&#39;).checked === true) {
      outputText.innerText += &#39;\n#SBATCH --exclusive&#39;;
    }
    if (document.getElementById(&#39;nomultithread&#39;).checked === true) {
      outputText.innerText += &#39;\n#SBATCH --hint=nomultithread&#39;;
    }
    if (document.getElementById(&#39;output-file&#39;).value !== &#39;&#39;) {
      outputText.innerText += &#39;\n#SBATCH --output=&#39;
      + document.getElementById(&#39;output-file&#39;).value;
    }
    if (document.getElementById(&#39;error-file&#39;).value !== &#39;&#39;) {
      outputText.innerText += &#39;\n#SBATCH --error=&#39;
      + document.getElementById(&#39;error-file&#39;).value;
    }
    if (document.getElementById(&#39;array&#39;).value !== &#39;&#39;) {
      outputText.innerText += &#39;\n#SBATCH --array=&#39;
      + document.getElementById(&#39;array&#39;).value;
    }
    if (document.getElementById(&#39;type-depend&#39;).value !== &#39;none&#39;) {
      outputText.innerText += &#39;\n#SBATCH --dependency=&#39;
      + document.getElementById(&#39;type-depend&#39;).value;
      if (document.getElementById(&#39;type-depend&#39;).value !== &#39;singleton&#39;) {
        outputText.innerText += &#39;:&#39; + document.getElementById(&#39;jobid&#39;).value;
      }
    }

    outputText.innerText += &#39;\n\n# Setup computational environment, i.e, load desired modules&#39;;
    outputText.innerText += &#39;\n# module purge&#39;;
    outputText.innerText += &#39;\n# module load &lt;module name&gt;&#39;;
    outputText.innerText += &#39;\n\n&#39;;

    if (document.getElementById(&#39;check-workspace&#39;).checked) {
      outputText.innerText += &#39;\n# Allocate workspace as working directory&#39;;
      outputText.innerText += &#39;\nWSNAME=&#39;
      + document.getElementById(&#39;ws-name&#39;).value.trim() + &#39;_${SLURM_JOB_ID}&#39;;
      outputText.innerText += &#39;\nexport WSDIR=$(ws_allocate -F &#39;
      + document.getElementById(&#39;workspace-filesystem&#39;).value
      + &#39; -n ${WSNAME}&#39;;
      if (document.getElementById(&#39;duration&#39;).value) {
        outputText.innerText += &#39; -d &#39; + document.getElementById(&#39;duration&#39;).value
      }
      outputText.innerText += &#39;)&#39;;
      outputText.innerText += &#39;\necho &quot;Workspace: ${WSDIR}&quot;&#39;;

      outputText.innerText += &#39;\n# Check allocation&#39;;
      outputText.innerText += &#39;\n[ -z &quot;${WSDIR}&quot; ] &amp;&amp; echo &quot;Error: Cannot allocate workspace {$WSNAME}&quot; &amp;&amp; exit 1&#39;;

      outputText.innerText += &#39;\n\n# Change to workspace directory&#39;;
      outputText.innerText += &#39;\ncd ${WSDIR}&#39;;
    }

    if (document.getElementById(&#39;check-workspace&#39;).checked &amp;&amp; document.getElementById(&#39;check-delete&#39;).checked) {
      outputText.innerText += &#39;\n\n# The workspace where results from multiple experiments will be saved for later analysis.&#39;;
      outputText.innerText += &#39;\n# Remark: Make sure RESULT_WSDIR exists!&#39;;
      outputText.innerText += &#39;\nRESULT_WSDIR=&quot;/path/to/workspace-experiments-results&quot;&#39;
      outputText.innerText += &#39;\ntest -z &quot;${RESULT_WSDIR}&quot; &amp;&amp; echo &quot;Error: Cannot find workspace ${RESULT_WSDIR}&quot; &amp;&amp; exit 1&#39;;
    }

    if (document.getElementById(&#39;executable&#39;).value !== &#39;&#39;) {
      outputText.innerText += &#39;\n\n# Execute parallel application &#39;;
      outputText.innerText += &#39;\nsrun &#39;
      + document.getElementById(&#39;executable&#39;).value;
    } else {
      outputText.innerText += &#39;\n\n# Execute parallel application &#39;;
      outputText.innerText += &#39;\n# srun &lt;application&gt;&#39;;
    }

    if (document.getElementById(&#39;check-workspace&#39;).checked &amp;&amp; document.getElementById(&#39;check-delete&#39;).checked) {
      outputText.innerText += &#39;\n\n# Save your results to the general workspace RESULT_WSDIR (s.a.).&#39;;
      outputText.innerText += &#39;\n# Compress results with bzip2 (which includes CRC32 checksums)&#39;;
      outputText.innerText += &#39;\n# Remark: Assume all result and log files of interest are in the directory `results`.&#39;;
      outputText.innerText += &#39;\nbzip2 --compress --stdout -4 &quot;${WSDIR}/results&quot; &gt; ${RESULT_WSDIR}/${SLURM_JOB_ID}.bz2&#39;;
      outputText.innerText += &#39;\nRETURN_CODE=$?&#39;;
      outputText.innerText += &#39;\nCOMPRESSION_SUCCESS=&quot;$(if test ${RETURN_CODE} -eq 0; then echo&#39;
                              +&#39; \&#39;TRUE\&#39;; else echo \&#39;FALSE\&#39;; fi)&quot;&#39;;

      outputText.innerText += &#39;\n\n# Clean up workspace&#39;;
      outputText.innerText += &#39;\nif [ &quot;TRUE&quot; = ${COMPRESSION_SUCCESS} ]; then&#39;;
      outputText.innerText += &#39;\n    if [ -d ${WSDIR} ] &amp;&amp; rm -rf ${WSDIR}/*&#39;;
      outputText.innerText += &#39;\n    # Reduce grace period to 1 day&#39;;
      outputText.innerText += &#39;\n    ws_release -F &#39;
                              + document.getElementById(&#39;workspace-filesystem&#39;).value
                              + &#39; ${WSNAME}&#39;;
      outputText.innerText += &#39;\nelse&#39;
      outputText.innerText += &#39;\n    echo &quot;Error with compression and writing of results&quot;&#39;
      outputText.innerText += &#39;\n    echo &quot;Please check the folder \&quot;${WSDIR}\&quot; for any&#39;
                              + &#39; partial(?) results.n&#39;;
      outputText.innerText += &#39;\n    exit 1&#39;;
      outputText.innerText += &#39;\nfi&#39;;
    }
  }

  function validateTimelimit() {
    // walltime: Check if value is set
    let elem = document.getElementById(&#39;timelimit&#39;)
    elem.style.backgroundColor = &#39;&#39;;
    let walltime = elem.value.trim()
    if (walltime) {
      // minutes, minutes:seconds, hours:minutes:seconds
      let re_minutes = /^([0-9]+:)?[0-9]+(:[0-9]+)?$/;
      // days-hours, days-hours:minutes and days-hours:minutes:seconds
      let re_days = /^[0-9]+-[0-9]+(:[0-9]+){0,2}$/;
      if (!re_minutes.test(walltime) &amp;&amp;
          !re_days.test(walltime)) {
        elem.style.backgroundColor = &#39;rgb(255, 121, 121)&#39;;
        return false;
      }
    }
    return true;
  }

  const validateEmailString = (email) =&gt; {
    return String(email)
      .toLowerCase()
      .match(
        /^(([^&lt;&gt;()[\]\\.,;:\s@&quot;]+(\.[^&lt;&gt;()[\]\\.,;:\s@&quot;]+)*)|(&quot;.+&quot;))@((\[[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\])|(([a-zA-Z\-0-9]+\.)+[a-zA-Z]{2,}))$/
      );
  };

  function validateEmail() {
    let elem = document.getElementById(&#39;mail&#39;)
    elem.style.backgroundColor = &#39;&#39;;
    let email = elem.value.trim()
    if (document.getElementById(&#39;mail-all&#39;).checked === true
        || document.getElementById(&#39;mail-begin&#39;).checked === true
        || document.getElementById(&#39;mail-end&#39;).checked === true
        || document.getElementById(&#39;mail-fail&#39;).checked === true) {
      // if checked type but empty email or invalid email
      if (! email || !validateEmailString(email)) {
        elem.style.backgroundColor = &#39;rgb(255, 121, 121)&#39;;
        return false;
      }
    } else {
      // If email is given but no Type is selected
      if (email) {
        elem.style.backgroundColor = &#39;rgb(255, 121, 121)&#39;;
        return false;
      }
    }
    return true;
  }

  function validateArray() {
    // walltime: Check if value is set
    let elem = document.getElementById(&#39;array&#39;)
    elem.style.backgroundColor = &#39;&#39;;
    let array = elem.value.trim()
    let reArray = /^[0-9]+(-[0-9]+)?(,[0-9]+(-[0-9]+)?)*(:[0-9]+)?(%[0-9]+)?$/;
    // If array is filled, check validity
    if (array) {
      if (!reArray.test(array)) {
        elem.style.backgroundColor = &#39;rgb(255, 121, 121)&#39;;
        return false;
      }
    }
    return true;
  }

  function validateWorkspace() {
    // Workspace name can consist of alphanumeric characters, -, ., and _.
    // Has to start with alphanumerical character.
    let elem = document.getElementById(&#39;ws-name&#39;)
    elem.style.backgroundColor = &#39;&#39;;
    let ws_name = elem.value.trim()
    let re_allowed = /^[a-zA-Z0-9][a-zA-Z0-9\-\.\_]*$/;
    if (!re_allowed.test(ws_name)) {
      elem.style.backgroundColor = &#39;rgb(255, 121, 121)&#39;;
      return false;
    }
    return true;
  }

  function validateNumericField(field) {
    // remove all leading zeros
    let elem = document.getElementById(field);
    let elem_label = document.getElementById(field + &#39;-text&#39;);
    elem.style.backgroundColor = &#39;&#39;;
    elem_label.style.display = &#39;none&#39;;
    let val_str = elem.value.trim();
    if (val_str) {
      // Check if value is not a number
      if (isNaN(val_str)) {
        elem.style.backgroundColor = &#39;rgb(255, 121, 121)&#39;
        return false;
      }
      // Ensure it is an integer
      let val_num = Number(val_str);
      if (!Number.isInteger(val_num)) {
        elem.style.backgroundColor = &#39;rgb(255, 121, 121)&#39;
        return false;
      }
      let min = minValues[field];
      let max = maxValues[field];
      if (val_num &lt; min || val_num &gt; max) {
        elem.style.backgroundColor = &#39;rgb(255, 121, 121)&#39;;
        elem_label.style.display = &#39;inline&#39;;
        return false;
      }
    }
    // If value is empty or only spaces, its ok
    return true;
  }

  function validateNumericFieldFactory(field) {
    return function() {
      validateNumericField(field);
    }
  }

  /**
   * Proof if all values are correct, if yes it prints the output, else it highlights incorrect values
   */
  var validateAllFields = function() {
    let allFieldsValid = true;
    if (!validateTimelimit()) {
      allFieldsValid = false;
    }
    if (!validateEmail()) {
      allFieldsValid = false;
    }
    if (!validateArray()) {
      allFieldsValid = false;
    }

    // Build list of numerical fields
    let fields = [&#39;nodes&#39;, &#39;tasks&#39;, &#39;tasks/node&#39;, &#39;cpus&#39;, &#39;gpus&#39;, &#39;gpus/task&#39;, &#39;mem&#39;];
    for (let index = 0; index &lt; fields.length; index++) {
      if (!validateNumericField(fields[index])) {
        allFieldsValid = false;
      }
    }
    //fields.forEach(field =&gt; validateNumericField(field))

    if (document.getElementById(&#39;check-workspace&#39;).checked === true) {
      if (!validateNumericField(&#39;duration&#39;)) {
        allFieldsValid = false;
      }
      if (!validateWorkspace()) {
        allFieldsValid = false;
      }
    }

    if (allFieldsValid === true) {
      document.getElementById(&#39;output-text&#39;).style.display = &#39;none&#39;;
      generateOutput();
    } else {
      document.getElementById(&#39;output-text&#39;).style.display = &#39;block&#39;;
    }
  }

  // copy to clipboard
  document.getElementById(&#39;copy-button&#39;).addEventListener(&#39;click&#39;, function () {
    let code = document.getElementById(&#39;output&#39;);

    // select the text
    let range = document.createRange();
    range.selectNodeContents(code);
    let selection = window.getSelection();
    selection.removeAllRanges();
    selection.addRange(range);

    // copy to clipboard
    navigator.clipboard.writeText(code.innerText);

    // remove selection
    selection.removeAllRanges();
  });

  // save as file
  document.getElementById(&#39;save-button&#39;).addEventListener(&#39;click&#39;, function () {
    // create file informations
    var file = new Blob([document.getElementById(&#39;output&#39;).innerText], {type: &#39;text/plain&#39;});
    // create url and link
    var url = URL.createObjectURL(file);
    var a = document.createElement(&#39;a&#39;);
    a.href = url;
    if (document.getElementById(&#39;job-name&#39;).value !== &#39;&#39;) {
      a.download = document.getElementById(&#39;job-name&#39;).value + &quot;.sh&quot;
    }
    else {
      a.download = &#39;sbatchfile.sh&#39;;
    }
    document.body.appendChild(a);
    // activate the link
    a.click();
    // remove link after some time
    setTimeout(function() {
        document.body.removeChild(a);
        window.URL.revokeObjectURL(url);
    }, 0);
  });

  // remove the error field, if checkbox is active
  document.getElementById(&#39;one-output&#39;).addEventListener(&#39;change&#39;, function () {
    if (document.getElementById(&#39;one-output&#39;).checked) {
      document.getElementById(&#39;err-div&#39;).style.display = &#39;none&#39;;
      document.getElementById(&#39;err-div&#39;).value = &#39;&#39;;
    } else {
      document.getElementById(&#39;err-div&#39;).style.display = &#39;&#39;;
    }
  });

  // show workspace div, if checkbox is active
  document.getElementById(&#39;check-workspace&#39;).addEventListener(&#39;change&#39;, function () {
    let hidden = document.getElementsByClassName(&#39;row hidden&#39;);
    [].forEach.call(hidden, function (row) {
      if (document.getElementById(&#39;check-workspace&#39;).checked === true) {
        row.style.cssText = &#39;display:flex !important&#39;;
      } else {
        row.style.cssText = &#39;display:none !important&#39;;
      }
    })
  });

  /**
   * Function to fill the information panel about the currently selected partition
   */
  var fillPartitionInfo = function() {
    let panelText = document.getElementById(&#39;info-panel-partition&#39;);
    let partitionLimits = limitsPartition[document.getElementById(&#39;partition&#39;).value];

    panelText.innerText = &quot;Partition &quot; + document.getElementById(&#39;partition&#39;).value;
    if (partitionLimits[&#39;Description&#39;]) {
      panelText.innerText += &quot;: &quot; + partitionLimits[&#39;Description&#39;];
    }
    panelText.innerText += &#39;\nNodes: &#39; + partitionLimits[&#39;nodes&#39;];
    panelText.innerText += &#39;\nCores per node: &#39; + partitionLimits[&#39;Cores&#39;];
    panelText.innerText += &#39;\nHyper threading: &#39; + partitionLimits[&#39;HTCores&#39;];
    panelText.innerText += &#39;\nRAM per core: &#39; + partitionLimits[&#39;MemoryPerCore&#39;] + &#39; MB&#39;;
    panelText.innerText += &#39;\nRAM per node: &#39; + partitionLimits[&#39;MemoryPerNode&#39;] + &#39; MB&#39;;
    panelText.innerText += &#39;\nGPUs per node: &#39; + partitionLimits[&#39;GPU&#39;];
  }

  /**
   * Function to fill the information panel about the currently selected partition
   */
  var fillWorkspaceInfo = function() {
    let panelText = document.getElementById(&#39;info-panel-ws&#39;);
    let workspaceLimits = limitsWorkspace[document.getElementById(&#39;workspace-filesystem&#39;).value];

    panelText.innerText = workspaceLimits[&#39;info&#39;];
    panelText.innerText += &#39;\nDuration: &#39; + workspaceLimits[&#39;duration&#39;];
    panelText.innerText += &#39;\nExtensions: &#39; + workspaceLimits[&#39;extensions&#39;];
  }

  /**
   * Function to fill the tooltip about the partitions
   */
  var fillTooltips = function() {
    for (const [key, value] of Object.entries(limitsPartition)) {
      let panelText = document.getElementById(key);
      let partitionLimits = limitsPartition[key];

      panelText.title = partitionLimits[&#39;Description&#39;];
      panelText.title += &#39;\nNodes: &#39; + partitionLimits[&#39;nodes&#39;];
      panelText.title += &#39;\nCores per node: &#39; + partitionLimits[&#39;Cores&#39;];
      panelText.title += &#39;\nHyper threading: &#39; + partitionLimits[&#39;HTCores&#39;];
      panelText.title += &#39;\nRAM per core: &#39; + partitionLimits[&#39;MemoryPerCore&#39;] + &#39; MB&#39;;
      panelText.title += &#39;\nRAM per node: &#39; + partitionLimits[&#39;MemoryPerNode&#39;] + &#39; MB&#39;;
      panelText.title += &#39;\nGPUs per node: &#39; + partitionLimits[&#39;GPU&#39;];
    }
  }

  /**
   * Function to fill the tooltip about the workspaces
   */
   var fillTooltipsWorkspace = function() {
    for (const [key, value] of Object.entries(limitsWorkspace)) {
      let panelText = document.getElementById(key);
      let partitionLimits = limitsWorkspace[key];

      panelText.title = partitionLimits[&#39;info&#39;];
      panelText.title += &#39;\nDuration: &#39; + partitionLimits[&#39;duration&#39;];
      panelText.title += &#39;\nExtensions: &#39; + partitionLimits[&#39;extensions&#39;];
    }
  }

  /**
   * Function to fill the tooltip about limits of the field
   *
   * @param {string} field The id for the field to set the tooltip
   */
  var setTooltips = function(field) {
    let panelText = document.getElementById(field);

    panelText.title = &#39;Limits by current setting:&#39;;
    panelText.title += &#39;\nmin: &#39; + minValues[field];
    panelText.title += &#39;\nmax: &#39; + maxValues[field];
    panelText.title += &#39;\nEmpty the field if unneeded&#39;;

    // set limit labels
    let limitText = document.getElementById(field + &#39;-text&#39;);
    limitText.innerText = &#39;min: &#39; + minValues[field];
    limitText.innerText += &#39; max: &#39; + maxValues[field];
  }

  /**
   * Get the value of a field, or its maximum
   */
  var getValue = function(field, type) {
    let number = 0;
    // get field value
    rawNodes = document.getElementById(field).value;
    // set to maximum if value is undefined or out of range
    if (
      rawNodes !== &#39;&#39;
      &amp;&amp; Number(rawNodes) &gt;= minValues[field]
      &amp;&amp; Number(rawNodes) &lt;= maxValues[field]
    ) {
      number = Number(document.getElementById(field).value);
    } else {
      number = type === &#39;min&#39; ? minValues[field] : maxValues[field];
    }
    return number;
  }

  /**
   * Set the limits for the nodes field
   */
   var setLimitNodes = function() {
    // get partition limits from dictionary
    let partitionLimits = limitsPartition[document.getElementById(&#39;partition&#39;).value];

    // set max for nodes
    maxValues[&#39;nodes&#39;] = partitionLimits[&#39;nodes&#39;];

    // set min for nodes
    if (
      document.getElementById(&#39;tasks&#39;).value !== &#39;&#39;
      &amp;&amp; document.getElementById(&#39;tasks/node&#39;).value !== &#39;&#39;
      ) {
      let tasks = getValue(&#39;tasks&#39;, &#39;min&#39;);
      let tasksPerNode = getValue(&#39;tasks/node&#39;, &#39;min&#39;);
      minValues[&#39;nodes&#39;] = Math.ceil(tasks / tasksPerNode);
    } else {
      minValues[&#39;nodes&#39;] = 1;
    }

    // set min for nodes
    setTooltips(&#39;nodes&#39;);
  }

  /**
   * Set the limits for the tasks field
   */
  var setLimitTasks = function() {
    // get partition limits from dictionary
    let partitionLimits = limitsPartition[document.getElementById(&#39;partition&#39;).value];

    // set max
    let nodes = getValue(&#39;nodes&#39;, &#39;max&#39;);
    let taskPerNode = getValue(&#39;tasks/node&#39;, &#39;max&#39;);
    // multithreading
    let limit = document.getElementById(&#39;nomultithread&#39;).checked === true ? &#39;Cores&#39; : &#39;HTCores&#39;;
    maxValues[&#39;tasks&#39;] = nodes * partitionLimits[limit];
    // limit if nodes and tasks/node
    if (
      document.getElementById(&#39;tasks/node&#39;).value !== &#39;&#39;
      &amp;&amp; document.getElementById(&#39;nodes&#39;).value !== &#39;&#39;
    ) {
      maxValues[&#39;tasks&#39;] = taskPerNode * nodes;
    } else {
      minValues[&#39;tasks/node&#39;] = 1;
    }

    // set min
    nodes = getValue(&#39;nodes&#39;, &#39;min&#39;);
    minValues[&#39;tasks&#39;] = nodes;
    setTooltips(&#39;tasks&#39;);
  }

  /**
   * Set the limits for tasks per node field
   */
  var setLimitTasksPerNode = function() {
    // get partition limits from dictionary
    let partitionLimits = limitsPartition[document.getElementById(&#39;partition&#39;).value];

    // set max
    let nodes = getValue(&#39;nodes&#39;, &#39;max&#39;);
    let tasks = getValue(&#39;tasks&#39;, &#39;max&#39;);

    // multithreading
    let limit = document.getElementById(&#39;nomultithread&#39;).checked === true ? &#39;Cores&#39; : &#39;HTCores&#39;;
    maxValues[&#39;tasks/node&#39;] = partitionLimits[limit];
    //set min
    nodes = getValue(&#39;nodes&#39;, &#39;min&#39;);
    tasks = getValue(&#39;tasks&#39;, &#39;min&#39;);
    if (
      document.getElementById(&#39;tasks&#39;).value !== &#39;&#39;
      &amp;&amp; document.getElementById(&#39;nodes&#39;).value !== &#39;&#39;
    ) {
      minValues[&#39;tasks/node&#39;] = Math.ceil(tasks / nodes);
    } else {
      minValues[&#39;tasks/node&#39;] = 1;
    }

    // set min and max for --mincpus if gpus are allocated
    if (
      document.getElementById(&#39;gpus&#39;).value !== &#39;&#39;
      &amp;&amp; document.getElementById(&#39;nodes&#39;).value !== &#39;&#39;
      &amp;&amp; document.getElementById(&#39;tasks&#39;).value !== &#39;&#39;
    ) {
      minValues[&#39;tasks/node&#39;] = Math.ceil(tasks / nodes);
      nodes = getValue(&#39;nodes&#39;, &#39;max&#39;);
      tasks = getValue(&#39;tasks&#39;, &#39;max&#39;);
      maxValues[&#39;tasks/node&#39;] = Math.floor(tasks / nodes);
    }
    // set tooltips
    setTooltips(&#39;tasks/node&#39;);
  }

  /**
   * Set the limits for cpu per task field
   */
   var setLimitCpu = function() {
    // get partition limits from dictionary
    let partitionLimits = limitsPartition[document.getElementById(&#39;partition&#39;).value];

    // set max
    // multithreading
    let limit = document.getElementById(&#39;nomultithread&#39;).checked === true ? &#39;Cores&#39; : &#39;HTCores&#39;;
    let nodes = getValue(&#39;nodes&#39;, &#39;max&#39;);
    let tasks = getValue(&#39;tasks&#39;, &#39;max&#39;);
    let tasksPerNode = getValue(&#39;tasks/node&#39;, &#39;max&#39;);
    let maxValue = [partitionLimits[limit]];
    maxValue.push(Math.floor(partitionLimits[limit] / Math.ceil(tasks / nodes)));
    maxValue.push(Math.floor(partitionLimits[limit] / tasksPerNode));
    maxValues[&#39;cpus&#39;] = Math.min.apply(null, maxValue);
    // set max for cpus if gpus are set
    if (
      document.getElementById(&#39;gpus&#39;).value !== &#39;&#39;
      &amp;&amp; document.getElementById(&#39;gpus&#39;).value !== &#39;0&#39;
      &amp;&amp; document.getElementById(&#39;exclusive&#39;).checked !== true
    ) {
      let gpus = getValue(&#39;gpus&#39;, &#39;max&#39;);
      maxValues[field] = Math.floor(gpus / partitionLimits[&#39;GPU&#39;] * partitionLimits[limit]);
    }
    //set min
    minValues[&#39;cpus&#39;] = 1;
    // set tooltips
    setTooltips(&#39;cpus&#39;);
  }

  /**
   * Set the limits for gpu per node field
   */
   var setLimitGpu = function() {
    // get partition limits from dictionary
    let partitionLimits = limitsPartition[document.getElementById(&#39;partition&#39;).value];

    // set max for gpus
    maxValues[&#39;gpus&#39;] = partitionLimits[&#39;GPU&#39;];
    setTooltips(&#39;gpus&#39;);
    //set min
    if (document.getElementById(&#39;gpus/task&#39;).value !== &#39;&#39;) {
      let tasks = getValue(&#39;tasks&#39;, &#39;min&#39;);
      let nodes = getValue(&#39;nodes&#39;, &#39;min&#39;);
      let gpusPerTask = getValue(&#39;gpus/task&#39;, &#39;min&#39;);
      minValues[&#39;gpus&#39;] = Math.ceil(tasks / nodes * gpusPerTask);
    } else {
      minValues[&#39;gpus&#39;] = 0;
    }
    // set tooltips
    setTooltips(&#39;gpus&#39;);
  }

  /**
   * Set the limits for the gpus per task field
   */
  var setLimitGpuPerTask = function() {
    // get partition limits from dictionary
    let partitionLimits = limitsPartition[document.getElementById(&#39;partition&#39;).value];

    // get value from base
    let tasks = getValue(&#39;tasks&#39;, &#39;max&#39;);
    let tasksNode = getValue(&#39;tasks/node&#39;, &#39;max&#39;);
    let nodes = getValue(&#39;nodes&#39;, &#39;max&#39;);

    // set new max
    let maxValue = [partitionLimits[&#39;GPU&#39;]];
    if (tasks !== &#39;&#39;) {
      maxValue.push(Math.floor(partitionLimits[&#39;GPU&#39;] / Math.ceil(Number(tasks) / Number(nodes))));
    }
    if (tasksNode !== &#39;&#39;) {
      maxValue.push(Math.floor(partitionLimits[&#39;GPU&#39;] / Number(document.getElementById(&#39;tasks/node&#39;).value)));
    }
    maxValues[&#39;gpus/task&#39;] = Math.min.apply(null, maxValue);
    // set tooltips for new limits
    setTooltips(&#39;gpus/task&#39;);
  }

  /**
   * Update the max for memory per cpu values
   */
  var setLimitMem = function() {
    // get partition limits from dictionary
    let partitionLimits = limitsPartition[document.getElementById(&#39;partition&#39;).value];
    maxValues[&#39;mem&#39;] = partitionLimits[&#39;MemoryPerCore&#39;];
    if (document.getElementById(&#39;nomultithread&#39;).checked === true) {
      maxValues[&#39;mem&#39;] *= partitionLimits[&#39;ThreadsPerCore&#39;];
    }
    if (document.getElementById(&#39;byte&#39;).value === &#39;G&#39;) {
      maxValues[&#39;mem&#39;] = Math.floor(maxValues[&#39;mem&#39;] / 1024);
    }
    setTooltips(&#39;mem&#39;);
  }

  /**
   * Set the limits for the duration field
   */
  var setLimitDuration = function() {
    // get partition limits from dictionary
    let workspaceLimits = limitsWorkspace[document.getElementById(&#39;workspace-filesystem&#39;).value];
    // set new max
    maxValues[&#39;duration&#39;] = workspaceLimits[&#39;duration&#39;];

    //set min
    // get days and hours from walltime
    let reArray = /^(([0-9]{1,3})-)?([0-9]{2}):([0-9]{2}):([0-9]{2})$/;
    let match = reArray.exec(document.getElementById(&#39;timelimit&#39;).value);
    if (match === null) {
      setTooltips(&#39;duration&#39;);
      return;
    }
    // if days are defined or not
    if (match[2]) {
      minValues[&#39;duration&#39;] = Number(match[2]);
    }
    minValues[&#39;duration&#39;] += Math.ceil(Number(match[3]) / 24);
    if ((Number(match[4]) !== 0 || Number(match[5]) !== 0) &amp;&amp; Number(match[3]) % 24 === 0) {
      minValues[&#39;duration&#39;] += 1;
    }
    // set tooltips for new limits
    setTooltips(&#39;duration&#39;);
  }

  /**
   * Update the value und max for CPU and GPU values
   */
  var LimitChange = function() {
    setLimitNodes();
    setLimitTasks();
    setLimitTasksPerNode();
    setLimitCpu();
    if (document.getElementById(&#39;div-gpu&#39;).style.display !== &#39;none&#39;) {
      setLimitGpu();
      setLimitGpuPerTask();
    }
    setLimitMem();
    setLimitDuration();
  }

  /**
   * Function to trigger updates, if parttion was changed
   */
  var partitionLimitChange = function() {
    // get partition limits from dictionary
    let partitionLimits = limitsPartition[document.getElementById(&#39;partition&#39;).value];
    // hide the GPU field, if partition do not have GPUs
    if (partitionLimits[&#39;GPU&#39;] === 0) {
      document.getElementById(&#39;div-gpu&#39;).style.display = &#39;none&#39;;
      document.getElementById(&#39;div-gpu/task&#39;).style.display = &#39;none&#39;;
      document.getElementById(&#39;gpus&#39;).value = &#39;&#39;;
      document.getElementById(&#39;gpus/task&#39;).value = &#39;&#39;;
    } else {
      document.getElementById(&#39;div-gpu&#39;).style.display = &#39;&#39;;
      document.getElementById(&#39;div-gpu/task&#39;).style.display = &#39;&#39;;
    }
    // hide the multithreading field if it isnt supported
    if (partitionLimits[&#39;ThreadsPerCore&#39;] === 1) {
      document.getElementById(&#39;div-thread&#39;).style.display = &#39;none&#39;;
      document.getElementById(&#39;nomultithread&#39;).checked = false;
    } else {
      document.getElementById(&#39;div-thread&#39;).style.display = &#39;&#39;;
    }
    // update other values
    LimitChange();
  }

  // set up event listeners, if field change
  document.getElementById(&#39;partition&#39;).addEventListener(&#39;change&#39;, partitionLimitChange);
  document.getElementById(&#39;partition&#39;).addEventListener(&#39;change&#39;, fillPartitionInfo);
  document.getElementById(&#39;nodes&#39;).addEventListener(&#39;change&#39;, LimitChange);
  document.getElementById(&#39;tasks&#39;).addEventListener(&#39;change&#39;, LimitChange);
  document.getElementById(&#39;tasks/node&#39;).addEventListener(&#39;change&#39;, LimitChange);
  document.getElementById(&#39;cpus&#39;).addEventListener(&#39;change&#39;, LimitChange);
  document.getElementById(&#39;gpus&#39;).addEventListener(&#39;change&#39;, LimitChange);
  document.getElementById(&#39;gpus/task&#39;).addEventListener(&#39;change&#39;, LimitChange);
  document.getElementById(&#39;mem&#39;).addEventListener(&#39;change&#39;, LimitChange);
  document.getElementById(&#39;byte&#39;).addEventListener(&#39;change&#39;, setLimitMem);
  document.getElementById(&#39;exclusive&#39;).addEventListener(&#39;change&#39;, LimitChange);
  document.getElementById(&#39;nomultithread&#39;).addEventListener(&#39;change&#39;, LimitChange);
  document.getElementById(&#39;workspace-filesystem&#39;).addEventListener(&#39;change&#39;, setLimitDuration);
  document.getElementById(&#39;workspace-filesystem&#39;).addEventListener(&#39;change&#39;, fillWorkspaceInfo);
  // Set up field validator events
  document.getElementById(&#39;nodes&#39;).addEventListener(&#39;change&#39;, validateNumericFieldFactory(&#39;nodes&#39;));
  document.getElementById(&#39;tasks&#39;).addEventListener(&#39;change&#39;, validateNumericFieldFactory(&#39;tasks&#39;));
  document.getElementById(&#39;tasks/node&#39;).addEventListener(&#39;change&#39;, validateNumericFieldFactory(&#39;tasks/node&#39;));
  document.getElementById(&#39;cpus&#39;).addEventListener(&#39;change&#39;, validateNumericFieldFactory(&#39;cpus&#39;));
  document.getElementById(&#39;gpus&#39;).addEventListener(&#39;change&#39;, validateNumericFieldFactory(&#39;gpus&#39;));
  document.getElementById(&#39;gpus/task&#39;).addEventListener(&#39;change&#39;, validateNumericFieldFactory(&#39;gpus/task&#39;));
  document.getElementById(&#39;mem&#39;).addEventListener(&#39;change&#39;, validateNumericFieldFactory(&#39;mem&#39;));
  document.getElementById(&#39;array&#39;).addEventListener(&#39;change&#39;, validateArray);
  document.getElementById(&#39;ws-name&#39;).addEventListener(&#39;change&#39;, validateWorkspace);
  document.getElementById(&#39;timelimit&#39;).addEventListener(&#39;change&#39;, validateTimelimit);
  // We do not validate Email on change since the validateEmail checks if mail is correct + a box is selected.
  // In the user workflow, this would trigger a red field when they enter a correct Email, but have not selected a checkbox
  // To avoid confusion, we only check on generate.

  // hide jobid field if unneeded
  document.getElementById(&#39;type-depend&#39;).addEventListener(&#39;change&#39;, function() {
    if (
      document.getElementById(&#39;type-depend&#39;).value === &#39;none&#39; ||
      document.getElementById(&#39;type-depend&#39;).value === &#39;singleton&#39;
    ) {
      document.getElementById(&#39;jobid&#39;).style.cssText = &#39;display:none !important&#39;;
    } else {
      document.getElementById(&#39;jobid&#39;).style.cssText = &#39;display:inline !important&#39;;
    }
  });

  document.getElementById(&#39;generate-button&#39;).addEventListener(&#39;click&#39;, validateAllFields);

  // initialize webpage

  // set up the collapsible fields
  let colls = document.getElementsByClassName(&#39;collapsible&#39;);
  [].forEach.call(colls, function (coll) {
    // add event listeners
    coll.addEventListener(&#39;click&#39;, function() {
      this.classList.toggle(&#39;active&#39;);
      let content = this.nextElementSibling;
      if (content.style.display === &#39;block&#39;) {
        content.style.display = &#39;none&#39;;
      } else {
        content.style.display = &#39;block&#39;;
      }
    });

    // extended at beginning
    let content = coll.nextElementSibling;
    content.style.display = &#39;block&#39;;
    coll.classList.toggle(&#39;active&#39;);
  })

  // set up of partition options
  let select = document.getElementById(&#39;partition&#39;);

  for (const [key, value] of Object.entries(limitsPartition)) {
    let option = document.createElement(&#39;option&#39;);
    option.id = key;
    option.value = key;
    option.innerText = key;
    if (key === &#39;haswell64&#39;) {
      option.selected = &#39;selected&#39;;
    }
    select.appendChild(option);
  }

  // set up of workspace options
  select = document.getElementById(&#39;workspace-filesystem&#39;);

  for (const [key, value] of Object.entries(limitsWorkspace)) {
    let option = document.createElement(&#39;option&#39;);
    option.id = key;
    option.value = key;
    option.innerText = key;
    if (key === &#39;scratch&#39;) {
      option.selected = &#39;selected&#39;;
    }
    select.appendChild(option);
  }

  // set up info texts
  for (const [key, value] of Object.entries(info)) {
    document.getElementById(key + &#39;-info&#39;).title = value[&#39;text&#39;];
  }

  // initialize UI
  partitionLimitChange();
  fillPartitionInfo();
  fillWorkspaceInfo();
  fillTooltips();
  fillTooltipsWorkspace();
&lt;/script&gt;
</pre></div>
</div>
  </body>
</html>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="slurm-resource-limits">
<h1>Slurm Resource Limits<a class="headerlink" href="#slurm-resource-limits" title="Permalink to this heading">#</a></h1>
<p>There is no such thing as free lunch at ZIH systems. Since compute nodes are operated in multi-user
node by default, jobs of several users can run at the same time at the very same node sharing
resources, like memory (but not CPU). On the other hand, a higher throughput can be achieved by
smaller jobs. Thus, restrictions w.r.t. <span class="xref myst">memory</span> and
<span class="xref myst">runtime limits</span> have to be respected when submitting jobs.</p>
<section id="id38">
<h2>Runtime Limits<a class="headerlink" href="#id38" title="Permalink to this heading">#</a></h2>
<p>!!! warning ‚ÄúRuntime limits on login nodes‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>There is a time limit of 600 seconds set for processes on login nodes. Each process running
longer than this time limit is automatically killed. The login nodes are shared ressources
between all users of ZIH system and thus, need to be available and cannot be used for productive
runs.

```
CPU time limit exceeded
```

Please submit extensive application runs to the compute nodes using the [batch system](slurm.md).
</pre></div>
</div>
<p>!!! note ‚ÄúRuntime limits are enforced.‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>A job is canceled as soon as it exceeds its requested limit. Currently, the maximum run time
limit is 7 days.
</pre></div>
</div>
<p>Shorter jobs come with multiple advantages:</p>
<ul class="simple">
<li><p>lower risk of loss of computing time,</p></li>
<li><p>shorter waiting time for scheduling,</p></li>
<li><p>higher job fluctuation; thus, jobs with high priorities may start faster.</p></li>
</ul>
<p>To bring down the percentage of long running jobs we restrict the number of cores with jobs longer
than 2 days to approximately 50% and with jobs longer than 24 to 75% of the total number of cores.
(These numbers are subject to change.) As best practice we advise a run time of about 8h.</p>
<p>!!! hint ‚ÄúPlease always try to make a good estimation of your needed time limit.‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>For this, you can use a command line like this to compare the requested timelimit with the
elapsed time for your completed jobs that started after a given date:

```console
marie@login$ sacct -X -S 2021-01-01 -E now --format=start,JobID,jobname,elapsed,timelimit -s COMPLETED
```
</pre></div>
</div>
<p>Instead of running one long job, you should split it up into a chain job. Even applications that are
not capable of checkpoint/restart can be adapted. Please refer to the section
<span class="xref myst">Checkpoint/Restart</span> for further documentation.</p>
</section>
<section id="id39">
<h2>Memory Limits<a class="headerlink" href="#id39" title="Permalink to this heading">#</a></h2>
<p>!!! note ‚ÄúMemory limits are enforced.‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Jobs which exceed their per-node memory limit are killed automatically by the batch system.
</pre></div>
</div>
<p>Memory requirements for your job can be specified via the <code class="docutils literal notranslate"><span class="pre">sbatch/srun</span></code> parameters:</p>
<p><code class="docutils literal notranslate"><span class="pre">--mem-per-cpu=&lt;MB&gt;</span></code> or <code class="docutils literal notranslate"><span class="pre">--mem=&lt;MB&gt;</span></code> (which is ‚Äúmemory per node‚Äù). The <strong>default limit</strong> regardless
of the partition it runs on is quite low at <strong>300 MB</strong> per CPU. If you need more memory, you need
to request it.</p>
<p>ZIH systems comprise different sets of nodes with different amount of installed memory which affect
where your job may be run. To achieve the shortest possible waiting time for your jobs, you should
be aware of the limits shown in the
<span class="xref myst">Slurm resource limits table</span>.</p>
</section>
<section id="slurm-resource-limits-table">
<h2>Slurm Resource Limits Table<a class="headerlink" href="#slurm-resource-limits-table" title="Permalink to this heading">#</a></h2>
<p>The physical installed memory might differ from the amount available for Slurm jobs. One reason are
so-called diskless compute nodes, i.e., nodes without additional local drive. At these nodes, the
operating system and other components reside in the main memory, lowering the available memory for
jobs. The reserved amount of memory for the system operation might vary slightly over time. The
following table depicts the resource limits for <span class="xref myst">all our HPC systems</span>.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>HPC System</p></th>
<th class="head text-left"><p>Nodes</p></th>
<th class="head text-right"><p># Nodes</p></th>
<th class="head text-right"><p>Cores per Node</p></th>
<th class="head text-right"><p>Threads per Core</p></th>
<th class="head text-right"><p>Memory per Node [in MB]</p></th>
<th class="head text-right"><p>Memory per (SMT) Core [in MB]</p></th>
<th class="head text-right"><p>GPUs per Node</p></th>
<th class="head text-right"><p>Cores per GPU</p></th>
<th class="head text-right"><p>Job Max Time [in days]</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Capella</span></code></span></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">c[1-144].capella</span></code></p></td>
<td class="text-right"><p>144</p></td>
<td class="text-right"><p>56</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>768,000</p></td>
<td class="text-right"><p>13,438</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-right"><p>14</p></td>
<td class="text-right"><p>1</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Barnard</span></code></span></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">n[1001-1630].barnard</span></code></p></td>
<td class="text-right"><p>630</p></td>
<td class="text-right"><p>104</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>515,000</p></td>
<td class="text-right"><p>4,951</p></td>
<td class="text-right"><p>-</p></td>
<td class="text-right"><p>-</p></td>
<td class="text-right"><p>unlimited</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Alpha</span> <span class="pre">Centauri</span></code></span></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">i[8001-8037].alpha</span></code></p></td>
<td class="text-right"><p>37</p></td>
<td class="text-right"><p>48</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>990,000</p></td>
<td class="text-right"><p>10,312</p></td>
<td class="text-right"><p>8</p></td>
<td class="text-right"><p>6</p></td>
<td class="text-right"><p>unlimited</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Julia</span></code></span></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">julia</span></code></p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>896</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>48,390,000</p></td>
<td class="text-right"><p>54,006</p></td>
<td class="text-right"><p>-</p></td>
<td class="text-right"><p>-</p></td>
<td class="text-right"><p>unlimited</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Romeo</span></code></span></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">i[7001-7186].romeo</span></code></p></td>
<td class="text-right"><p>186</p></td>
<td class="text-right"><p>128</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>505,000</p></td>
<td class="text-right"><p>1,972</p></td>
<td class="text-right"><p>-</p></td>
<td class="text-right"><p>-</p></td>
<td class="text-right"><p>unlimited</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Power9</span></code></span></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">ml[1-29].power9</span></code></p></td>
<td class="text-right"><p>29</p></td>
<td class="text-right"><p>44</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-right"><p>254,000</p></td>
<td class="text-right"><p>1,443</p></td>
<td class="text-right"><p>6</p></td>
<td class="text-right"><p>-</p></td>
<td class="text-right"><p>unlimited</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>{: summary=‚ÄùSlurm resource limits table‚Äù align=‚Äùbottom‚Äù}</p></td>
<td class="text-left"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
</tr>
</tbody>
</table>
<p>All HPC systems have Simultaneous Multithreading (SMT) enabled. You request for this
additional threads using the Slurm option <code class="docutils literal notranslate"><span class="pre">--hint=multithread</span></code> or by setting the environment
variable <code class="docutils literal notranslate"><span class="pre">SLURM_HINT=multithread</span></code>. Besides the usage of the threads to speed up the computations,
the memory of the other threads is allocated implicitly, too, and you will always get
<code class="docutils literal notranslate"><span class="pre">Memory</span> <span class="pre">per</span> <span class="pre">Core</span></code>*<code class="docutils literal notranslate"><span class="pre">number</span> <span class="pre">of</span> <span class="pre">threads</span></code> as memory pledge.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="quick-start">
<h1>Quick Start<a class="headerlink" href="#quick-start" title="Permalink to this heading">#</a></h1>
<p>This page will give new users guidance through the steps needed to submit a High Performance
Computing (HPC) job:</p>
<ul class="simple">
<li><p>Applying for the ZIH HPC login</p></li>
<li><p>Accessing the ZIH HPC systems</p></li>
<li><p>Transferring code/data to ZIH HPC systems</p></li>
<li><p>Accessing software</p></li>
<li><p>Running a parallel HPC job</p></li>
</ul>
<section id="introductory-instructions">
<h2>Introductory Instructions<a class="headerlink" href="#introductory-instructions" title="Permalink to this heading">#</a></h2>
<p>The ZIH HPC systems are Linux systems (as most HPC systems). Basic Linux knowledge will
be needed. Being familiar with this <a class="reference external" href="https://hpc-wiki.info/hpc/Shell">collection</a>
of the most important Linux commands is helpful.</p>
<p>To work on the ZIH HPC systems and to follow the instructions on this page as well as other
compendium pages, it is important to be familiar with the
<a class="reference external" href="https://hpc-wiki.info/hpc/HPC-Dictionary">basic terminology</a> in HPC such as
<a class="reference external" href="https://hpc-wiki.info/hpc/SSH">SSH</a>, <a class="reference external" href="https://hpc-wiki.info/hpc/HPC-Dictionary#Cluster">cluster</a>,
<a class="reference external" href="https://hpc-wiki.info/hpc/HPC-Dictionary#Login_Node">login node</a>,
<a class="reference external" href="https://hpc-wiki.info/hpc/HPC-Dictionary#Backend_Node">compute node</a>,
<a class="reference external" href="https://hpc-wiki.info/hpc/HPC-Dictionary#File_System">local and shared filesystem</a>,
<a class="reference external" href="https://hpc-wiki.info/hpc/Shell">command line (CLI) or shell</a>.</p>
<p>If you are new to HPC, we recommend visiting the introductory article about HPC at
<a class="reference external" href="https://hpc-wiki.info/hpc/Getting_Started">https://hpc-wiki.info/hpc/Getting_Started</a>.</p>
<p>Throughout the compendium, <code class="docutils literal notranslate"><span class="pre">marie&#64;login</span></code> is used as an indication of working on the ZIH HPC command
line and <code class="docutils literal notranslate"><span class="pre">marie&#64;local</span></code> as working on your local machine‚Äôs command line. <code class="docutils literal notranslate"><span class="pre">marie</span></code> stands-in for your
username.</p>
</section>
<section id="obtaining-access">
<h2>Obtaining Access<a class="headerlink" href="#obtaining-access" title="Permalink to this heading">#</a></h2>
<p>A ZIH HPC login is needed to use the systems. It is different from the ZIH login (which
members of the TU Dresden have), but has the same credentials. Apply for it via the
<a class="reference external" href="https://selfservice.zih.tu-dresden.de/index.php/hpclogin/noLogin">HPC login application form</a>.</p>
<p>Since HPC is structured in projects, there are two possibilities to work on the ZIH HPC systems:</p>
<ul class="simple">
<li><p>Creating a
<a class="reference external" href="https://tu-dresden.de/zih/hochleistungsrechnen/zugang/projektantrag#section-3">new project</a></p></li>
<li><p>Joining an existing project: e.g. new researchers in an existing project, students in projects for
teaching purposes. The details will be provided to you by the project administrator.</p></li>
</ul>
<p>A HPC project on the ZIH HPC systems includes: a project directory, project group, project members
(at least admin and manager), and resource quotas for compute time (CPU/GPU hours) and storage.</p>
<p>It is essential to grant appropriate file permissions so that newly added users can access a
project appropriately.</p>
</section>
<section id="accessing-zih-hpc-systems">
<h2>Accessing ZIH HPC Systems<a class="headerlink" href="#accessing-zih-hpc-systems" title="Permalink to this heading">#</a></h2>
<p>ZIH provides five homogeneous compute systems, called clusters. These can only be accessed
within the TU Dresden campus networks. Access from outside is possible by establishing a
<a class="reference external" href="https://tu-dresden.de/zih/dienste/service-katalog/arbeitsumgebung/zugang_datennetz/vpn#section-4">VPN connection</a>.
Each of these clusters can be accessed in the three ways described below, depending on the user‚Äôs
needs and previous knowledge:</p>
<ul class="simple">
<li><p><span class="xref myst">JupyterHub</span>: browser based connection, easiest way for beginners</p></li>
<li><p><span class="xref myst">SSH connection</span> (command line/terminal/console): ‚Äúclassical‚Äù connection,
command line knowledge is required</p></li>
<li><p><span class="xref myst">Desktop Visualization</span>,
<span class="xref myst">Graphical User Interfaces (GUIs)</span> and similar:
e.g. commercial software such as Ansys, LS-DYNA (are not covered here).</p></li>
</ul>
<p>Next, the mentioned access methods are described step by step.</p>
<section id="id40">
<h3>JupyterHub<a class="headerlink" href="#id40" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Access JupyterHub at
<a class="reference external" href="https://jupyterhub.hpc.tu-dresden.de">https://jupyterhub.hpc.tu-dresden.de</a>.</p></li>
<li><p>Log in with your ZIH-login credentials.</p></li>
<li><p>Choose a profile (system and resources):
<img alt="Simple form" src="63_chat_with_docs/misc/jupyterhub-spawner-options.jpg" />
{: align=‚Äùcenter‚Äù}</p></li>
<li><p>You will see the following - wait until resources are allocated:
<img alt="Spawning" src="63_chat_with_docs/misc/jupyterhub-spawning.jpg" /></p></li>
<li><p>Once JupyterLab is loaded, you will see all available kernels on the system you chose,
categorized by <code class="docutils literal notranslate"><span class="pre">Notebook</span></code>, <code class="docutils literal notranslate"><span class="pre">Console</span></code> and <code class="docutils literal notranslate"><span class="pre">Other</span></code>, with which you can start right away. If you miss
software packages that you wish to use, you can
<span class="xref myst">build your own environment and jupyter kernel</span>.
Note that you will now be working in your home directory as opposed to a specific workspace
(see <span class="xref myst">Data Management and Data Transfer</span>
section below for more details).</p></li>
</ol>
<p>!!! caution ‚ÄúStopping your Jupyter session‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Once you are done, you have to explicitly stop the Jupyter session by clicking
`File` &amp;#8594 `Hub Control Panel` &amp;#8594 `Stop My Server`.
Otherwise it will run for the amount of hours you chose with the spawning profile.
Logging out will not stop your server.
</pre></div>
</div>
<p>Explore the <span class="xref myst">JupyterHub</span> page for more information.</p>
</section>
<section id="ssh-connection-command-line">
<h3>SSH Connection (Command Line)<a class="headerlink" href="#ssh-connection-command-line" title="Permalink to this heading">#</a></h3>
<p>The more ‚Äúclassical‚Äù way to work with HPC is based on the command line. After following
the instructions below, you will be on one of the login nodes.
This is the starting point for many tasks such as launching jobs and doing data management.</p>
<p>!!! hint ‚ÄúUsing SSH key pair‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>We recommend to create an SSH key pair by following the
[instructions here](../access/ssh_login.md#before-your-first-connection).
Using an SSH key pair is beneficial for security reasons, although it is not necessary to work
with ZIH HPC systems.
</pre></div>
</div>
<p>=== ‚ÄúWindows 10 and higher/Mac/Linux users‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Windows users might need to install [Windows Terminal](https://www.microsoft.com/en-us/p/windows-terminal/9n0dx20hk701?activetab=pivot:overviewtab).

1. Open a terminal/shell/console and type in
```console
marie@local$ ssh marie@login2.barnard.hpc.tu-dresden.de
```

1. After typing in your password, you end up seeing something like the following image.

![Successful SSH login](misc/ssh-success-login.png)
{: align=&quot;center&quot;}
</pre></div>
</div>
<p>=== ‚ÄúUsers of older versions of Windows‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Install and set up [MobaXTerm](../access/ssh_mobaxterm.md) or [PuTTY](../access/ssh_putty.md).
</pre></div>
</div>
<p>For more information explore the <span class="xref myst">access compendium page</span>.
<span class="xref myst">Configuring default parameters</span>
makes connecting more comfortable.</p>
</section>
</section>
<section id="data-transfer-and-data-management">
<h2>Data Transfer and Data Management<a class="headerlink" href="#data-transfer-and-data-management" title="Permalink to this heading">#</a></h2>
<p>First, it is shown how to create a workspace, then how to transfer data within and to/from the ZIH
HPC system. Also keep in mind to set the file permissions when collaborating with other researchers.</p>
<section id="create-a-workspace">
<h3>Create a Workspace<a class="headerlink" href="#create-a-workspace" title="Permalink to this heading">#</a></h3>
<p>There are different places for storing your data on ZIH HPC systems, called <span class="xref myst">Filesystems</span>.
You need to create a <span class="xref myst">workspace</span> for your data on one of these
(see example below).</p>
<p>The filesystems have different <span class="xref myst">properties</span> (available space,
storage time limit, permission rights). Therefore, choose the one that fits your project best.
To start we recommend the Lustre filesystem <strong>horse</strong>.</p>
<p>!!! example ‚ÄúCreating a workspace on Lustre filesystem horse‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The following command creates a workspace

```console
marie@login$ ws_allocate -F horse -r 7 -m marie@tu-dresden.de -n number_crunch -d 90
Info: creating workspace.
/data/horse/ws/marie-number_crunch
remaining extensions  : 10
remaining time in days: 90
```

To explain:

- `ws_allocate` - command to allocate
- `-F horse` - on the horse filesystem
- `-r 7 -m marie@tu-dresden.de` - send a reminder to `marie@tu-dresden.de` 7 days before expiration
- `-n number_crunch` - workspace name
- `-d 90` - a life time of 90 days

The path to this workspace is `/data/horse/ws/marie-number_crunch`. You will need it when
transferring data or running jobs.
</pre></div>
</div>
<p>Find more <span class="xref myst">information on workspaces in the compendium</span>.</p>
</section>
<section id="transferring-data-within-zih-hpc-systems">
<h3>Transferring Data <em>Within</em> ZIH HPC Systems<a class="headerlink" href="#transferring-data-within-zih-hpc-systems" title="Permalink to this heading">#</a></h3>
<p>The approach depends on the data volume: up to 100 MB or above.</p>
<p>???+ example ‚Äú<code class="docutils literal notranslate"><span class="pre">cp</span></code>/<code class="docutils literal notranslate"><span class="pre">mv</span></code> for small data (up to 100 MB)‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Use the command `cp` to copy the file `example.R` from your ZIH home directory to a workspace:

 ```console
 marie@login$ cp /home/marie/example.R /data/horse/ws/marie-number_crunch
 ```

Analogously use command `mv` to move a file.

Find more examples for the `cp` command on [bropages.org](http://bropages.org/cp) or use
manual pages with `man cp`.
</pre></div>
</div>
<p>???+ example ‚Äú<code class="docutils literal notranslate"><span class="pre">dtcp</span></code>/<code class="docutils literal notranslate"><span class="pre">dtmv</span></code> for medium to large data (above 100 MB)‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Use the command `dtcp` to copy the directory `/walrus/ws/large-dataset` from one
filesystem location to another:

```console
marie@login$ dtcp -r /walrus/ws/large-dataset /data/horse/ws/marie-number_crunch/data
```
Analogously use the command `dtmv` to move a file or folder.

More details on the [datamover](../data_transfer/datamover.md) are available in the data
transfer section.
</pre></div>
</div>
</section>
<section id="transferring-data-to-from-zih-hpc-systems">
<h3>Transferring Data <em>To/From</em> ZIH HPC Systems<a class="headerlink" href="#transferring-data-to-from-zih-hpc-systems" title="Permalink to this heading">#</a></h3>
<p>???+ example ‚Äú<code class="docutils literal notranslate"><span class="pre">scp</span></code> for transferring data to ZIH HPC systems‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Copy the file `example.R` from your local machine to a workspace on the ZIH systems:

```console
marie@local$ scp /home/marie/Documents/example.R marie@dataport1.hpc.tu-dresden.de:/data/horse/ws/marie-number_crunch/
Password:
example.R                                                     100%  312    32.2KB/s   00:00
```

Note, the target path contains `dataport1.hpc.tu-dresden.de`, which is one of the
so called [dataport nodes](../data_transfer/dataport_nodes.md) that allows for data transfer
from/to the outside.
</pre></div>
</div>
<p>???+ example ‚Äú<code class="docutils literal notranslate"><span class="pre">scp</span></code> to transfer data from ZIH HPC systems to local machine‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Copy the file `results.csv` from a workspace on the ZIH HPC systems to your local machine:

```console
marie@local$ scp marie@dataport1.hpc.tu-dresden.de:/data/horse/ws/marie-number_crunch/results.csv /home/marie/Documents/
```

Feel free to explore further [examples](http://bropages.org/scp) of the `scp` command
and possibilities of the [dataport nodes](../data_transfer/dataport_nodes.md).
</pre></div>
</div>
<p>!!! caution ‚ÄúTerabytes of data‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you are planning to move terabytes or even more from an outside machine into ZIH systems,
please contact the ZIH [HPC support](mailto:hpc-support@tu-dresden.de) in advance.
</pre></div>
</div>
</section>
<section id="permission-rights">
<h3>Permission Rights<a class="headerlink" href="#permission-rights" title="Permalink to this heading">#</a></h3>
<p>Whenever working within a collaborative environment, take care of the file permissions.
Esp. after creating and transferring data, file permission configuration might be necessary.</p>
<p><strong>By default, workspaces are accessible only for the user who created the workspace.</strong>
Files created by a user in the project directory have read-only access for other group members
by default. Therefore, the correct file permissions must be configured (using <code class="docutils literal notranslate"><span class="pre">chmod</span></code>
and <code class="docutils literal notranslate"><span class="pre">chgrp</span></code>) for all files in the project home and the workspaces that should be fully
accessible (read, write, execute) to your collaborator group.
Please refer to an <a class="reference external" href="https://hpc-wiki.info/hpc/Introduction_to_Linux_in_HPC/Users_and_permissions">overview on users and permissions</a>
in Linux.</p>
<p>??? example ‚ÄúChecking and changing file permissions‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The following example checks for file permissions (`ls -la`) of the file dataset.csv and adds
permissions for write access for the group (`chmod g+w`).

```console
marie@login$ ls -la /data/horse/ws/marie-training-data/dataset.csv # list file permissions
-rw-r--r-- 1 marie p_number_crunch 0 12. Jan 15:11 /data/horse/ws/marie-training-data/dataset.csv

marie@login$ chmod g+w /data/horse/ws/marie-training-data/dataset.csv # add write permissions

marie@login$ ls -la /data/horse/ws/marie-training-data/dataset.csv # list file permissions again
-rw-rw-r-- 1 marie p_number_crunch 0 12. Jan 15:11 /data/horse/ws/marie-training-data/dataset.csv
```
</pre></div>
</div>
<p>??? hint ‚ÄúGUI-based data management‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- Transferring data and managing file permissions for smaller amounts of data can be handled
by SSH clients.
- More so for Linux-based systems, `sshfs` (a command-line tool for safely mounting a remote
folder from a server to a local machine) can be used to mount user home, project home or
workspaces within the local folder structure.
Data can be transferred directly with drag and drop in your local file explorer.
Moreover, this approach makes it possible to edit files with your common editors and tools on
the local machine.
- Windows users can use [SFTP Drive](https://www.nsoftware.com/sftp/drive/) utility, to mount
remote filesystems as Windows drives.
</pre></div>
</div>
</section>
</section>
<section id="software-environment">
<h2>Software Environment<a class="headerlink" href="#software-environment" title="Permalink to this heading">#</a></h2>
<p>The <span class="xref myst">software</span> on the ZIH HPC systems is not installed system-wide,
but is provided within so-called <span class="xref myst">modules</span>.
In order to use specific software you need to ‚Äúload‚Äù the respective module.
This modifies the current environment (so only for the current user in the current session)
such that the software becomes available.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Different clusters (HPC systems) have different software or might have different versions of
the same available software. See [software](../software/overview.md) for more details.
</pre></div>
</div>
<p>Use the command <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">spider</span> <span class="pre">&lt;software&gt;</span></code> to check all available versions of a software that is
available on the one specific system you are currently on:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>spider<span class="w"> </span>Python
<span class="go">--------------------------------------------------------------------------------------------------------------------------------</span>
<span class="go">  Python:</span>
<span class="go">--------------------------------------------------------------------------------------------------------------------------------</span>
<span class="go">    Description:</span>
<span class="go">      Python is a programming language that lets you work more quickly and integrate your systems more effectively.</span>

<span class="go">     Versions:</span>
<span class="go">        Python/2.7.14-foss-2018a</span>
<span class="go">        [...]</span>
<span class="go">        Python/3.8.6</span>
<span class="go">        Python/3.9.5-bare</span>
<span class="go">        Python/3.9.5</span>
<span class="go">     Other possible modules matches:</span>
<span class="go">        Biopython  Boost.Python  GitPython  IPython  PythonAnaconda  flatbuffers-python  netcdf4-python  protobuf-python  python</span>

<span class="go">--------------------------------------------------------------------------------------------------------------------------------</span>
<span class="go">  To find other possible module matches execute:</span>

<span class="gp">      $ </span>module<span class="w"> </span>-r<span class="w"> </span>spider<span class="w"> </span><span class="s1">&#39;.*Python.*&#39;</span>

<span class="go">--------------------------------------------------------------------------------------------------------------------------------</span>
<span class="go">  For detailed information about a specific &quot;Python&quot; package (including how to load the modules) use the module&#39;s full name.</span>
<span class="go">  Note that names that have a trailing (E) are extensions provided by other modules.</span>
<span class="go">  For example:</span>

<span class="gp">     $ </span>module<span class="w"> </span>spider<span class="w"> </span>Python/3.9.5
<span class="go">--------------------------------------------------------------------------------------------------------------------------------</span>
</pre></div>
</div>
<p>We now see the list of available Python versions.</p>
<ul class="simple">
<li><p>To get information on a specific module, use <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">spider</span> <span class="pre">&lt;software&gt;/&lt;version&gt;</span></code>:</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>spider<span class="w"> </span>Python/3.9.5
<span class="go">--------------------------------------------------------------------------------------------------------------------------------</span>
<span class="go">  Python: Python/3.9.5</span>
<span class="go">--------------------------------------------------------------------------------------------------------------------------------</span>
<span class="go">    Description:</span>
<span class="go">      Python is a programming language that lets you work more quickly and integrate your systems more effectively.</span>


<span class="go">    You will need to load all module(s) on any one of the lines below before the &quot;Python/3.10.4&quot; module is available to load.</span>

<span class="go">      GCCcore/11.3.0</span>

<span class="go">    This module provides the following extensions:</span>

<span class="go">      alabaster/0.7.12 (E), appdirs/1.4.4 (E), asn1crypto/1.4.0 (E), atomicwrites/1.4.0 (E), attrs/21.2.0 (E), Babel/2.9.1 (E), bcrypt/3.2.0 (E), bitstring/3.1.7 (E), blist/1.3.6 (E), CacheControl/0.12.6 (E), cachy/0.3.0 (E), certifi/2020.12.5 (E), cffi/1.14.5 (E), chardet/4.0.0 (E), cleo/0.8.1 (E), click/7.1.2 (E), clikit/0.6.2 (E), colorama/</span>
<span class="go">      [...]</span>

<span class="go">    Help:</span>
<span class="go">      Description</span>
<span class="go">      ===========</span>
<span class="go">      Python is a programming language that lets you work more quickly and integrate your systems</span>
<span class="go">       more effectively.</span>


<span class="go">      More information</span>
<span class="go">      ================</span>
<span class="go">       - Homepage: https://python.org/</span>


<span class="go">      Included extensions</span>
<span class="go">      ===================</span>
<span class="go">      alabaster-0.7.12, appdirs-1.4.4, asn1crypto-1.4.0, atomicwrites-1.4.0,</span>
<span class="go">      attrs-21.2.0, Babel-2.9.1, bcrypt-3.2.0, bitstring-3.1.7, blist-1.3.6,</span>
<span class="go">      [...]</span>
</pre></div>
</div>
<p>In some cases it is required to load additional modules before loading the desired software.
In the example above, it is <code class="docutils literal notranslate"><span class="pre">GCCcore/11.3.0</span></code>.</p>
<ul class="simple">
<li><p>Load prerequisites and the desired software:</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>GCCcore/11.3.0<span class="w">  </span><span class="c1"># load prerequisites</span>

<span class="go">Module GCCcore/11.3.0 loaded.</span>

<span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>Python/3.9.5<span class="w">   </span><span class="c1"># load desired version of software</span>
<span class="go">Module Python/3.9.5 and 11 dependencies loaded.</span>
</pre></div>
</div>
<p>For additional information refer to the detailed documentation on <span class="xref myst">modules</span>.</p>
<p>!!! hint ‚ÄúSpecial hints on different software‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>See also the section &quot;Applications and Software&quot; for more information on e.g.
[Python](../software/data_analytics_with_python.md),
[R](../software/data_analytics_with_r.md),
[Mathematica/MatLab](../software/mathematics.md), etc.
</pre></div>
</div>
<p>!!! hint ‚ÄúTip for Python packages‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The use of [Virtual Environments](../software/python_virtual_environments.md)
(best in [workspaces](../data_lifecycle/workspaces.md)) is required if you want to install
additional Python packages with `pip`.
When using `pip install` without an activated virtual environment you will get this error:
&gt; ERROR: Could not find an activated virtualenv (required).

Please check the module system, even for specific Python packages,
e.g. `numpy`, `tensorflow` or `pytorch`.
Those modules may provide much better performance than the packages found on PyPi
(installed via `pip`) which have to work on any system while our installation is optimized for
each ZIH system to make the best use of the specific CPUs and GPUs found here.
However the Python package ecosystem (like others) is very heterogeneous and dynamic,
with daily updates.
The central update cycle for software on ZIH HPC systems is approximately every six months.
So the software installed as modules might be a bit older.
</pre></div>
</div>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>When explicitely loading multiple modules you need to make sure that they are compatible.
So try to stick to modules using the same toolchain.
See the [Toolchains section](../software/modules.md#toolchains) for more information.
</pre></div>
</div>
</section>
<section id="running-a-program-job">
<h2>Running a Program/Job<a class="headerlink" href="#running-a-program-job" title="Permalink to this heading">#</a></h2>
<p>At HPC systems, computational work and resource requirements are encapsulated into so-called jobs.
Since all computational resources are shared with other users, these resources need to be
allocated. For managing these allocations a so-called job scheduler or a batch system is used -
on ZIH systems this is <a class="reference external" href="https://slurm.schedmd.com/quickstart.html">Slurm</a>.
It is possible to run a job <span class="xref myst">interactively</span>
(real time execution) or to submit it as a <span class="xref myst">batch job</span>
(scheduled execution).</p>
<p>For beginners, we highly advise to run the job interactively. To do so, use the <code class="docutils literal notranslate"><span class="pre">srun</span></code> command
on any of the ZIH HPC clusters (systems).
For this <code class="docutils literal notranslate"><span class="pre">srun</span></code> command, it is possible to define options like the number of tasks (<code class="docutils literal notranslate"><span class="pre">--ntasks</span></code>),
number of CPUs per task (<code class="docutils literal notranslate"><span class="pre">--cpus-per-task</span></code>),
the amount of time you would like to keep this interactive session open (<code class="docutils literal notranslate"><span class="pre">--time</span></code>), memory per
CPU (<code class="docutils literal notranslate"><span class="pre">--mem-per-cpu</span></code>) and many others.
See <span class="xref myst">Slurm documentation</span> for more details.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>srun<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">4</span><span class="w"> </span>--time<span class="o">=</span><span class="m">1</span>:00:00<span class="w"> </span>--mem-per-cpu<span class="o">=</span><span class="m">1700</span><span class="w"> </span>--pty<span class="w"> </span>bash<span class="w"> </span>-l<span class="w"> </span><span class="c1">#allocate 4 cores for the interactive job</span>
<span class="gp">marie@compute$ </span>module<span class="w"> </span>load<span class="w"> </span>Python<span class="w"> </span><span class="c1">#load necessary packages</span>
<span class="gp">marie@compute$ </span><span class="nb">cd</span><span class="w"> </span>/data/horse/ws/marie-number_crunch/<span class="w"> </span><span class="c1">#go to your created workspace</span>
<span class="gp">marie@compute$ </span>python<span class="w"> </span>test.py<span class="w"> </span><span class="c1">#execute your file</span>
<span class="go">Hello, World!</span>
</pre></div>
</div>
<p>For more information, follow the <span class="xref myst">interactive jobs</span>
or the <span class="xref myst">batch job</span> documentation.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="big-data-analytics">
<h1>Big Data Analytics<a class="headerlink" href="#big-data-analytics" title="Permalink to this heading">#</a></h1>
<p><a class="reference external" href="https://spark.apache.org/">Apache Spark</a>, <a class="reference external" href="https://flink.apache.org/">Apache Flink</a>
and <a class="reference external" href="https://hadoop.apache.org/">Apache Hadoop</a> are frameworks for processing and integrating
Big Data.
These frameworks are also offered as software <span class="xref myst">modules</span>.
You can check module versions and availability with the command</p>
<p>=== ‚ÄúSpark‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;login$</span> <span class="pre">module</span> <span class="pre">avail</span> <span class="pre">Spark</span>&#160;&#160;&#160;&#160; </code>
=== ‚ÄúFlink‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;login$</span> <span class="pre">module</span> <span class="pre">avail</span> <span class="pre">Flink</span>&#160;&#160;&#160;&#160; </code></p>
<p><strong>Prerequisites:</strong> To work with the frameworks, you need <span class="xref myst">access</span> to ZIH
systems and basic knowledge about data analysis and the batch system
<span class="xref myst">Slurm</span>.</p>
<p>The usage of Big Data frameworks is different from other modules due to their master-worker
approach. That means, before an application can be started, one has to do additional steps.
In the following, we assume that a Spark application should be started and give alternative
commands for Flink where applicable.</p>
<p>The steps are:</p>
<ol class="arabic simple">
<li><p>Load the Spark software module</p></li>
<li><p>Configure the Spark cluster</p></li>
<li><p>Start a Spark cluster</p></li>
<li><p>Start the Spark application</p></li>
</ol>
<p>Apache Spark can be used in <span class="xref myst">interactive</span> and <span class="xref myst">batch</span> jobs as well
as via <span class="xref myst">Jupyter notebooks</span>. All three ways are outlined in the following.</p>
<section id="id41">
<h2>Interactive Jobs<a class="headerlink" href="#id41" title="Permalink to this heading">#</a></h2>
<section id="default-configuration">
<h3>Default Configuration<a class="headerlink" href="#default-configuration" title="Permalink to this heading">#</a></h3>
<p>The Spark and Flink modules are available in the <code class="docutils literal notranslate"><span class="pre">power</span></code> environment.
Thus, Spark and Flink can be executed using different CPU architectures, e.g., Power.</p>
<p>Let us assume that two nodes should be used for the computation. Use a <code class="docutils literal notranslate"><span class="pre">srun</span></code> command similar to
the following to start an interactive session. The following code
snippet shows a job submission with an allocation of two nodes with 60000 MB main
memory exclusively for one hour:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login.power$ </span>srun<span class="w"> </span>--nodes<span class="o">=</span><span class="m">2</span><span class="w"> </span>--mem<span class="o">=</span>60000M<span class="w"> </span>--exclusive<span class="w"> </span>--time<span class="o">=</span><span class="m">01</span>:00:00<span class="w"> </span>--pty<span class="w"> </span>bash<span class="w"> </span>-l
</pre></div>
</div>
<p>Once you have the shell, load desired Big Data framework using the command</p>
<p>=== ‚ÄúSpark‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">module</span> <span class="pre">load</span> <span class="pre">Spark</span>&#160;&#160;&#160;&#160; </code>
=== ‚ÄúFlink‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">module</span> <span class="pre">load</span> <span class="pre">Flink</span>&#160;&#160;&#160;&#160; </code></p>
<p>Before the application can be started, the cluster with the allocated nodes needs to be set up. To
do this, configure the cluster first using the configuration template at <code class="docutils literal notranslate"><span class="pre">$SPARK_HOME/conf</span></code> for
Spark or <code class="docutils literal notranslate"><span class="pre">$FLINK_ROOT_DIR/conf</span></code> for Flink:</p>
<p>=== ‚ÄúSpark‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">source</span> <span class="pre">framework-configure.sh</span> <span class="pre">spark</span> <span class="pre">$SPARK_HOME/conf</span>&#160;&#160;&#160;&#160; </code>
=== ‚ÄúFlink‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">source</span> <span class="pre">framework-configure.sh</span> <span class="pre">flink</span> <span class="pre">$FLINK_ROOT_DIR/conf</span>&#160;&#160;&#160;&#160; </code></p>
<p>This places the configuration in a directory called <code class="docutils literal notranslate"><span class="pre">cluster-conf-&lt;JOB_ID&gt;</span></code> in your home directory,
where <code class="docutils literal notranslate"><span class="pre">&lt;JOB_ID&gt;</span></code> stands for the id of the Slurm job. After that, you can start in
the usual way:</p>
<p>=== ‚ÄúSpark‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">start-all.sh</span>&#160;&#160;&#160;&#160; </code>
=== ‚ÄúFlink‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">start-cluster.sh</span>&#160;&#160;&#160;&#160; </code></p>
<p>The necessary background processes should now be set up and you can start your application, e. g.:</p>
<p>=== ‚ÄúSpark‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">spark-submit</span> <span class="pre">--class</span> <span class="pre">org.apache.spark.examples.SparkPi</span> <span class="pre">\</span>&#160;&#160;&#160;&#160; <span class="pre">$SPARK_HOME/examples/jars/spark-examples_2.12-3.0.1.jar</span> <span class="pre">1000</span>&#160;&#160;&#160;&#160; </code>
=== ‚ÄúFlink‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">flink</span> <span class="pre">run</span> <span class="pre">$FLINK_ROOT_DIR/examples/batch/KMeans.jar</span>&#160;&#160;&#160;&#160; </code></p>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Do not delete the directory `cluster-conf-&lt;JOB_ID&gt;` while the job is still
running. This leads to errors.
</pre></div>
</div>
</section>
<section id="custom-configuration">
<h3>Custom Configuration<a class="headerlink" href="#custom-configuration" title="Permalink to this heading">#</a></h3>
<p>The script <code class="docutils literal notranslate"><span class="pre">framework-configure.sh</span></code> is used to derive a configuration from a template. It takes two
parameters:</p>
<ul class="simple">
<li><p>The framework to set up (parameter <code class="docutils literal notranslate"><span class="pre">spark</span></code> for Spark, <code class="docutils literal notranslate"><span class="pre">flink</span></code> for Flink, and <code class="docutils literal notranslate"><span class="pre">hadoop</span></code> for Hadoop)</p></li>
<li><p>A configuration template</p></li>
</ul>
<p>Thus, you can modify the configuration by replacing the default configuration template with a
customized one. This way, your custom configuration template is reusable for different jobs. You
can start with a copy of the default configuration ahead of your interactive session:</p>
<p>=== ‚ÄúSpark‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;login.power$</span> <span class="pre">cp</span> <span class="pre">-r</span> <span class="pre">$SPARK_HOME/conf</span> <span class="pre">my-config-template</span>&#160;&#160;&#160;&#160; </code>
=== ‚ÄúFlink‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;login.power$</span> <span class="pre">cp</span> <span class="pre">-r</span> <span class="pre">$FLINK_ROOT_DIR/conf</span> <span class="pre">my-config-template</span>&#160;&#160;&#160;&#160; </code></p>
<p>After you have changed <code class="docutils literal notranslate"><span class="pre">my-config-template</span></code>, you can use your new template in an interactive job
with:</p>
<p>=== ‚ÄúSpark‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">source</span> <span class="pre">framework-configure.sh</span> <span class="pre">spark</span> <span class="pre">my-config-template</span>&#160;&#160;&#160;&#160; </code>
=== ‚ÄúFlink‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">source</span> <span class="pre">framework-configure.sh</span> <span class="pre">flink</span> <span class="pre">my-config-template</span>&#160;&#160;&#160;&#160; </code></p>
</section>
<section id="using-hadoop-distributed-filesystem-hdfs">
<h3>Using Hadoop Distributed Filesystem (HDFS)<a class="headerlink" href="#using-hadoop-distributed-filesystem-hdfs" title="Permalink to this heading">#</a></h3>
<p>If you want to use Spark and HDFS together (or in general more than one framework), a scheme
similar to the following can be used:</p>
<p>=== ‚ÄúSpark‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">module</span> <span class="pre">load</span> <span class="pre">Hadoop</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">module</span> <span class="pre">load</span> <span class="pre">Spark</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">source</span> <span class="pre">framework-configure.sh</span> <span class="pre">hadoop</span> <span class="pre">$HADOOP_ROOT_DIR/etc/hadoop</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">source</span> <span class="pre">framework-configure.sh</span> <span class="pre">spark</span> <span class="pre">$SPARK_HOME/conf</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">start-dfs.sh</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">start-all.sh</span>&#160;&#160;&#160;&#160; </code>
=== ‚ÄúFlink‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">module</span> <span class="pre">load</span> <span class="pre">Hadoop</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">module</span> <span class="pre">load</span> <span class="pre">Flink</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">source</span> <span class="pre">framework-configure.sh</span> <span class="pre">hadoop</span> <span class="pre">$HADOOP_ROOT_DIR/etc/hadoop</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">source</span> <span class="pre">framework-configure.sh</span> <span class="pre">flink</span> <span class="pre">$FLINK_ROOT_DIR/conf</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">start-dfs.sh</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">start-cluster.sh</span>&#160;&#160;&#160;&#160; </code></p>
</section>
</section>
<section id="id42">
<h2>Batch Jobs<a class="headerlink" href="#id42" title="Permalink to this heading">#</a></h2>
<p>Using <code class="docutils literal notranslate"><span class="pre">srun</span></code> directly on the shell blocks the shell and launches an interactive job. Apart from
short test runs, it is <strong>recommended to launch your jobs in the background using batch jobs</strong>. For
that, you can conveniently put the parameters directly into the job file and submit it via
<code class="docutils literal notranslate"><span class="pre">sbatch</span> <span class="pre">[options]</span> <span class="pre">&lt;job</span> <span class="pre">file&gt;</span></code>.</p>
<p>Please use a <span class="xref myst">batch job</span> with a configuration, similar to the
example below:</p>
<p>??? example ‚Äúexample-starting-script.sbatch‚Äù
=== ‚ÄúSpark‚Äù
```bash
#!/bin/bash -l
#SBATCH ‚Äìtime=01:00:00
#SBATCH ‚Äìnodes=2
#SBATCH ‚Äìexclusive
#SBATCH ‚Äìmem=60000M
#SBATCH ‚Äìjob-name=‚Äùexample-spark‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    module load Spark/3.0.1-Hadoop-2.7-Java-1.8-Python-3.7.4-GCCcore-8.3.0

    function myExitHandler () {
        stop-all.sh
    }

    #configuration
    . framework-configure.sh spark $SPARK_HOME/conf

    #register cleanup hook in case something goes wrong
    trap myExitHandler EXIT

    start-all.sh

    spark-submit --class org.apache.spark.examples.SparkPi $SPARK_HOME/examples/jars/spark-examples_2.12-3.0.1.jar 1000

    stop-all.sh

    exit 0
    ```
=== &quot;Flink&quot;
    ```bash
    #!/bin/bash -l
    #SBATCH --time=01:00:00
    #SBATCH --nodes=2
    #SBATCH --exclusive
    #SBATCH --mem=60000M
    #SBATCH --job-name=&quot;example-flink&quot;

    module load Flink/1.12.3-Java-1.8.0_161-OpenJDK-Python-3.7.4-GCCcore-8.3.0

    function myExitHandler () {
        stop-cluster.sh
    }

    #configuration
    . framework-configure.sh flink $FLINK_ROOT_DIR/conf

    #register cleanup hook in case something goes wrong
    trap myExitHandler EXIT

    #start the cluster
    start-cluster.sh

    #run your application
    flink run $FLINK_ROOT_DIR/examples/batch/KMeans.jar

    #stop the cluster
    stop-cluster.sh

    exit 0
    ```
</pre></div>
</div>
</section>
<section id="jupyter-notebook">
<h2>Jupyter Notebook<a class="headerlink" href="#jupyter-notebook" title="Permalink to this heading">#</a></h2>
<p>You can run Jupyter notebooks with Spark and Flink on the ZIH systems in a similar way as described
on the <span class="xref myst">JupyterHub</span> page.</p>
<section id="spawning-a-notebook">
<h3>Spawning a Notebook<a class="headerlink" href="#spawning-a-notebook" title="Permalink to this heading">#</a></h3>
<p>Go to <a class="reference external" href="https://jupyterhub.hpc.tu-dresden.de">https://jupyterhub.hpc.tu-dresden.de</a>.
In the tab ‚ÄúAdvanced‚Äù, go to the field ‚ÄúPreload modules‚Äù and select the following Spark or Flink
module:</p>
<p>=== ‚ÄúSpark‚Äù
<code class="docutils literal notranslate">&#160;&#160;&#160; <span class="pre">Spark/3.0.1-Hadoop-2.7-Java-1.8-Python-3.7.4-GCCcore-8.3.0</span>&#160;&#160;&#160; </code>
=== ‚ÄúFlink‚Äù
<code class="docutils literal notranslate">&#160;&#160;&#160; <span class="pre">Flink/1.12.3-Java-1.8.0_161-OpenJDK-Python-3.7.4-GCCcore-8.3.0</span>&#160;&#160;&#160; </code></p>
<p>When your Jupyter instance is started, you can set up Spark/Flink. Since the setup in the notebook
requires more steps than in an interactive session, we have created example notebooks that you can
use as a starting point for convenience: <span class="xref myst">SparkExample.ipynb</span>,
<span class="xref myst">FlinkExample.ipynb</span></p>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The notebooks only work with the Spark or Flink module mentioned above. When using other
Spark/Flink modules, it is possible that you have to do additional or other steps in order to
make Spark/Flink running.
</pre></div>
</div>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>You could work with simple examples in your home directory, but, according to the
[storage concept](../data_lifecycle/overview.md), **please use
[workspaces](../data_lifecycle/workspaces.md) for your study and work projects**. For this
reason, you have to use advanced options of Jupyterhub and put &quot;/&quot; in &quot;Workspace scope&quot; field.
</pre></div>
</div>
</section>
</section>
<section id="faq">
<h2>FAQ<a class="headerlink" href="#faq" title="Permalink to this heading">#</a></h2>
<p>Q: Command <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">framework-configure.sh</span> <span class="pre">hadoop</span> <span class="pre">$HADOOP_ROOT_DIR/etc/hadoop</span></code> gives the output:
<code class="docutils literal notranslate"><span class="pre">bash:</span> <span class="pre">framework-configure.sh:</span> <span class="pre">No</span> <span class="pre">such</span> <span class="pre">file</span> <span class="pre">or</span> <span class="pre">directory</span></code>. How can this be resolved?</p>
<p>A: Please try to re-submit or re-run the job and if that doesn‚Äôt help re-login to the ZIH system.</p>
<p>Q: There are a lot of errors and warnings during the set up of the session</p>
<p>A: Please check the work capability on a simple example as shown in this documentation.</p>
<p>!!! help</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you have questions or need advice, please use the contact form on
[https://scads.ai/about-us/](https://scads.ai/about-us/) or contact the HPC support.
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="building-software">
<h1>Building Software<a class="headerlink" href="#building-software" title="Permalink to this heading">#</a></h1>
<p>While it is possible to do short compilations on the login nodes, it is generally considered good
practice to use a job for that, especially when using many parallel make processes. Since 2016,
the <code class="docutils literal notranslate"><span class="pre">/projects</span></code> filesystem is mounted read-only on all compute
nodes in order to prevent users from doing large I/O there (which is what the <code class="docutils literal notranslate"><span class="pre">/data/horse</span></code> is for).
In consequence, you cannot compile in <code class="docutils literal notranslate"><span class="pre">/projects</span></code> within a job. If you wish to install
software for your project group anyway, you can use a build directory in the <code class="docutils literal notranslate"><span class="pre">/data/horse</span></code> filesystem
instead.</p>
<p>Every sane build system should allow you to keep your source code tree and your build directory
separate, some even demand them to be different directories. Plus, you can set your installation
prefix (the target directory) back to your <code class="docutils literal notranslate"><span class="pre">/projects</span></code> folder and do the ‚Äúmake install‚Äù step on the
login nodes.</p>
<p>For instance, when using CMake and keeping your source in <code class="docutils literal notranslate"><span class="pre">/projects</span></code>, you could do the following:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>save<span class="w"> </span>path<span class="w"> </span>to<span class="w"> </span>your<span class="w"> </span><span class="nb">source</span><span class="w"> </span>directory:
<span class="gp">marie@login$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">SRCDIR</span><span class="o">=</span>/projects/p_number_crunch/mysource

<span class="gp"># </span>create<span class="w"> </span>a<span class="w"> </span>build<span class="w"> </span>directory<span class="w"> </span><span class="k">in</span><span class="w"> </span>/data/horse:
<span class="gp">marie@login$ </span>mkdir<span class="w"> </span>/data/horse/p_number_crunch/mysoftware_build

<span class="gp"># </span>change<span class="w"> </span>to<span class="w"> </span>build<span class="w"> </span>directory<span class="w"> </span>within<span class="w"> </span>/data/horse:
<span class="gp">marie@login$ </span><span class="nb">cd</span><span class="w"> </span>/data/horse/p_number_crunch/mysoftware_build

<span class="gp"># </span>create<span class="w"> </span>Makefiles:
<span class="gp">marie@login$ </span>cmake<span class="w"> </span>-DCMAKE_INSTALL_PREFIX<span class="o">=</span>/projects/p_number_crunch/mysoftware<span class="w"> </span><span class="nv">$SRCDIR</span>

<span class="gp"># </span>build<span class="w"> </span><span class="k">in</span><span class="w"> </span>a<span class="w"> </span>job:
<span class="gp">marie@login$ </span>srun<span class="w"> </span>--mem-per-cpu<span class="o">=</span><span class="m">1500</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">12</span><span class="w"> </span>--pty<span class="w"> </span>make<span class="w"> </span>-j<span class="w"> </span><span class="m">12</span>

<span class="gp"># </span><span class="k">do</span><span class="w"> </span>the<span class="w"> </span>install<span class="w"> </span>step<span class="w"> </span>on<span class="w"> </span>the<span class="w"> </span>login<span class="w"> </span>node<span class="w"> </span>again:
<span class="gp">marie@login$ </span>make<span class="w"> </span>install
</pre></div>
</div>
<p>As a bonus, your compilation should also be faster in the parallel <code class="docutils literal notranslate"><span class="pre">/data/horse</span></code> filesystem than it
would be in the comparatively slow NFS-based <code class="docutils literal notranslate"><span class="pre">/projects</span></code> filesystem.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="computational-fluid-dynamics-cfd">
<h1>Computational Fluid Dynamics (CFD)<a class="headerlink" href="#computational-fluid-dynamics-cfd" title="Permalink to this heading">#</a></h1>
<p>The following CFD applications are available on our system:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p><strong>Module</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>OpenFOAM</strong></p></td>
<td><p>openfoam</p></td>
</tr>
<tr class="row-odd"><td><p><strong>CFX</strong></p></td>
<td><p>ansys</p></td>
</tr>
<tr class="row-even"><td><p><strong>Fluent</strong></p></td>
<td><p>ansys</p></td>
</tr>
<tr class="row-odd"><td><p><strong>ICEM CFD</strong></p></td>
<td><p>ansys</p></td>
</tr>
<tr class="row-even"><td><p><strong>STAR-CCM+</strong></p></td>
<td><p>star</p></td>
</tr>
</tbody>
</table>
<section id="openfoam">
<h2>OpenFOAM<a class="headerlink" href="#openfoam" title="Permalink to this heading">#</a></h2>
<p>The OpenFOAM (Open Field Operation and Manipulation) CFD Toolbox can simulate anything from complex
fluid flows involving chemical reactions, turbulence and heat transfer, to solid dynamics,
electromagnetics and the pricing of financial options. OpenFOAM is developed primarily by
<a class="reference external" href="https://www.openfoam.com">OpenCFD Ltd</a> and is freely available and open-source,
licensed under the GNU General Public License.</p>
<p>The command <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">spider</span> <span class="pre">OpenFOAM</span></code> provides the list of installed OpenFOAM versions. In order to
use OpenFOAM, it is mandatory to set the environment by sourcing the <code class="docutils literal notranslate"><span class="pre">bashrc</span></code> (for users running
bash or ksh) or <code class="docutils literal notranslate"><span class="pre">cshrc</span></code> (for users running tcsh or csh) provided by OpenFOAM:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>OpenFOAM/VERSION
<span class="gp">marie@login$ source $</span>FOAM_BASH
<span class="gp">marie@login$ # </span><span class="nb">source</span><span class="w"> </span><span class="nv">$FOAM_CSH</span>
</pre></div>
</div>
<p>???+ example ‚ÄúExample for OpenFOAM job script:‚Äù
```bash
#!/bin/bash
#SBATCH ‚Äìtime=12:00:00     # walltime
#SBATCH ‚Äìntasks=60         # number of processor cores (i.e. tasks)
#SBATCH ‚Äìmem-per-cpu=500M  # memory per CPU core
#SBATCH ‚Äìjob-name=‚ÄùTest‚Äù   # job name
#SBATCH <a class="reference external" href="mailto:--mail-user=marie&#37;&#52;&#48;tu-dresden&#46;de">‚Äìmail-user=marie<span>&#64;</span>tu-dresden<span>&#46;</span>de</a>  # email address (only tu-dresden)
#SBATCH ‚Äìmail-type=ALL</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>OUTFILE=&quot;Output&quot;
module load OpenFOAM
source $FOAM_BASH
cd /horse/ws/marie-example-workspace  # work directory using workspace
srun pimpleFoam -parallel &gt; &quot;$OUTFILE&quot;
```
</pre></div>
</div>
</section>
<section id="ansys-cfx">
<h2>Ansys CFX<a class="headerlink" href="#ansys-cfx" title="Permalink to this heading">#</a></h2>
<p>Ansys CFX is a powerful finite-volume-based program package for modeling general fluid flow in
complex geometries. The main components of the CFX package are the flow solver cfx5solve, the
geometry and mesh generator cfx5pre, and the post-processor cfx5post.</p>
<p>???+ example ‚ÄúExample for CFX job script:‚Äù
```bash
#!/bin/bash
#SBATCH ‚Äìtime=12:00                                       # walltime
#SBATCH ‚Äìntasks=4                                         # number of processor cores (i.e. tasks)
#SBATCH ‚Äìmem-per-cpu=1900M                                # memory per CPU core
#SBATCH <a class="reference external" href="mailto:--mail-user=marie&#37;&#52;&#48;tu-dresden&#46;de">‚Äìmail-user=marie<span>&#64;</span>tu-dresden<span>&#46;</span>de</a>                    # email address (only tu-dresden)
#SBATCH ‚Äìmail-type=ALL</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>module load ANSYS
cd /horse/ws/marie-example-workspace                       # work directory using workspace
cfx-parallel.sh -double -def StaticMixer.def
```
</pre></div>
</div>
</section>
<section id="ansys-fluent">
<h2>Ansys Fluent<a class="headerlink" href="#ansys-fluent" title="Permalink to this heading">#</a></h2>
<p>???+ example ‚ÄúFluent needs the host names and can be run in parallel like this:‚Äù
```bash
#!/bin/bash
#SBATCH ‚Äìtime=12:00                        # walltime
#SBATCH ‚Äìntasks=4                          # number of processor cores (i.e. tasks)
#SBATCH ‚Äìmem-per-cpu=1900M                 # memory per CPU core
#SBATCH <a class="reference external" href="mailto:--mail-user=marie&#37;&#52;&#48;tu-dresden&#46;de">‚Äìmail-user=marie<span>&#64;</span>tu-dresden<span>&#46;</span>de</a>     # email address (only tu-dresden)
#SBATCH ‚Äìmail-type=ALL</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>module purge
module load release/23.10
module load ANSYS/2023R1
fluent 2ddp -t$SLURM_NTASKS -g -mpi=openmpi -pinfiniband -cnf=$(/software/util/slurm/bin/create_rankfile -f CCM) -i input.jou
```
</pre></div>
</div>
<p>To use fluent interactively, please try:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>ANSYS/19.2
<span class="gp">marie@login$ </span>srun<span class="w"> </span>--nodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">4</span><span class="w"> </span>--time<span class="o">=</span><span class="m">1</span>:00:00<span class="w"> </span>--pty<span class="w"> </span>--x11<span class="o">=</span>first<span class="w"> </span>bash
<span class="gp">marie@compute$ </span>fluent<span class="w"> </span><span class="p">&amp;</span>
</pre></div>
</div>
</section>
<section id="star-ccm">
<h2>STAR-CCM+<a class="headerlink" href="#star-ccm" title="Permalink to this heading">#</a></h2>
<p>!!! note
You have to use your own license in order to run STAR-CCM+ on ZIH systems, so you have to specify
the parameters <code class="docutils literal notranslate"><span class="pre">-licpath</span></code> and <code class="docutils literal notranslate"><span class="pre">-podkey</span></code>, see the example below.</p>
<p>Our installation provides a script <code class="docutils literal notranslate"><span class="pre">create_rankfile</span> <span class="pre">-f</span> <span class="pre">CCM</span></code> that generates a host list from the
Slurm job environment that can be passed to <code class="docutils literal notranslate"><span class="pre">starccm+</span></code>, enabling it to run across multiple nodes.</p>
<p>???+ example
```bash
#!/bin/bash
#SBATCH ‚Äìtime=12:00                        # walltime
#SBATCH ‚Äìntasks=32                         # number of processor cores (i.e. tasks)
#SBATCH ‚Äìmem-per-cpu=2500M                 # memory per CPU core
#SBATCH <a class="reference external" href="mailto:--mail-user=marie&#37;&#52;&#48;tu-dresden&#46;de">‚Äìmail-user=marie<span>&#64;</span>tu-dresden<span>&#46;</span>de</a>     # email address (only tu-dresden)
#SBATCH ‚Äìmail-type=ALL</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>module load STAR-CCM+

LICPATH=&quot;port@host&quot;
PODKEY=&quot;your podkey&quot;
INPUT_FILE=&quot;your_simulation.sim&quot;
starccm+ -collab -rsh ssh -cpubind off -np $SLURM_NTASKS -on $(/sw/taurus/tools/slurmtools/default/bin/create_rankfile -f CCM) -batch -power -licpath $LICPATH -podkey $PODKEY $INPUT_FILE
```
</pre></div>
</div>
<p>!!! note
The software path of the script <code class="docutils literal notranslate"><span class="pre">create_rankfile</span> <span class="pre">-f</span> <span class="pre">CCM</span></code> is different on the
<span class="xref myst">new HPC system Barnard</span>.</p>
<p>???+ example
```bash
#!/bin/bash
#SBATCH ‚Äìtime=12:00                        # walltime
#SBATCH ‚Äìntasks=32                         # number of processor cores (i.e. tasks)
#SBATCH ‚Äìmem-per-cpu=2500M                 # memory per CPU core
#SBATCH <a class="reference external" href="mailto:--mail-user=marie&#37;&#52;&#48;tu-dresden&#46;de">‚Äìmail-user=marie<span>&#64;</span>tu-dresden<span>&#46;</span>de</a>     # email address (only tu-dresden)
#SBATCH ‚Äìmail-type=ALL</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>module load STAR-CCM+

LICPATH=&quot;port@host&quot;
PODKEY=&quot;your podkey&quot;
INPUT_FILE=&quot;your_simulation.sim&quot;
starccm+ -collab -rsh ssh -cpubind off -np $SLURM_NTASKS -on $(/software/util/slurm/bin/create_rankfile -f CCM) -batch -power -licpath $LICPATH -podkey $PODKEY $INPUT_FILE
```
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="ci-cd-on-hpc">
<h1>CI/CD on HPC<a class="headerlink" href="#ci-cd-on-hpc" title="Permalink to this heading">#</a></h1>
<p>We provide a <strong>GitLab Runner</strong> that allows you to run a GitLab pipeline on the ZIH systems. With
that you can continuously build, test, and benchmark your HPC software in the target environment.</p>
<section id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>You (and ideally every involved developer) need an <span class="xref myst">HPC-Login</span>.</p></li>
<li><p>You manage your source code in a repository at the <a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de">TU Chemnitz GitLab instance</a></p></li>
</ul>
</section>
<section id="setup-process">
<h2>Setup process<a class="headerlink" href="#setup-process" title="Permalink to this heading">#</a></h2>
<ol class="arabic">
<li><p>Open your repository in the browser.</p></li>
<li><p>Hover <em>Settings</em> and then click on <em>CI/CD</em></p>
<p><img alt="Hover Settings and then click on CI/CD" src="63_chat_with_docs/misc/menu12_en.png" />
{ align=center }</p>
</li>
<li><p><em>Expand</em> the <em>Runners</em> section</p>
<p><img alt="Expand the Runners section" src="63_chat_with_docs/misc/menu3_en.png" />
{ align=center }</p>
</li>
<li><p>Copy the <em>registration token</em></p>
<p><img alt="Copy the registration token" src="63_chat_with_docs/misc/menu4_en.png" />
{ align=center }</p>
</li>
<li><p>Now, you can request the registration of your repository with the
<span class="xref myst">HPC-Support</span>. In the ticket, you need to add the URL of the GitLab
repository and the registration token.</p></li>
</ol>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>At the moment, only repositories hosted at the TU Chemnitz GitLab are supported.
</pre></div>
</div>
</section>
<section id="gitlab-pipelines">
<h2>GitLab pipelines<a class="headerlink" href="#gitlab-pipelines" title="Permalink to this heading">#</a></h2>
<p>As the ZIH provides the CI/CD as an GitLab runner, you can run any pipeline already working on other
runners with the CI/CD at the ZIH systems. This also means, to configure the actual steps performed
once your pipeline runs, you need to define the <code class="docutils literal notranslate"><span class="pre">.gitlab-ci.yml</span></code> file in the root of your
repository. There is a <a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/help/ci/index.md">comprehensive
documentation</a> and a <a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/help/ci/yaml/index">reference for the
<code class="docutils literal notranslate"><span class="pre">.gitlab-ci.yml</span></code> file</a> available at every
GitLab instance. There‚Äôs also a <a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/help/ci/quick_start/index.md">quick start
guide</a>.</p>
<p>The main difference to other GitLab runner is that every pipeline jobs will be scheduled as an
individual HPC job on the ZIH systems. Therefore, an important aspect is the possibility to set
Slurm parameters. While scheduling jobs allows to run code directly on the target system, it also
means that a single pipeline has to wait for resource allocation. Hence, you want to restrict,
which commits will run the complete pipeline, or which commits only run a part of the pipeline.</p>
<section id="passing-slurm-parameters">
<h3>Passing Slurm parameters<a class="headerlink" href="#passing-slurm-parameters" title="Permalink to this heading">#</a></h3>
<p>You can pass Slurm parameters via the <a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/help/ci/yaml/index#variables"><code class="docutils literal notranslate"><span class="pre">variables</span></code>
keyword</a>, either globally for the
whole yaml file, or on a per-job base.</p>
<p>Use the variable <code class="docutils literal notranslate"><span class="pre">SCHEDULER_PARAMETERS</span></code> and define the same parameters you would use for <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">srun</span></code> or
<code class="docutils literal notranslate"><span class="pre">sbatch</span></code></span>.</p>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The parameters `--job-name`, `--output`, and `--wait` are handled by the GitLab runner and must
not be used. If used, the run will fail.
</pre></div>
</div>
<p>!!! tip</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Make sure to set the `--account` such that the allocation of HPC resources is accounted
correctly.
</pre></div>
</div>
<p>!!! example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The following YAML file defines a configuration section `.test-job`, and two jobs,
`test-job-haswell` and `test-job-power9`, extending from that. The two job share the
`before_script`, `script`, and `after_script` configuration, but differ in the
`SCHEDULER_PARAMETERS`. The `test-job-haswell` and `test-job-power9` are scheduled on the partition
`haswell` and partition `power9`, respectively.

```yaml
.test-job:
before_script:
    - date
    - pwd
    - hostname
script:
    - date
    - pwd
    - hostname
after_script:
    - date
    - pwd
    - hostname

test-job-haswell:
extends: .test-job
variables:
    SCHEDULER_PARAMETERS: -p haswell


test-job-power9:
extends: .test-job
variables:
    SCHEDULER_PARAMETERS: -p power9
```
</pre></div>
</div>
</section>
</section>
<section id="current-limitations">
<h2>Current limitations<a class="headerlink" href="#current-limitations" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Every runner job is currently limited to <strong>one hour</strong>. Once this time limit passes, the runner job
gets canceled regardless of the requested runtime from Slurm. This time <em>includes</em> the waiting
time for HPC resources.</p></li>
</ul>
</section>
<section id="pitfalls-and-recommendations">
<h2>Pitfalls and Recommendations<a class="headerlink" href="#pitfalls-and-recommendations" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>While the <a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/help/ci/yaml/index#before_script"><code class="docutils literal notranslate"><span class="pre">before_script</span></code></a>
and <a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/help/ci/yaml/index#script"><code class="docutils literal notranslate"><span class="pre">script</span></code></a> array of commands are
executed on the allocated resources, the
<a class="reference external" href="https://gitlab.hrz.tu-chemnitz.de/help/ci/yaml/index#after_script"><code class="docutils literal notranslate"><span class="pre">after_script</span></code></a> runs on the
GitLab runner node. We recommend that you do not use <code class="docutils literal notranslate"><span class="pre">after_script</span></code>.</p></li>
<li><p>It is likely that all your runner jobs will be executed in a slightly different directory on the
shared filesystem. Some build systems, for example CMake, expect that the configure and build is
executed in the same directory. In this case, we recommend to use one job for configure and
build.</p></li>
</ul>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="compilers-and-flags">
<h1>Compilers and Flags<a class="headerlink" href="#compilers-and-flags" title="Permalink to this heading">#</a></h1>
<p>The following compilers are available on the ZIH system:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>GNU Compiler Collection</p></th>
<th class="head"><p>Clang Compiler</p></th>
<th class="head"><p>Intel Compiler</p></th>
<th class="head"><p>PGI Compiler (Nvidia HPC SDK)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Further information</p></td>
<td><p><a class="reference external" href="https://gcc.gnu.org/">GCC website</a></p></td>
<td><p><a class="reference external" href="https://clang.llvm.org/docs/UsersManual.html">Clang documentation</a></p></td>
<td><p><a class="reference external" href="https://software.intel.com/en-us/c-compilers">C/C++</a>, <a class="reference external" href="https://software.intel.com/en-us/fortran-compilers">Fortran</a></p></td>
<td><p><a class="reference external" href="https://www.pgroup.com">PGI website</a></p></td>
</tr>
<tr class="row-odd"><td><p>Module name</p></td>
<td><p>GCC</p></td>
<td><p>Clang</p></td>
<td><p>iccifort</p></td>
<td><p>PGI</p></td>
</tr>
<tr class="row-even"><td><p>C Compiler</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">gcc</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">clang</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">icc</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">pgcc</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>C++ Compiler</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">g++</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">clang++</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">icpc</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">pgc++</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Fortran Compiler</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">gfortran</span></code></p></td>
<td><p>-</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ifort</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">pgfortran</span></code></p></td>
</tr>
</tbody>
</table>
<p>For an overview of the installed compiler versions, please use <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">spider</span> <span class="pre">&lt;module</span> <span class="pre">name&gt;</span></code>
on the ZIH systems.
Additionally you can use <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">av</span></code> and look below ‚Äúcompilers‚Äù to see all available compiler modules.</p>
<p>All compilers support various language standards, at least up to ISO C11, ISO C++ 2014, and Fortran 2003.
Please check the man pages to verify that your code can be compiled.</p>
<p>Please note that the linking of C++ files normally requires the C++ version of the compiler to link
the correct libraries.</p>
<section id="compiler-flags">
<h2>Compiler Flags<a class="headerlink" href="#compiler-flags" title="Permalink to this heading">#</a></h2>
<p>Common options are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-g</span></code> to include information required for debugging</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-pg</span></code> to generate gprof-like sample-based profiling information during the run</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-O0</span></code>, <code class="docutils literal notranslate"><span class="pre">-O1</span></code>, <code class="docutils literal notranslate"><span class="pre">-O2</span></code>, <code class="docutils literal notranslate"><span class="pre">-O3</span></code> to customize the optimization level from
no (<code class="docutils literal notranslate"><span class="pre">-O0</span></code>) to aggressive (<code class="docutils literal notranslate"><span class="pre">-O3</span></code>) optimization</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-I</span></code> to set search path for header files</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-L</span></code> to set search path for libraries</p></li>
</ul>
<p>Please note that aggressive optimization allows deviation from the strict IEEE arithmetic.
Since the performance impact of options like <code class="docutils literal notranslate"><span class="pre">-fp-model</span> <span class="pre">strict</span></code> is very hard you
have to balance speed and desired accuracy of your application yourself.</p>
<p>The user benefits from the (nearly) same set of compiler flags for optimization for the C, C++, and
Fortran-compilers.
In the following table, only a couple of important compiler-dependent options are listed.
For more detailed information about these and further flags, the user should refer to the man
pages or use the option <code class="docutils literal notranslate"><span class="pre">--help</span></code> to list all options of the compiler.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>GCC</p></th>
<th class="head"><p>Intel</p></th>
<th class="head"><p>PGI</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">-fopenmp</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-fopenmp</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-mp</span></code></p></td>
<td><p>turn on OpenMP support</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">-std=c99</span></code>, <code class="docutils literal notranslate"><span class="pre">-std=c++11</span></code>, <code class="docutils literal notranslate"><span class="pre">-std=f2018</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-std=c99</span></code>, <code class="docutils literal notranslate"><span class="pre">-std=c++11</span></code>, <code class="docutils literal notranslate"><span class="pre">-std18</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-c99</span></code>, <code class="docutils literal notranslate"><span class="pre">--c++11</span></code>, n/a</p></td>
<td><p>set language standard, for example C99, C++11, Fortran 2018</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">-mieee-fp</span></code> <code class="docutils literal notranslate"><span class="pre">-frounding-math</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-fp-model</span> <span class="pre">precise</span></code> or <code class="docutils literal notranslate"><span class="pre">-fp-model</span> <span class="pre">strict</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-Kieee</span></code></p></td>
<td><p>limit floating-point optimizations and maintain declared precision</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">-ffast-math</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-mp1</span></code> or <code class="docutils literal notranslate"><span class="pre">-fp-model</span> <span class="pre">fast</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-Mfprelaxed</span></code></p></td>
<td><p>allow floating-point optimizations, may violate IEEE conformance</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">-Ofast</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-fast</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-fast</span></code></p></td>
<td><p>Maximize performance, implies a couple of other flags</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">-fsignaling-nans</span></code> <code class="docutils literal notranslate"><span class="pre">-fno-trapping-math</span></code></p></td>
<td><p>C/C++: <code class="docutils literal notranslate"><span class="pre">-fpe-trap</span></code>, Fortran: <code class="docutils literal notranslate"><span class="pre">-fpe-all</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-Ktrap</span></code></p></td>
<td><p>controls the behavior when floating-point exceptions occur</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">-mavx</span></code> <code class="docutils literal notranslate"><span class="pre">-msse4.2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-mavx</span></code> <code class="docutils literal notranslate"><span class="pre">-msse4.2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-fastsse</span></code></p></td>
<td><p>‚Äúgenerally optimal flags‚Äù for supporting SSE instructions</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">-flto</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-ipo</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-Mipa</span></code></p></td>
<td><p>interprocedural / link-time optimization (across source files)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">-floop-parallelize-all</span> <span class="pre">-ftree-parallelize-loops=&lt;numthreads&gt;</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-parallel</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-Mconcur</span></code></p></td>
<td><p>auto-parallelizer</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">-fprofile-generate</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-prof-gen</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-Mpfi</span></code></p></td>
<td><p>create instrumented code to generate profile in file</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">-fprofile-use</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-prof-use</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-Mpfo</span></code></p></td>
<td><p>use profile data for optimization</p></td>
</tr>
</tbody>
</table>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>We can not generally give advice as to which option should be used. To gain maximum performance
please test the compilers and a few combinations of optimization flags. In case of doubt, you
can also contact [HPC support](../support/support.md) and ask the staff for help.
</pre></div>
</div>
<section id="architecture-specific-optimizations">
<h3>Architecture-specific Optimizations<a class="headerlink" href="#architecture-specific-optimizations" title="Permalink to this heading">#</a></h3>
<p>Different architectures of CPUs feature different vector extensions (like SSE4.2 and AVX)
to accelerate computations.
The following matrix shows proper compiler flags for the architectures at the ZIH:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>HPC System</p></th>
<th class="head"><p>Architecture</p></th>
<th class="head"><p>GCC</p></th>
<th class="head"><p>Intel</p></th>
<th class="head"><p>Nvidia HPC</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Alpha</span> <span class="pre">Centauri</span></code></span></p></td>
<td><p>AMD Rome</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-march=znver2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-march=core-avx2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-tp=zen2</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Barnard</span></code></span></p></td>
<td><p>Intel Sapphire Rapids</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-march=sapphirerapids</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-march=core-sapphirerapids</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Capella</span></code></span></p></td>
<td><p>AMD Genoa</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-march=znver4</span></code></p></td>
<td><p></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-tp=zen4</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Julia</span></code></span></p></td>
<td><p>Intel Cascade Lake</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-march=cascadelake</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-march=cascadelake</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-tp=cascadelake</span></code></p></td>
</tr>
<tr class="row-even"><td><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Romeo</span></code></span></p></td>
<td><p>AMD Rome</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-march=znver2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-march=core-avx2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-tp=zen2</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>All x86</p></td>
<td><p>Host‚Äôs architecture</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-march=native</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-xHost</span></code> or <code class="docutils literal notranslate"><span class="pre">-march=native</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-tp=host</span></code></p></td>
</tr>
<tr class="row-even"><td><p><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Power9</span></code></span></p></td>
<td><p>IBM Power9</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-mcpu=power9</span></code> or <code class="docutils literal notranslate"><span class="pre">-mcpu=native</span></code></p></td>
<td><p></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-tp=pwr9</span></code> or <code class="docutils literal notranslate"><span class="pre">-tp=host</span></code></p></td>
</tr>
</tbody>
</table>
<p>To build an executable for different node types with the Intel compiler, use
<code class="docutils literal notranslate"><span class="pre">-axcode</span></code>, where <code class="docutils literal notranslate"><span class="pre">code</span></code> is to be replaced with one or more target architectures.
For Cascade Lake and Sapphire Rapids. the option <code class="docutils literal notranslate"><span class="pre">-axcascadelake,sapphirerapids</span></code>
(for Intel compilers) instructs the compiler to optimized code paths for the
specified architecture(s), if possible.
If the application is executed on one of these architectures, the optimized code
path will be chosen.
A baseline code path will also be generated.
This path is used on other architectures than the specified ones and is used
in code sections that were not optimized by the compiler for a specific architecture.
Other optimization flags can be used as well for, e.g. <code class="docutils literal notranslate"><span class="pre">-O3</span></code>.
However, the <code class="docutils literal notranslate"><span class="pre">-march</span></code> option cannot be used here, as this will overwrite the
<code class="docutils literal notranslate"><span class="pre">-axcode</span></code> option.
This increases the size of the program code (might result in
poorer L1 instruction cache hits) but enables to run the same program on
different hardware types with compiler optimizations.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="singularity">
<h1>Singularity<a class="headerlink" href="#singularity" title="Permalink to this heading">#</a></h1>
<p><a class="reference external" href="https://www.ibm.com/cloud/learn/containerization">Containerization</a> encapsulating or packaging up
software code and all its dependencies to run uniformly and consistently on any infrastructure. On
ZIH systems <a class="reference external" href="https://sylabs.io/">Singularity</a> is used as a standard container solution. Singularity
enables users to have full control of their environment. This means that you don‚Äôt have to ask the
HPC support to install anything for you - you can put it in a Singularity container and run! As
opposed to Docker (the most famous container solution), Singularity is much more suited to being
used in an HPC environment and more efficient in many cases. Docker images can easily be used in
Singularity. Information about the use of Singularity on ZIH systems can be found on this page.</p>
<p>In some cases using Singularity requires a Linux machine with root privileges
(e.g. using the cluster <code class="docutils literal notranslate"><span class="pre">Power9</span></code>), the same architecture and a compatible kernel.
For many reasons, users on ZIH systems cannot be granted root permissions.
A solution is a Virtual Machine (VM) on the cluster <code class="docutils literal notranslate"><span class="pre">Power9</span></code> which allows users to gain
root permissions in an isolated environment.
There are two main options on how to work with Virtual Machines on ZIH systems:</p>
<ol class="arabic simple">
<li><p><span class="xref myst">VM tools</span>: Automated algorithms for using virtual machines;</p></li>
<li><p><span class="xref myst">Manual method</span>: It requires more operations but gives you more flexibility
and reliability.</p></li>
</ol>
<section id="usage-of-singularity">
<h2>Usage of Singularity<a class="headerlink" href="#usage-of-singularity" title="Permalink to this heading">#</a></h2>
<p>If you wish to containerize your workflow and/or applications, you can use Singularity containers on
ZIH systems. As opposed to Docker, this solution is much more suited to being used in an HPC
environment.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>It is not possible for users to generate new custom containers on ZIH systems directly, because
creating a new container requires root privileges.
</pre></div>
</div>
<p>However, new containers can be created on your local workstation and moved to ZIH systems for
execution. Follow the instructions for <span class="xref myst">locally installing Singularity</span> and
<span class="xref myst">container creation</span>. Moreover, existing Docker container can easily be
converted, see <span class="xref myst">Import a Docker container</span>.</p>
<p>If you are already familiar with Singularity, you might be more interested in our <span class="xref myst">Singularity
recipes and hints</span>.</p>
<section id="local-installation">
<h3>Local Installation<a class="headerlink" href="#local-installation" title="Permalink to this heading">#</a></h3>
<p>The local installation of Singularity comprises two steps: Make <code class="docutils literal notranslate"><span class="pre">go</span></code> available and then follow the
instructions from the official documentation to install Singularity.</p>
<ol class="arabic">
<li><p>Check if <code class="docutils literal notranslate"><span class="pre">go</span></code> is installed by executing <code class="docutils literal notranslate"><span class="pre">go</span> <span class="pre">version</span></code>.  If it is <strong>not</strong>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>wget<span class="w"> </span><span class="s1">&#39;https://storage.googleapis.com/golang/getgo/installer_linux&#39;</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>chmod<span class="w"> </span>+x
<span class="go">installer_linux &amp;&amp; ./installer_linux &amp;&amp; source $HOME/.bash_profile</span>
</pre></div>
</div>
</li>
<li><p>Instructions to
<a class="reference external" href="https://github.com/sylabs/singularity/blob/master/INSTALL.md#clone-the-repo">install Singularity</a>
from the official documentation:</p>
<p>Clone the repository</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>mkdir<span class="w"> </span>-p<span class="w"> </span><span class="si">${</span><span class="nv">GOPATH</span><span class="si">}</span>/src/github.com/sylabs
<span class="gp">marie@local$ cd $</span><span class="o">{</span>GOPATH<span class="o">}</span>/src/github.com/sylabs
<span class="gp">marie@local$ </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/sylabs/singularity.git
<span class="gp">marie@local$ </span><span class="nb">cd</span><span class="w"> </span>singularity
</pre></div>
</div>
<p>Checkout the version you want (see the <a class="reference external" href="https://github.com/sylabs/singularity/releases">GitHub releases page</a>
for available releases), e.g.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>git<span class="w"> </span>checkout<span class="w"> </span>v3.2.1
</pre></div>
</div>
<p>Build and install</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ cd $</span><span class="o">{</span>GOPATH<span class="o">}</span>/src/github.com/sylabs/singularity
<span class="gp">marie@local$ </span>./mconfig<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>./builddir<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>make
<span class="gp">marie@local$ </span>sudo<span class="w"> </span>make<span class="w"> </span>install
</pre></div>
</div>
</li>
</ol>
</section>
<section id="container-creation">
<h3>Container Creation<a class="headerlink" href="#container-creation" title="Permalink to this heading">#</a></h3>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>It is not possible for users to generate new custom containers on ZIH systems directly, because
creating a new container requires root privileges.
</pre></div>
</div>
<p>There are two possibilities:</p>
<ol class="arabic simple">
<li><p>Create a new container on your local workstation (where you have the necessary privileges), and
then copy the container file to ZIH systems for execution. Therefore you also have to install
<a class="reference external" href="https://sylabs.io/guides/3.0/user-guide/quick_start.html#quick-installation-steps">Singularity</a>
on your local workstation.</p></li>
<li><p>You can, however, import an existing container from, e.g., Docker.</p></li>
</ol>
<p>Both methods are outlined in the following.</p>
<section id="new-custom-container">
<h4>New Custom Container<a class="headerlink" href="#new-custom-container" title="Permalink to this heading">#</a></h4>
<p>You can create a new custom container on your workstation, if you have root rights.</p>
<p>!!! attention ‚ÄúRespect the micro-architectures‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>You cannot create containers for the cluster `Power`, as it bases on Power9 micro-architecture
which is different to the x86 architecture in common computers/laptops. For that you can use
the [VM Tools](singularity_power9.md).
</pre></div>
</div>
<p>Creating a container is done by writing a definition file, such as <code class="docutils literal notranslate"><span class="pre">myDefinition.def</span></code>, and passing
it to <code class="docutils literal notranslate"><span class="pre">singularity</span></code> via</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>singularity<span class="w"> </span>build<span class="w"> </span>myContainer.sif<span class="w"> </span>myDefinition.def
</pre></div>
</div>
<p>A definition file contains a bootstrap
<a class="reference external" href="https://sylabs.io/guides/3.2/user-guide/definition_files.html#header">header</a>
where you choose the base and
<a class="reference external" href="https://sylabs.io/guides/3.2/user-guide/definition_files.html#sections">sections</a>
where you install your software.</p>
<p>The most common approach is to start from an existing Docker image from DockerHub. For example, to
start from an <a class="reference external" href="https://hub.docker.com/_/ubuntu">Ubuntu image</a> copy the following into a new file
called <code class="docutils literal notranslate"><span class="pre">ubuntu.def</span></code> (or any other filename of your choice)</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Bootstrap:<span class="w"> </span>docker
From:<span class="w"> </span>ubuntu:trusty

%runscript
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;This is what happens when you run the container...&quot;</span>

%post
<span class="w">    </span>apt-get<span class="w"> </span>install<span class="w"> </span>g++
</pre></div>
</div>
<p>Then you can call</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>singularity<span class="w"> </span>build<span class="w"> </span>ubuntu.sif<span class="w"> </span>ubuntu.def
</pre></div>
</div>
<p>And it will install Ubuntu with g++ inside your container, according to your definition file.
More bootstrap options are available. The following example, for instance, bootstraps a basic CentOS
7 image.</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>BootStrap:<span class="w"> </span>yum
OSVersion:<span class="w"> </span><span class="m">7</span>
MirrorURL:<span class="w"> </span>http://mirror.centos.org/centos-%<span class="o">{</span>OSVERSION<span class="o">}</span>/%<span class="o">{</span>OSVERSION<span class="o">}</span>/os/<span class="nv">$basearch</span>/
Include:<span class="w"> </span>yum

%runscript
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;This is what happens when you run the container...&quot;</span>

%post
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Hello from inside the container&quot;</span>
<span class="w">    </span>yum<span class="w"> </span>-y<span class="w"> </span>install<span class="w"> </span>vim-minimal
</pre></div>
</div>
<p>More examples of definition files can be found at
<a class="github reference external" href="https://github.com/singularityware/singularity/tree/master/examples">singularityware/singularity</a>.</p>
</section>
<section id="import-a-docker-container">
<h4>Import a Docker Container<a class="headerlink" href="#import-a-docker-container" title="Permalink to this heading">#</a></h4>
<p>!!! hint</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>As opposed to bootstrapping a container, importing from Docker does **not require root
privileges** and therefore works on ZIH systems directly. Please note, that the Singularity
commands are only available on the compute nodes and not on the login nodes.
</pre></div>
</div>
<p>You can import an image directly from the Docker repository (Docker Hub):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>singularity<span class="w"> </span>build<span class="w"> </span>my-container.sif<span class="w"> </span>docker://ubuntu:latest
</pre></div>
</div>
<p>Creating a Singularity container directly from a local Docker image is possible but not
recommended. The steps are:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>Start<span class="w"> </span>a<span class="w"> </span>docker<span class="w"> </span>registry
<span class="gp">marie@local$ </span>docker<span class="w"> </span>run<span class="w"> </span>-d<span class="w"> </span>-p<span class="w"> </span><span class="m">5000</span>:5000<span class="w"> </span>--restart<span class="o">=</span>always<span class="w"> </span>--name<span class="w"> </span>registry<span class="w"> </span>registry:2

<span class="gp"># </span>Push<span class="w"> </span><span class="nb">local</span><span class="w"> </span>docker<span class="w"> </span>container<span class="w"> </span>to<span class="w"> </span>it
<span class="gp">marie@local$ </span>docker<span class="w"> </span>tag<span class="w"> </span>alpine<span class="w"> </span>localhost:5000/alpine
<span class="gp">marie@local$ </span>docker<span class="w"> </span>push<span class="w"> </span>localhost:5000/alpine

<span class="gp"># </span>Create<span class="w"> </span>def<span class="w"> </span>file<span class="w"> </span><span class="k">for</span><span class="w"> </span>singularity<span class="w"> </span>like<span class="w"> </span>this...
<span class="gp">marie@local$ </span>cat<span class="w"> </span>example.def
<span class="go">Bootstrap: docker</span>
<span class="go">Registry: &lt;a href=&quot;http://localhost:5000&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;http://localhost:5000&lt;/a&gt;</span>
<span class="go">From: alpine</span>

<span class="gp"># </span>Build<span class="w"> </span>singularity<span class="w"> </span>container
<span class="gp">marie@local$ </span>singularity<span class="w"> </span>build<span class="w"> </span>--nohttps<span class="w"> </span>alpine.sif<span class="w"> </span>example.def
</pre></div>
</div>
</section>
<section id="start-from-a-dockerfile">
<h4>Start from a Dockerfile<a class="headerlink" href="#start-from-a-dockerfile" title="Permalink to this heading">#</a></h4>
<p>As Singularity definition files and Dockerfiles are very similar you can start creating a definition
file from an existing Dockerfile by ‚Äútranslating‚Äù each section.</p>
<p>There are tools to automate this. One of them is
<a class="reference external" href="https://github.com/singularityhub/singularity-cli">spython</a> which can be installed with <code class="docutils literal notranslate"><span class="pre">pip</span></code>
(add <code class="docutils literal notranslate"><span class="pre">--user</span></code> if you don‚Äôt want to install it system-wide):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>pip3<span class="w"> </span>install<span class="w"> </span>-U<span class="w"> </span>spython
</pre></div>
</div>
<p>With this you can simply issue the following command to convert a Dockerfile in the current folder
into a Singularity definition file:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>spython<span class="w"> </span>recipe<span class="w"> </span>Dockerfile<span class="w"> </span>myDefinition.def
</pre></div>
</div>
<p>Please <strong>verify</strong> your generated definition and adjust where required!</p>
<p>There are some notable changes between Singularity definitions and Dockerfiles:</p>
<ol class="arabic simple">
<li><p>Command chains in Dockerfiles (<code class="docutils literal notranslate"><span class="pre">apt-get</span> <span class="pre">update</span> <span class="pre">&amp;&amp;</span> <span class="pre">apt-get</span> <span class="pre">install</span> <span class="pre">foo</span></code>) must be split into
separate commands (<code class="docutils literal notranslate"><span class="pre">apt-get</span> <span class="pre">update;</span> <span class="pre">apt-get</span> <span class="pre">install</span> <span class="pre">foo</span></code>). Otherwise a failing command before the
ampersand is considered ‚Äúchecked‚Äù and does not fail the build.</p></li>
<li><p>The environment variables section in Singularity is only set on execution of the final image, not
during the build as with Docker. So <code class="docutils literal notranslate"><span class="pre">*ENV*</span></code> sections from Docker must be translated to an entry
in the <code class="docutils literal notranslate"><span class="pre">%environment</span></code> section and <strong>additionally</strong> set in the <code class="docutils literal notranslate"><span class="pre">%runscript</span></code> section if the
variable is used there.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">*VOLUME*</span></code> sections from Docker cannot be represented in Singularity containers. Use the runtime
option `-B` to bind folders manually.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CMD</span></code> and <code class="docutils literal notranslate"><span class="pre">ENTRYPOINT</span></code> from Docker do not have a direct representation in Singularity.
The closest is to check if any arguments are given in the <code class="docutils literal notranslate"><span class="pre">%runscript</span></code> section and call the
command from <code class="docutils literal notranslate"><span class="pre">ENTRYPOINT</span></code> with those, if none are given call <code class="docutils literal notranslate"><span class="pre">ENTRYPOINT</span></code> with the
arguments of <code class="docutils literal notranslate"><span class="pre">CMD</span></code>:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="nv">$#</span><span class="w"> </span>-gt<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">  </span>&lt;ENTRYPOINT&gt;<span class="w"> </span><span class="s2">&quot;</span><span class="nv">$@</span><span class="s2">&quot;</span>
<span class="k">else</span>
<span class="w">  </span>&lt;ENTRYPOINT&gt;<span class="w"> </span>&lt;CMD&gt;
<span class="k">fi</span>
</pre></div>
</div>
</section>
</section>
<section id="use-the-containers">
<h3>Use the Containers<a class="headerlink" href="#use-the-containers" title="Permalink to this heading">#</a></h3>
<section id="enter-a-shell-in-your-container">
<h4>Enter a Shell in Your Container<a class="headerlink" href="#enter-a-shell-in-your-container" title="Permalink to this heading">#</a></h4>
<p>A read-only shell can be entered as follows:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>singularity<span class="w"> </span>shell<span class="w"> </span>my-container.sif
</pre></div>
</div>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>In contrast to, for instance, Docker, this will mount various folders from the host system
including $HOME. This may lead to problems with, e.g., Python that stores local packages in the
home folder, which may not work inside the container. It also makes reproducibility harder. It
is therefore recommended to use `--contain/-c` to not bind `$HOME` (and others like `/tmp`)
automatically and instead set up your binds manually via `-B` parameter. Example:

```console
marie@compute$ singularity shell --contain -B /data/horse,/my/folder-on-host:/folder-in-container my-container.sif
```
</pre></div>
</div>
<p>You can write into those folders by default. If this is not desired, add an <code class="docutils literal notranslate"><span class="pre">:ro</span></code> for read-only to
the bind specification (e.g. <code class="docutils literal notranslate"><span class="pre">-B</span> <span class="pre">/data/horse:/data/horse:ro\</span></code>).  Note that we already defined bind
paths for <code class="docutils literal notranslate"><span class="pre">/data/horse</span></code>, <code class="docutils literal notranslate"><span class="pre">/projects</span></code> and <code class="docutils literal notranslate"><span class="pre">/sw</span></code> in our global <code class="docutils literal notranslate"><span class="pre">singularity.conf</span></code>, so you needn‚Äôt use
the <code class="docutils literal notranslate"><span class="pre">-B</span></code> parameter for those.</p>
<p>If you wish to install additional packages, you have to use the <code class="docutils literal notranslate"><span class="pre">-w</span></code> parameter to
enter your container with it being writable. This, again, must be done on a system where you have
the necessary privileges, otherwise you can only edit files that your user has the permissions for.
E.g:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>singularity<span class="w"> </span>shell<span class="w"> </span>-w<span class="w"> </span>my-container.sif
<span class="go">Singularity.my-container.sif&gt; yum install htop</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">-w</span></code> parameter should only be used to make permanent changes to your container, not for your
productive runs (it can only be used writable by one user at the same time). You should write your
output to the usual ZIH filesystems like <code class="docutils literal notranslate"><span class="pre">/data/horse</span></code>. Launching applications in your container</p>
</section>
<section id="run-a-command-inside-the-container">
<h4>Run a Command Inside the Container<a class="headerlink" href="#run-a-command-inside-the-container" title="Permalink to this heading">#</a></h4>
<p>While the <code class="docutils literal notranslate"><span class="pre">shell</span></code> command can be useful for tests and setup, you can also launch your applications
inside the container directly using ‚Äúexec‚Äù:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>singularity<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>my-container.sif<span class="w"> </span>/opt/myapplication/bin/run_myapp
</pre></div>
</div>
<p>This can be useful if you wish to create a wrapper script that transparently calls a containerized
application for you. E.g.:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>

<span class="k">if</span><span class="w"> </span>!<span class="w"> </span><span class="nb">type</span><span class="w"> </span>singularity<span class="w"> </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">  </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Singularity not found. Is the module loaded?&quot;</span>
<span class="w">  </span><span class="nb">exit</span><span class="w"> </span><span class="m">1</span>
<span class="k">fi</span>

singularity<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>/projects/p_number_crunch/my-container.sif<span class="w"> </span>/opt/myapplication/run_myapp<span class="w"> </span><span class="s2">&quot;</span><span class="nv">$@</span><span class="s2">&quot;</span>
</pre></div>
</div>
<p>The better approach is to use <code class="docutils literal notranslate"><span class="pre">singularity</span> <span class="pre">run</span></code>, which executes whatever was set in the <code class="docutils literal notranslate"><span class="pre">%runscript</span></code>
section of the definition file with the arguments you pass to it. Example: Build the following
definition file into an image:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Bootstrap:<span class="w"> </span>docker
From:<span class="w"> </span>ubuntu:trusty

%post
<span class="w">  </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>g++
<span class="w">  </span><span class="nb">echo</span><span class="w"> </span><span class="s1">&#39;#include &lt;iostream&gt;&#39;</span><span class="w"> </span>&gt;<span class="w"> </span>main.cpp
<span class="w">  </span><span class="nb">echo</span><span class="w"> </span><span class="s1">&#39;int main(int argc, char** argv){ std::cout &lt;&lt; argc &lt;&lt; &quot; args for &quot; &lt;&lt; argv[0] &lt;&lt; std::endl; }&#39;</span><span class="w"> </span>&gt;&gt;<span class="w"> </span>main.cpp
<span class="w">  </span>g++<span class="w"> </span>main.cpp<span class="w"> </span>-o<span class="w"> </span>myCoolApp
<span class="w">  </span>mv<span class="w"> </span>myCoolApp<span class="w"> </span>/usr/local/bin/myCoolApp

%runscript
<span class="w">  </span>myCoolApp<span class="w"> </span><span class="s2">&quot;</span><span class="nv">$@</span>
<span class="s2">singularity build my-container.sif example.def</span>
</pre></div>
</div>
<p>Then you can run your application via</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>singularity<span class="w"> </span>run<span class="w"> </span>my-container.sif<span class="w"> </span>first_arg<span class="w"> </span>2nd_arg
</pre></div>
</div>
<p>Alternatively you can execute the container directly which is equivalent:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>./my-container.sif<span class="w"> </span>first_arg<span class="w"> </span>2nd_arg
</pre></div>
</div>
<p>With this you can even masquerade an application with a Singularity container as if it was an actual
program by naming the container just like the binary:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>mv<span class="w"> </span>my-container.sif<span class="w"> </span>myCoolAp
</pre></div>
</div>
</section>
</section>
<section id="use-cases">
<h3>Use-Cases<a class="headerlink" href="#use-cases" title="Permalink to this heading">#</a></h3>
<p>One common use-case for containers is that you need an operating system with a newer
<a class="reference external" href="https://www.gnu.org/software/libc/">glibc</a> version than what is available on ZIH systems. E.g., the
bullx Linux on ZIH systems used to be based on RHEL 6 having a rather dated glibc version 2.12, some
binary-distributed applications didn‚Äôt work on that anymore. You can use one of our pre-made CentOS
7 container images (<code class="docutils literal notranslate"><span class="pre">/data/horse/lustre/scratch2/singularity/centos7.img</span></code>) to circumvent this
problem.</p>
<p>!!! example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@compute$ singularity exec /data/horse/lustre/scratch2/singularity/centos7.img ldd --version
ldd (GNU libc) 2.17
```
</pre></div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="software-installation-with-easybuild">
<h1>Software Installation with EasyBuild<a class="headerlink" href="#software-installation-with-easybuild" title="Permalink to this heading">#</a></h1>
<p>Sometimes the <span class="xref myst">modules</span> installed in the cluster are not enough for your purposes and
you need some other software or a different version of a software.</p>
<p>For most commonly used software, chances are high that there is already a <em>recipe</em> that EasyBuild
provides, which you can use. But what is EasyBuild?</p>
<p>!!! note ‚ÄúEasyBuild‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>[EasyBuild](https://easybuild.io/) is the software used to build and install software on ZIH
systems.
</pre></div>
</div>
<p>The aim of this page is to introduce users to working with EasyBuild and to utilizing it to create
modules.</p>
<section id="id43">
<h2>Prerequisites<a class="headerlink" href="#id43" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><span class="xref myst">Shell access</span> to ZIH systems</p></li>
<li><p>Basic knowledge about:</p>
<ul class="simple">
<li><p><span class="xref myst">the ZIH system</span></p></li>
<li><p><span class="xref myst">the module system</span> on ZIH systems</p></li>
</ul>
</li>
</ol>
<p>EasyBuild uses a configuration file called recipe or ‚ÄúEasyConfig‚Äù, which contains all the
information about how to obtain and build the software:</p>
<ul class="simple">
<li><p>Name</p></li>
<li><p>Version</p></li>
<li><p>Toolchain (think: Compiler + some more)</p></li>
<li><p>Download URL</p></li>
<li><p>Build system (e.g. <code class="docutils literal notranslate"><span class="pre">configure</span> <span class="pre">&amp;&amp;</span> <span class="pre">make</span></code> or <code class="docutils literal notranslate"><span class="pre">cmake</span> <span class="pre">&amp;&amp;</span> <span class="pre">make</span></code>)</p></li>
<li><p>Config parameters</p></li>
<li><p>Tests to ensure a successful build</p></li>
</ul>
<p>The build system part is implemented in so-called ‚ÄúEasyBlocks‚Äù and contains the common workflow.
Sometimes, those are specialized to encapsulate behavior specific to multiple/all versions of the
software. Everything is written in Python, which gives authors a great deal of flexibility.</p>
</section>
<section id="set-up-a-custom-module-environment-and-build-your-own-modules">
<h2>Set Up a Custom Module Environment and Build Your Own Modules<a class="headerlink" href="#set-up-a-custom-module-environment-and-build-your-own-modules" title="Permalink to this heading">#</a></h2>
<p>Installation of the new software (or version) does not require any specific credentials.</p>
<section id="id44">
<h3>Prerequisites<a class="headerlink" href="#id44" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>An existing EasyConfig</p></li>
<li><p>a place to put your modules.</p></li>
</ol>
</section>
<section id="step-by-step-guide">
<h3>Step by Step Guide<a class="headerlink" href="#step-by-step-guide" title="Permalink to this heading">#</a></h3>
<p><strong>Step 1:</strong> Create a <span class="xref myst">workspace</span> where you
install your modules. You need a place where your modules are placed. This needs to be done only
once:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ws_allocate<span class="w"> </span>EasyBuild<span class="w"> </span><span class="m">50</span>
<span class="gp">marie@login$ </span>ws_list<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span><span class="s1">&#39;directory.*EasyBuild&#39;</span>
<span class="go">     workspace directory  : /data/horse/ws/marie-EasyBuild</span>
</pre></div>
</div>
<p><strong>Step 2:</strong> Allocate nodes. You can do this with interactive jobs (see the example below) and/or
put commands in a batch file and source it. The latter is recommended for non-interactive jobs,
using the command <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> instead of <code class="docutils literal notranslate"><span class="pre">srun</span></code>. For the sake of illustration, we use an
interactive job as an example. Depending on the partitions that you want the module to be usable on
later, you need to select nodes with the same architecture. Thus, use nodes from cluster <code class="docutils literal notranslate"><span class="pre">power</span></code> for
building, if you want to use the module on nodes of that cluster. ~~In this example, we assume
that we want to use the module on nodes with x86 architecture and thus, we use Haswell nodes.~~</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>srun<span class="w"> </span>--nodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">4</span><span class="w"> </span>--time<span class="o">=</span><span class="m">08</span>:00:00<span class="w"> </span>--pty<span class="w"> </span>/bin/bash<span class="w"> </span>-l
</pre></div>
</div>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Using EasyBuild on the login nodes is not allowed.
</pre></div>
</div>
<p><strong>Step 3:</strong> Specify the workspace. The rest of the guide is based on it. Please create an
environment variable called <code class="docutils literal notranslate"><span class="pre">WORKSPACE</span></code> with the path to your workspace:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">WORKSPACE</span><span class="o">=</span>/data/horse/ws/marie-EasyBuild<span class="w">    </span><span class="c1">#see output of ws_list above</span>
</pre></div>
</div>
<p><strong>Step 4:</strong> Load the correct module environment <code class="docutils literal notranslate"><span class="pre">release</span></code> according to your needs:</p>
<p>=== ‚Äú23.04‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">module</span> <span class="pre">load</span> <span class="pre">release/23.04</span>&#160;&#160;&#160;&#160; </code></p>
<p><strong>Step 5:</strong> Load module <code class="docutils literal notranslate"><span class="pre">EasyBuild</span></code></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>load<span class="w"> </span>EasyBuild
</pre></div>
</div>
<p><strong>Step 6:</strong> Set up the EasyBuild configuration.</p>
<p>This can be either done via environment variables:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">EASYBUILD_CONFIGFILES</span><span class="o">=</span>/software/util/etc/easybuild.d/zih.cfg<span class="w"> </span><span class="se">\</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">EASYBUILD_DETECT_LOADED_MODULES</span><span class="o">=</span>unload<span class="w"> </span><span class="se">\</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">EASYBUILD_SUBDIR_USER_MODULES</span><span class="o">=</span><span class="w"> </span><span class="se">\</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">EASYBUILD_BUILDPATH</span><span class="o">=</span><span class="s2">&quot;/dev/shm/</span><span class="si">${</span><span class="nv">USER</span><span class="si">}</span><span class="s2">-EasyBuild</span><span class="si">${</span><span class="nv">SLURM_JOB_ID</span><span class="k">:-</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">EASYBUILD_SOURCEPATH</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">WORKSPACE</span><span class="si">}</span><span class="s2">/sources:/software/util/sources&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">EASYBUILD_INSTALLPATH</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">WORKSPACE</span><span class="si">}</span><span class="s2">/easybuild&quot;</span>
</pre></div>
</div>
<p>Or you can do that via the configuration file at <code class="docutils literal notranslate"><span class="pre">$HOME/.config/easybuild/config.cfg</span></code>.
An initial file can be generated with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>eb<span class="w"> </span>--confighelp<span class="w"> </span>&gt;<span class="w"> </span>~/.config/easybuild/config.cfg
</pre></div>
</div>
<p>Edit this file by uncommenting the above settings and specifying the respective values.
Note the difference in naming as each setting in the environment has the <code class="docutils literal notranslate"><span class="pre">EASYBUILD_</span></code> prefix
and is uppercase, while it is lowercase in the config.
For example <code class="docutils literal notranslate"><span class="pre">$EASYBUILD_DETECT_LOADED_MODULES</span></code> above corresponds to <code class="docutils literal notranslate"><span class="pre">detect-loaded-modules</span></code>
in the config file.</p>
<p>Note that you cannot use environment variables (like <code class="docutils literal notranslate"><span class="pre">$WORKSPACE</span></code> or <code class="docutils literal notranslate"><span class="pre">$USER</span></code>) in the config file.
So the approach with the <code class="docutils literal notranslate"><span class="pre">$EASYBUILD_</span></code> variables is more flexible but needs to be done before each
use of EasyBuild and could be forgotten.</p>
<p>You can also combine those approaches setting some in the config and some in the environment,
the latter will take precedence.
The first variable <code class="docutils literal notranslate"><span class="pre">$EASYBUILD_CONFIGFILES</span></code> makes sure the settings used for installing all other modules
on the cluster are used.
I.e. that config file is read before the custom one in your <code class="docutils literal notranslate"><span class="pre">$HOME</span></code>.
By that most of the configuration is already set up.<br />
But of course e.g. the installation path needs to be set by you.</p>
<p>The configuration used can be shown via:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>eb<span class="w"> </span>--show-config
</pre></div>
</div>
<p>This shows all changed/non-default options while the parameter <code class="docutils literal notranslate"><span class="pre">--show-full-config</span></code> shows all options.</p>
<p>The hierarchical module naming scheme (used on our systems) affects e.g. location and naming of modules.
In order for EasyBuild to use the existing modules,
you need to use the ‚Äúall‚Äù modules folder of the main tree.
But likely only the ‚ÄúCore‚Äù subdirectory is set in <code class="docutils literal notranslate"><span class="pre">$MODULEPATH</span></code>.
Nonetheless, the module search path can be extended easily with <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">use</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ echo $</span>MODULEPATH
<span class="go">/software/modules/rapids/r23.10/all/Core:/software/modules/releases/rapids</span>
<span class="gp">marie@compute$ </span>module<span class="w"> </span>use<span class="w"> </span>/software/modules/rapids/r23.10/all
<span class="gp">marie@compute$ echo $</span>MODULEPATH
<span class="go">/software/modules/rapids/r23.10/all:/software/modules/rapids/r23.10/all/Core:/software/modules/releases/rapids</span>
</pre></div>
</div>
<p>Take care to adjust the path to the release you use.
I.e. in the above example the module <code class="docutils literal notranslate"><span class="pre">release/23.10</span></code> was loaded resulting in
<code class="docutils literal notranslate"><span class="pre">/software/modules/rapids/r23.10/all/Core</span></code> on this cluster.
For the <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">use</span></code> command you take that (from <code class="docutils literal notranslate"><span class="pre">$MODULEPATH</span></code>) and only strip of the <code class="docutils literal notranslate"><span class="pre">/Core</span></code>.</p>
<p>Or you can use this one-line command to do it automatically:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>ml<span class="w"> </span>use<span class="w"> </span><span class="k">$(</span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;</span><span class="nv">$MODULEPATH</span><span class="s2">&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-oE<span class="w"> </span><span class="s1">&#39;(^|:)[^:]+/Core:&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sed<span class="w"> </span><span class="s1">&#39;s|/Core:||&#39;</span><span class="k">)</span>
</pre></div>
</div>
<p>Finally, you need to tell LMod about your modules:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">ZIH_USER_MODULES</span><span class="o">=</span><span class="nv">$EASYBUILD_INSTALLPATH</span>
</pre></div>
</div>
<p><strong>Step 7:</strong> Now search for an existing EasyConfig:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>eb<span class="w"> </span>--search<span class="w"> </span>TensorFlow
</pre></div>
</div>
<p><strong>Step 8:</strong> Build the EasyConfig and its dependencies (option <code class="docutils literal notranslate"><span class="pre">-r</span></code>)</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>eb<span class="w"> </span>TensorFlow-1.8.0-fosscuda-2018a-Python-3.6.4.eb<span class="w"> </span>-r
</pre></div>
</div>
<p>This may take a long time.</p>
<p>If you want to investigate what would be build by that command, first run it with <code class="docutils literal notranslate"><span class="pre">-D</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>eb<span class="w"> </span>TensorFlow-1.8.0-fosscuda-2018a-Python-3.6.4.eb<span class="w"> </span>-Dr
</pre></div>
</div>
<p><strong>Step 9:</strong> To use your custom build modules you need to load the ‚Äúbase‚Äù modenv (see step 4)
and add your custom modules to the search path.</p>
<p>Using the variable from step 6:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>use<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">EASYBUILD_INSTALLPATH</span><span class="si">}</span><span class="s2">/modules/all&quot;</span>
<span class="gp">marie@compute$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">ZIH_USER_MODULES</span><span class="o">=</span><span class="nv">$EASYBUILD_INSTALLPATH</span>
<span class="gp">marie@compute$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">LMOD_IGNORE_CACHE</span><span class="o">=</span><span class="m">1</span>
</pre></div>
</div>
<p><strong>OR</strong> directly the path from step 1:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>use<span class="w"> </span><span class="s2">&quot;/data/horse/ws/marie-EasyBuild/easybuild/modules/all&quot;</span>
<span class="gp">marie@compute$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">ZIH_USER_MODULES</span><span class="o">=</span>/data/horse/ws/marie-EasyBuild/easybuild
<span class="gp">marie@compute$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">LMOD_IGNORE_CACHE</span><span class="o">=</span><span class="m">1</span>
</pre></div>
</div>
<p>Then you can load it just like any other module:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>load<span class="w"> </span>TensorFlow-1.8.0-fosscuda-2018a-Python-3.6.4<span class="w">  </span><span class="c1">#replace with the name of your module</span>
</pre></div>
</div>
<p>The key is the <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">use</span></code> command, which brings your modules into scope, so <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">load</span></code> can find
them.
The <code class="docutils literal notranslate"><span class="pre">LMOD_IGNORE_CACHE</span></code> line makes <code class="docutils literal notranslate"><span class="pre">LMod</span></code> pick up the custom modules instead of searching the
system cache which doesn‚Äôt include your new modules.</p>
</section>
</section>
<section id="troubleshooting">
<h2>Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permalink to this heading">#</a></h2>
<p>When building your EasyConfig fails, you can first check the log mentioned and scroll to the bottom
to see what went wrong.</p>
<p>It might also be helpful to inspect the build environment EasyBuild uses. For that you can run:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>eb<span class="w"> </span>myEC.eb<span class="w"> </span>--dump-env-script<span class="sb">`</span>
</pre></div>
</div>
<p>This command creates a sourceable <code class="docutils literal notranslate"><span class="pre">.env</span></code>-file with <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">load</span></code> and <code class="docutils literal notranslate"><span class="pre">export</span></code> commands that show
what EasyBuild does before running, e.g., the configuration step.</p>
<p>It might also be helpful to use</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">LMOD_IGNORE_CACHE</span><span class="o">=</span><span class="m">0</span>
</pre></div>
</div>
<p>(Especially) when you want to use additional features of EasyBuild, such as the
<a class="reference external" href="https://docs.easybuild.io/integration-with-github/">GitHub integration</a>,
you might need to set a specific Python version to use by EasyBuild.</p>
<p>That is unrelated to any Python module you might wish to use or install!
Furthermore, when using EasyBuild you should <strong>not</strong> have any other modules loaded,
not even <code class="docutils literal notranslate"><span class="pre">Python</span></code>.</p>
<p>Which Python executable is used by EasyBuild can be shown by executing:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span><span class="nv">EB_VERBOSE</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>eb<span class="w"> </span>--version
</pre></div>
</div>
<p>You can change it by setting <code class="docutils literal notranslate"><span class="pre">EB_PYTHON</span></code>, e.g.:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">EB_PYTHON</span><span class="o">=</span>python3.8
</pre></div>
</div>
<p>In case you are using a virtualenv for use with EasyBuild
then using <code class="docutils literal notranslate"><span class="pre">python</span></code> instead of <code class="docutils literal notranslate"><span class="pre">python3.8</span></code> or similar is enough
as there will be a <code class="docutils literal notranslate"><span class="pre">python</span></code> binary available inside your virtualenv.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="data-analytics">
<h1>Data Analytics<a class="headerlink" href="#data-analytics" title="Permalink to this heading">#</a></h1>
<p>On ZIH systems, there are many possibilities for working with tools from the field of data
analytics. The boundaries between data analytics and machine learning are fluid.
Therefore, it may be worthwhile to search for a specific issue within the data analytics and
machine learning sections.</p>
<p>The following tools are available on ZIH systems, among others:</p>
<ul class="simple">
<li><p><span class="xref myst">Python</span></p></li>
<li><p><span class="xref myst">R</span></p></li>
<li><p><span class="xref myst">RStudio</span></p></li>
<li><p><span class="xref myst">Big Data framework Spark</span></p></li>
<li><p><span class="xref myst">MATLAB and Mathematica</span></p></li>
</ul>
<p>Detailed information about frameworks for machine learning, such as <span class="xref myst">TensorFlow</span>
and <span class="xref myst">PyTorch</span>, can be found in the <span class="xref myst">machine learning</span> subsection.</p>
<p>Other software, not listed here, can be searched with</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>spider<span class="w"> </span>&lt;software_name&gt;
</pre></div>
</div>
<p>Refer to the section covering <span class="xref myst">modules</span> for further information on the modules system.
Additional software or special versions of <span class="xref myst">individual modules</span>
can be installed individually by each user. If possible, the use of
<span class="xref myst">virtual environments</span> is
recommended (e.g. for Python). Likewise, software can be used within <span class="xref myst">containers</span>.</p>
<p>For the transfer of larger amounts of data into and within the system, the
<span class="xref myst">export nodes and Datamover</span> should be used.
Data is stored in the <span class="xref myst">workspaces</span>.
Software modules or virtual environments can also be installed in workspaces to enable
collaborative work even within larger groups.</p>
<!--General recommendations for setting up workflows can be found in the experiments section.-->
</section>
<section class="tex2jax_ignore mathjax_ignore" id="data-analytics-with-python">
<h1>Data Analytics with Python<a class="headerlink" href="#data-analytics-with-python" title="Permalink to this heading">#</a></h1>
<p>Python is a high-level interpreted language widely used in research and science. Using ZIH system
allows you to work with Python quicker and more effective. Here, a general introduction to working
with Python on ZIH systems is given. Further documentation is available for specific
<span class="xref myst">machine learning frameworks</span>.</p>
<section id="python-console-and-virtual-environments">
<h2>Python Console and Virtual Environments<a class="headerlink" href="#python-console-and-virtual-environments" title="Permalink to this heading">#</a></h2>
<p>Often, it is useful to create an isolated development environment, which can be shared among
a research group and/or teaching class. For this purpose,
<span class="xref myst">Python virtual environments</span> can be used.</p>
<p>!!! hint
For working with conda virtual environments, it may be necessary to configure your shell as
described in <span class="xref myst">Python virtual environments</span></p>
<p>The interactive Python interpreter can also be used on ZIH systems via an interactive job:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>srun<span class="w"> </span>--gres<span class="o">=</span>gpu:1<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">7</span><span class="w"> </span>--pty<span class="w"> </span>--mem-per-cpu<span class="o">=</span><span class="m">8000</span><span class="w"> </span>bash
<span class="gp">marie@compute$ </span>module<span class="w"> </span>load<span class="w"> </span>Python
<span class="gp">marie@compute$ </span>python
<span class="go">Python 3.8.6 (default, Feb 17 2021, 11:48:51)</span>
<span class="go">[GCC 10.2.0] on linux</span>
<span class="go">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span>
<span class="go">&gt;&gt;&gt;</span>
</pre></div>
</div>
</section>
<section id="jupyter-notebooks">
<h2>Jupyter Notebooks<a class="headerlink" href="#jupyter-notebooks" title="Permalink to this heading">#</a></h2>
<p>Jupyter notebooks allow to analyze data interactively using your web browser. One advantage of
Jupyter is, that code, documentation and visualization can be included in a single notebook, so that
it forms a unit. Jupyter notebooks can be used for many tasks, such as data cleaning and
transformation, numerical simulation, statistical modeling, data visualization and also machine
learning.</p>
<p>On ZIH systems, a <span class="xref myst">JupyterHub</span> is available, which can be used to run a
Jupyter notebook on a node, using a GPU when needed.</p>
</section>
<section id="parallel-computing-with-python">
<h2>Parallel Computing with Python<a class="headerlink" href="#parallel-computing-with-python" title="Permalink to this heading">#</a></h2>
<section id="pandas-with-pandarallel">
<h3>Pandas with Pandarallel<a class="headerlink" href="#pandas-with-pandarallel" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="https://pandas.pydata.org/">Pandas</a>{:target=‚Äù_blank‚Äù} is a widely used library for data
analytics in Python.
In many cases, an existing source code using Pandas can be easily modified for parallel execution by
using the <a class="reference external" href="https://github.com/nalepae/pandarallel/tree/v1.5.2">pandarallel</a> module. The number of
threads that can be used in parallel depends on the number of cores (parameter <code class="docutils literal notranslate"><span class="pre">--cpus-per-task</span></code>)
within the Slurm request, e.g.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>srun<span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">4</span><span class="w"> </span>--mem<span class="o">=</span>2G<span class="w"> </span>--hint<span class="o">=</span>nomultithread<span class="w"> </span>--pty<span class="w"> </span>--time<span class="o">=</span><span class="m">8</span>:00:00<span class="w"> </span>bash
</pre></div>
</div>
<p>The above request allows to use 4 parallel threads.</p>
<p>The following example shows how to parallelize the apply method for pandas dataframes with the
pandarallel module. If the pandarallel module is not installed already, use a
<span class="xref myst">virtual environment</span> to install the module.</p>
<p>??? example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```python
import pandas as pd
import numpy as np
from pandarallel import pandarallel

pandarallel.initialize()
# unfortunately the initialize method gets the total number of physical cores without
# taking into account allocated cores by Slurm, but the choice of the -c parameter is of relevance here

N_rows = 10**5
N_cols = 5
df = pd.DataFrame(np.random.randn(N_rows, N_cols))

# here some function that needs to be executed in parallel
def transform(x):
    return(np.mean(x))

print(&#39;calculate with normal apply...&#39;)
df.apply(func=transform, axis=1)

print(&#39;calculate with pandarallel...&#39;)
df.parallel_apply(func=transform, axis=1)
```
</pre></div>
</div>
<p>For more examples of using pandarallel check out
<a class="reference external" href="https://github.com/nalepae/pandarallel/blob/master/docs/examples_mac_linux.ipynb">https://github.com/nalepae/pandarallel/blob/master/docs/examples.ipynb</a>.</p>
</section>
<section id="dask">
<h3>Dask<a class="headerlink" href="#dask" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="https://dask.org/">Dask</a> is a flexible and open-source library
for parallel computing in Python.
It replaces some Python data structures with parallel versions
in order to provide advanced
parallelism for analytics, enabling performance at scale
for some of the popular tools.
For instance: Dask arrays replace NumPy arrays,
Dask dataframes replace Pandas dataframes.
Furthermore, Dask-ML scales machine learning APIs like Scikit-Learn and XGBoost.</p>
<p>Dask is composed of two parts:</p>
<ul class="simple">
<li><p>Dynamic task scheduling optimized for computation and interactive
computational workloads.</p></li>
<li><p>Big Data collections like parallel arrays, data frames, and lists that extend common interfaces
like NumPy, Pandas, or Python iterators to larger-than-memory or distributed environments.
These parallel collections run on top of dynamic task schedulers.</p></li>
</ul>
<p>Dask supports several user interfaces:</p>
<ul class="simple">
<li><p>High-Level</p>
<ul>
<li><p>Arrays: Parallel NumPy</p></li>
<li><p>Bags: Parallel lists</p></li>
<li><p>DataFrames: Parallel Pandas</p></li>
<li><p>Machine Learning: Parallel Scikit-Learn</p></li>
<li><p>Others from external projects, like XArray</p></li>
</ul>
</li>
<li><p>Low-Level</p>
<ul>
<li><p>Delayed: Parallel function evaluation</p></li>
<li><p>Futures: Real-time parallel function evaluation</p></li>
</ul>
</li>
</ul>
<section id="dask-modules-on-zih-systems">
<h4>Dask Modules on ZIH Systems<a class="headerlink" href="#dask-modules-on-zih-systems" title="Permalink to this heading">#</a></h4>
<p>On ZIH systems, Dask is available as a module.
Check available versions and load your preferred one:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>spider<span class="w"> </span>dask
<span class="go">------------------------------------------------------------------------------------------</span>
<span class="go">    dask:</span>
<span class="go">----------------------------------------------------------------------------------------------</span>
<span class="go">    Versions:</span>
<span class="go">        dask/2.8.0-fosscuda-2019b-Python-3.7.4</span>
<span class="go">        dask/2.8.0-Python-3.7.4</span>
<span class="go">        dask/2.8.0 (E)</span>
<span class="go">[...]</span>
<span class="gp">marie@compute$ </span>module<span class="w"> </span>load<span class="w"> </span>dask/2.8.0-fosscuda-2019b-Python-3.7.4
<span class="gp">marie@compute$ </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import dask; print(dask.__version__)&quot;</span>
<span class="go">2021.08.1</span>
</pre></div>
</div>
<p>The preferred way is to use Dask as a separate module as was described above.
However, you can use it as part of the <strong>Anaconda</strong> module, e.g: <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">load</span> <span class="pre">Anaconda3</span></code>.</p>
</section>
<section id="scheduling-by-dask">
<h4>Scheduling by Dask<a class="headerlink" href="#scheduling-by-dask" title="Permalink to this heading">#</a></h4>
<p>Whenever you use functions on Dask collections (Dask Array, Dask Bag, etc.), Dask models these as
single tasks forming larger task graphs in the background without you noticing.
After Dask generates these task graphs,
it needs to execute them on parallel hardware.
This is the job of a task scheduler.
Please use Distributed scheduler for your
Dask computations on the cluster and avoid using a Single machine scheduler.</p>
<section id="distributed-scheduler">
<h5>Distributed Scheduler<a class="headerlink" href="#distributed-scheduler" title="Permalink to this heading">#</a></h5>
<p>There are a variety of ways to set Distributed scheduler.
However, <code class="docutils literal notranslate"><span class="pre">dask.distributed</span></code> scheduler will be used for many of them.
To use the <code class="docutils literal notranslate"><span class="pre">dask.distributed</span></code> scheduler you must set up a Client:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">dask.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">Client</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>  <span class="c1"># Connect to distributed cluster and override default</span>
<span class="n">df</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>  <span class="c1"># This now runs on the distributed system</span>
</pre></div>
</div>
<p>The idea behind Dask is to scale Python and distribute computation among the workers (multiple
machines, jobs).
The preferred and simplest way to run Dask on ZIH systems
today both for new or experienced users
is to use <strong><a class="reference external" href="https://jobqueue.dask.org/">dask-jobqueue</a></strong>.</p>
<p>However, Dask-jobqueue is slightly oriented toward
interactive analysis
usage, and it might be better to use tools like
<strong><a class="reference external" href="https://docs.dask.org/en/latest/setup/hpc.html#using-mpi">Dask-mpi</a></strong>
in some routine batch production workloads.</p>
</section>
<section id="dask-mpi">
<h5>Dask-mpi<a class="headerlink" href="#dask-mpi" title="Permalink to this heading">#</a></h5>
<p>You can launch a Dask network using
<code class="docutils literal notranslate"><span class="pre">mpirun</span></code> or <code class="docutils literal notranslate"><span class="pre">mpiexec</span></code> and the <code class="docutils literal notranslate"><span class="pre">dask-mpi</span></code> command line executable.
This depends on the <span class="xref myst">mpi4py library</span>.
For more detailed information, please check
<a class="reference external" href="https://docs.dask.org/en/latest/setup/hpc.html#using-mpi">the official documentation</a>.</p>
</section>
<section id="dask-jobqueue">
<h5>Dask-jobqueue<a class="headerlink" href="#dask-jobqueue" title="Permalink to this heading">#</a></h5>
<p><a class="reference external" href="https://jobqueue.dask.org/">Dask-jobqueue</a> can be used as the standard way
to use dask for most users.
It allows an easy deployment of Dask Distributed on HPC with Slurm
or other job queuing systems.</p>
<p>Dask-jobqueue is available as an extension
for a Dask module (which can be loaded by: <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">load</span> <span class="pre">dask</span></code>).</p>
<p>The availability of the exact packages (such a Dask-jobqueue)
in the module can be checked by the
<code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">whatis</span> <span class="pre">&lt;name_of_the_module&gt;</span></code> command, e.g. <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">whatis</span> <span class="pre">dask</span></code>.</p>
<p>Moreover, it is possible to install and use <code class="docutils literal notranslate"><span class="pre">dask-jobqueue</span></code>
in your local python environments.
You can install Dask-jobqueue with <code class="docutils literal notranslate"><span class="pre">pip</span></code> or <code class="docutils literal notranslate"><span class="pre">conda</span></code>.</p>
<section id="example-of-using-dask-jobqueue-with-slurmcluster">
<h6>Example of Using Dask-Jobqueue with SLURMCluster<a class="headerlink" href="#example-of-using-dask-jobqueue-with-slurmcluster" title="Permalink to this heading">#</a></h6>
<p><a class="reference external" href="https://jobqueue.dask.org/en/latest/howitworks.html#workers-vs-jobs">Dask-jobqueue</a>
allows running jobs on the ZIH system
inside the python code and scale computations over the jobs.
<a class="reference external" href="https://jobqueue.dask.org/en/latest/howitworks.html#workers-vs-jobs">Dask-jobqueue</a>
creates a Dask Scheduler in the Python process
where the cluster object is instantiated.
Please check the example of a definition of the cluster object
for the cluster <code class="docutils literal notranslate"><span class="pre">Alpha</span></code> (queue at the dask terms) on the ZIH system:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">dask_jobqueue</span><span class="w"> </span><span class="kn">import</span> <span class="n">SLURMCluster</span>

<span class="n">cluster</span> <span class="o">=</span> <span class="n">SLURMCluster</span><span class="p">(</span><span class="n">queue</span><span class="o">=</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span>
  <span class="n">cores</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
  <span class="n">processes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
  <span class="n">project</span><span class="o">=</span><span class="s1">&#39;p_number_crunch&#39;</span><span class="p">,</span>
  <span class="n">memory</span><span class="o">=</span><span class="s2">&quot;8GB&quot;</span><span class="p">,</span>
  <span class="n">walltime</span><span class="o">=</span><span class="s2">&quot;00:30:00&quot;</span><span class="p">)</span>

</pre></div>
</div>
<p>These parameters above specify the characteristics of a
single job or a single compute node,
rather than the characteristics of your computation as a whole.
It hasn‚Äôt actually launched any jobs yet.
For the full computation, you will then ask for a number of
jobs using the scale command, e.g : <code class="docutils literal notranslate"><span class="pre">cluster.scale(2)</span></code>.
Thus, you have to specify a <code class="docutils literal notranslate"><span class="pre">SLURMCluster</span></code> by <code class="docutils literal notranslate"><span class="pre">dask_jobqueue</span></code>,
scale it and use it for your computations. There is an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">Client</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dask_jobqueue</span><span class="w"> </span><span class="kn">import</span> <span class="n">SLURMCluster</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dask</span><span class="w"> </span><span class="kn">import</span> <span class="n">delayed</span>

<span class="n">cluster</span> <span class="o">=</span> <span class="n">SLURMCluster</span><span class="p">(</span>
  <span class="n">cores</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
  <span class="n">processes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
  <span class="n">project</span><span class="o">=</span><span class="s1">&#39;p_number_crunch&#39;</span><span class="p">,</span>
  <span class="n">memory</span><span class="o">=</span><span class="s2">&quot;80GB&quot;</span><span class="p">,</span>
  <span class="n">walltime</span><span class="o">=</span><span class="s2">&quot;00:30:00&quot;</span><span class="p">,</span>
  <span class="n">extra</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;--resources gpu=1&#39;</span><span class="p">])</span>

<span class="n">cluster</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>             <span class="c1">#scale it to 2 workers!</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span>     <span class="c1">#command will show you number of workers (python objects corresponds to jobs)</span>
</pre></div>
</div>
<p>Please have a look at the <code class="docutils literal notranslate"><span class="pre">extra</span></code> parameter in the script above.
This could be used to specify a
special hardware availability that the scheduler
is not aware of, for example, GPUs.
Please don‚Äôt forget to specify the name of your project.</p>
<p>The Python code for setting up Slurm clusters
and scaling clusters can be run by the <code class="docutils literal notranslate"><span class="pre">srun</span></code>
(but remember that using <code class="docutils literal notranslate"><span class="pre">srun</span></code> directly on the shell
blocks the shell and launches an
interactive job) or batch jobs or
<span class="xref myst">JupyterHub</span> with loaded Dask
(by module or by Python virtual environment).</p>
<p>!!! note
The job to run original code (de facto an interface) with a setup should be simple and light.
Please don‚Äôt use a lot of resources for that.</p>
<p>The following example shows using
Dask by <code class="docutils literal notranslate"><span class="pre">dask-jobqueue</span></code> with <code class="docutils literal notranslate"><span class="pre">SLURMCluster</span></code> and <code class="docutils literal notranslate"><span class="pre">dask.array</span></code>
for the Monte-Carlo estimation of Pi.</p>
<p>??? example ‚ÄúExample of using SLURMCluster‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```python
#use of dask-jobqueue for the estimation of Pi by Monte-Carlo method

import time
from time import time, sleep
from dask.distributed import Client
from dask_jobqueue import SLURMCluster
import subprocess as sp

import dask.array as da
import numpy as np

#setting up the dashboard

uid = int( sp.check_output(&#39;id -u&#39;, shell=True).decode(&#39;utf-8&#39;).replace(&#39;\n&#39;,&#39;&#39;) )
portdash = 10001 + uid

#create a Slurm cluster, please specify your project

cluster = SLURMCluster(cores=2, project=&#39;p_number_crunch&#39;, memory=&quot;8GB&quot;, walltime=&quot;00:30:00&quot;, extra=[&#39;--resources gpu=1&#39;], scheduler_options={&quot;dashboard_address&quot;: f&quot;:{portdash}&quot;})

#submit the job to the scheduler with the number of nodes (here 2) requested:

cluster.scale(2)

#wait for Slurm to allocate a resources

sleep(120)

#check resources

client = Client(cluster)
client

#real calculations with a Monte Carlo method

def calc_pi_mc(size_in_bytes, chunksize_in_bytes=200e6):
  &quot;&quot;&quot;Calculate PI using a Monte Carlo estimate.&quot;&quot;&quot;

  size = int(size_in_bytes / 8)
  chunksize = int(chunksize_in_bytes / 8)

  xy = da.random.uniform(0, 1, size=(size / 2, 2), chunks=(chunksize / 2, 2))

  in_circle = ((xy ** 2).sum(axis=-1) &lt; 1)
  pi = 4 * in_circle.mean()

  return pi

def print_pi_stats(size, pi, time_delta, num_workers):
  &quot;&quot;&quot;Print pi, calculate offset from true value, and print some stats.&quot;&quot;&quot;
  print(f&quot;{size / 1e9} GB\n&quot;
        f&quot;\tMC pi: {pi : 13.11f}&quot;
        f&quot;\tErr: {abs(pi - np.pi) : 10.3e}\n&quot;
        f&quot;\tWorkers: {num_workers}&quot;
        f&quot;\t\tTime: {time_delta : 7.3f}s&quot;)

#let&#39;s loop over different volumes of double-precision random numbers and estimate it

for size in (1e9 * n for n in (1, 10, 100)):

  start = time()
  pi = calc_pi_mc(size).compute()
  elaps = time() - start

  print_pi_stats(size, pi, time_delta=elaps, num_workers=len(cluster.scheduler.workers))

#Scaling the Cluster to twice its size and re-run the experiments

new_num_workers = 2 * len(cluster.scheduler.workers)

print(f&quot;Scaling from {len(cluster.scheduler.workers)} to {new_num_workers} workers.&quot;)

cluster.scale(new_num_workers)

sleep(120)

client

#Re-run same experiments with doubled cluster

for size in (1e9 * n for n in (1, 10, 100)):

  start = time()
  pi = calc_pi_mc(size).compute()
  elaps = time() - start

  print_pi_stats(size, pi, time_delta=elaps, num_workers=len(cluster.scheduler.workers))
```
</pre></div>
</div>
<p>Please check the availability of resources that you want to allocate
by the script for the example above.
You can do it with <code class="docutils literal notranslate"><span class="pre">sinfo</span></code> command. The script doesn‚Äôt work
without available cluster resources.</p>
</section>
</section>
</section>
</section>
<section id="mpi4py-mpi-for-python">
<h3>Mpi4py -  MPI for Python<a class="headerlink" href="#mpi4py-mpi-for-python" title="Permalink to this heading">#</a></h3>
<p>Message Passing Interface (MPI) is a standardized and
portable message-passing standard, designed to
function on a wide variety of parallel computing architectures.</p>
<p>Mpi4py (MPI for Python) provides bindings of the MPI standard for
the Python programming language,
allowing any Python program to exploit multiple processors.</p>
<p>Mpi4py is based on MPI-2 C++ bindings. It supports almost all MPI calls.
It supports communication of pickle-able Python objects.
Mpi4py provides optimized communication of NumPy arrays.</p>
<p>Mpi4py is included in the SciPy-bundle modules on the ZIH system.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>load<span class="w"> </span>SciPy-bundle/2020.11-foss-2020b
<span class="go">Module SciPy-bundle/2020.11-foss-2020b and 28 dependencies loaded.</span>
<span class="gp">marie@compute$ </span>pip<span class="w"> </span>list
<span class="go">Package                       Version</span>
<span class="go">----------------------------- ----------</span>
<span class="go">[...]</span>
<span class="go">mpi4py                        3.0.3</span>
<span class="go">[...]</span>
</pre></div>
</div>
<p>Other versions of the package can be found with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>spider<span class="w"> </span>mpi4py
<span class="go">-----------------------------------------------------------------------------------------------------------------------------------------</span>
<span class="go">  mpi4py:</span>
<span class="go">-----------------------------------------------------------------------------------------------------------------------------------------</span>
<span class="go">     Versions:</span>
<span class="go">        mpi4py/1.3.1</span>
<span class="go">        mpi4py/2.0.0-impi</span>
<span class="go">        mpi4py/3.0.0 (E)</span>
<span class="go">        mpi4py/3.0.2 (E)</span>
<span class="go">        mpi4py/3.0.3 (E)</span>

<span class="go">Names marked by a trailing (E) are extensions provided by another module.</span>

<span class="go">-----------------------------------------------------------------------------------------------------------------------------------------</span>
<span class="go">  For detailed information about a specific &quot;mpi4py&quot; package (including how to load the modules), use the module&#39;s full name.</span>
<span class="go">  Note that names that have a trailing (E) are extensions provided by other modules.</span>
<span class="go">  For example:</span>

<span class="gp">     $ </span>module<span class="w"> </span>spider<span class="w"> </span>mpi4py/3.0.3
<span class="go">-----------------------------------------------------------------------------------------------------------------------------------------</span>
</pre></div>
</div>
<p>Moreover, it is possible to install mpi4py in your local conda
environment.</p>
<p>The example of mpi4py usage for the verification that
mpi4py is running correctly can be found below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>
<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%d</span><span class="s2"> of </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">(),</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()))</span>
</pre></div>
</div>
<p>For the multi-node case, use a script similar to this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --nodes=2</span>
<span class="c1">#SBATCH --tasks-per-node=2</span>
<span class="c1">#SBATCH --cpus-per-task=1</span>

module<span class="w"> </span>load<span class="w"> </span>release/23.04
module<span class="w"> </span>load<span class="w"> </span>Anaconda3/2022.05

<span class="nb">eval</span><span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>conda<span class="w"> </span>shell.bash<span class="w"> </span>hook<span class="k">)</span><span class="s2">&quot;</span>
conda<span class="w"> </span>activate<span class="w"> </span>/home/marie/conda-virtual-environment/kernel2<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>srun<span class="w"> </span>python<span class="w"> </span>mpi4py_test.py<span class="w">    </span><span class="c1">#specify name of your virtual environment</span>
</pre></div>
</div>
<p>For the verification of the multi-node case,
you can use the Python code from the previous part
(with verification of the installation) as a test file.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="data-analytics-with-r">
<h1>Data Analytics with R<a class="headerlink" href="#data-analytics-with-r" title="Permalink to this heading">#</a></h1>
<p><a class="reference external" href="https://www.r-project.org/about.html">R</a> is a programming language and environment for statistical
computing and graphics. It provides a wide variety of statistical (linear and nonlinear modeling,
classical statistical tests, time-series analysis, classification, etc.), machine learning
algorithms and graphical techniques.  R is an integrated suite of software facilities for data
manipulation, calculation and graphing.</p>
<p>We recommend using the clusters Barnard and/or Romeo to work with R. For more details
see our <span class="xref myst">hardware documentation</span>.</p>
<section id="r-console">
<h2>R Console<a class="headerlink" href="#r-console" title="Permalink to this heading">#</a></h2>
<p>In the following example, the <code class="docutils literal notranslate"><span class="pre">srun</span></code> command is used to start an interactive job, so that the output
is visible to the user. Please check the <span class="xref myst">Slurm page</span> for details.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login.barnard$ </span>srun<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span><span class="w"> </span>--nodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">4</span><span class="w"> </span>--mem-per-cpu<span class="o">=</span><span class="m">2541</span><span class="w"> </span>--time<span class="o">=</span><span class="m">01</span>:00:00<span class="w"> </span>--pty<span class="w"> </span>bash
<span class="gp">[marie@barnard ]$ </span>module<span class="w"> </span>load<span class="w"> </span>release/23.10<span class="w">  </span>GCC/11.3.0<span class="w">  </span>OpenMPI/4.1.4<span class="w"> </span>R/4.2.1
<span class="go">Module GCC/11.3.0, OpenMPI/4.1.4, R/4.2.1 and 109 dependencies loaded.</span>
<span class="gp">[marie@barnard ]$ </span>which<span class="w"> </span>R
<span class="go">/software/rapids/r23.10/R/4.2.1-foss-2022a/bin/R</span>
</pre></div>
</div>
<p>Using interactive sessions is recommended only for short test runs, while for larger runs batch jobs
should be used. Examples can be found on the <span class="xref myst">Slurm page</span>.</p>
<p>It is also possible to run <code class="docutils literal notranslate"><span class="pre">Rscript</span></code> command directly (after loading the module):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@barnard$ </span>Rscript<span class="w"> </span>&lt;/path/to/script/your_script.R&gt;<span class="w"> </span>&lt;param1&gt;<span class="w"> </span>&lt;param2&gt;
</pre></div>
</div>
</section>
<section id="r-in-jupyterhub">
<h2>R in JupyterHub<a class="headerlink" href="#r-in-jupyterhub" title="Permalink to this heading">#</a></h2>
<p>In addition to using interactive and batch jobs, it is possible to work with R using
<span class="xref myst">JupyterHub</span>.</p>
<p>The production and test <span class="xref myst">environments</span> of
JupyterHub contain R kernel. It can be started either in the notebook or in the console.</p>
</section>
<section id="rstudio">
<h2>RStudio<a class="headerlink" href="#rstudio" title="Permalink to this heading">#</a></h2>
<p>For using R with RStudio please refer to the documentation on
<span class="xref myst">Data Analytics with RStudio</span>.</p>
</section>
<section id="install-packages-in-r">
<h2>Install Packages in R<a class="headerlink" href="#install-packages-in-r" title="Permalink to this heading">#</a></h2>
<p>By default, user-installed packages are saved in the users home in a folder depending on
the architecture (<code class="docutils literal notranslate"><span class="pre">x86</span></code> or <code class="docutils literal notranslate"><span class="pre">PowerPC</span></code>). Therefore the packages should be installed using interactive
jobs on the compute node:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>load<span class="w"> </span>R
<span class="go">[...]</span>
<span class="go">Module R/3.6.0-foss-2019a and 56 dependencies loaded.</span>
<span class="gp">marie@compute$ </span>R<span class="w"> </span>-e<span class="w"> </span><span class="s1">&#39;install.packages(&quot;ggplot2&quot;)&#39;</span>
<span class="go">[...]</span>
</pre></div>
</div>
</section>
<section id="deep-learning-with-r">
<h2>Deep Learning with R<a class="headerlink" href="#deep-learning-with-r" title="Permalink to this heading">#</a></h2>
<p>The deep learning frameworks perform extremely fast when run on accelerators such as GPU.
Therefore, using nodes with built-in GPUs, e.g., clusters
<span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Capella</span></code></span>,
<span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Alpha</span></code></span> and
<span class="xref myst"><code class="docutils literal notranslate"><span class="pre">Power9</span></code></span> is beneficial for the examples here.</p>
<section id="r-interface-to-tensorflow">
<h3>R Interface to TensorFlow<a class="headerlink" href="#r-interface-to-tensorflow" title="Permalink to this heading">#</a></h3>
<p>The <a class="reference external" href="https://tensorflow.rstudio.com/">‚ÄúTensorFlow‚Äù R package</a> provides R users access to the
TensorFlow framework. <a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a> is an open-source software library
for numerical computation using data flow graphs.</p>
<p>The respective modules can be loaded with the following</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>load<span class="w"> </span>R/3.6.2-fosscuda-2019b
<span class="go">[...]</span>
<span class="go">Module R/3.6.2-fosscuda-2019b and 63 dependencies loaded.</span>
<span class="gp">marie@compute$ </span>module<span class="w"> </span>load<span class="w"> </span>TensorFlow/2.3.1-fosscuda-2019b-Python-3.7.4
<span class="go">Module TensorFlow/2.3.1-fosscuda-2019b-Python-3.7.4 and 15 dependencies loaded.</span>
</pre></div>
</div>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> Be aware that for compatibility reasons it is important to choose [modules](modules.md) with
 the same toolchain version (in this case `fosscuda/2019b`).
</pre></div>
</div>
<p>In order to interact with Python-based frameworks (like TensorFlow) <code class="docutils literal notranslate"><span class="pre">reticulate</span></code> R library is used.
To configure it to point to the correct Python executable in your virtual environment, create
a file named <code class="docutils literal notranslate"><span class="pre">.Rprofile</span></code> in your project directory (e.g. R-TensorFlow) with the following
contents:</p>
<div class="highlight-R notranslate"><div class="highlight"><pre><span></span><span class="nf">Sys.setenv</span><span class="p">(</span><span class="n">RETICULATE_PYTHON</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;/sw/installed/Python/3.7.4-GCCcore-8.3.0/bin/python&quot;</span><span class="p">)</span><span class="w">    </span><span class="c1">#assign RETICULATE_PYTHON to the python executable</span>
</pre></div>
</div>
<p>Let‚Äôs start R, install some libraries and evaluate the result:</p>
<div class="highlight-rconsole notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt; </span><span class="nf">install.packages</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;reticulate&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;tensorflow&quot;</span><span class="p">))</span>
<span class="go">Installing packages into ‚Äò~/R/x86_64-pc-linux-gnu-library/3.6‚Äô</span>
<span class="go">(as ‚Äòlib‚Äô is unspecified)</span>
<span class="gp">&gt; </span><span class="n">reticulate</span><span class="o">::</span><span class="nf">py_config</span><span class="p">()</span>
<span class="go">python:         /software/rome/Python/3.7.4-GCCcore-8.3.0/bin/python</span>
<span class="go">libpython:      /sw/installed/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so</span>
<span class="go">pythonhome:     /software/rome/Python/3.7.4-GCCcore-8.3.0:/software/rome/Python/3.7.4-GCCcore-8.3.0</span>
<span class="go">version:        3.7.4 (default, Mar 25 2020, 13:46:43)  [GCC 8.3.0]</span>
<span class="go">numpy:          /software/rome/SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/numpy</span>
<span class="go">numpy_version:  1.17.3</span>

<span class="go">NOTE: Python version was forced by RETICULATE_PYTHON</span>

<span class="gp">&gt; </span><span class="nf">library</span><span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="go">2021-08-26 16:11:47.110548: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1</span>
<span class="gp">&gt; </span><span class="n">tf</span><span class="o">$</span><span class="nf">constant</span><span class="p">(</span><span class="s">&quot;Hello TensorFlow&quot;</span><span class="p">)</span>
<span class="go">2021-08-26 16:14:00.269248: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1</span>
<span class="go">2021-08-26 16:14:00.674878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:</span>
<span class="go">pciBusID: 0000:0b:00.0 name: A100-SXM4-40GB computeCapability: 8.0</span>
<span class="go">coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s</span>
<span class="go">[...]</span>
<span class="go">tf.Tensor(b&#39;Hello TensorFlow&#39;, shape=(), dtype=string)</span>
</pre></div>
</div>
<p>??? example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The example shows the use of the TensorFlow package with the R for the classification problem
related to the MNIST data set.
```R
library(tensorflow)
library(keras)

# Data preparation
batch_size &lt;- 128
num_classes &lt;- 10
epochs &lt;- 12

# Input image dimensions
img_rows &lt;- 28
img_cols &lt;- 28

# Shuffled and split the data between train and test sets
mnist &lt;- dataset_mnist()
x_train &lt;- mnist$train$x
y_train &lt;- mnist$train$y
x_test &lt;- mnist$test$x
y_test &lt;- mnist$test$y

# Redefine dimension of train/test inputs
x_train &lt;- array_reshape(x_train, c(nrow(x_train), img_rows, img_cols, 1))
x_test &lt;- array_reshape(x_test, c(nrow(x_test), img_rows, img_cols, 1))
input_shape &lt;- c(img_rows, img_cols, 1)

# Transform RGB values into [0,1] range
x_train &lt;- x_train / 255
x_test &lt;- x_test / 255

cat(&#39;x_train_shape:&#39;, dim(x_train), &#39;\n&#39;)
cat(nrow(x_train), &#39;train samples\n&#39;)
cat(nrow(x_test), &#39;test samples\n&#39;)

# Convert class vectors to binary class matrices
y_train &lt;- to_categorical(y_train, num_classes)
y_test &lt;- to_categorical(y_test, num_classes)

# Define Model
model &lt;- keras_model_sequential() %&gt;%
  layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = &#39;relu&#39;,
                input_shape = input_shape) %&gt;%
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = &#39;relu&#39;) %&gt;%
  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%
  layer_dropout(rate = 0.25) %&gt;%
  layer_flatten() %&gt;%
  layer_dense(units = 128, activation = &#39;relu&#39;) %&gt;%
  layer_dropout(rate = 0.5) %&gt;%
  layer_dense(units = num_classes, activation = &#39;softmax&#39;)

# Compile model
model %&gt;% compile(
  loss = loss_categorical_crossentropy,
  optimizer = optimizer_adadelta(),
  metrics = c(&#39;accuracy&#39;)
)

# Train model
model %&gt;% fit(
  x_train, y_train,
  batch_size = batch_size,
  epochs = epochs,
  validation_split = 0.2
)
scores &lt;- model %&gt;% evaluate(
  x_test, y_test, verbose = 0
)

# Output metrics
cat(&#39;Test loss:&#39;, scores[[1]], &#39;\n&#39;)
cat(&#39;Test accuracy:&#39;, scores[[2]], &#39;\n&#39;)
```
</pre></div>
</div>
</section>
</section>
<section id="parallel-computing-with-r">
<h2>Parallel Computing with R<a class="headerlink" href="#parallel-computing-with-r" title="Permalink to this heading">#</a></h2>
<p>Generally, the R code is serial. However, many computations in R can be made faster by the use of
parallel computations. This section concentrates on most general methods and examples.
The <a class="reference external" href="https://www.rdocumentation.org/packages/parallel/versions/3.6.2">parallel</a> library
will be used below.</p>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Please do not install or update R packages related to parallelism as it could lead to
conflicts with other preinstalled packages.
</pre></div>
</div>
<section id="basic-lapply-based-parallelism">
<h3>Basic lapply-Based Parallelism<a class="headerlink" href="#basic-lapply-based-parallelism" title="Permalink to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">lapply()</span></code> function is a part of base R. lapply is useful for performing operations on list-objects.
Roughly speaking, lapply is a vectorization of the source code and it is the first step before
explicit parallelization of the code.</p>
</section>
<section id="shared-memory-parallelism">
<h3>Shared-Memory Parallelism<a class="headerlink" href="#shared-memory-parallelism" title="Permalink to this heading">#</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">parallel</span></code> library includes the <code class="docutils literal notranslate"><span class="pre">mclapply()</span></code> function which is a shared memory version of
lapply. The ‚Äúmc‚Äù stands for ‚Äúmulticore‚Äù. This function distributes the <code class="docutils literal notranslate"><span class="pre">lapply</span></code> tasks across
multiple CPU cores to be executed in parallel.</p>
<p>This is a simple option for parallelization. It doesn‚Äôt require much effort to rewrite the serial
code to use <code class="docutils literal notranslate"><span class="pre">mclapply</span></code> function. Check out an example below.</p>
<p>??? example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```R
library(parallel)

# here some function that needs to be executed in parallel
average &lt;- function(size){
  norm_vector &lt;- rnorm(n=size, mean=mu, sd=sigma)
  return(mean(norm_vector))
}

# variable initialization
mu &lt;- 1.0
sigma &lt;- 1.0
vector_length &lt;- 10^7
n_repeat &lt;- 100
sample_sizes &lt;- rep(vector_length, times=n_repeat)


# shared-memory version
threads &lt;- as.integer(Sys.getenv(&quot;SLURM_CPUS_ON_NODE&quot;))
# here the name of the variable depends on the correct sbatch configuration
# unfortunately the built-in function gets the total number of physical cores without
# taking into account allocated cores by Slurm

list_of_averages &lt;- mclapply(X=sample_sizes, FUN=average, mc.cores=threads)  # apply function &quot;average&quot; 100 times
```
</pre></div>
</div>
<p>The disadvantages of using shared-memory parallelism approach are, that the number of parallel tasks
is limited to the number of cores on a single node. The maximum number of cores on a single node can
be found in our <span class="xref myst">hardware documentation</span>.</p>
<p>Submitting a multicore R job to Slurm is very similar to submitting an
<span class="xref myst">OpenMP Job</span>,
since both are running multicore jobs on a <strong>single</strong> node. Below is an example:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --nodes=1</span>
<span class="c1">#SBATCH --tasks-per-node=1</span>
<span class="c1">#SBATCH --cpus-per-task=16</span>
<span class="c1">#SBATCH --time=00:10:00</span>
<span class="c1">#SBATCH --output=test_Rmpi.out</span>
<span class="c1">#SBATCH --error=test_Rmpi.err</span>

module<span class="w"> </span>purge
module<span class="w"> </span>load<span class="w"> </span>release/23.10<span class="w">  </span>GCC/11.3.0<span class="w">  </span>OpenMPI/4.1.4
module<span class="w"> </span>load<span class="w"> </span>R/4.2.1

R<span class="w"> </span>CMD<span class="w"> </span>BATCH<span class="w"> </span>Rcode.R
</pre></div>
</div>
</section>
<section id="distributed-memory-parallelism">
<h3>Distributed-Memory Parallelism<a class="headerlink" href="#distributed-memory-parallelism" title="Permalink to this heading">#</a></h3>
<p>In order to go beyond the limitation of the number of cores on a single node, a cluster of workers
shall be set up. There are three options for it: MPI, PSOCK and FORK clusters.
We use <code class="docutils literal notranslate"><span class="pre">makeCluster</span></code> function from <code class="docutils literal notranslate"><span class="pre">parallel</span></code> library to create a set of copies of R processes
running in parallel. The desired type of the cluster can be specified with a parameter <code class="docutils literal notranslate"><span class="pre">TYPE</span></code>.</p>
<section id="mpi-cluster">
<h4>MPI Cluster<a class="headerlink" href="#mpi-cluster" title="Permalink to this heading">#</a></h4>
<p>This way of the R parallelism uses the
<a class="reference external" href="http://cran.r-project.org/web/packages/Rmpi/index.html">Rmpi</a> package and the
<a class="reference external" href="https://en.wikipedia.org/wiki/Message_Passing_Interface">MPI</a> (Message Passing Interface) as a
‚Äúback-end‚Äù for its parallel operations. The MPI-based job in R is very similar to submitting an
<span class="xref myst">MPI Job</span> since both are running
multicore jobs on multiple nodes. Below is an example of running R script with the Rmpi on the ZIH
system:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --ntasks=16              # this parameter determines how many processes will be spawned, please use &gt;=8</span>
<span class="c1">#SBATCH --cpus-per-task=1</span>
<span class="c1">#SBATCH --time=01:00:00</span>
<span class="c1">#SBATCH --output=test_Rmpi.out</span>
<span class="c1">#SBATCH --error=test_Rmpi.err</span>

module<span class="w"> </span>purge
module<span class="w"> </span>load<span class="w"> </span>release/23.10<span class="w">  </span>GCC/11.3.0<span class="w">  </span>OpenMPI/4.1.4
module<span class="w"> </span>load<span class="w"> </span>R/4.2.1

mpirun<span class="w"> </span>-np<span class="w"> </span><span class="m">1</span><span class="w"> </span>R<span class="w"> </span>CMD<span class="w"> </span>BATCH<span class="w"> </span>Rmpi.R<span class="w">   </span><span class="c1"># specify the absolute path to the R script, like: /scratch/ws/marie-Work/R/Rmpi.R</span>

<span class="c1"># submit with sbatch &lt;script_name&gt;</span>
</pre></div>
</div>
<p>Slurm option <code class="docutils literal notranslate"><span class="pre">--ntasks</span></code> controls the total number of parallel tasks. The number of
nodes required to complete this number of tasks will be automatically selected.
However, in some specific cases, you can specify the number of nodes and the number of necessary
tasks per node explicitly:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span><span class="c1">#SBATCH --nodes=2</span>
<span class="c1">#SBATCH --tasks-per-node=16</span>
<span class="c1">#SBATCH --cpus-per-task=1</span>

module<span class="w"> </span>purge
module<span class="w"> </span>load<span class="w"> </span>release/23.10<span class="w">  </span>GCC/11.3.0<span class="w">  </span>OpenMPI/4.1.4
module<span class="w"> </span>load<span class="w"> </span>R/4.2.1

mpirun<span class="w"> </span>-np<span class="w"> </span><span class="m">1</span><span class="w"> </span>R<span class="w"> </span>CMD<span class="w"> </span>BATCH<span class="w"> </span>--no-save<span class="w"> </span>--no-restore<span class="w"> </span>Rmpi_c.R
</pre></div>
</div>
<p>Use an example below, where 32 global ranks are distributed over 2 nodes with 16 cores each.
Each MPI rank has 1 core assigned to it.</p>
<p>??? example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```R
library(Rmpi)

# initialize an Rmpi environment
ns &lt;- mpi.universe.size()-1
mpi.spawn.Rslaves(nslaves=ns)

# send these commands to the slaves
mpi.bcast.cmd( id &lt;- mpi.comm.rank() )
mpi.bcast.cmd( ns &lt;- mpi.comm.size() )
mpi.bcast.cmd( host &lt;- mpi.get.processor.name() )

# all slaves execute this command
mpi.remote.exec(paste(&quot;I am&quot;, id, &quot;of&quot;, ns, &quot;running on&quot;, host))

# close down the Rmpi environment
mpi.close.Rslaves(dellog = FALSE)
mpi.exit()
```
</pre></div>
</div>
<p>Another example:</p>
<p>??? example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```R
library(Rmpi)
library(parallel)

# here some function that needs to be executed in parallel
average &lt;- function(size){
  norm_vector &lt;- rnorm(n=size, mean=mu, sd=sigma)
  return(mean(norm_vector))
}

# variable initialization
mu &lt;- 1.0
sigma &lt;- 1.0
vector_length &lt;- 10^7
n_repeat &lt;- 100
sample_sizes &lt;- rep(vector_length, times=n_repeat)

# cluster setup
# get number of available MPI ranks
threads = mpi.universe.size()-1
print(paste(&quot;The cluster of size&quot;, threads, &quot;will be setup...&quot;))

# initialize MPI cluster
cl &lt;- makeCluster(threads, type=&quot;MPI&quot;, outfile=&quot;&quot;)

# distribute required variables for the execution over the cluster
clusterExport(cl, list(&quot;mu&quot;,&quot;sigma&quot;))

list_of_averages &lt;- parLapply(X=sample_sizes, fun=average, cl=cl)

# shut down the cluster
#snow::stopCluster(cl)  # usually it hangs over here with Open MPI &gt; 2.0. In this case this command may be avoided, Slurm will clean up after the job finishes
```
</pre></div>
</div>
<p>To use Rmpi and MPI please use one of these clusters: <code class="docutils literal notranslate"><span class="pre">Alpha</span></code>, <code class="docutils literal notranslate"><span class="pre">Barnard</span></code> or <code class="docutils literal notranslate"><span class="pre">Romeo</span></code>.</p>
<p>Use <code class="docutils literal notranslate"><span class="pre">mpirun</span></code> command to start the R script. It is a wrapper that enables the communication
between processes running on different nodes. It is important to use <code class="docutils literal notranslate"><span class="pre">-np</span> <span class="pre">1</span></code> (the number of spawned
processes by <code class="docutils literal notranslate"><span class="pre">mpirun</span></code>), since the R takes care of it with <code class="docutils literal notranslate"><span class="pre">makeCluster</span></code> function.</p>
</section>
<section id="psock-cluster">
<h4>PSOCK cluster<a class="headerlink" href="#psock-cluster" title="Permalink to this heading">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">type=&quot;PSOCK&quot;</span></code> uses TCP sockets to transfer data between nodes. PSOCK is the default on <em>all</em>
systems. The advantage of this method is that it does not require external libraries such as MPI.
On the other hand, TCP sockets are relatively
<a class="reference external" href="http://glennklockwood.blogspot.com/2013/06/whats-killing-cloud-interconnect.html">slow</a>. Creating
a PSOCK cluster is similar to launching an MPI cluster, but instead of specifying the number of
parallel workers, you have to manually specify the number of nodes according to the
hardware specification and parameters of your job.</p>
<p>??? example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```R
library(parallel)

# a function that needs to be executed in parallel
average &lt;- function(size){
  norm_vector &lt;- rnorm(n=size, mean=mu, sd=sigma)
  return(mean(norm_vector))
}

# variable initialization
mu &lt;- 1.0
sigma &lt;- 1.0
vector_length &lt;- 10^7
n_repeat &lt;- 100
sample_sizes &lt;- rep(vector_length, times=n_repeat)

# cluster setup

# get number of available nodes (should be equal to &quot;ntasks&quot;)
mynodes = 8
print(paste(&quot;The cluster of size&quot;, threads, &quot;will be setup...&quot;))

# initialize cluster
cl &lt;- makeCluster(mynodes, type=&quot;PSOCK&quot;, outfile=&quot;&quot;)

# distribute required variables for the execution over the cluster
clusterExport(cl, list(&quot;mu&quot;,&quot;sigma&quot;))

list_of_averages &lt;- parLapply(X=sample_sizes, fun=average, cl=cl)

# shut down the cluster
print(paste(&quot;Program finished&quot;))
```
</pre></div>
</div>
</section>
<section id="fork-cluster">
<h4>FORK Cluster<a class="headerlink" href="#fork-cluster" title="Permalink to this heading">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">type=&quot;FORK&quot;</span></code> method behaves exactly like the <code class="docutils literal notranslate"><span class="pre">mclapply</span></code> function discussed in the previous
section. Like <code class="docutils literal notranslate"><span class="pre">mclapply</span></code>, it can only use the cores available on a single node. However this method
requires exporting the workspace data to other processes. The FORK method in a combination with
<code class="docutils literal notranslate"><span class="pre">parLapply</span></code> function might be used in situations, where different source code should run on each
parallel process.</p>
</section>
</section>
<section id="other-parallel-options">
<h3>Other Parallel Options<a class="headerlink" href="#other-parallel-options" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://cran.r-project.org/web/packages/foreach/index.html">foreach</a> library.
It is functionally equivalent to the
<a class="reference external" href="https://www.glennklockwood.com/data-intensive/r/lapply-parallelism.html">lapply-based parallelism</a>
discussed before but based on the for-loop</p></li>
<li><p><a class="reference external" href="https://cran.r-project.org/web/packages/future/index.html">future</a>
library. The purpose of this package is to provide a lightweight and
unified Future API for sequential and parallel processing of R
expression via futures</p></li>
<li><p><a class="reference external" href="https://www.glennklockwood.com/data-intensive/r/alternative-parallelism.html#6-1-poor-man-s-parallelism">Poor-man‚Äôs parallelism</a>
(simple data parallelism). It is the simplest, but not an elegant way to parallelize R code.
It runs several copies of the same R script where each copy reads a different part of the input
data.</p></li>
<li><p><a class="reference external" href="https://www.glennklockwood.com/data-intensive/r/alternative-parallelism.html#6-2-hands-off-parallelism">Hands-off (OpenMP)</a>
method. R has <a class="reference external" href="https://www.openmp.org/resources/">OpenMP</a> support. Thus using OpenMP is a simple
method where you don‚Äôt need to know much about the parallelism options in your code. Please be
careful and don‚Äôt mix this technique with other methods!</p></li>
</ul>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="data-analytics-with-rstudio">
<h1>Data Analytics with RStudio<a class="headerlink" href="#data-analytics-with-rstudio" title="Permalink to this heading">#</a></h1>
<p><a class="reference external" href="https://rstudio.com/">RStudio</a> is an integrated development environment (IDE) for R. It includes
a console, syntax-highlighting editor that supports direct code execution, as well as tools for
plotting, history, debugging and workspace management. RStudio is also available on ZIH systems.</p>
<p>The easiest option is to run RStudio in JupyterHub directly in the browser. It can be started
similarly to a new kernel from <span class="xref myst">JupyterLab</span> launcher.</p>
<p><img alt="RStudio launcher in JupyterHub" src="63_chat_with_docs/misc/data_analytics_with_rstudio_launcher.jpg" />
{: style=‚Äùwidth:90%‚Äù }</p>
<p>!!! tip
If an error ‚Äúcould not start RStudio in time‚Äù occurs, try reloading the web page with <code class="docutils literal notranslate"><span class="pre">F5</span></code>.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="debugging">
<h1>Debugging<a class="headerlink" href="#debugging" title="Permalink to this heading">#</a></h1>
<p>Debugging is an essential but also rather time consuming step during application development. Tools
dramatically reduce the amount of time spent to detect errors. Besides the ‚Äúclassical‚Äù serial
programming errors, which may usually be easily detected with a regular debugger, there exist
programming errors that result from the usage of OpenMP, Pthreads, or MPI. These errors may also be
detected with debuggers (preferably debuggers with support for parallel applications), however,
specialized tools like MPI checking tools (e.g. Marmot) or thread checking tools (e.g. Intel Thread
Checker) can simplify this task.</p>
<p>This page provides detailed information on classic debugging at ZIH systems.  The more specific
topic <span class="xref myst">MPI Usage Error Detection</span> covers tools to detect MPI usage
errors.</p>
<section id="overview-of-available-debuggers-at-zih">
<h2>Overview of available Debuggers at ZIH<a class="headerlink" href="#overview-of-available-debuggers-at-zih" title="Permalink to this heading">#</a></h2>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head text-left"><p>GDB</p></th>
<th class="head text-left"><p>Arm DDT</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Interface</p></td>
<td class="text-left"><p>Command line</p></td>
<td class="text-left"><p>Graphical user interface</p></td>
</tr>
<tr class="row-odd"><td><p>Languages</p></td>
<td class="text-left"><p>C/C++, Fortran</p></td>
<td class="text-left"><p>C/C++, Fortran, Python (limited)</p></td>
</tr>
<tr class="row-even"><td><p>Parallel Debugging</p></td>
<td class="text-left"><p>Threads</p></td>
<td class="text-left"><p>Threads, MPI, GPU, hybrid</p></td>
</tr>
<tr class="row-odd"><td><p>Licenses at ZIH</p></td>
<td class="text-left"><p>Free</p></td>
<td class="text-left"><p>1024 (max. number of processes/threads)</p></td>
</tr>
<tr class="row-even"><td><p>Official documentation</p></td>
<td class="text-left"><p><a class="reference external" href="https://www.gnu.org/software/gdb/">GDB website</a></p></td>
<td class="text-left"><p><a class="reference external" href="https://developer.arm.com/tools-and-software/server-and-hpc/debug-and-profile/arm-forge/arm-ddt">Arm DDT website</a></p></td>
</tr>
</tbody>
</table>
</section>
<section id="general-advice">
<h2>General Advice<a class="headerlink" href="#general-advice" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>You need to compile your code with the flag <code class="docutils literal notranslate"><span class="pre">-g</span></code> to enable
debugging. This tells the compiler to include information about
variable and function names, source code lines etc. into the
executable.</p></li>
<li><p>It is also recommendable to reduce or even disable optimizations
(<code class="docutils literal notranslate"><span class="pre">-O0</span></code> or gcc‚Äôs <code class="docutils literal notranslate"><span class="pre">-Og</span></code>). At least inlining should be disabled (usually
<code class="docutils literal notranslate"><span class="pre">-fno-inline</span></code>).</p></li>
<li><p>For parallel applications: try to reproduce the problem with less
processes or threads before using a parallel debugger.</p></li>
<li><p>Use the compiler‚Äôs check capabilities to find typical problems at
compile time or run time, read the manual (<code class="docutils literal notranslate"><span class="pre">man</span> <span class="pre">gcc</span></code>, <code class="docutils literal notranslate"><span class="pre">man</span> <span class="pre">ifort</span></code>, etc.)</p>
<ul>
<li><p>Intel C++ example: <code class="docutils literal notranslate"><span class="pre">icpc</span> <span class="pre">-g</span> <span class="pre">-std=c++14</span> <span class="pre">-w3</span> <span class="pre">-check=stack,uninit</span> <span class="pre">-check-pointers=rw</span> <span class="pre">-fp-trap=all</span></code></p></li>
<li><p>Intel Fortran example: <code class="docutils literal notranslate"><span class="pre">ifort</span> <span class="pre">-g</span> <span class="pre">-std03</span> <span class="pre">-warn</span> <span class="pre">all</span> <span class="pre">-check</span> <span class="pre">all</span> <span class="pre">-fpe-all=0</span> <span class="pre">-traceback</span></code></p></li>
<li><p>The flag <code class="docutils literal notranslate"><span class="pre">-traceback</span></code> of the Intel Fortran compiler causes to print
stack trace and source code location when the program terminates
abnormally.</p></li>
</ul>
</li>
<li><p>If your program crashes and you get an address of the failing
instruction, you can get the source code line with the command
<code class="docutils literal notranslate"><span class="pre">addr2line</span> <span class="pre">-e</span> <span class="pre">&lt;executable&gt;</span> <span class="pre">&lt;address&gt;</span></code> (if compiled with <code class="docutils literal notranslate"><span class="pre">-g</span></code>).</p></li>
<li><p>Use <span class="xref myst">Memory Debuggers</span> to
verify the proper usage of memory.</p></li>
<li><p>Core dumps are useful when your program crashes after a long
runtime.</p></li>
<li><p>Slides from user training: <span class="xref myst">Introduction to Parallel Debugging</span></p></li>
</ul>
</section>
<section id="gnu-debugger-gdb">
<h2>GNU Debugger (GDB)<a class="headerlink" href="#gnu-debugger-gdb" title="Permalink to this heading">#</a></h2>
<p>The GNU Debugger (GDB) offers only limited to no support for parallel
applications and Fortran 90. However, it might be the debugger you are
most used to. GDB works best for serial programs. You can start GDB in
several ways:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head text-left"><p>Command</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Run program under GDB</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">gdb</span> <span class="pre">&lt;executable&gt;</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Attach running program to GDB</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">gdb</span> <span class="pre">--pid</span> <span class="pre">&lt;process</span> <span class="pre">ID&gt;</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Open a core dump</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">gdb</span> <span class="pre">&lt;executable&gt;</span> <span class="pre">&lt;core</span> <span class="pre">file&gt;</span></code></p></td>
</tr>
</tbody>
</table>
<p>This <a class="reference external" href="http://users.ece.utexas.edu/~adnan/gdb-refcard.pdf">GDB Reference Sheet</a> makes life easier
when you often use GDB.</p>
<p>Fortran 90 programmers may issue an <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">load</span> <span class="pre">DDT</span></code> before their debug session. This makes the GDB
modified by DDT available, which has better support for Fortran 90 (e.g.  derived types).</p>
</section>
<section id="arm-ddt">
<h2>Arm DDT<a class="headerlink" href="#arm-ddt" title="Permalink to this heading">#</a></h2>
<p><img alt="DDT Main Window" src="63_chat_with_docs/misc/ddt-main-window.png" /></p>
<ul class="simple">
<li><p>Intuitive graphical user interface and great support for parallel applications</p></li>
<li><p>We have 1024 licenses, so many user can use this tool for parallel debugging</p></li>
<li><p>Don‚Äôt expect that debugging an MPI program with hundreds of processes will always work without
problems</p>
<ul>
<li><p>The more processes and nodes involved, the higher is the probability for timeouts or other
problems</p></li>
<li><p>Debug with as few processes as required to reproduce the bug you want to find</p></li>
</ul>
</li>
<li><p>Module to load before using: <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">load</span> <span class="pre">DDT</span></code> Start: <code class="docutils literal notranslate"><span class="pre">ddt</span> <span class="pre">&lt;executable&gt;</span></code></p>
<ul>
<li><p>If the GUI runs too slow over your remote connection: Use
<span class="xref myst">WebVNC</span> to start a remote desktop session in
a web browser.</p></li>
</ul>
</li>
<li><p>Slides from user training: <span class="xref myst">Parallel Debugging with DDT</span></p></li>
</ul>
<section id="serial-program-example">
<h3>Serial Program Example<a class="headerlink" href="#serial-program-example" title="Permalink to this heading">#</a></h3>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>DDT
<span class="go">Module DDT/24.0.5 loaded.</span>
<span class="gp">marie@login$ </span>srun<span class="w"> </span>--pty<span class="w"> </span>--x11<span class="o">=</span>first<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span><span class="w"> </span>--time<span class="o">=</span><span class="m">2</span>:00:00<span class="w"> </span>bash
<span class="go">srun: job 123456 queued and waiting for resources</span>
<span class="go">srun: job 123456 has been allocated resources</span>
<span class="gp">marie@compute$ </span>ddt<span class="w"> </span>./myprog
</pre></div>
</div>
<ul class="simple">
<li><p>Run dialog window of DDT opens.</p></li>
<li><p>Optionally: configure options like program arguments.</p></li>
<li><p>Hit <em>Run</em>.</p></li>
</ul>
</section>
<section id="multi-threaded-program-example">
<h3>Multi-threaded Program Example<a class="headerlink" href="#multi-threaded-program-example" title="Permalink to this heading">#</a></h3>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>DDT
<span class="go">Module DDT/24.0.5 loaded.</span>
<span class="gp">marie@login$ </span>srun<span class="w"> </span>--pty<span class="w"> </span>--x11<span class="o">=</span>first<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">5</span><span class="w"> </span>--time<span class="o">=</span><span class="m">2</span>:00:00<span class="w"> </span>bash
<span class="go">srun: job 123457 queued and waiting for resources</span>
<span class="go">srun: job 123457 has been allocated resources</span>
<span class="gp">marie@compute$ </span>ddt<span class="w"> </span>./myprog
</pre></div>
</div>
<ul class="simple">
<li><p>Run dialog window of DDT opens.</p></li>
<li><p>Optionally: configure options like program arguments.</p></li>
<li><p>If OpenMP: set number of threads.</p></li>
<li><p>Hit <em>Run</em>.</p></li>
</ul>
</section>
<section id="mpi-parallel-program-example">
<h3>MPI-Parallel Program Example<a class="headerlink" href="#mpi-parallel-program-example" title="Permalink to this heading">#</a></h3>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>salloc<span class="w"> </span>--x11<span class="o">=</span>first<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">2</span><span class="w"> </span>--time<span class="o">=</span><span class="m">2</span>:00:00
<span class="go">salloc: Pending job allocation 123458</span>
<span class="go">salloc: job 123458 queued and waiting for resources</span>
<span class="go">salloc: job 123458 has been allocated resources</span>
<span class="go">salloc: Granted job allocation 123458</span>
<span class="gp">marie@login$ </span>ddt<span class="w"> </span>srun<span class="w"> </span>./myprog
</pre></div>
</div>
<ul class="simple">
<li><p>Run dialog window of DDT opens.</p></li>
<li><p>If MPI-OpenMP-hybrid: set number of threads.</p></li>
<li><p>Hit <em>Run</em></p></li>
</ul>
</section>
</section>
<section id="memory-debugging">
<h2>Memory Debugging<a class="headerlink" href="#memory-debugging" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Memory debuggers find memory management bugs, e.g.</p>
<ul>
<li><p>Use of non-initialized memory</p></li>
<li><p>Access memory out of allocated bounds</p></li>
</ul>
</li>
<li><p>DDT has memory debugging included (needs to be enabled in the run dialog)</p></li>
</ul>
<section id="valgrind-memcheck">
<h3>Valgrind (Memcheck)<a class="headerlink" href="#valgrind-memcheck" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Simulation of the program run in a virtual machine which accurately observes memory operations.</p></li>
<li><p>Extreme run time slow-down: use small program runs!</p></li>
<li><p>Finds more memory errors than other debuggers.</p></li>
<li><p>Further information:</p>
<ul>
<li><p><a class="reference external" href="http://www.valgrind.org">Valgrind Website</a></p></li>
<li><p><a class="reference external" href="https://www.valgrind.org/docs/manual/mc-manual.html">Memcheck Manual</a>
(explanation of output, command-line options)</p></li>
</ul>
</li>
<li><p>For serial or multi-threaded programs:</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>Valgrind
<span class="go">Module Valgrind/3.14.0-foss-2018b and 12 dependencies loaded.</span>
<span class="gp">marie@login$ </span>srun<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span><span class="w"> </span>valgrind<span class="w"> </span>./myprog
</pre></div>
</div>
<ul class="simple">
<li><p>Not recommended for MPI parallel programs, since usually the MPI library will throw
a lot of errors. But you may use Valgrind the following way such that every rank
writes its own Valgrind log file:</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>Valgrind
<span class="go">Module Valgrind/3.14.0-foss-2018b and 12 dependencies loaded.</span>
<span class="gp">marie@login$ </span>srun<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">4</span><span class="w"> </span>valgrind<span class="w"> </span>--log-file<span class="o">=</span>valgrind-%p.out<span class="w"> </span>./myprog
</pre></div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="distributed-training">
<h1>Distributed Training<a class="headerlink" href="#distributed-training" title="Permalink to this heading">#</a></h1>
<section id="internal-distribution">
<h2>Internal Distribution<a class="headerlink" href="#internal-distribution" title="Permalink to this heading">#</a></h2>
<p>Training a machine learning model can be a very time-consuming task.
Distributed training allows scaling up deep learning tasks,
so we can train very large models and speed up training time.</p>
<p>There are two paradigms for distributed training:</p>
<ol class="arabic simple">
<li><p>data parallelism:
each device has a replica of the model and computes over different parts of the data.</p></li>
<li><p>model parallelism:
models are distributed over multiple devices.</p></li>
</ol>
<p>In the following, we will stick to the concept of data parallelism because it is a widely-used
technique.
There are basically two strategies to train the scattered data throughout the devices:</p>
<ol class="arabic simple">
<li><p>synchronous training: devices (workers) are trained over different slices of the data and at the
end of each step gradients are aggregated.</p></li>
<li><p>asynchronous training:
all devices are independently trained over the data and update variables asynchronously.</p></li>
</ol>
<section id="distributed-tensorflow">
<h3>Distributed TensorFlow<a class="headerlink" href="#distributed-tensorflow" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="https://www.tensorflow.org/guide/distributed_training">TensorFlow</a> provides a high-end API to
train your model and distribute the training on multiple GPUs or machines with minimal code changes.</p>
<p>The primary distributed training method in TensorFlow is <code class="docutils literal notranslate"><span class="pre">tf.distribute.Strategy</span></code>.
There are multiple strategies that distribute the training depending on the specific use case,
the data and the model.</p>
<p>TensorFlow refers to the synchronous training as mirrored strategy.
There are two mirrored strategies available whose principles are the same:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tf.distribute.MirroredStrategy</span></code> supports the training on multiple GPUs on one machine.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tf.distribute.MultiWorkerMirroredStrategy</span></code> for multiple machines, each with multiple GPUs.</p></li>
</ul>
<p>The Central Storage Strategy applies to environments where the GPUs might not be able to store
the entire model:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tf.distribute.experimental.CentralStorageStrategy</span></code> supports the case of a single machine
with multiple GPUs.</p></li>
</ul>
<p>The CPU holds the global state of the model and GPUs perform the training.</p>
<p>In some cases asynchronous training might be the better choice, for example, if workers differ on
capability, are down for maintenance, or have different priorities.
The Parameter Server Strategy is capable of applying asynchronous training:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tf.distribute.experimental.ParameterServerStrategy</span></code> requires several Parameter Servers and workers.</p></li>
</ul>
<p>The Parameter Server holds the parameters and is responsible for updating
the global state of the models.
Each worker runs the training loop independently.</p>
<p>??? example ‚ÄúMulti Worker Mirrored Strategy‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>In this case, we will go through an example with Multi Worker Mirrored Strategy.
Multi-node training requires a `TF_CONFIG` environment variable to be set which will
be different on each node.

```console
marie@compute$ TF_CONFIG=&#39;{&quot;cluster&quot;: {&quot;worker&quot;: [&quot;10.1.10.58:12345&quot;, &quot;10.1.10.250:12345&quot;]}, &quot;task&quot;: {&quot;index&quot;: 0, &quot;type&quot;: &quot;worker&quot;}}&#39; python main.py
```

The `cluster` field describes how the cluster is set up (same on each node).
Here, the cluster has two nodes referred to as workers.
The `IP:port` information is listed in the `worker` array.
The `task` field varies from node to node.
It specifies the type and index of the node.
In this case, the training job runs on worker 0, which is `10.1.10.58:12345`.
We need to adapt this snippet for each node.
The second node will have `&#39;task&#39;: {&#39;index&#39;: 1, &#39;type&#39;: &#39;worker&#39;}`.

With two modifications, we can parallelize the serial code:
We need to initialize the distributed strategy:

```python
strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
```

And define the model under the strategy scope:

```python
with strategy.scope():
    model = resnet.resnet56(img_input=img_input, classes=NUM_CLASSES)
    model.compile(
        optimizer=opt,
        loss=&#39;sparse_categorical_crossentropy&#39;,
        metrics=[&#39;sparse_categorical_accuracy&#39;])
model.fit(train_dataset,
    epochs=NUM_EPOCHS)
```

To run distributed training, the training script needs to be copied to all nodes,
in this case on two nodes.
TensorFlow is available as a module.
Check for the version.
The `TF_CONFIG` environment variable can be set as a prefix to the command.
Now, run the script on the cluster `alpha` simultaneously on both nodes:

```bash
#!/bin/bash

#SBATCH --job-name=distr
#SBATCH --output=%j.out
#SBATCH --error=%j.err
#SBATCH --mem=64000
#SBATCH --nodes=2
#SBATCH --ntasks=2
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=14
#SBATCH --gres=gpu:1
#SBATCH --time=01:00:00

function print_nodelist {
    scontrol show hostname $SLURM_NODELIST
}
NODE_1=$(print_nodelist | awk &#39;{print $1}&#39; | sort -u | head -n 1)
NODE_2=$(print_nodelist | awk &#39;{print $1}&#39; | sort -u | tail -n 1)
IP_1=$(dig +short ${NODE_1}.alpha.hpc.tu-dresden.de)
IP_2=$(dig +short ${NODE_2}.alpha.hpc.tu-dresden.de)

module load release/23.04 GCC/10.2.0 CUDA/11.1.1 OpenMPI/4.0.5 TensorFlow/2.4.1

# On the first node
TF_CONFIG=&#39;{&quot;cluster&quot;: {&quot;worker&quot;: [&quot;&#39;&quot;${NODE_1}&quot;&#39;:33562&quot;, &quot;&#39;&quot;${NODE_2}&quot;&#39;:33561&quot;]}, &quot;task&quot;: {&quot;index&quot;: 0, &quot;type&quot;: &quot;worker&quot;}}&#39; srun --nodelist=${NODE_1} --nodes=1 --ntasks=1 --gres=gpu:1 python main_ddl.py &amp;

# On the second node
TF_CONFIG=&#39;{&quot;cluster&quot;: {&quot;worker&quot;: [&quot;&#39;&quot;${NODE_1}&quot;&#39;:33562&quot;, &quot;&#39;&quot;${NODE_2}&quot;&#39;:33561&quot;]}, &quot;task&quot;: {&quot;index&quot;: 1, &quot;type&quot;: &quot;worker&quot;}}&#39; srun --nodelist=${NODE_2} --nodes=1 --ntasks=1 --gres=gpu:1 python main_ddl.py &amp;

wait
```
</pre></div>
</div>
</section>
<section id="distributed-pytorch">
<h3>Distributed PyTorch<a class="headerlink" href="#distributed-pytorch" title="Permalink to this heading">#</a></h3>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>This section is under construction
</pre></div>
</div>
<p>PyTorch provides multiple ways to achieve data parallelism to train the deep learning models
efficiently. These models are part of the <code class="docutils literal notranslate"><span class="pre">torch.distributed</span></code> sub-package that ships with the main
deep learning package.</p>
<p>The easiest method to quickly prototype if the model is trainable in a multi-GPU setting is to wrap
the existing model with the <code class="docutils literal notranslate"><span class="pre">torch.nn.DataParallel</span></code> class as shown below,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">DataParalell</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>Adding this single line of code to the existing application will let PyTorch know that the model
needs to be parallelized. But since this method uses threading to achieve parallelism, it fails to
achieve true parallelism due to the well known issue of Global Interpreter Lock that exists in
Python. To work around this issue and gain performance benefits of parallelism, the use of
<code class="docutils literal notranslate"><span class="pre">torch.nn.DistributedDataParallel</span></code> is recommended. This involves little more code changes to set up,
but further increases the performance of model training. The starting step is to initialize the
process group by calling the <code class="docutils literal notranslate"><span class="pre">torch.distributed.init_process_group()</span></code> using the appropriate back end
such as NCCL, MPI or Gloo. The use of NCCL as back end is recommended as it is currently the fastest
back end when using GPUs.</p>
<section id="using-multiple-gpus-with-pytorch">
<h4>Using Multiple GPUs with PyTorch<a class="headerlink" href="#using-multiple-gpus-with-pytorch" title="Permalink to this heading">#</a></h4>
<p>The example below shows how to solve that problem by using model parallelism, which in contrast to
data parallelism splits a single model onto different GPUs, rather than replicating the entire
model on each GPU.
The high-level idea of model parallelism is to place different sub-networks of a model onto
different devices.
As only part of a model operates on any individual device a set of devices can collectively
serve a larger model.</p>
<p>It is recommended to use
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html">DistributedDataParallel</a>,
instead of this class, to do multi-GPU training, even if there is only a single node.
See: Use <code class="docutils literal notranslate"><span class="pre">nn.parallel.DistributedDataParallel</span></code> instead of multiprocessing or <code class="docutils literal notranslate"><span class="pre">nn.DataParallel</span></code>.
Check the <a class="reference external" href="https://pytorch.org/docs/stable/notes/cuda.html#cuda-nn-ddp-instead">PyTorch CUDA page</a>
and <a class="reference external" href="https://pytorch.org/docs/stable/notes/ddp.html#ddp">Distributed Data Parallel</a>.</p>
<p>??? example ‚ÄúParallel Model‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The main aim of this model is to show the way how to effectively implement your neural network
on multiple GPUs. It includes a comparison of different kinds of models and tips to improve the
performance of your model.
**Necessary** parameters for running this model are **2 GPU** and 14 cores.

Download: [example_PyTorch_parallel.zip (4.2 KB)](misc/example_PyTorch_parallel.zip)

Remember that for using [JupyterHub service](../access/jupyterhub.md) for PyTorch, you need to
create and activate a virtual environment (kernel) with loaded essential modules.

Run the example in the same way as the previous examples.
</pre></div>
</div>
</section>
<section id="distributed-data-parallel">
<h4>Distributed Data-Parallel<a class="headerlink" href="#distributed-data-parallel" title="Permalink to this heading">#</a></h4>
<p><a class="reference external" href="https://pytorch.org/docs/stable/nn.html#torch.nn.parallel.DistributedDataParallel">DistributedDataParallel</a>
(DDP) implements data parallelism at the module level which can run across multiple machines.
Applications using DDP should spawn multiple processes and create a single DDP instance per process.
DDP uses collective communications in the
<a class="reference external" href="https://pytorch.org/tutorials/intermediate/dist_tuto.html">torch.distributed</a> package to
synchronize gradients and buffers.</p>
<p>Please also look at the <a class="reference external" href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html">official tutorial</a>.</p>
<p>To use distributed data parallelism on ZIH systems, please make sure the value of
parameter <code class="docutils literal notranslate"><span class="pre">--ntasks-per-node=&lt;N&gt;</span></code> equals the number of GPUs you use per node.
Also, it can be useful to increase <code class="docutils literal notranslate"><span class="pre">memory/cpu</span></code> parameters if you run larger models.
Memory can be set up to:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--mem=250G</span></code> and <code class="docutils literal notranslate"><span class="pre">--cpus-per-task=7</span></code> for the <code class="docutils literal notranslate"><span class="pre">Power9</span></code> cluster.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--mem=900G</span></code> and <code class="docutils literal notranslate"><span class="pre">--cpus-per-task=6</span></code> for the <code class="docutils literal notranslate"><span class="pre">Alpha</span></code> cluster.</p></li>
</ul>
<p>Keep in mind that only one memory parameter (<code class="docutils literal notranslate"><span class="pre">--mem-per-cpu=&lt;MB&gt;</span></code> or <code class="docutils literal notranslate"><span class="pre">--mem=&lt;MB&gt;</span></code>) can be specified.</p>
</section>
</section>
</section>
<section id="external-distribution">
<h2>External Distribution<a class="headerlink" href="#external-distribution" title="Permalink to this heading">#</a></h2>
<section id="horovod">
<h3>Horovod<a class="headerlink" href="#horovod" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="https://github.com/horovod/horovod">Horovod</a> is the open-source distributed training framework
for TensorFlow, Keras and PyTorch.
It makes it easier to develop distributed deep learning projects and speeds them up.
Horovod scales well to a large number of nodes and has a strong focus on efficient training on
GPUs.</p>
<section id="why-use-horovod">
<h4>Why use Horovod?<a class="headerlink" href="#why-use-horovod" title="Permalink to this heading">#</a></h4>
<p>Horovod allows you to easily take a single-GPU TensorFlow and PyTorch program and
train it on many GPUs!
In some cases, the MPI model is much more straightforward and requires far less code changes than
the distributed code from TensorFlow for instance, with parameter servers.
Horovod uses MPI and NCCL which gives in some cases better results than
pure TensorFlow and PyTorch.</p>
</section>
<section id="horovod-as-module">
<h4>Horovod as Module<a class="headerlink" href="#horovod-as-module" title="Permalink to this heading">#</a></h4>
<p>Horovod is available as a module with <strong>TensorFlow</strong> or <strong>PyTorch</strong> for
<strong>all</strong> module environments.
Please check the <span class="xref myst">software module list</span> for the current version of the software.
Horovod can be loaded like other software on ZIH system:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>spider<span class="w"> </span>Horovod<span class="w">           </span><span class="c1"># Check available modules</span>
<span class="go">------------------------------------------------------------------------------------------------</span>
<span class="go">  Horovod:</span>
<span class="go">------------------------------------------------------------------------------------------------</span>
<span class="go">    Description:</span>
<span class="go">      Horovod is a distributed training framework for TensorFlow.</span>

<span class="go">     Versions:</span>
<span class="go">        Horovod/0.18.2-fosscuda-2019b-TensorFlow-2.0.0-Python-3.7.4</span>
<span class="go">        Horovod/0.19.5-fosscuda-2019b-TensorFlow-2.2.0-Python-3.7.4</span>
<span class="go">        Horovod/0.21.1-TensorFlow-2.4.1</span>
<span class="go">[...]</span>
<span class="gp">marie@compute$ </span>module<span class="w"> </span>load<span class="w"> </span>Horovod/0.19.5-fosscuda-2019b-TensorFlow-2.2.0-Python-3.7.4
</pre></div>
</div>
<p>Or if you want to use Horovod on the cluster <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, you can load it with the dependencies:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@alpha$ </span>module<span class="w"> </span>spider<span class="w"> </span>Horovod<span class="w">                         </span><span class="c1">#Check available modules</span>
<span class="gp">marie@alpha$ </span>module<span class="w"> </span>load<span class="w"> </span>release/23.04<span class="w">  </span>release/23.04<span class="w">  </span>GCC/11.3.0<span class="w">  </span>OpenMPI/4.1.4<span class="w">  </span>Horovod/0.28.1-CUDA-11.7.0-TensorFlow-2.11.0
</pre></div>
</div>
</section>
<section id="horovod-installation">
<h4>Horovod Installation<a class="headerlink" href="#horovod-installation" title="Permalink to this heading">#</a></h4>
<p>However, if it is necessary to use another version of Horovod, it is possible to install it
manually. For that, you need to create a <span class="xref myst">virtual environment</span> and
load the dependencies (e.g. MPI).
Installing TensorFlow can take a few hours and is not recommended.</p>
<section id="install-horovod-for-tensorflow-with-python-and-pip">
<h5>Install Horovod for TensorFlow with Python and Pip<a class="headerlink" href="#install-horovod-for-tensorflow-with-python-and-pip" title="Permalink to this heading">#</a></h5>
<p>This example shows the installation of Horovod for TensorFlow.
Adapt as required and refer to the <a class="reference external" href="https://horovod.readthedocs.io/en/stable/install_include.html">Horovod documentation</a>
for details.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@alpha$ </span><span class="nv">HOROVOD_GPU_OPERATIONS</span><span class="o">=</span>NCCL<span class="w"> </span><span class="nv">HOROVOD_WITH_TENSORFLOW</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--no-cache-dir<span class="w"> </span>horovod<span class="se">\[</span>tensorflow<span class="se">\]</span>
<span class="go">[...]</span>
<span class="gp">marie@alpha$ </span>horovodrun<span class="w"> </span>--check-build
<span class="go">Horovod v0.19.5:</span>

<span class="go">Available Frameworks:</span>
<span class="go">    [X] TensorFlow</span>
<span class="go">    [ ] PyTorch</span>
<span class="go">    [ ] MXNet</span>

<span class="go">Available Controllers:</span>
<span class="go">    [X] MPI</span>
<span class="go">    [ ] Gloo</span>

<span class="go">Available Tensor Operations:</span>
<span class="go">    [X] NCCL</span>
<span class="go">    [ ] DDL</span>
<span class="go">    [ ] CCL</span>
<span class="go">    [X] MPI</span>
<span class="go">    [ ] Gloo</span>
</pre></div>
</div>
<p>If you want to use Open MPI then specify <code class="docutils literal notranslate"><span class="pre">HOROVOD_GPU_ALLREDUCE=MPI</span></code>.
To have better performance it is recommended to use NCCL instead of Open MPI.</p>
</section>
<section id="verify-horovod-works">
<h5>Verify Horovod Works<a class="headerlink" href="#verify-horovod-works" title="Permalink to this heading">#</a></h5>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span>
<span class="go">2021-10-07 16:38:55.694445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">horovod.tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">hvd</span>                      <span class="c1">#import horovod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hvd</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>                                       <span class="c1">#initialize horovod</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span>
<span class="go">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Hello from:&#39;</span><span class="p">,</span> <span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">())</span>
<span class="go">Hello from: 0</span>
</pre></div>
</div>
<p>??? example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Follow the steps in the
[official examples](https://github.com/horovod/horovod/tree/master/examples)
to parallelize your code.
In Horovod, each GPU gets pinned to a process.
You can easily start your job with the following bash script with four processes on two nodes using the cluster Power:

```bash
#!/bin/bash
#SBATCH --nodes=2
#SBATCH --ntasks=4
#SBATCH --ntasks-per-node=2
#SBATCH --gres=gpu:2
#SBATCH --mem=250G
#SBATCH --time=01:00:00
#SBATCH --output=run_horovod.out

module load release/23.04
module load Horovod/0.19.5-fosscuda-2019b-TensorFlow-2.2.0-Python-3.7.4

srun python your_program.py
```

Do not forget to specify the total number of tasks `--ntasks` and the number of tasks per node
`--ntasks-per-node` which must match the number of GPUs per node.
</pre></div>
</div>
</section>
</section>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="measure-energy-consumption">
<h1>Measure Energy Consumption<a class="headerlink" href="#measure-energy-consumption" title="Permalink to this heading">#</a></h1>
<p>The Intel Haswell nodes of ZIH system are equipped with power instrumentation that allow the
recording and accounting of power dissipation and energy consumption data. The data is made
available through several different interfaces, which are described below.</p>
<section id="summary-of-measurement-interfaces">
<h2>Summary of Measurement Interfaces<a class="headerlink" href="#summary-of-measurement-interfaces" title="Permalink to this heading">#</a></h2>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Interface</p></th>
<th class="head text-left"><p>Sensors</p></th>
<th class="head text-left"><p>Rate</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Dataheap (C, Python, VampirTrace, Score-P)</p></td>
<td class="text-left"><p>Blade, (CPU)</p></td>
<td class="text-left"><p>1 sample/s</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>HDEEM* (C, Score-P)</p></td>
<td class="text-left"><p>Blade, CPU, DDR</p></td>
<td class="text-left"><p>1000 samples/s (Blade), 100 samples/s (VRs)</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>HDEEM Command Line Interface</p></td>
<td class="text-left"><p>Blade, CPU, DDR</p></td>
<td class="text-left"><p>1000 samples/s (Blade), 100 samples/s (VR)</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Slurm Accounting (<code class="docutils literal notranslate"><span class="pre">sacct</span></code>)</p></td>
<td class="text-left"><p>Blade</p></td>
<td class="text-left"><p>Per Job Energy</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Slurm Profiling (HDF5)</p></td>
<td class="text-left"><p>Blade</p></td>
<td class="text-left"><p>Up to 1 sample/s</p></td>
</tr>
</tbody>
</table>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Please specify `--partition=haswell --exclusive` along with your job request if you wish to use
HDEEM.
</pre></div>
</div>
<section id="accuracy-temporal-and-spatial-resolution">
<h3>Accuracy, Temporal and Spatial Resolution<a class="headerlink" href="#accuracy-temporal-and-spatial-resolution" title="Permalink to this heading">#</a></h3>
<p>In addition to the above mentioned interfaces, you can access the measurements through a
<span class="xref myst">C API</span> to get the full temporal and spatial resolution:</p>
<ul class="simple">
<li><p>** Blade:** 1000 samples/s for the whole node, includes both sockets, DRAM,
SSD, and other on-board consumers. Since the system is directly
water cooled, no cooling components are included in the blade
consumption.</p></li>
<li><p><strong>Voltage regulators (VR):</strong> 100 samples/s for each of the six VR
measurement points, one for each socket and four for eight DRAM
lanes (two lanes bundled).</p></li>
</ul>
<p>The GPU blades also have 1 sample/s power instrumentation but have a lower accuracy.</p>
<p>HDEEM measurements have an accuracy of 2 % for Blade (node) measurements, and 5 % for voltage
regulator (CPU, DDR) measurements.</p>
</section>
</section>
<section id="command-line-interface">
<h2>Command Line Interface<a class="headerlink" href="#command-line-interface" title="Permalink to this heading">#</a></h2>
<p>The HDEEM infrastructure can be controlled through command line tools. They are commonly used on
the node under test to start, stop, and query the measurement device.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">startHdeem</span></code>: Start a measurement. After the command succeeds, the
measurement data with the 1000 / 100 samples/s described above will be
recorded on the Board Management Controller (BMC), which is capable
of storing up to 8h of measurement data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">stopHdeem</span></code>: Stop a measurement. No further data is recorded and
the previously recorded data remains available on the BMC.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">printHdeem</span></code>: Read the data from the BMC. By default, the data is
written into a CSV file, whose name can be controlled using the
<code class="docutils literal notranslate"><span class="pre">-o</span></code> argument.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">checkHdeem</span></code>: Print the status of the measurement device.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clearHdeem</span></code>: Reset and clear the measurement device. No further
data can be read from the device after this command is executed
before a new measurement is started.</p></li>
</ul>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Please always execute `clearHdeem` before `startHdeem`.
</pre></div>
</div>
</section>
<section id="integration-in-application-performance-traces">
<h2>Integration in Application Performance Traces<a class="headerlink" href="#integration-in-application-performance-traces" title="Permalink to this heading">#</a></h2>
<p>The per-node power consumption data can be included as metrics in application traces by using the
provided metric plugins for Score-P (and VampirTrace). The plugins are provided as modules and set
all necessary environment variables that are required to record data for all nodes that are part of
the current job.</p>
<p>For 1 sample/s Blade values (Dataheap):</p>
<ul class="simple">
<li><p><span class="xref myst">Score-P</span>: use the module <code class="docutils literal notranslate"><span class="pre">scorep-dataheap</span></code></p></li>
<li><p><span class="xref myst">VampirTrace</span>: use the module <code class="docutils literal notranslate"><span class="pre">vampirtrace-plugins/power-1.1</span></code>
(<strong>Remark:</strong> VampirTrace is outdated!)</p></li>
</ul>
<p>For 1000 samples/s (Blade) and 100 samples/s (CPU{0,1}, DDR{AB,CD,EF,GH}):</p>
<ul class="simple">
<li><p><span class="xref myst">Score-P</span>: use the module <code class="docutils literal notranslate"><span class="pre">scorep-hdeem</span></code>. This
module requires a recent version of <code class="docutils literal notranslate"><span class="pre">scorep/sync-...</span></code>. Please use
the latest that fits your compiler and MPI version.</p></li>
</ul>
<p>By default, the modules are set up to record the power data for the nodes they are used on. For
further information on how to change this behavior, please use module show on the respective module.</p>
<p>!!! example ‚ÄúExample usage with <code class="docutils literal notranslate"><span class="pre">gcc</span></code>‚Äù</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@haswell$ </span>module<span class="w"> </span>load<span class="w"> </span>scorep/trunk-2016-03-17-gcc-xmpi-cuda7.5
<span class="gp">marie@haswell$ </span>module<span class="w"> </span>load<span class="w"> </span>scorep-dataheap
<span class="gp">marie@haswell$ </span>scorep<span class="w"> </span>gcc<span class="w"> </span>application.c<span class="w"> </span>-o<span class="w"> </span>application
<span class="gp">marie@haswell$ </span>srun<span class="w"> </span>./application
</pre></div>
</div>
<p>Once the application is finished, a trace will be available that allows you to correlate application
functions with the component power consumption of the parallel application.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>For energy measurements, only tracing is supported in Score-P/VampirTrace.
The modules therefore disables profiling and enables tracing,
please use [Vampir](vampir.md) to view the trace.
</pre></div>
</div>
<p><img alt="Energy measurements in Vampir" src="63_chat_with_docs/misc/energy_measurements-vampir.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>By default, <code class="docutils literal notranslate"><span class="pre">scorep-dataheap</span></code> records all sensors that are available. Currently this is the total
node consumption and the CPUs. <code class="docutils literal notranslate"><span class="pre">scorep-hdeem</span></code> also records all available sensors
(node, 2x CPU, 4x DDR) by default. You can change the selected sensors by setting the environment
variables:</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The power measurement modules `scorep-dataheap` and `scorep-hdeem` are
dynamic and only need to be loaded during execution.
However, `scorep-hdeem` does require the application to be linked with
a certain version of Score-P.
</pre></div>
</div>
<p>??? hint ‚ÄúFor HDEEM‚Äù
<code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">SCOREP_METRIC_HDEEM_PLUGIN=Blade,CPU*</span></code></p>
<p>??? hint ‚ÄúFor Dataheap‚Äù
<code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">SCOREP_METRIC_DATAHEAP_PLUGIN=localhost/watts</span></code></p>
<p>For more information on how to use Score-P, please refer to the <span class="xref myst">respective documentation</span>.</p>
</section>
<section id="access-using-slurm-tools">
<h2>Access Using Slurm Tools<a class="headerlink" href="#access-using-slurm-tools" title="Permalink to this heading">#</a></h2>
<p><span class="xref myst">Slurm</span> maintains its own database of job information, including
energy data. There are two main ways of accessing this data, which are described below.</p>
<section id="post-mortem-per-job-accounting">
<h3>Post-Mortem Per-Job Accounting<a class="headerlink" href="#post-mortem-per-job-accounting" title="Permalink to this heading">#</a></h3>
<p>This is the easiest way of accessing information about the energy consumed by a job and its job
steps. The Slurm tool <code class="docutils literal notranslate"><span class="pre">sacct</span></code> allows users to query post-mortem energy data for any past job or job
step by adding the field <code class="docutils literal notranslate"><span class="pre">ConsumedEnergy</span></code> to the <code class="docutils literal notranslate"><span class="pre">--format</span></code> parameter:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login $ </span>sacct<span class="w"> </span>--format<span class="o">=</span><span class="s2">&quot;jobid,jobname,ntasks,submit,start,end,ConsumedEnergy,nodelist,state&quot;</span><span class="w"> </span>-j<span class="w"> </span><span class="m">3967027</span>
<span class="go">       JobID    JobName   NTasks              Submit               Start                 End ConsumedEnergy        NodeList      State</span>
<span class="go">------------ ---------- -------- ------------------- ------------------- ------------------- -------------- --------------- ----------</span>
<span class="go">3967027            bash          2014-01-07T12:25:42 2014-01-07T12:25:52 2014-01-07T12:41:20                    taurusi1159  COMPLETED</span>
<span class="go">3967027.0         sleep        1 2014-01-07T12:26:07 2014-01-07T12:26:07 2014-01-07T12:26:18              0     taurusi1159  COMPLETED</span>
<span class="go">3967027.1         sleep        1 2014-01-07T12:29:06 2014-01-07T12:29:06 2014-01-07T12:29:16          1.67K     taurusi1159  COMPLETED</span>
<span class="go">3967027.2         sleep        1 2014-01-07T12:33:25 2014-01-07T12:33:25 2014-01-07T12:33:36          1.84K     taurusi1159  COMPLETED</span>
<span class="go">3967027.3         sleep        1 2014-01-07T12:34:06 2014-01-07T12:34:06 2014-01-07T12:34:11          1.09K     taurusi1159  COMPLETED</span>
<span class="go">3967027.4         sleep        1 2014-01-07T12:38:03 2014-01-07T12:38:03 2014-01-07T12:39:44         18.93K     taurusi1159  COMPLETED</span>
</pre></div>
</div>
<p>This example job consisted of 5 job steps, each executing a sleep of a different length. Note that the
<code class="docutils literal notranslate"><span class="pre">ConsumedEnergy</span></code> metric is only applicable to exclusive jobs.</p>
</section>
<section id="slurm-energy-profiling">
<h3>Slurm Energy Profiling<a class="headerlink" href="#slurm-energy-profiling" title="Permalink to this heading">#</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">srun</span></code> tool offers several options for profiling job steps by adding the <code class="docutils literal notranslate"><span class="pre">--profile</span></code> parameter.
Possible profiling options are <code class="docutils literal notranslate"><span class="pre">All</span></code>, <code class="docutils literal notranslate"><span class="pre">Energy</span></code>, <code class="docutils literal notranslate"><span class="pre">Task</span></code>, <code class="docutils literal notranslate"><span class="pre">Lustre</span></code>, and <code class="docutils literal notranslate"><span class="pre">Network</span></code>. In all cases, the
profiling information is stored in an HDF5 file that can be inspected using available HDF5 tools,
e.g., <code class="docutils literal notranslate"><span class="pre">h5dump</span></code>. The files are stored under <code class="docutils literal notranslate"><span class="pre">/scratch/profiling/</span></code> for each job, job step, and node. A
description of the data fields in the file can be found
<a class="reference external" href="http://slurm.schedmd.com/hdf5_profile_user_guide.html#HDF5">in the official documentation</a>.
In general, the data files
contain samples of the current <strong>power</strong> consumption on a per-second basis:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login $ </span>srun<span class="w"> </span>--partition<span class="w"> </span>haswell64<span class="w"> </span>--acctg-freq<span class="o">=</span><span class="m">2</span>,energy<span class="o">=</span><span class="m">1</span><span class="w"> </span>--profile<span class="o">=</span>energy<span class="w"> </span>sleep<span class="w"> </span><span class="m">10</span>
<span class="go">srun: job 3967674 queued and waiting for resources</span>
<span class="go">srun: job 3967674 has been allocated resources</span>
<span class="gp">marie@login $ </span>h5dump<span class="w"> </span>/scratch/profiling/marie/3967674_0_taurusi1073.h5
<span class="go">[...]</span>
<span class="go">  DATASET &quot;Energy_0000000002 Data&quot; {</span>
<span class="go">    DATATYPE  H5T_COMPOUND {</span>
<span class="go">      H5T_STRING {</span>
<span class="go">        STRSIZE 24;</span>
<span class="go">        STRPAD H5T_STR_NULLTERM;</span>
<span class="go">        CSET H5T_CSET_ASCII;</span>
<span class="go">        CTYPE H5T_C_S1;</span>
<span class="go">      } &quot;Date_Time&quot;;</span>
<span class="go">      H5T_STD_U64LE &quot;Time&quot;;</span>
<span class="go">      H5T_STD_U64LE &quot;Power&quot;;</span>
<span class="go">      H5T_STD_U64LE &quot;CPU_Frequency&quot;;</span>
<span class="go">    }</span>
<span class="go">    DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }</span>
<span class="go">    DATA {</span>
<span class="go">    (0): {</span>
<span class="go">        &quot;&quot;,</span>
<span class="go">        1389097545,  # timestamp</span>
<span class="go">        174,         # power value</span>
<span class="go">        1</span>
<span class="go">      }</span>
<span class="go">    }</span>
<span class="go">  }</span>
</pre></div>
</div>
</section>
</section>
<section id="using-the-hdeem-c-api">
<h2>Using the HDEEM C API<a class="headerlink" href="#using-the-hdeem-c-api" title="Permalink to this heading">#</a></h2>
<p>Please specify <code class="docutils literal notranslate"><span class="pre">--partition=haswell</span> <span class="pre">--exclusive</span></code> along with your job request if you wish to use HDEEM.</p>
<p>Please download the official documentation at
<a class="reference external" href="http://www.bull.com/download-hdeem-library-reference-guide">http://www.bull.com/download-hdeem-library-reference-guide</a>.</p>
<p>The HDEEM header and sample code are locally installed on the nodes.</p>
<p>??? hint ‚ÄúHDEEM header location‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>`/usr/include/hdeem.h`
</pre></div>
</div>
<p>??? hint ‚ÄúHDEEM sample location‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>`/usr/share/hdeem/sample/`
</pre></div>
</div>
</section>
<section id="further-information-and-citing">
<h2>Further Information and Citing<a class="headerlink" href="#further-information-and-citing" title="Permalink to this heading">#</a></h2>
<p>More information can be found in the paper
<a class="reference external" href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7016382">HDEEM: high definition energy efficiency monitoring</a>
by Daniel Hackenberg et al. Please cite this paper if you are using HDEEM for your scientific work.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="fem-software">
<h1>FEM Software<a class="headerlink" href="#fem-software" title="Permalink to this heading">#</a></h1>
<p>!!! hint ‚ÄúIts all in the modules‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>All packages described in this section, are organized in so-called modules. To list the available versions of a package and load a
particular, e.g., ANSYS, version, invoke the commands

```console
marie@login$ module avail ANSYS
[...]
marie@login$ # module load ANSYS/&lt;version&gt;
marie@login$ # e.g.
marie@login$ module load ANSYS/2022R2
```

The section [runtime environment](modules.md) provides a comprehensive overview
on the module system and relevant commands.
</pre></div>
</div>
<section id="abaqus">
<h2>Abaqus<a class="headerlink" href="#abaqus" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://www.3ds.com/de/produkte-und-services/simulia/produkte/abaqus/">Abaqus</a> is a general-purpose
finite element method program designed for advanced linear and nonlinear engineering analysis
applications with facilities for linking-in user developed material models, elements, friction laws,
etc.</p>
<section id="guide-by-user">
<h3>Guide by User<a class="headerlink" href="#guide-by-user" title="Permalink to this heading">#</a></h3>
<p>Eike Dohmen (from Inst. f. Leichtbau und Kunststofftechnik) sent us the description of his
Abaqus calculations. Please try to adapt your calculations in that way. Eike is normally a
Windows user and his description contains also some hints for basic Unix commands:
<span class="xref myst">Abaqus-Slurm.pdf (only in German)</span>.</p>
</section>
<section id="id45">
<h3>General<a class="headerlink" href="#id45" title="Permalink to this heading">#</a></h3>
<p>Abaqus calculations should be started using a job file (aka. batch script). Please refer to the
page covering the <span class="xref myst">batch system Slurm</span> if you are not familiar with
Slurm or <span class="xref myst">writing job files</span>.</p>
<p>??? example ‚ÄúUsage of Abaqus‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>(Thanks to Benjamin Groeger, Inst. f. Leichtbau und Kunststofftechnik)).

1. Prepare an Abaqus input-file. You can start with the input example from Benjamin:
[Rot-modell-BenjaminGroeger.inp](misc/Rot-modell-BenjaminGroeger.inp)
2. Prepare a job file on ZIH systems like this
```bash
#!/bin/bash
### needs ca 20 sec with 4cpu
### generates files:
###  yyyy.com
###  yyyy.dat
###  yyyy.msg
###  yyyy.odb
###  yyyy.prt
###  yyyy.sim
###  yyyy.sta
#SBATCH --nodes=1               # with &gt;1 node Abaqus needs a nodeliste
#SBATCH --ntasks-per-node=4
#SBATCH --mem=2048               # total memory
#SBATCH --time=00:04:00
#SBATCH --job-name=yyyy         # give a name, what ever you want
#SBATCH --mail-type=END,FAIL    # send email when the job finished or failed
#SBATCH --mail-user=marie@tu-dresden.de  # set your email
#SBATCH --account=p_number_crunch       # charge compute time to project p_number_crunch


# Abaqus has its own MPI
unset SLURM_GTIDS

# load module and start Abaqus
module load ABAQUS/2022
abaqus interactive input=Rot-modell-BenjaminGroeger.inp job=yyyy cpus=4 mp_mode=mpi
```
3. Start the job file (e.g., name `batch-Rot-modell-BenjaminGroeger.sh`)
```
marie@login$ sbatch batch-Rot-modell-BenjaminGroeger.sh      # Slurm will provide the Job Id (e.g., 3130522)
```
4. Control the status of the job
```
marie@login$ squeue --me     # in column &quot;ST&quot; (Status) you will find a R=Running or P=Pending (waiting for resources)
```
</pre></div>
</div>
</section>
</section>
<section id="ansys">
<h2>Ansys<a class="headerlink" href="#ansys" title="Permalink to this heading">#</a></h2>
<p>Ansys is a general-purpose finite element method program for engineering analysis, and includes
preprocessing, solution, and post-processing functions. It is used in a wide range of disciplines
for solutions to mechanical, thermal, and electronic problems.
<a class="reference external" href="http://www.ansys.com">Ansys and Ansys CFX</a> used to be separate packages in the past and are now
combined.</p>
<p>In general, HPC systems are not designed for interactive working with GUIs. Even so, it is possible to
start a Ansys workbench on the login nodes interactively for short tasks. The second and
<strong>recommended way</strong> is to use job files. Both modes are documented in the following.</p>
<p>!!! note ‚Äú‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Since the MPI library that Ansys uses internally (Platform MPI) has some problems integrating
seamlessly with Slurm, you have to unset the enviroment variable `SLURM_GTIDS` in your
environment befor running Ansysy workbench in interactive and batch mode.
</pre></div>
</div>
<section id="using-workbench-interactively">
<h3>Using Workbench Interactively<a class="headerlink" href="#using-workbench-interactively" title="Permalink to this heading">#</a></h3>
<p>Ansys workbench (<code class="docutils literal notranslate"><span class="pre">runwb2</span></code>) can be invoked interactively on the login nodes of ZIH systems for short
tasks.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>[X11 forwarding](../access/ssh_login.md#x11-forwarding) needs to enabled when establishing the
SSH connection. For OpenSSH the corresponding option is `-X` and it is valuable to use
compression of all data via `-C`.
</pre></div>
</div>
<p>=== ‚Äústartup script‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
[marie@login ~]$ start_ansysworkbench.sh
```
</pre></div>
</div>
<p>=== ‚Äúcustomized start‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
# SSH connection established using -CX
[marie@login$ ~]$ # module load ANSYS/&lt;version&gt;
[marie@login$ ~]$ # e.g.
[marie@login$ ~]$ module load ANSYS/2022R2
[marie@login$ ~]$ runwb2
```
</pre></div>
</div>
<p>If more time is needed, a CPU has to be allocated like this (see
<span class="xref myst">batch systems Slurm</span> for further information):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">[marie@login$ ~]$ </span><span class="c1"># module load ANSYS/&lt;version&gt;</span>
<span class="gp">[marie@login$ ~]$ </span><span class="c1"># e.g.</span>
<span class="gp">[marie@login$ ~]$ </span>module<span class="w"> </span>load<span class="w"> </span>ANSYS/2023R1
<span class="gp">[marie@login$ ~]$ </span>srun<span class="w"> </span>--time<span class="o">=</span><span class="m">00</span>:30:00<span class="w"> </span>--x11<span class="o">=</span>first<span class="w"> </span><span class="o">[</span>SLURM_OPTIONS<span class="o">]</span><span class="w"> </span>--pty<span class="w"> </span>bash
<span class="go">[...]</span>
<span class="gp">[marie@compute$ ~]$ </span>runwb2
</pre></div>
</div>
<p>!!! hint ‚ÄúBetter use DCV‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The software NICE Desktop Cloud Visualization (DCV) enables to
remotly access OpenGL-3D-applications running on ZIH systems using its GPUs
(cf. [virtual desktops](virtual_desktops.md)).
</pre></div>
</div>
<p>Ansys can be used under DCV to make use of GPU acceleration. Follow the instructions within
<span class="xref myst">virtual desktops</span> to set up a DCV session. Then, load a Ansys module, unset
the environment variable <code class="docutils literal notranslate"><span class="pre">SLURM_GTIDS</span></code>, and finally start the workbench:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@gpu$ </span>module<span class="w"> </span>load<span class="w"> </span>ANSYS
<span class="gp">marie@gpu$ </span><span class="nb">unset</span><span class="w"> </span>SLURM_GTIDS
<span class="gp">marie@gpu$ </span>runwb2
</pre></div>
</div>
</section>
<section id="using-workbench-in-batch-mode">
<h3>Using Workbench in Batch Mode<a class="headerlink" href="#using-workbench-in-batch-mode" title="Permalink to this heading">#</a></h3>
<p>The Ansys workbench (<code class="docutils literal notranslate"><span class="pre">runwb2</span></code>) can also be used in a job file to start calculations (the solver,
not GUI) from a workbench project into the background. To do so, you have to specify the <code class="docutils literal notranslate"><span class="pre">-B</span></code>
parameter (for batch mode), <code class="docutils literal notranslate"><span class="pre">-F</span></code> for your project file, and can then either add different commands via
<code class="docutils literal notranslate"><span class="pre">-E</span> <span class="pre">parameters</span> <span class="pre">directly</span></code>, or specify a workbench script file containing commands via <code class="docutils literal notranslate"><span class="pre">-R</span></code>.</p>
<p>??? example ‚ÄúAnsys Job File‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash
#SBATCH --time=0:30:00
#SBATCH --nodes=1
#SBATCH --ntasks=2
#SBATCH --mem-per-cpu=1000M

unset SLURM_GTIDS              # Odd, but necessary!

# module load ANSYS/&lt;version&gt;
# e.g.
module load ANSYS/2020R2

runwb2 -B -F Workbench_Taurus.wbpj -E &#39;Project.Update&#39; -E &#39;Save(Overwrite=True)&#39;
#or, if you wish to use a workbench replay file, replace the -E parameters with: -R mysteps.wbjn
```
</pre></div>
</div>
</section>
<section id="running-workbench-in-parallel">
<h3>Running Workbench in Parallel<a class="headerlink" href="#running-workbench-in-parallel" title="Permalink to this heading">#</a></h3>
<p>Unfortunately, the number of CPU cores you wish to use cannot simply be given as a command line
parameter to your <code class="docutils literal notranslate"><span class="pre">runwb2</span></code> call. Instead, you have to enter it into an XML file in your home
directory. This setting will then be <strong>used for all</strong> your <code class="docutils literal notranslate"><span class="pre">runwb2</span></code> jobs. While it is also possible
to edit this setting via the Mechanical GUI, experience shows that this can be problematic via
X11-forwarding and we only managed to use the GUI properly via <span class="xref myst">DCV</span>, so we
recommend you simply edit the XML file directly with a text editor of your choice. It is located
under:</p>
<p><code class="docutils literal notranslate"><span class="pre">$HOME/.mw/Application</span> <span class="pre">Data/Ansys/v181/SolveHandlers.xml</span></code></p>
<p>(mind the space in there.) You might have to adjust the Ansys version
(here <code class="docutils literal notranslate"><span class="pre">v181</span></code>) in the path to your preferred version. In this file, you can find the parameter</p>
<p><code class="docutils literal notranslate"><span class="pre">&lt;MaxNumberProcessors&gt;2&lt;/MaxNumberProcessors&gt;</span></code></p>
<p>that you can simply change to something like 16 or 24. For now, you should stay within single-node
boundaries, because multi-node calculations require additional parameters. The number you choose
should match your used <code class="docutils literal notranslate"><span class="pre">--cpus-per-task</span></code> parameter in your job file.</p>
</section>
<section id="running-mapdl">
<h3>Running MAPDL<a class="headerlink" href="#running-mapdl" title="Permalink to this heading">#</a></h3>
<p><em>Ansys Parametric Design Language</em> (APDL) is a powerful structured scripting language used to
interact with the Ansys Mechanical solver. Mechanical APDL (MAPDL), a finite element analysis
program, is driven by APDL. APDL and MAPDL can be used for many tasks, ranging from creating
geometries for analysis to setting up sophisticated solver settings for highly complex analyses</p>
<section id="shared-memory-mode">
<h4>Shared-Memory Mode<a class="headerlink" href="#shared-memory-mode" title="Permalink to this heading">#</a></h4>
<p>MAPDL can be invoked in so-called shared-memory mode to make use of threads in order to speedup
computation. The multi-threading approach is restricted to one node. In contrast, MAPDL offers a
MPI-parallel mode to distribute the computation across  multiple nodes. This mode is described
below.</p>
<section id="interactive-mode">
<h5>Interactive mode<a class="headerlink" href="#interactive-mode" title="Permalink to this heading">#</a></h5>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>srun<span class="w"> </span>--nodes<span class="w"> </span><span class="m">1</span><span class="w"> </span>--ntasks-per-node<span class="o">=</span><span class="m">4</span><span class="w"> </span>--time<span class="o">=</span><span class="m">0</span>:20:00<span class="w"> </span>--mem-per-cpu<span class="o">=</span><span class="m">1700</span><span class="w"> </span>--pty<span class="w"> </span>bash<span class="w"> </span>-l
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@node$ </span>module<span class="w"> </span>load<span class="w"> </span>ANSYS/2021R2
<span class="gp">marie@node$ </span>mapdl<span class="w"> </span>-smp<span class="w"> </span>-np<span class="w"> </span><span class="si">${</span><span class="nv">SLURM_NTASKS</span><span class="si">}</span>
</pre></div>
</div>
</section>
<section id="batch-mode">
<h5>Batch mode<a class="headerlink" href="#batch-mode" title="Permalink to this heading">#</a></h5>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --nodes=1</span>
<span class="c1">#SBATCH --ntasks-per-node=4</span>
<span class="c1">#SBATCH --mem=2000</span>
<span class="c1">#SBATCH --job-name=ansys_mapdl</span>
<span class="c1">#SBATCH --output=output_ansys_mapdl</span>
<span class="c1">#SBATCH --time=01:00:00</span>

module<span class="w"> </span>load<span class="w"> </span>ANSYS/2021R2

<span class="c1"># -smp use shared memory parallel version</span>
<span class="c1"># -b (batch mode)</span>
<span class="c1"># -np specify number of cpu&#39;s to use</span>
<span class="c1"># -j jobname</span>

mapdl<span class="w"> </span>-smp<span class="w"> </span>-b<span class="w"> </span>-np<span class="w"> </span><span class="si">${</span><span class="nv">SLURM_NTASKS</span><span class="si">}</span><span class="w"> </span>-j<span class="w"> </span>solution<span class="w"> </span>-i<span class="w"> </span>&lt;input-file&gt;
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>sbatch<span class="w"> </span>mapdl_job.sh
</pre></div>
</div>
</section>
</section>
<section id="distributed-memory-mode">
<h4>Distributed-Memory Mode<a class="headerlink" href="#distributed-memory-mode" title="Permalink to this heading">#</a></h4>
<p>MAPDL can be run in distributed-memory mode using multiple compute nodes in either interactive as
well as batch mode as shown in the following.</p>
<p>In both cases, it is necessary to create a nodelist and provide it to MAPDL via <code class="docutils literal notranslate"><span class="pre">-machines</span></code> command
line option.</p>
<section id="id46">
<h5>Interactive Mode<a class="headerlink" href="#id46" title="Permalink to this heading">#</a></h5>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>srun<span class="w"> </span>--nodes<span class="w"> </span><span class="m">4</span><span class="w"> </span>--ntasks-per-node<span class="o">=</span><span class="m">4</span><span class="w"> </span>--time<span class="o">=</span><span class="m">0</span>:20:00<span class="w"> </span>--mem-per-cpu<span class="o">=</span><span class="m">1700</span><span class="w"> </span>--pty<span class="w"> </span>bash<span class="w"> </span>-l

<span class="gp"># </span>generate<span class="w"> </span>node<span class="w"> </span>list
<span class="gp">marie@node$ NODELIST=$</span><span class="o">(</span><span class="k">for</span><span class="w"> </span>node<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="k">$(</span><span class="w"> </span>scontrol<span class="w"> </span>show<span class="w"> </span>hostnames<span class="w"> </span><span class="si">${</span><span class="nv">SLURM_JOB_NODELIST</span><span class="si">}</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>uniq<span class="w"> </span><span class="k">)</span><span class="p">;</span><span class="w"> </span><span class="k">do</span><span class="w"> </span><span class="nb">echo</span><span class="w"> </span>-n<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="s2">:</span><span class="si">${</span><span class="nv">SLURM_NTASKS_PER_NODE</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">;</span><span class="w"> </span><span class="k">done</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sed<span class="w"> </span><span class="s1">&#39;s/:$//&#39;</span><span class="o">)</span>

<span class="gp">marie@node$ </span><span class="nv">KMP_AFFINITY</span><span class="o">=</span>none<span class="w"> </span>mapdl<span class="w"> </span>-machines<span class="w"> </span><span class="si">${</span><span class="nv">NODELIST</span><span class="si">}</span>
</pre></div>
</div>
</section>
<section id="id47">
<h5>Batch Mode<a class="headerlink" href="#id47" title="Permalink to this heading">#</a></h5>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --nodes=4</span>
<span class="c1">#SBATCH --ntasks-per-node=4</span>
<span class="c1">#SBATCH --mem=2000</span>
<span class="c1">#SBATCH --job-name=ansys_mapdl</span>
<span class="c1">#SBATCH --output=output_ansys_mapdl</span>
<span class="c1">#SBATCH --time=01:00:00</span>

module<span class="w"> </span>purge
module<span class="w"> </span>load<span class="w"> </span>ANSYS/2021R2

<span class="c1"># generate node list</span>
<span class="nv">NODELIST</span><span class="o">=</span><span class="k">$(for</span><span class="w"> </span>node<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="k">$(</span><span class="w"> </span>scontrol<span class="w"> </span>show<span class="w"> </span>hostnames<span class="w"> </span><span class="si">${</span><span class="nv">SLURM_JOB_NODELIST</span><span class="si">}</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>uniq<span class="w"> </span><span class="k">)</span><span class="p">;</span><span class="w"> </span><span class="k">do</span><span class="w"> </span><span class="nb">echo</span><span class="w"> </span>-n<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">node</span><span class="si">}</span><span class="s2">:</span><span class="si">${</span><span class="nv">SLURM_NTASKS_PER_NODE</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">;</span><span class="w"> </span><span class="k">done</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sed<span class="w"> </span><span class="s1">&#39;s/:$//&#39;</span><span class="k">)</span>

<span class="c1"># -b (batch mode)</span>
<span class="c1"># -machines xxx   specify machines list for distributed Ansys</span>
<span class="c1"># -j jobname</span>
setenv<span class="w"> </span>KMP_AFFINITY<span class="w"> </span>none

mapdl<span class="w"> </span>-b<span class="w"> </span>-machines<span class="w"> </span><span class="si">${</span><span class="nv">NODELIST</span><span class="si">}</span><span class="w"> </span>-j<span class="w"> </span>solution<span class="w"> </span>-i<span class="w"> </span>&lt;input-file&gt;
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>sbatch<span class="w"> </span>mapdl_job.sh
</pre></div>
</div>
</section>
</section>
</section>
</section>
<section id="comsol-multiphysics">
<h2>COMSOL Multiphysics<a class="headerlink" href="#comsol-multiphysics" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://www.comsol.com">COMSOL Multiphysics</a> (formerly FEMLAB) is a finite element analysis, solver
and Simulation software package for various physics and engineering applications, especially coupled
phenomena, or multiphysics.</p>
<p>COMSOL may be used remotely on ZIH systems or locally on the desktop, using ZIH license server.</p>
<p>For using COMSOL on ZIH systems, we recommend the interactive client-server mode (see COMSOL
manual).</p>
<section id="client-server-mode">
<h3>Client-Server Mode<a class="headerlink" href="#client-server-mode" title="Permalink to this heading">#</a></h3>
<p>In this mode, COMSOL runs as server process on the ZIH system and as client process on your local
workstation. The client process needs a dummy license for installation, but no license for normal
work. Using this mode is almost undistinguishable from working with a local installation. It also works
well with Windows clients. For this operation mode to work, you must build an SSH tunnel through the
firewall of ZIH. For further information, please refer to the COMSOL manual.</p>
</section>
<section id="id48">
<h3>Usage<a class="headerlink" href="#id48" title="Permalink to this heading">#</a></h3>
<p>??? example ‚ÄúServer Process‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Start the server process with 2 cores, 4 GB RAM and max. 2 hours running time using an
interactive Slurm job like this:

```console
marie@login$ module load COMSOL
marie@login$ srun --ntasks=1 --cpus-per-task=2 --mem-per-cpu=4096 --time=02:00:00 --pty --x11=first server -np 2
```
</pre></div>
</div>
<p>??? example ‚ÄúBackground Job‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Interactive working is great for debugging and setting experiments up. But, if you have a huge
workload, you should definitively rely on job files. I.e., you put the necessary steps to get
the work done into scripts and submit these scripts to the batch system. These two steps are
outlined:

1. Create a [job file](../jobs_and_resources/slurm.md#job-files), e.g.
```bash
#!/bin/bash
#SBATCH --time=24:00:00
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=2
#SBATCH --cpus-per-task=12
#SBATCH --mem-per-cpu=2500

module load COMSOL
srun comsol -mpi=intel batch -inputfile ./MyInputFile.mph
```
</pre></div>
</div>
</section>
<section id="interactive-usage-with-x11-forwarding">
<h3>Interactive Usage with X11 Forwarding<a class="headerlink" href="#interactive-usage-with-x11-forwarding" title="Permalink to this heading">#</a></h3>
<p>=== ‚Äústarter script‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ start_comsol.sh
```
</pre></div>
</div>
<p>=== ‚Äúcustomized startup‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you&#39;d like to work interactively using COMSOL, you can request for an interactive job with,
e.g., 4 cores and 2500 MB RAM for 8 hours and X11 forwarding to open the COMSOL GUI:

```console
marie@login$ module load COMSOL
marie@login$ srun --ntasks=1 --cpus-per-task=2 --mem-per-cpu=2500 --time=01:00:00 --pty --x11=first comsol -np 2
```
</pre></div>
</div>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Please make sure, that the option *Preferences* --&gt; Graphics --&gt; *Renedering* is set to *software
rendering*. Than, you can work from within the campus network.
</pre></div>
</div>
</section>
</section>
<section id="ls-dyna">
<h2>LS-DYNA<a class="headerlink" href="#ls-dyna" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://www.dynamore.de/de">LS-DYNA</a> is a general-purpose, implicit and explicit FEM software for
nonlinear structural analysis. Both, the shared memory version and the distributed memory version
(<code class="docutils literal notranslate"><span class="pre">mpp</span></code>) are installed on ZIH systems.</p>
<p>You need a job file (aka. batch script) to run the MPI version.</p>
<p>??? example ‚ÄúMinimal Job File‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash
#SBATCH --time=01:00:00       # walltime
#SBATCH --ntasks=16           # number of processor cores (i.e. tasks)
#SBATCH --mem-per-cpu=1900M   # memory per CPU core

module load LS-DYNA
srun mpp-dyna i=neon_refined01_30ms.k memory=120000000
```

Submit the job file named `job.sh` to the batch system via

```console
marie@login$ sbatch job.sh
```

Please refer to the section [Slurm](../jobs_and_resources/slurm.md) for further details and
options on the batch system as well as monitoring commands.
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="gpu-programming">
<h1>GPU Programming<a class="headerlink" href="#gpu-programming" title="Permalink to this heading">#</a></h1>
<section id="available-gpus">
<h2>Available GPUs<a class="headerlink" href="#available-gpus" title="Permalink to this heading">#</a></h2>
<p>The full hardware specifications of the GPU-compute nodes may be found in the
<span class="xref myst">HPC Resources</span> page.
Note that the clusters may have different <span class="xref myst">modules</span> available:</p>
<p>E.g. the available CUDA versions can be listed with</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@compute$<span class="w"> </span>module<span class="w"> </span>spider<span class="w"> </span>CUDA
</pre></div>
</div>
<p>Note that some modules use a specific CUDA version which is visible in the module name,
e.g. <code class="docutils literal notranslate"><span class="pre">GDRCopy/2.1-CUDA-11.1.1</span></code> or <code class="docutils literal notranslate"><span class="pre">Horovod/0.28.1-CUDA-11.7.0-TensorFlow-2.11.0</span></code>.</p>
<p>This especially applies to the optimized CUDA libraries like <code class="docutils literal notranslate"><span class="pre">cuDNN</span></code>, <code class="docutils literal notranslate"><span class="pre">NCCL</span></code> and <code class="docutils literal notranslate"><span class="pre">magma</span></code>.</p>
<p>!!! important ‚ÄúCUDA-aware MPI‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>When running CUDA applications using MPI for interprocess communication you need to additionally load the modules
that enable CUDA-aware MPI which may provide improved performance.
Those are `UCX-CUDA` and `UCC-CUDA` which supplement the `UCX` and `UCC` modules respectively.
Some modules, like `NCCL`, load those automatically.
</pre></div>
</div>
</section>
<section id="using-gpus-with-slurm">
<h2>Using GPUs with Slurm<a class="headerlink" href="#using-gpus-with-slurm" title="Permalink to this heading">#</a></h2>
<p>For general information on how to use Slurm, read the respective <span class="xref myst">page in this compendium</span>.
When allocating resources on a GPU-node, you must specify the number of requested GPUs by using the
<code class="docutils literal notranslate"><span class="pre">--gres=gpu:&lt;N&gt;</span></code> option, like this:</p>
<p>=== ‚Äúcluster <code class="docutils literal notranslate"><span class="pre">Alpha</span></code> or <code class="docutils literal notranslate"><span class="pre">Capella</span></code>‚Äù
```bash
#!/bin/bash                           # Batch script starts with shebang line</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>#SBATCH --ntasks=1                    # All #SBATCH lines have to follow uninterrupted
#SBATCH --time=01:00:00               # after the shebang line
#SBATCH --account=p_number_crunch     # Comments start with # and do not count as interruptions
#SBATCH --job-name=fancyExp
#SBATCH --output=simulation-%j.out
#SBATCH --error=simulation-%j.err
#SBATCH --gres=gpu:1                  # request GPU(s) from Slurm

module purge                          # Set up environment, e.g., clean modules environment
module load module/version module2    # and load necessary modules

srun ./application [options]          # Execute parallel application with srun
```
</pre></div>
</div>
<p>Alternatively, you can work on the clusters interactively:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@login.&lt;cluster_name&gt;$<span class="w"> </span>srun<span class="w"> </span>--nodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--gres<span class="o">=</span>gpu:&lt;N&gt;<span class="w"> </span>--runtime<span class="o">=</span><span class="m">00</span>:30:00<span class="w"> </span>--pty<span class="w"> </span>bash
marie@compute$<span class="w"> </span>module<span class="w"> </span>purge<span class="p">;</span><span class="w"> </span>module<span class="w"> </span>switch<span class="w"> </span>release/&lt;env&gt;
</pre></div>
</div>
</section>
<section id="directive-based-gpu-programming">
<h2>Directive Based GPU Programming<a class="headerlink" href="#directive-based-gpu-programming" title="Permalink to this heading">#</a></h2>
<p>Directives are special compiler commands in your C/C++ or Fortran source code. They tell the
compiler how to parallelize and offload work to a GPU. This section explains how to use this
technique.</p>
<section id="openacc">
<h3>OpenACC<a class="headerlink" href="#openacc" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="https://www.openacc.org">OpenACC</a> is a directive based GPU programming model. It currently
only supports NVIDIA GPUs as a target.</p>
<p>Please use the following information as a start on OpenACC:</p>
<section id="introduction">
<h4>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">#</a></h4>
<p>OpenACC can be used with the PGI and NVIDIA HPC compilers. The NVIDIA HPC compiler, as part of the
<a class="reference external" href="https://docs.nvidia.com/hpc-sdk/index.html">NVIDIA HPC SDK</a>, supersedes the PGI compiler.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">nvc</span></code> compiler (NOT the <code class="docutils literal notranslate"><span class="pre">nvcc</span></code> compiler, which is used for CUDA) is available for the NVIDIA
Tesla V100 and Nvidia A100 nodes.</p>
</section>
<section id="using-openacc-with-pgi-compilers">
<h4>Using OpenACC with PGI compilers<a class="headerlink" href="#using-openacc-with-pgi-compilers" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Load the latest version via <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">load</span> <span class="pre">PGI</span></code> or search for available versions with
<code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">search</span> <span class="pre">PGI</span></code></p></li>
<li><p>For compilation, please add the compiler flag <code class="docutils literal notranslate"><span class="pre">-acc</span></code> to enable OpenACC interpreting by the
compiler</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-Minfo</span></code> tells you what the compiler is actually doing to your code</p></li>
<li><p>Add <code class="docutils literal notranslate"><span class="pre">-ta=nvidia:ampere</span></code> to enable optimizations for the A100 GPUs</p></li>
<li><p>You may find further information on the PGI compiler in the
<a class="reference external" href="https://docs.nvidia.com/hpc-sdk/pgi-compilers/20.4/x86/pgi-user-guide/index.htm">user guide</a>
and in the <a class="reference external" href="https://docs.nvidia.com/hpc-sdk/pgi-compilers/20.4/x86/pgi-ref-guide/index.htm">reference guide</a>,
which includes descriptions of available
<a class="reference external" href="https://docs.nvidia.com/hpc-sdk/pgi-compilers/20.4/x86/pgi-ref-guide/index.htm#cmdln-options-ref">command line options</a></p></li>
</ul>
</section>
<section id="using-openacc-with-nvidia-hpc-compilers">
<h4>Using OpenACC with NVIDIA HPC compilers<a class="headerlink" href="#using-openacc-with-nvidia-hpc-compilers" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Switch into the correct module environment for your selected compute nodes
(see <span class="xref myst">list of available GPUs</span>)</p></li>
<li><p>Load the <code class="docutils literal notranslate"><span class="pre">NVHPC</span></code> module for the correct module environment.
Either load the default (<code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">load</span> <span class="pre">NVHPC</span></code>) or search for a specific version.</p></li>
<li><p>Use the correct compiler for your code: <code class="docutils literal notranslate"><span class="pre">nvc</span></code> for C, <code class="docutils literal notranslate"><span class="pre">nvc++</span></code> for C++ and <code class="docutils literal notranslate"><span class="pre">nvfortran</span></code> for Fortran</p></li>
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">-acc</span></code> and <code class="docutils literal notranslate"><span class="pre">-Minfo</span></code> flag as with the PGI compiler</p></li>
<li><p>To create optimized code for either the V100 or A100, use <code class="docutils literal notranslate"><span class="pre">-gpu=cc70</span></code> or <code class="docutils literal notranslate"><span class="pre">-gpu=cc80</span></code>, respectively</p></li>
<li><p>Further information on this compiler is provided in the
<a class="reference external" href="https://docs.nvidia.com/hpc-sdk/compilers/hpc-compilers-user-guide/index.html">user guide</a> and the
<a class="reference external" href="https://docs.nvidia.com/hpc-sdk/compilers/hpc-compilers-ref-guide/index.html">reference guide</a>,
which includes descriptions of available
<a class="reference external" href="https://docs.nvidia.com/hpc-sdk/compilers/hpc-compilers-ref-guide/index.html#cmdln-options-ref">command line options</a></p></li>
<li><p>Information specific the use of OpenACC with the NVIDIA HPC compiler is compiled in a
<a class="reference external" href="https://docs.nvidia.com/hpc-sdk/compilers/openacc-gs/index.html">guide</a></p></li>
</ul>
</section>
</section>
<section id="openmp-target-offloading">
<h3>OpenMP target offloading<a class="headerlink" href="#openmp-target-offloading" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="https://www.openmp.org/">OpenMP</a> supports target offloading as of version 4.0. A dedicated set of
compiler directives can be used to annotate code-sections that are intended for execution on the
GPU (i.e., target offloading). Not all compilers with OpenMP support target offloading, refer to
the <a class="reference external" href="https://www.openmp.org/resources/openmp-compilers-tools/">official list</a> for details.
Furthermore, some compilers, such as GCC, have basic support for target offloading, but do not
enable these features by default and/or achieve poor performance.</p>
<p>On the ZIH system, compilers with OpenMP target offloading support are provided on the clusters
<code class="docutils literal notranslate"><span class="pre">power9</span></code> and <code class="docutils literal notranslate"><span class="pre">alpha</span></code>. Two compilers with good performance can be used: the NVIDIA HPC compiler and the
IBM XL compiler.</p>
<section id="using-openmp-target-offloading-with-nvidia-hpc-compilers">
<h4>Using OpenMP target offloading with NVIDIA HPC compilers<a class="headerlink" href="#using-openmp-target-offloading-with-nvidia-hpc-compilers" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Load the module environments and the NVIDIA HPC SDK as described in the
<span class="xref myst">OpenACC</span> section</p></li>
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">-mp=gpu</span></code> flag to enable OpenMP with offloading</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-Minfo</span></code> tells you what the compiler is actually doing to your code</p></li>
<li><p>The same compiler options as mentioned <span class="xref myst">above</span> are
available for OpenMP, including the <code class="docutils literal notranslate"><span class="pre">-gpu=ccXY</span></code> flag as mentioned above.</p></li>
<li><p>OpenMP-specific advice may be found in the
<a class="reference external" href="https://docs.nvidia.com/hpc-sdk/compilers/hpc-compilers-user-guide/#openmp-use">respective section in the user guide</a></p></li>
</ul>
</section>
<section id="using-openmp-target-offloading-with-the-ibm-xl-compilers">
<h4>Using OpenMP target offloading with the IBM XL compilers<a class="headerlink" href="#using-openmp-target-offloading-with-the-ibm-xl-compilers" title="Permalink to this heading">#</a></h4>
<p>The IBM XL compilers (<code class="docutils literal notranslate"><span class="pre">xlc</span></code> for C, <code class="docutils literal notranslate"><span class="pre">xlc++</span></code> for C++ and <code class="docutils literal notranslate"><span class="pre">xlf</span></code> for Fortran (with sub-version for
different versions of Fortran)) are only available on the cluster <code class="docutils literal notranslate"><span class="pre">power9</span></code> with NVIDIA Tesla V100 GPUs.</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">-qsmp</span> <span class="pre">-qoffload</span></code> combination of flags enables OpenMP target offloading support</p></li>
<li><p>Optimizations specific to the V100 GPUs can be enabled by using the
<a class="reference external" href="https://www.ibm.com/docs/en/xl-c-and-cpp-linux/16.1.1?topic=descriptions-qtgtarch"><code class="docutils literal notranslate"><span class="pre">-qtgtarch=sm_70</span></code></a>
flag.</p></li>
<li><p>IBM provides a <a class="reference external" href="https://www.ibm.com/docs/en/xl-c-and-cpp-linux/16.1.1">XL compiler documentation</a>
with a
<a class="reference external" href="https://www.ibm.com/docs/en/xl-c-and-cpp-linux/16.1.1?topic=reference-pragma-directives-openmp-parallelization">list of supported OpenMP directives</a>
and information on
<a class="reference external" href="https://www.ibm.com/docs/en/xl-c-and-cpp-linux/16.1.1?topic=gpus-programming-openmp-device-constructs">target-offloading specifics</a></p></li>
</ul>
</section>
</section>
</section>
<section id="native-gpu-programming">
<h2>Native GPU Programming<a class="headerlink" href="#native-gpu-programming" title="Permalink to this heading">#</a></h2>
<section id="cuda">
<h3>CUDA<a class="headerlink" href="#cuda" title="Permalink to this heading">#</a></h3>
<p>Native <a class="reference external" href="http://www.nvidia.com/cuda">CUDA</a> programs can sometimes offer a better performance.
NVIDIA provides some <a class="reference external" href="https://developer.nvidia.com/how-to-cuda-c-cpp">introductory material and links</a>.
An <a class="reference external" href="https://developer.nvidia.com/blog/even-easier-introduction-cuda/">introduction to CUDA</a> is
provided as well. The <a class="reference external" href="https://docs.nvidia.com/cuda/index.html">toolkit documentation page</a> links to
the <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html">programming guide</a> and the
<a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html">best practice guide</a>.
Optimization guides for supported NVIDIA architectures are available, including for
<a class="reference external" href="https://docs.nvidia.com/cuda/volta-tuning-guide/index.html">Volta (V100)</a> and
<a class="reference external" href="https://docs.nvidia.com/cuda/ampere-tuning-guide/index.html">Ampere (A100)</a>.</p>
<p>In order to compile an application with CUDA use the <code class="docutils literal notranslate"><span class="pre">nvcc</span></code> compiler command, which is described in
detail in <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">nvcc documentation</a>.
This compiler is available via several <code class="docutils literal notranslate"><span class="pre">CUDA</span></code> packages, a default version can be loaded via
<code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">load</span> <span class="pre">CUDA</span></code>. Additionally, the <code class="docutils literal notranslate"><span class="pre">NVHPC</span></code> modules provide CUDA tools as well.</p>
<p>For using CUDA with Open MPI at multiple nodes, the <code class="docutils literal notranslate"><span class="pre">OpenMPI</span></code> module loaded shall have be compiled
with CUDA support. If you aren‚Äôt sure if the module you are using has support for it you can check
it as following:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">ompi_info --parsable --all | grep mpi_built_with_cuda_support:value | awk -F&quot;:&quot; &#39;{print &quot;Open MPI supports CUDA:&quot;,$7}&#39;</span>
</pre></div>
</div>
<section id="usage-of-the-cuda-compiler">
<h4>Usage of the CUDA Compiler<a class="headerlink" href="#usage-of-the-cuda-compiler" title="Permalink to this heading">#</a></h4>
<p>The simple invocation <code class="docutils literal notranslate"><span class="pre">nvcc</span> <span class="pre">&lt;code.cu&gt;</span></code> will compile a valid CUDA program. <code class="docutils literal notranslate"><span class="pre">nvcc</span></code> differentiates
between the device and the host code, which will be compiled in separate phases. Therefore, compiler
options can be defined specifically for the device as well as for the host code. By default, the GCC
is used as the host compiler. The following flags may be useful:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--generate-code</span></code> (<code class="docutils literal notranslate"><span class="pre">-gencode</span></code>): generate optimized code for a target GPU (caution: these binaries
cannot be used with GPUs of other generations).</p>
<ul>
<li><p>For Volta (V100): <code class="docutils literal notranslate"><span class="pre">--generate-code</span> <span class="pre">arch=compute_70,code=sm_70</span></code>,</p></li>
<li><p>For Ampere (A100): <code class="docutils literal notranslate"><span class="pre">--generate-code</span> <span class="pre">arch=compute_80,code=sm_80</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">-Xcompiler</span></code>: pass flags to the host compiler. E.g., generate OpenMP-parallel host code:
<code class="docutils literal notranslate"><span class="pre">-Xcompiler</span> <span class="pre">-fopenmp</span></code>.
The <code class="docutils literal notranslate"><span class="pre">-Xcompiler</span></code> flag has to be invoked for each host-flag</p></li>
</ul>
</section>
</section>
</section>
<section id="performance-analysis">
<h2>Performance Analysis<a class="headerlink" href="#performance-analysis" title="Permalink to this heading">#</a></h2>
<p>Consult NVIDIA‚Äôs <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html">Best Practices Guide</a>
and the <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#performance-guidelines">performance guidelines</a>
for possible steps to take for the performance analysis and optimization.</p>
<p>Multiple tools can be used for the performance analysis.
For the analysis of applications on the newer GPUs (V100 and A100),
we recommend the use of the newer NVIDIA Nsight tools, <a class="reference external" href="https://developer.nvidia.com/nsight-systems">Nsight Systems</a>
for a system-wide sampling and tracing and <a class="reference external" href="https://developer.nvidia.com/nsight-compute">Nsight Compute</a>
for a detailed analysis of individual kernels.</p>
<section id="nvidia-nvprof-visual-profiler">
<h3>NVIDIA nvprof &amp; Visual Profiler<a class="headerlink" href="#nvidia-nvprof-visual-profiler" title="Permalink to this heading">#</a></h3>
<p>The nvprof command line and the Visual Profiler are available once a CUDA module has been loaded.
For a simple analysis, you can call <code class="docutils literal notranslate"><span class="pre">nvprof</span></code> without any options, like such:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@compute$<span class="w"> </span>nvprof<span class="w"> </span>./application<span class="w"> </span><span class="o">[</span>options<span class="o">]</span>
</pre></div>
</div>
<p>For a more in-depth analysis, we recommend you use the command line tool first to generate a report
file, which you can later analyze in the Visual Profiler. In order to collect a set of general
metrics for the analysis in the Visual Profiler, use the <code class="docutils literal notranslate"><span class="pre">--analysis-metrics</span></code> flag to collect
metrics and <code class="docutils literal notranslate"><span class="pre">--export-profile</span></code> to generate a report file, like this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@compute$<span class="w"> </span>nvprof<span class="w"> </span>--analysis-metrics<span class="w"> </span>--export-profile<span class="w">  </span>&lt;output&gt;.nvvp<span class="w"> </span>./application<span class="w"> </span><span class="o">[</span>options<span class="o">]</span>
</pre></div>
</div>
<p><span class="xref myst">Transfer the report file to your local system</span> and analyze it in
the Visual Profiler (<code class="docutils literal notranslate"><span class="pre">nvvp</span></code>) locally. This will give the smoothest user experience. Alternatively,
you can use <span class="xref myst">X11-forwarding</span>. Refer to the documentation for details about
the individual
<a class="reference external" href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#visual-views">features and views of the Visual Profiler</a>.</p>
<p>Besides these generic analysis methods, you can profile specific aspects of your GPU kernels.
<code class="docutils literal notranslate"><span class="pre">nvprof</span></code> can profile specific events. For this, use</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@compute$<span class="w"> </span>nvprof<span class="w"> </span>--query-events
</pre></div>
</div>
<p>to get a list of available events.
Analyze one or more events by using specifying one or more events, separated by comma:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@compute$<span class="w"> </span>nvprof<span class="w"> </span>--events<span class="w"> </span>&lt;event_1&gt;<span class="o">[</span>,&lt;event_2&gt;<span class="o">[</span>,...<span class="o">]]</span><span class="w"> </span>./application<span class="w"> </span><span class="o">[</span>options<span class="o">]</span>
</pre></div>
</div>
<p>Additionally, you can analyze specific metrics.
Similar to the profiling of events, you can get a list of available metrics:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@compute$<span class="w"> </span>nvprof<span class="w"> </span>--query-metrics
</pre></div>
</div>
<p>One or more metrics can be profiled at the same time:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@compute$<span class="w"> </span>nvprof<span class="w"> </span>--metrics<span class="w"> </span>&lt;metric_1&gt;<span class="o">[</span>,&lt;metric_2&gt;<span class="o">[</span>,...<span class="o">]]</span><span class="w"> </span>./application<span class="w"> </span><span class="o">[</span>options<span class="o">]</span>
</pre></div>
</div>
<p>If you want to limit the profiler‚Äôs scope to one or more kernels, you can use the
<code class="docutils literal notranslate"><span class="pre">--kernels</span> <span class="pre">&lt;kernel_1&gt;[,&lt;kernel_2&gt;]</span></code> flag. For further command line options, refer to the
<a class="reference external" href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#nvprof-command-line-options">documentation on command line options</a>.</p>
</section>
<section id="nvidia-nsight-systems">
<h3>NVIDIA Nsight Systems<a class="headerlink" href="#nvidia-nsight-systems" title="Permalink to this heading">#</a></h3>
<p>Use <a class="reference external" href="https://developer.nvidia.com/nsight-systems">NVIDIA Nsight Systems</a> for a system-wide sampling
of your code. Refer to the
<a class="reference external" href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html">NVIDIA Nsight Systems User Guide</a> for
details. With this, you can identify parts of your code that take a long time to run and are
suitable optimization candidates.</p>
<p>Use the command-line version to sample your code and create a report file for later analysis:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@compute$<span class="w"> </span>nsys<span class="w"> </span>profile<span class="w"> </span><span class="o">[</span>--stats<span class="o">=</span>true<span class="o">]</span><span class="w"> </span>./application<span class="w"> </span><span class="o">[</span>options<span class="o">]</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">--stats=true</span></code> flag is optional and will create a summary on the command line. Depending on your
needs, this analysis may be sufficient to identify optimizations targets.</p>
<p>The graphical user interface version can be used for a thorough analysis of your previously
generated report file. For an optimal user experience, we recommend a local installation of NVIDIA
Nsight Systems. In this case, you can
<span class="xref myst">transfer the report file to your local system</span>.
Alternatively, you can use <span class="xref myst">X11-forwarding</span>. The graphical user interface is
usually available as <code class="docutils literal notranslate"><span class="pre">nsys-ui</span></code>.</p>
<p>Furthermore, you can use the command line interface for further analyses. Refer to the
documentation for a
<a class="reference external" href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html#cli-options">list of available command line options</a>.</p>
</section>
<section id="nvidia-nsight-compute">
<h3>NVIDIA Nsight Compute<a class="headerlink" href="#nvidia-nsight-compute" title="Permalink to this heading">#</a></h3>
<p>Nsight Compute is used for the analysis of individual GPU-kernels. It supports GPUs from the Volta
architecture onward (on the ZIH system: V100 and A100). If you are familiar with nvprof,
you may want to consult the <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html#nvprof-guide">Nvprof Transition Guide</a>,
as Nsight Compute uses a new scheme for metrics.
We recommend those kernels as optimization targets that require a large portion of you run time,
according to Nsight Systems. Nsight Compute is particularly useful for CUDA code, as you have much
greater control over your code compared to the directive based approaches.</p>
<p>Nsight Compute comes in a
<a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html">command line</a>
and a <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html">graphical version</a>.
Refer to the
<a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html">Kernel Profiling Guide</a>
to get an overview of the functionality of these tools.</p>
<p>You can call the command line version (<code class="docutils literal notranslate"><span class="pre">ncu</span></code>) without further options to get a broad overview of
your kernel‚Äôs performance:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@compute$<span class="w"> </span>ncu<span class="w"> </span>./application<span class="w"> </span><span class="o">[</span>options<span class="o">]</span>
</pre></div>
</div>
<p>As with the other profiling tools, the Nsight Compute profiler can generate report files like this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@compute$<span class="w"> </span>ncu<span class="w"> </span>--export<span class="w"> </span>&lt;report&gt;<span class="w"> </span>./application<span class="w"> </span><span class="o">[</span>options<span class="o">]</span>
</pre></div>
</div>
<p>The report file will automatically get the file ending <code class="docutils literal notranslate"><span class="pre">.ncu-rep</span></code>, you do not need to specify this
manually.</p>
<p>This report file can be analyzed in the graphical user interface profiler. Again, we recommend you
generate a report file on a compute node and
<span class="xref myst">transfer the report file to your local system</span>.
Alternatively, you can use <span class="xref myst">X11-forwarding</span>. The graphical user interface is
usually available as <code class="docutils literal notranslate"><span class="pre">ncu-ui</span></code> or <code class="docutils literal notranslate"><span class="pre">nv-nsight-cu</span></code>.</p>
<p>Similar to the <code class="docutils literal notranslate"><span class="pre">nvprof</span></code> profiler, you can analyze specific metrics. NVIDIA provides a
<a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-guide">Metrics Guide</a>. Use
<code class="docutils literal notranslate"><span class="pre">--query-metrics</span></code> to get a list of available metrics, listing them by base name. Individual metrics
can be collected by using</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@compute$<span class="w"> </span>ncu<span class="w"> </span>--metrics<span class="w"> </span>&lt;metric_1&gt;<span class="o">[</span>,&lt;metric_2&gt;,...<span class="o">]</span><span class="w"> </span>./application<span class="w"> </span><span class="o">[</span>options<span class="o">]</span>
</pre></div>
</div>
<p>Collection of events is no longer possible with Nsight Compute. Instead, many nvprof events can be
<a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html#nvprof-event-comparison">measured with metrics</a>.</p>
<p>You can collect metrics for individual kernels by specifying the <code class="docutils literal notranslate"><span class="pre">--kernel-name</span></code> flag.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="hyperparameter-optimization-omniopt">
<h1>Hyperparameter Optimization (OmniOpt)<a class="headerlink" href="#hyperparameter-optimization-omniopt" title="Permalink to this heading">#</a></h1>
<p>Classical simulation methods as well as machine learning methods (e.g. neural networks) have a large
number of hyperparameters that significantly determine the accuracy, efficiency, and transferability
of the method. In classical simulations, the hyperparameters are usually determined by adaptation to
measured values. Esp. in neural networks, the hyperparameters determine the network architecture:
number and type of layers, number of neurons, activation functions, measures against overfitting
etc. The most common methods to determine hyperparameters are intuitive testing, grid search or
random search.</p>
<p>The tool OmniOpt performs hyperparameter optimization within a broad range of applications as
classical simulations or machine learning algorithms. OmniOpt is robust and it checks and installs
all dependencies automatically and fixes many problems in the background. While OmniOpt optimizes,
no further intervention is required. You can follow the ongoing output live in the console.
Overhead of OmniOpt is minimal and virtually imperceptible.</p>
<section id="quick-start-with-omniopt">
<h2>Quick start with OmniOpt<a class="headerlink" href="#quick-start-with-omniopt" title="Permalink to this heading">#</a></h2>
<p>The following instructions demonstrate the basic usage of OmniOpt on the ZIH system, based on the
hyperparameter optimization for a neural network.</p>
<p>The typical OmniOpt workflow comprises at least the following steps:</p>
<ol class="arabic simple">
<li><p><span class="xref myst">Prepare application script and software environment</span></p></li>
<li><p><span class="xref myst">Configure and run OmniOpt</span></p></li>
<li><p><span class="xref myst">Check and evaluate OmniOpt results</span></p></li>
</ol>
<section id="prepare-application-script-and-software-environment">
<h3>Prepare Application Script and Software Environment<a class="headerlink" href="#prepare-application-script-and-software-environment" title="Permalink to this heading">#</a></h3>
<p>The following example application script was created from
<a class="reference external" href="https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html">https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html</a>
as a starting point.
Therein, a neural network is trained on the MNIST Fashion data set.</p>
<p>There are the following script preparation steps for OmniOpt:</p>
<ol class="arabic">
<li><p>Changing hard-coded hyperparameters (chosen here: batch size, epochs, size of layer 1 and 2) into
command line parameters.  Esp. for this example, the Python module <code class="docutils literal notranslate"><span class="pre">argparse</span></code> (see the docs at
<a class="reference external" href="https://docs.python.org/3/library/argparse.html">https://docs.python.org/3/library/argparse.html</a>
is used.</p>
<p>??? note ‚ÄúParsing arguments in Python‚Äù
There are many ways for parsing arguments into Python scripts. The easiest approach is
the <code class="docutils literal notranslate"><span class="pre">sys</span></code> module (see
<a class="reference external" href="https://www.geeksforgeeks.org/how-to-use-sys-argv-in-python">www.geeksforgeeks.org/how-to-use-sys-argv-in-python</a>),
which would be fully sufficient for usage with OmniOpt. Nevertheless, this basic approach
has no consistency checks or error handling etc.</p>
</li>
<li><p>Mark the output of the optimization target (chosen here: average loss) by prefixing it with the
RESULT string. OmniOpt takes the <strong>last appearing value</strong> prefixed with the RESULT string. In
the example, different epochs are performed and the average from the last epoch is caught by
OmniOpt. Additionally, the <code class="docutils literal notranslate"><span class="pre">RESULT</span></code> output has to be a <strong>single line</strong>. After all these changes,
the final script is as follows (with the lines containing relevant changes highlighted).</p>
<p>??? example ‚ÄúFinal modified Python script: MNIST Fashion ‚Äú</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> ```python linenums=&quot;1&quot; hl_lines=&quot;18-33 52-53 66-68 72 74 76 85 125-126&quot;
 #!/usr/bin/env python
 # coding: utf-8

 # # Example for using OmniOpt
 #
 # source code taken from: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html
 # parameters under consideration:#
 # 1. batch size
 # 2. epochs
 # 3. size output layer 1
 # 4. size output layer 2

 import torch
 from torch import nn
 from torch.utils.data import DataLoader
 from torchvision import datasets
 from torchvision.transforms import ToTensor, Lambda, Compose
 import argparse

 # parsing hpyerparameters as arguments
 parser = argparse.ArgumentParser(description=&quot;Demo application for OmniOpt for hyperparameter optimization, example: neural network on MNIST fashion data.&quot;)

 parser.add_argument(&quot;--out-layer1&quot;, type=int, help=&quot;the number of outputs of layer 1&quot;, default = 512)
 parser.add_argument(&quot;--out-layer2&quot;, type=int, help=&quot;the number of outputs of layer 2&quot;, default = 512)
 parser.add_argument(&quot;--batchsize&quot;, type=int, help=&quot;batchsize for training&quot;, default = 64)
 parser.add_argument(&quot;--epochs&quot;, type=int, help=&quot;number of epochs&quot;, default = 5)

 args = parser.parse_args()

 batch_size = args.batchsize
 epochs = args.epochs
 num_nodes_out1 = args.out_layer1
 num_nodes_out2 = args.out_layer2

 # Download training data from open data sets.
 training_data = datasets.FashionMNIST(
     root=&quot;data&quot;,
     train=True,
     download=True,
     transform=ToTensor(),
 )

 # Download test data from open data sets.
 test_data = datasets.FashionMNIST(
     root=&quot;data&quot;,
     train=False,
     download=True,
     transform=ToTensor(),
 )

 # Create data loaders.
 train_dataloader = DataLoader(training_data, batch_size=batch_size)
 test_dataloader = DataLoader(test_data, batch_size=batch_size)

 for X, y in test_dataloader:
     print(&quot;Shape of X [N, C, H, W]: &quot;, X.shape)
     print(&quot;Shape of y: &quot;, y.shape, y.dtype)
     break

 # Get cpu or gpu device for training.
 device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;
 print(&quot;Using {} device&quot;.format(device))

 # Define model
 class NeuralNetwork(nn.Module):
     def __init__(self, out1, out2):
         self.o1 = out1
         self.o2 = out2
         super(NeuralNetwork, self).__init__()
         self.flatten = nn.Flatten()
         self.linear_relu_stack = nn.Sequential(
             nn.Linear(28*28, out1),
             nn.ReLU(),
             nn.Linear(out1, out2),
             nn.ReLU(),
             nn.Linear(out2, 10),
             nn.ReLU()
         )

     def forward(self, x):
         x = self.flatten(x)
         logits = self.linear_relu_stack(x)
         return logits

 model = NeuralNetwork(out1=num_nodes_out1, out2=num_nodes_out2).to(device)
 print(model)

 loss_fn = nn.CrossEntropyLoss()
 optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)

 def train(dataloader, model, loss_fn, optimizer):
     size = len(dataloader.dataset)
     for batch, (X, y) in enumerate(dataloader):
         X, y = X.to(device), y.to(device)

         # Compute prediction error
         pred = model(X)
         loss = loss_fn(pred, y)

         # Backpropagation
         optimizer.zero_grad()
         loss.backward()
         optimizer.step()

         if batch % 200 == 0:
             loss, current = loss.item(), batch * len(X)
             print(f&quot;loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]&quot;)

 def test(dataloader, model, loss_fn):
     size = len(dataloader.dataset)
     num_batches = len(dataloader)
     model.eval()
     test_loss, correct = 0, 0
     with torch.no_grad():
         for X, y in dataloader:
             X, y = X.to(device), y.to(device)
             pred = model(X)
             test_loss += loss_fn(pred, y).item()
             correct += (pred.argmax(1) == y).type(torch.float).sum().item()
     test_loss /= num_batches
     correct /= size
     print(f&quot;Test Error: \n Accuracy: {(100*correct):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \n&quot;)


     #print statement esp. for OmniOpt (single line!!)
     print(f&quot;RESULT: {test_loss:&gt;8f} \n&quot;)

 for t in range(epochs):
     print(f&quot;Epoch {t+1}\n-------------------------------&quot;)
     train(train_dataloader, model, loss_fn, optimizer)
     test(test_dataloader, model, loss_fn)
 print(&quot;Done!&quot;)
 ```
</pre></div>
</div>
</li>
<li><p>Testing script functionality and determine software requirements for the chosen
<span class="xref myst">cluster</span>. In the following, the
cluster <code class="docutils literal notranslate"><span class="pre">Alpha</span></code> is used. Please note the parameters <code class="docutils literal notranslate"><span class="pre">--out-layer1</span></code>, <code class="docutils literal notranslate"><span class="pre">--batchsize</span></code>, <code class="docutils literal notranslate"><span class="pre">--epochs</span></code> when
calling the Python script. Additionally, note the <code class="docutils literal notranslate"><span class="pre">RESULT</span></code> string with the output for OmniOpt.</p>
<p>??? hint ‚ÄúHint for installing Python modules‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> Note that for this example the module `torchvision` is not available on the cluster `alpha`
 and it is installed by creating a [virtual environment](python_virtual_environments.md). It is
 recommended to install such a virtual environment into a
 [workspace](../data_lifecycle/workspaces.md).

 ```console
 marie@login$ module load release/23.04  GCC/11.3.0  OpenMPI/4.1.4 PyTorch/1.12.1
 marie@login$ mkdir &lt;/path/to/workspace/python-environments&gt;    #create folder
 marie@login$ virtualenv --system-site-packages &lt;/path/to/workspace/python-environments/torchvision_env&gt;
 marie@login$ source &lt;/path/to/workspace/python-environments/torchvision_env&gt;/bin/activate #activate virtual environment
 marie@login$ pip install torchvision #install torchvision module
 ```
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>Job<span class="w"> </span>submission<span class="w"> </span>on<span class="w"> </span>alpha<span class="w"> </span>nodes<span class="w"> </span>with<span class="w"> </span><span class="m">1</span><span class="w"> </span>GPU<span class="w"> </span>on<span class="w"> </span><span class="m">1</span><span class="w"> </span>node<span class="w"> </span>with<span class="w"> </span><span class="m">800</span><span class="w"> </span>MB<span class="w"> </span>per<span class="w"> </span>CPU
<span class="gp">marie@login$ </span>srun<span class="w"> </span>--gres<span class="o">=</span>gpu:1<span class="w"> </span>-n<span class="w"> </span><span class="m">1</span><span class="w"> </span>-c<span class="w"> </span><span class="m">7</span><span class="w"> </span>--pty<span class="w"> </span>--mem-per-cpu<span class="o">=</span><span class="m">800</span><span class="w"> </span>bash
<span class="gp">marie@alpha$ </span>module<span class="w"> </span>load<span class="w"> </span>release/23.04<span class="w"> </span>GCC/11.3.0<span class="w">  </span>OpenMPI/4.1.4<span class="w"> </span>PyTorch/1.12.1
<span class="gp"># </span>Activate<span class="w"> </span>virtual<span class="w"> </span>environment
<span class="gp">marie@alpha$ </span><span class="nb">source</span><span class="w"> </span>&lt;/path/to/workspace/python-environments/torchvision_env&gt;/bin/activate

<span class="gp">marie@alpha$ </span>python<span class="w"> </span>&lt;/path/to/your/script/mnistFashion.py&gt;<span class="w"> </span>--out-layer1<span class="o">=</span><span class="m">200</span><span class="w"> </span>--batchsize<span class="o">=</span><span class="m">10</span><span class="w"> </span>--epochs<span class="o">=</span><span class="m">3</span>
<span class="go">[...]</span>
<span class="go">Epoch 3</span>
<span class="go">-------------------------------</span>
<span class="go">loss: 1.422406  [    0/60000]</span>
<span class="go">loss: 0.852647  [10000/60000]</span>
<span class="go">loss: 1.139685  [20000/60000]</span>
<span class="go">loss: 0.572221  [30000/60000]</span>
<span class="go">loss: 1.516888  [40000/60000]</span>
<span class="go">loss: 0.445737  [50000/60000]</span>
<span class="go">Test Error:</span>
<span class="go"> Accuracy: 69.5%, Avg loss: 0.878329</span>

<span class="go">RESULT: 0.878329</span>

<span class="go">Done!</span>
</pre></div>
</div>
</li>
</ol>
<p>Using the modified script within OmniOpt requires configuring and loading of the software
environment. The recommended way is to wrap the necessary calls in a shell script.</p>
<p>??? example ‚ÄúExample for wrapping with shell script‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash -l
# ^ Shebang-Line, so that it is known that this is a bash file
# -l means &#39;load this as login shell&#39;, so that /etc/profile gets loaded and you can use &#39;module load&#39; or &#39;ml&#39; as usual

# If you don&#39;t use this script via `./run.sh&#39; or just `srun run.sh&#39;, but like `srun bash run.sh&#39;, please add the &#39;-l&#39; there too.
# Like this:
# srun bash -l run.sh

# Load modules your program needs, always specify versions!
module load release/23.04 GCC/10.2.0 CUDA/11.1.1 OpenMPI/4.0.5 PyTorch/1.7.1
source &lt;/path/to/workspace/python-environments/torchvision_env&gt;/bin/activate #activate virtual environment

# Load your script. $@ is all the parameters that are given to this shell file.
python &lt;/path/to/your/script/mnistFashion.py&gt; $@
```
</pre></div>
</div>
<p>When the wrapped shell script is running properly, the preparations are finished and the next step
is configuring OmniOpt.</p>
</section>
<section id="configure-and-run-omniopt">
<h3>Configure and Run OmniOpt<a class="headerlink" href="#configure-and-run-omniopt" title="Permalink to this heading">#</a></h3>
<p>Configuring OmniOpt is done via the GUI at
<a class="reference external" href="https://imageseg.scads.ai/omnioptgui/">https://imageseg.scads.ai/omnioptgui/</a>.
This GUI guides through the configuration process and as result a configuration file is created
automatically according to the GUI input. If you are more familiar with using OmniOpt later on,
this configuration file can be modified directly without using the GUI.</p>
<p>A screenshot of
<a class="reference external" href="https://imageseg.scads.ai/omnioptgui/?maxevalserror=5&amp;mem_per_worker=1000&amp;number_of_parameters=3&amp;param_0_values=10%2C50%2C100&amp;param_1_values=8%2C16%2C32&amp;param_2_values=10%2C15%2C30&amp;param_0_name=out-layer1&amp;param_1_name=batchsize&amp;param_2_name=batchsize&amp;account=&amp;projectname=mnist_fashion_optimization_set_1&amp;partition=alpha&amp;searchtype=tpe.suggest&amp;param_0_type=hp.choice&amp;param_1_type=hp.choice&amp;param_2_type=hp.choice&amp;max_evals=1000&amp;objective_program=bash%20%3C%2Fpath%2Fto%2Fwrapper-script%2Frun-mnist-fashion.sh%3E%20--out-layer1%3D%28%24x_0%29%20--batchsize%3D%28%24x_1%29%20--epochs%3D%28%24x_2%29&amp;workdir=%3C%2Fscratch%2Fws%2Fomniopt-workdir%2F%3E">the GUI</a>,
including a properly configuration for the MNIST fashion example is shown below.</p>
<p>Please modify the paths for <code class="docutils literal notranslate"><span class="pre">objective</span> <span class="pre">program</span></code> and <code class="docutils literal notranslate"><span class="pre">workdir</span></code> according to your needs.</p>
<p><img alt="GUI for configuring OmniOpt" src="63_chat_with_docs/misc/hyperparameter_optimization-OmniOpt-GUI.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>Using OmniOpt for a first trial example, it is often sufficient to concentrate on the following
configuration parameters:</p>
<ol class="arabic simple">
<li><p><strong>Optimization run name:</strong> A name for an OmniOpt run given a belonging configuration.</p></li>
<li><p><strong>Partition:</strong> Choose the cluster on the ZIH system that fits the programs‚Äô needs.</p></li>
<li><p><strong>Enable GPU:</strong> Decide whether a program could benefit from GPU usage or not.</p></li>
<li><p><strong>Workdir:</strong> The directory where OmniOpt is saving its necessary files and all results. Derived
from the optimization run name, each configuration creates a single directory.
Make sure that this working directory is writable from the compute nodes. It is recommended to
use a <span class="xref myst">workspace</span>.</p></li>
<li><p><strong>Objective program:</strong> Provide all information for program execution. Typically, this will
contain the command for executing a wrapper script.</p></li>
<li><p><strong>Parameters:</strong> The hyperparameters to be optimized with the names OmniOpt should use. For the
example here, the variable names are identical to the input parameters of the Python script.
However, these names can be chosen differently, since the connection to OmniOpt is realized via
the variables (<code class="docutils literal notranslate"><span class="pre">$x_0</span></code>), (<code class="docutils literal notranslate"><span class="pre">$x_1</span></code>), etc. from the GUI section ‚ÄúObjective program‚Äù. Please note that
it is not necessary to name the parameters explicitly in your script but only within the OmniOpt
configuration.</p></li>
</ol>
<p>After all parameters are entered into the GUI, the call for OmniOpt is generated automatically and
displayed on the right. This command contains all necessary instructions (including requesting
resources with Slurm). <strong>Thus, this command can be executed directly on a login node on the ZIH
system.</strong></p>
<p><img alt="GUI for configuring OmniOpt" src="63_chat_with_docs/misc/hyperparameter_optimization-OmniOpt-final-command.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>After executing this command OmniOpt is doing all the magic in the background and there are no
further actions necessary.</p>
<p>??? hint ‚ÄúHints on the working directory‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1. Starting OmniOpt without providing a working directory will store OmniOpt into the present directory.
1. Within the given working directory, a new folder named &quot;omniopt&quot; as default, is created.
1. Within one OmniOpt working directory, there can be multiple optimization projects.
1. It is possible to have as many working directories as you want (with multiple optimization runs).
1. It is recommended to use a [workspace](../data_lifecycle/workspaces.md) as working directory, but not the home directory.
</pre></div>
</div>
</section>
<section id="check-and-evaluate-omniopt-results">
<h3>Check and Evaluate OmniOpt Results<a class="headerlink" href="#check-and-evaluate-omniopt-results" title="Permalink to this heading">#</a></h3>
<p>For getting informed about the current status of OmniOpt or for looking into results, the evaluation
tool of OmniOpt is used. Switch to the OmniOpt folder and run <code class="docutils literal notranslate"><span class="pre">evaluate-run.sh</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>bash<span class="w"> </span>&lt;/data/horse/ws/omniopt-workdir/&gt;evaluate-run.sh
</pre></div>
</div>
<p>After initializing and checking for updates in the background, OmniOpt is asking to select the
optimization run of interest.  After selecting the optimization run, there will be a menu with the
items as shown below.  If OmniOpt has still running jobs there appear some menu items that refer to
these running jobs (image shown below to the right).</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p>evaluation options (all jobs finished)</p></th>
<th class="head text-center"><p>evaluation options (still running jobs)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><img alt="GUI for configuring OmniOpt" src="63_chat_with_docs/misc/OmniOpt-evaluate-menu.png" /></p></td>
<td class="text-center"><p><img alt="GUI for configuring OmniOpt" src="63_chat_with_docs/misc/OmniOpt-still-running-jobs.png" /></p></td>
</tr>
</tbody>
</table>
<p>For now, we assume that OmniOpt has finished already.
In order to look into the results, there are the following basic approaches.</p>
<ol class="arabic">
<li><p><strong>Graphical approach:</strong>
There are basically two graphical approaches: two dimensional scatter plots and parallel plots.</p>
<p>Below there is shown a parallel plot from the MNIST fashion example.
<img alt="GUI for configuring OmniOpt" src="63_chat_with_docs/misc/OmniOpt-parallel-plot.png" />{: align=‚Äùcenter‚Äù}</p>
<p>??? hint ‚ÄúHints on parallel plots‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> Parallel plots are suitable especially for dealing with multiple dimensions. The parallel
 plot created by OmniOpt is an interactive `html` file that is stored in the OminOpt working
 directory under `projects/&lt;name_of_optimization_run&gt;/parallel-plot`. The interactivity
 of this plot is intended to make optimal combinations of the hyperparameters visible more
 easily. Get more information about this interactivity by clicking the &quot;Help&quot; button at the
 top of the graphic (see red arrow on the image above).
</pre></div>
</div>
<p>After creating a 2D scatter plot or a parallel plot, OmniOpt will try to display the
corresponding file (<code class="docutils literal notranslate"><span class="pre">html</span></code>, <code class="docutils literal notranslate"><span class="pre">png</span></code>) directly on the ZIH system. Therefore, X11 forwarding must be
enabled, either by <span class="xref myst">SSH configuration
</span> or by using e.g. <code class="docutils literal notranslate"><span class="pre">ssh</span> <span class="pre">-XC</span> <span class="pre">alpha</span></code>
while logging in. Nevertheless, because of latency using X11 forwarding, it is recommended to
download the created files and explore them on the local machine (esp. for the parallel plot).
The created files are saved at
<code class="docutils literal notranslate"><span class="pre">projects/&lt;name_of_optimization_run&gt;/{2d-scatterplots,parallel-plot}</span></code>.</p>
</li>
<li><p><strong>Getting the raw data:</strong>
As a second approach, the raw data of the optimization process can be exported as a CSV file.
The created output files are stored in the folder <code class="docutils literal notranslate"><span class="pre">projects/&lt;name_of_optimization_run&gt;/csv</span></code>.</p></li>
</ol>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="external-licenses">
<h1>External Licenses<a class="headerlink" href="#external-licenses" title="Permalink to this heading">#</a></h1>
<p>It is possible (please <span class="xref myst">contact the support team</span> first) for users to install
their own software and use their own license servers, e.g. FlexLM. The outbound IP addresses from
ZIH systems are:</p>
<ul class="simple">
<li><p>NAT via 141.76.5.48/28 (for both login and compute nodes)</p></li>
</ul>
<p>The IT department of the external institute has to open the firewall for license communications
(might be multiple ports) from ZIH systems and enable handing-out license to these IPs and login.</p>
<p>The user has to configure the software to use the correct license server. This can typically be done
by environment variable or file.</p>
<p>!!! attention</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you are using software we have installed, but bring your own license key (e.g.
commercial ANSYS), make sure that to substitute the environment variables we are using as default!
(To verify this, run `printenv|grep licenses` and make sure that you dont&#39; see entries refering to
our ZIH license server.)
</pre></div>
</div>
<section id="how-to-adjust-the-license-setting">
<h2>How to adjust the license setting<a class="headerlink" href="#how-to-adjust-the-license-setting" title="Permalink to this heading">#</a></h2>
<p>Most programs, that work with the FlexLM license manager,
can be instructed to look for another license server,
by overwriting the environment variable ‚ÄúLM_LICENSE_FILE‚Äù.
Do note that not all proprietary software looks for that environment variable.</p>
<p>!!! example ‚ÄúChanging the license server‚Äù
<code class="docutils literal notranslate"><span class="pre">console</span>&#160;&#160;&#160;&#160; <span class="pre">marie&#64;compute$</span> <span class="pre">export</span> <span class="pre">LM_LICENSE_FILE=12345&#64;example.com</span>&#160;&#160;&#160;&#160; </code>
Here ‚Äú12345‚Äù is the port on which the license server is listening,
while ‚Äú<a class="reference external" href="http://example.com">example.com</a>‚Äù is the network addresss of the license server.</p>
<p>Some licensed software comes with a license file,
it can be similarly specified like this:</p>
<p>!!! example ‚ÄúChanging license‚Äù
<code class="docutils literal notranslate"><span class="pre">bash</span>&#160;&#160;&#160;&#160; <span class="pre">export</span> <span class="pre">LM_LICENSE_FILE=&lt;SOME_PATH&gt;</span>&#160;&#160;&#160;&#160; </code></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Example:

```console
export LM_LICENSE_FILE=$HOME/mylicense.dat
```
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="record-course-of-events-with-lo2s">
<h1>Record Course of Events with lo2s<a class="headerlink" href="#record-course-of-events-with-lo2s" title="Permalink to this heading">#</a></h1>
<p>Lightweight node-level performance monitoring tool <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> creates parallel OTF2 traces with a focus
on both application and system view. The traces can contain any of the following information:</p>
<ul class="simple">
<li><p>From running threads</p>
<ul>
<li><p>Calling context samples based on instruction overflows</p></li>
<li><p>The calling context samples are annotated with the disassembled assembler instruction string</p></li>
<li><p>The frame pointer-based call-path for each calling context sample</p></li>
<li><p>Per-thread performance counter readings</p></li>
<li><p>Which thread was scheduled on which CPU at what time</p></li>
</ul>
</li>
<li><p>From the system</p>
<ul>
<li><p>Metrics from tracepoints (e.g., the selected C-state or P-state)</p></li>
<li><p>The node-level system tree (CPUs (HW-threads), cores, packages)</p></li>
<li><p>CPU power measurements (x86_energy)</p></li>
<li><p>Microarchitecture specific metrics (x86_adapt, per package or core)</p></li>
<li><p>Arbitrary metrics through plugins (Score-P compatible)</p></li>
</ul>
</li>
</ul>
<p>In general, <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> operates either in <strong>process monitoring</strong> or <strong>system monitoring</strong> mode.</p>
<p>With <strong>process monitoring</strong>, all information is grouped by each thread of a monitored process
group - it shows you <em>on which CPU is each monitored thread running</em>. <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> either acts as a
prefix command to run the process (and also tracks its children) or <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> attaches to a running
process.</p>
<p>In the <strong>system monitoring</strong> mode, information is grouped by logical CPU - it shows you
<em>which thread was running on a given CPU</em>. Metrics are also shown per CPU.</p>
<p>In both modes, <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> always groups system-level metrics (e.g., tracepoints) by their respective
system hardware component.</p>
<section id="id49">
<h2>Usage<a class="headerlink" href="#id49" title="Permalink to this heading">#</a></h2>
<p>Only the basic usage is shown in this Wiki. For a more detailed explanation, refer to the
<a class="reference external" href="https://github.com/tud-zih-energy/lo2s">Lo2s website</a>.</p>
<p>Before using <code class="docutils literal notranslate"><span class="pre">lo2s</span></code>, set up the correct environment with</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>lo2s
</pre></div>
</div>
<p>As <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> is built upon <span class="xref myst">perf</span>, its usage and limitations are very similar to that.
In particular, you can use <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> as a prefix command just like <code class="docutils literal notranslate"><span class="pre">perf</span></code>. Even some of the command
line arguments are inspired by <code class="docutils literal notranslate"><span class="pre">perf</span></code>. The main difference to <code class="docutils literal notranslate"><span class="pre">perf</span></code> is that <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> will output
a <span class="xref myst">Vampir trace</span>, which allows a full-blown performance analysis almost like
<span class="xref myst">Score-P</span>.</p>
<p>To record the behavior of an application, prefix the application run with <code class="docutils literal notranslate"><span class="pre">lo2s</span></code>. We recommend
using the double dash <code class="docutils literal notranslate"><span class="pre">--</span></code> to prevent mixing command line arguments between <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> and the user
application. In the following example, we run <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> on the application <code class="docutils literal notranslate"><span class="pre">sleep</span> <span class="pre">2</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>lo2s<span class="w"> </span>--no-kernel<span class="w"> </span>--<span class="w"> </span>sleep<span class="w"> </span><span class="m">2</span>
<span class="go">[ lo2s: sleep 2  (0), 1 threads, 0.014082s CPU, 2.03315s total ]</span>
<span class="go">[ lo2s: 5 wakeups, wrote 2.48 KiB lo2s_trace_2021-10-12T12-39-06 ]</span>
</pre></div>
</div>
<p>This will record the application in the <code class="docutils literal notranslate"><span class="pre">process</span> <span class="pre">monitoring</span> <span class="pre">mode</span></code>. This means, the applications
process, its forked processes, and threads are recorded and can be analyzed using Vampir.
The main view will represent each process and thread over time. There will be a metric ‚ÄúCPU‚Äù
indicating for each process, on which CPU it was executed during the runtime.</p>
</section>
<section id="required-permissions">
<h2>Required Permissions<a class="headerlink" href="#required-permissions" title="Permalink to this heading">#</a></h2>
<p>By design, <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> almost exclusively utilizes Linux Kernel facilities such as perf and tracepoints
to perform the application measurements. For security reasons, these facilities require special
permissions, in particular <code class="docutils literal notranslate"><span class="pre">perf_event_paranoid</span></code> and read permissions to the <code class="docutils literal notranslate"><span class="pre">debugfs</span></code> under
<code class="docutils literal notranslate"><span class="pre">/sys/kernel/debug</span></code>.</p>
<p>Luckily, for the <code class="docutils literal notranslate"><span class="pre">process</span> <span class="pre">monitoring</span> <span class="pre">mode</span></code> the default settings allow you to run <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> just fine.
All you need to do is pass the <code class="docutils literal notranslate"><span class="pre">--no-kernel</span></code> parameter like in the example above.</p>
<p>For the <code class="docutils literal notranslate"><span class="pre">system</span> <span class="pre">monitoring</span> <span class="pre">mode</span></code> you can get the required permission with the Slurm parameter
<code class="docutils literal notranslate"><span class="pre">--exclusive</span></code>. (Note: Regardless of the actual requested processes per node, you will accrue
cpu-hours as if you had reserved all cores on the node.)</p>
</section>
<section id="memory-requirements">
<h2>Memory Requirements<a class="headerlink" href="#memory-requirements" title="Permalink to this heading">#</a></h2>
<p>When requesting memory for your jobs, you need to take into account that <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> needs a substantial
amount of memory for its operation. Unfortunately, the amount of memory depends on the application.
The amount mainly scales with the number of processes spawned by the traced application. For each
processes, there is a fixed-sized buffer. This should be fine for a typical HPC application, but
can lead to extreme cases there the buffers are orders of magnitude larger than the resulting trace.
For instance, recording a CMake run, which spawns hundreds of processes, each running only for
a few milliseconds, leaving each buffer almost empty. Still, the buffers needs to be allocated
and thus require a lot of memory.</p>
<p>Given such a case, we recommend to use the <code class="docutils literal notranslate"><span class="pre">system</span> <span class="pre">monitoring</span> <span class="pre">mode</span></code> instead, as the memory in this
mode scales with the number of logical CPUs instead of the number of processes.</p>
</section>
<section id="advanced-topic-system-monitoring">
<h2>Advanced Topic: System Monitoring<a class="headerlink" href="#advanced-topic-system-monitoring" title="Permalink to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">system</span> <span class="pre">monitoring</span> <span class="pre">mode</span></code> gives a different view. As the name implies, the focus isn‚Äôt on processes
anymore, but the system as a whole. In particular, a trace recorded in this mode will show a timeline
for each logical CPU of the system. To enable this mode, you need to pass <code class="docutils literal notranslate"><span class="pre">-a</span></code> parameter.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>lo2s<span class="w"> </span>-a
<span class="go">^C[ lo2s (system mode): monitored processes: 0, 0.136623s CPU, 13.7872s total ]</span>
<span class="go">[ lo2s (system mode): 36 wakeups, wrote 301.39 KiB lo2s_trace_2021-11-01T09-44-31 ]</span>
</pre></div>
</div>
<p>Note: As you can read in the above example, <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> monitored zero processes even though it was run
in the <code class="docutils literal notranslate"><span class="pre">system</span> <span class="pre">monitoring</span> <span class="pre">mode</span></code>. Certainly, there are more than none processes running on a system.
However, as the user accounts on our HPC systems are limited to only see their own processes and <code class="docutils literal notranslate"><span class="pre">lo2s</span></code>
records in the scope of the user, it will only see the users own processes. Hence, in the example
above, there are no other processes running.</p>
<p>When using the <code class="docutils literal notranslate"><span class="pre">system</span> <span class="pre">monitoring</span> <span class="pre">mode</span></code> without passing a program, <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> will run indefinitely.
You can stop the measurement by sending <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> a <code class="docutils literal notranslate"><span class="pre">SIGINT</span></code> signal or hit <code class="docutils literal notranslate"><span class="pre">ctrl+C</span></code>. However, if you pass
a program, <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> will start that program and run the measurement until the started process finishes.
Of course, the process and any of its child processes and threads will be visible in the resulting trace.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>lo2s<span class="w"> </span>-a<span class="w"> </span>--<span class="w"> </span>sleep<span class="w"> </span><span class="m">10</span>
<span class="go">[ lo2s (system mode): sleep 10  (0), 1 threads, monitored processes: 1, 0.133598s CPU, 10.3996s total ]</span>
<span class="go">[ lo2s (system mode): 39 wakeups, wrote 280.39 KiB lo2s_trace_2021-11-01T09-55-04 ]</span>
</pre></div>
</div>
<p>Like in the <code class="docutils literal notranslate"><span class="pre">process</span> <span class="pre">monitoring</span> <span class="pre">mode</span></code>, <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> can also sample instructions in the system monitoring mode.
You can enable the instruction sampling by passing the parameter <code class="docutils literal notranslate"><span class="pre">--instruction-sampling</span></code> to <code class="docutils literal notranslate"><span class="pre">lo2s</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>lo2s<span class="w"> </span>-a<span class="w"> </span>--instruction-sampling<span class="w"> </span>--<span class="w"> </span>make<span class="w"> </span>-j
<span class="go">[ lo2s (system mode): make -j  (0), 268 threads, monitored processes: 286, 258.789s CPU, 445.076s total ]</span>
<span class="go">[ lo2s (system mode): 3815 wakeups, wrote 39.24 MiB lo2s_trace_2021-10-29T15-08-44 ]</span>
</pre></div>
</div>
</section>
<section id="advanced-topic-metric-plugins">
<h2>Advanced Topic: Metric Plugins<a class="headerlink" href="#advanced-topic-metric-plugins" title="Permalink to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">Lo2s</span></code> is compatible with <span class="xref myst">Score-P</span> metric plugins, but only a subset will work.
In particular, <code class="docutils literal notranslate"><span class="pre">lo2s</span></code> only supports asynchronous plugins with the per host or once scope.
You can find a large set of plugins in the <a class="reference external" href="https://github.com/score-p">Score-P Organization on GitHub</a>.</p>
<p>To activate plugins, you can use the same environment variables as with Score-P, or with <code class="docutils literal notranslate"><span class="pre">LO2S</span></code> as
prefix:</p>
<ul class="simple">
<li><p>LO2S_METRIC_PLUGINS</p></li>
<li><p>LO2S_METRIC_PLUGIN</p></li>
<li><p>LO2S_METRIC_PLUGIN_PLUGIN</p></li>
</ul>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="machine-learning">
<h1>Machine Learning<a class="headerlink" href="#machine-learning" title="Permalink to this heading">#</a></h1>
<p>This is an introduction of how to run machine learning (ML) applications on ZIH systems.
We recommend using the GPU clusters <code class="docutils literal notranslate"><span class="pre">Alpha</span></code>, <code class="docutils literal notranslate"><span class="pre">Capella</span></code>, and <code class="docutils literal notranslate"><span class="pre">Power9</span></code> for machine learning purposes.
The hardware specification of each cluster can be found in the page
<span class="xref myst">HPC Resources</span>.</p>
<section id="id50">
<h2>Modules<a class="headerlink" href="#id50" title="Permalink to this heading">#</a></h2>
<p>The way of loading modules is identical on each cluster. Here we show an example
on the cluster <code class="docutils literal notranslate"><span class="pre">Alpha</span></code> how to load the module environment:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@alpha$ </span>module<span class="w"> </span>load<span class="w"> </span>release/23.04
</pre></div>
</div>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Software and their available versions may differ among the clusters. Check the available
modules with `module spider &lt;module_name&gt;`
</pre></div>
</div>
</section>
<section id="machine-learning-via-console">
<h2>Machine Learning via Console<a class="headerlink" href="#machine-learning-via-console" title="Permalink to this heading">#</a></h2>
<section id="python-and-virtual-environments">
<h3>Python and Virtual Environments<a class="headerlink" href="#python-and-virtual-environments" title="Permalink to this heading">#</a></h3>
<p>Python users should use a <span class="xref myst">virtual environment</span> when conducting
machine learning tasks via console.</p>
<p>For more details on machine learning or data science with Python see
<span class="xref myst">data analytics with Python</span>.</p>
</section>
<section id="r">
<h3>R<a class="headerlink" href="#r" title="Permalink to this heading">#</a></h3>
<p>R also supports machine learning via console. It does not require a virtual environment due to a
different package management.</p>
<p>For more details on machine learning or data science with R see
<span class="xref myst">data analytics with R</span>.</p>
</section>
</section>
<section id="machine-learning-with-jupyter">
<h2>Machine Learning with Jupyter<a class="headerlink" href="#machine-learning-with-jupyter" title="Permalink to this heading">#</a></h2>
<p>The <a class="reference external" href="https://jupyter.org/">Jupyter Notebook</a> is an open-source web application that allows you to
create documents containing live code, equations, visualizations, and narrative text.
<span class="xref myst">JupyterHub</span> allows to work with machine learning frameworks (e.g.
TensorFlow or PyTorch) on ZIH systems and to run your Jupyter notebooks on HPC nodes.</p>
<p>After accessing JupyterHub, you can start a new session and configure it. For machine learning
purposes, select either cluster <code class="docutils literal notranslate"><span class="pre">Alpha</span></code>, <code class="docutils literal notranslate"><span class="pre">Capella</span></code> or <code class="docutils literal notranslate"><span class="pre">Power9</span></code> and the resources, your application requires.</p>
<p>In your session you can use <span class="xref myst">Python</span>,
<span class="xref myst">R</span> or <span class="xref myst">RStudio</span> for your
machine learning and data science topics.</p>
</section>
<section id="machine-learning-with-containers">
<h2>Machine Learning with Containers<a class="headerlink" href="#machine-learning-with-containers" title="Permalink to this heading">#</a></h2>
<p>Some machine learning tasks require using containers. In the HPC domain, the
<a class="reference external" href="https://singularity.hpcng.org/">Singularity</a> container system is a widely used tool. Docker
containers can also be used by Singularity. You can find further information on working with
containers on ZIH systems in our <span class="xref myst">containers documentation</span>.</p>
<p>The official source for Docker containers with TensorFlow, PyTorch and many other packages is
the <a class="reference external" href="https://hub.docker.com/r/ibmcom/powerai/">PowerAI container</a> DockerHub repository of IBM.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>You could find other versions of software in the container on the &quot;tag&quot; tab on the Docker web
page of the container.
</pre></div>
</div>
<p>In the following example, we build a Singularity container on the cluster <code class="docutils literal notranslate"><span class="pre">Power9</span></code>
with TensorFlow from the DockerHub and start it:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@power9$ </span>singularity<span class="w"> </span>build<span class="w"> </span>my-ML-container.sif<span class="w"> </span>docker://ibmcom/powerai:1.6.2-tensorflow-ubuntu18.04-py37-ppc64le<span class="w">    </span><span class="c1">#create a container from the DockerHub with TensorFlow version 1.6.2</span>
<span class="go">[...]</span>
<span class="gp">marie@power9$ </span>singularity<span class="w"> </span>run<span class="w"> </span>--nv<span class="w"> </span>my-ML-container.sif<span class="w">    </span><span class="c1">#run my-ML-container.sif container supporting the Nvidia&#39;s GPU. You can also work with your container by: singularity shell, singularity exec</span>
<span class="go">[...]</span>
</pre></div>
</div>
</section>
<section id="additional-libraries-for-machine-learning">
<h2>Additional Libraries for Machine Learning<a class="headerlink" href="#additional-libraries-for-machine-learning" title="Permalink to this heading">#</a></h2>
<p>The following NVIDIA libraries are available on all nodes:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Path</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>NCCL</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/usr/local/cuda/targets/ppc64le-linux</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>cuDNN</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/usr/local/cuda/targets/ppc64le-linux</span></code></p></td>
</tr>
</tbody>
</table>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>For optimal NCCL performance it is recommended to set the
**NCCL_MIN_NRINGS** environment variable during execution. You can try
different values but 4 should be a pretty good starting point.
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">NCCL_MIN_NRINGS</span><span class="o">=</span><span class="m">4</span>
</pre></div>
</div>
<section id="hpc-related-software">
<h3>HPC-Related Software<a class="headerlink" href="#hpc-related-software" title="Permalink to this heading">#</a></h3>
<p>The following HPC related software is installed on all nodes:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Path</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>IBM Spectrum MPI</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/opt/ibm/spectrum_mpi/</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>PGI compiler</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/opt/pgi/</span></code></p></td>
</tr>
<tr class="row-even"><td><p>IBM XLC Compiler</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/opt/ibm/xlC/</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>IBM XLF Compiler</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/opt/ibm/xlf/</span></code></p></td>
</tr>
<tr class="row-even"><td><p>IBM ESSL</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/opt/ibmmath/essl/</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>IBM PESSL</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/opt/ibmmath/pessl/</span></code></p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="datasets-for-machine-learning">
<h2>Datasets for Machine Learning<a class="headerlink" href="#datasets-for-machine-learning" title="Permalink to this heading">#</a></h2>
<p>There are many different datasets designed for research purposes. If you would like to download some
of them, keep in mind that many machine learning libraries have direct access to public datasets
without downloading it, e.g. <a class="reference external" href="https://www.tensorflow.org/datasets">TensorFlow Datasets</a>. If you
still need to download some datasets use <span class="xref myst">Datamover</span> machine.</p>
<section id="the-imagenet-dataset">
<h3>The ImageNet Dataset<a class="headerlink" href="#the-imagenet-dataset" title="Permalink to this heading">#</a></h3>
<p>The ImageNet project is a large visual database designed for use in visual object recognition
software research. In order to save space in the filesystem by avoiding to have multiple duplicates
of this lying around, we have put a copy of the ImageNet database (ILSVRC2012 and ILSVR2017) under
<code class="docutils literal notranslate"><span class="pre">/data/horse/shared/imagenet</span></code> which you can use without having to download it again. For the future,
the ImageNet dataset will be available in
<span class="xref myst">Warm Archive</span>. ILSVR2017 also includes a dataset
for recognition objects from a video. Please respect the corresponding
<a class="reference external" href="https://image-net.org/download.php">Terms of Use</a>.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="mathematics-applications">
<h1>Mathematics Applications<a class="headerlink" href="#mathematics-applications" title="Permalink to this heading">#</a></h1>
<p>!!! cite ‚ÄúGalileo Galilei‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Nature is written in mathematical language.
</pre></div>
</div>
<!--*Please do not run expensive interactive sessions on the login nodes.  Instead, use* `srun --pty-->
<!--...` *to let the batch system place it on a compute node.*-->
<section id="mathematica">
<h2>Mathematica<a class="headerlink" href="#mathematica" title="Permalink to this heading">#</a></h2>
<p>Mathematica is a general computing environment, organizing many algorithmic, visualization, and user
interface capabilities within a document-like user interface paradigm.</p>
<section id="fonts">
<h3>Fonts<a class="headerlink" href="#fonts" title="Permalink to this heading">#</a></h3>
<p>To remotely use the graphical front-end, you have to add the Mathematica fonts to the local
font manager.</p>
<section id="linux-workstation">
<h4>Linux Workstation<a class="headerlink" href="#linux-workstation" title="Permalink to this heading">#</a></h4>
<p>You need to copy the fonts from ZIH systems to your local system and expand the font path</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>scp<span class="w"> </span>-r<span class="w"> </span>dataport:/software/rapids/r24.04/Mathematica/13.0.1/SystemFiles/Fonts/Type1/
<span class="go">~/.fonts</span>
<span class="gp">marie@local$ </span>xset<span class="w"> </span>fp+<span class="w"> </span>~/.fonts/Type1
</pre></div>
</div>
<p>!!! important ‚ÄúSCP command‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The previous SCP command requires that you have already set up your [SSH configuration
](../access/ssh_login.md#configuring-default-parameters-for-ssh).
</pre></div>
</div>
</section>
<section id="windows-workstation">
<h4>Windows Workstation<a class="headerlink" href="#windows-workstation" title="Permalink to this heading">#</a></h4>
<p>You have to add additional Mathematica fonts at your local PC
<span class="xref myst">download fonts archive</span>.</p>
<p>If you use <strong>Xming</strong> as X-server at your PC (refer to
<span class="xref myst">remote access from Windows</span>, follow these steps:</p>
<ol class="arabic simple">
<li><p>Create a new folder <code class="docutils literal notranslate"><span class="pre">Mathematica</span></code> in the directory <code class="docutils literal notranslate"><span class="pre">fonts</span></code> of the installation directory of Xming
(mostly: <code class="docutils literal notranslate"><span class="pre">C:\\Programme\\Xming\\fonts\\</span></code>)</p></li>
<li><p>Extract the fonts archive into this new directory <code class="docutils literal notranslate"><span class="pre">Mathematica</span></code>.  In result you should have the
two directories <code class="docutils literal notranslate"><span class="pre">DBF</span></code> and <code class="docutils literal notranslate"><span class="pre">Type1</span></code>.</p></li>
<li><p>Add the path to these font files into the file <code class="docutils literal notranslate"><span class="pre">font-dirs</span></code>.  You can find it in
<code class="docutils literal notranslate"><span class="pre">C:\\Programme\\Xming\\</span></code>.</p></li>
</ol>
<div class="highlight-shell-session notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>font-dirs
<span class="gp"># </span>comma-separated<span class="w"> </span>list<span class="w"> </span>of<span class="w"> </span>directories<span class="w"> </span>to<span class="w"> </span>add<span class="w"> </span>to<span class="w"> </span>the<span class="w"> </span>default<span class="w"> </span>font<span class="w"> </span>path
<span class="gp"># </span>defaults<span class="w"> </span>are<span class="w"> </span>built-ins,<span class="w"> </span>misc,<span class="w"> </span>TTF,<span class="w"> </span>Type1,<span class="w"> </span>75dpi,<span class="w"> </span>100dpi
<span class="gp"># </span>also<span class="w"> </span>allows<span class="w"> </span>entries<span class="w"> </span>on<span class="w"> </span>individual<span class="w"> </span>lines
<span class="go">C:\Programme\Xming\fonts\dejavu,C:\Programme\Xming\fonts\cyrillic</span>
<span class="go">C:\Programme\Xming\fonts\Mathematica\DBF</span>
<span class="go">C:\Programme\Xming\fonts\Mathematica\Type1</span>
<span class="go">C:\WINDOWS\Fonts</span>
</pre></div>
</div>
</section>
</section>
<section id="using-textual-interface-of-mathematica">
<h3>Using Textual Interface of Mathematica<a class="headerlink" href="#using-textual-interface-of-mathematica" title="Permalink to this heading">#</a></h3>
<p>Once a Mathematica module is loaded, you can use Mathematica‚Äôs textual interface via the command
<code class="docutils literal notranslate"><span class="pre">math</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>release/24.04<span class="w"> </span>Mathematica/13.0.1
<span class="go">[...]</span>
<span class="gp">marie@login$ </span>math
<span class="go">Mathematica 13.0.1 Kernel for Linux x86 (64-bit)</span>
<span class="go">Copyright 1988-2022 Wolfram Research, Inc.</span>

<span class="go">In[1]:= Sum[i, {i,1,100}]</span>
<span class="go">Out[1]= 5050</span>
<span class="go">In[2]:= Quit[];</span>
</pre></div>
</div>
</section>
<section id="mathematica-and-slurm">
<h3>Mathematica and Slurm<a class="headerlink" href="#mathematica-and-slurm" title="Permalink to this heading">#</a></h3>
<p>For running compute intensive and long calculations, please use the batch system
<span class="xref myst">Slurm</span>. To submit Mathematica jobs to the resource scheduler Slurm,
the Mathematica commands to be executed must be containined in a single <code class="docutils literal notranslate"><span class="pre">.m</span></code>-script. The <code class="docutils literal notranslate"><span class="pre">.m</span></code>-script
will then be passed to the <code class="docutils literal notranslate"><span class="pre">math</span></code> command in a job file.</p>
<p>??? example ‚Äú1. Hello-world-script for Mathematica‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The file `math_example.m` is your input script that includes the calculation statements for
Mathematica.

```
Print[&quot;Hello, World!&quot;];

(* Perform some calculations *)
x = 10;
y = 20;

sum = x + y;
product = x * y;

Print[&quot;The sum of &quot;, x, &quot; and &quot;, y, &quot; is: &quot;, sum];
Print[&quot;The product of &quot;, x, &quot; and &quot;, y, &quot; is: &quot;, product];
```
</pre></div>
</div>
<p>??? example ‚Äú2. Job file‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The file `jobfile.sh` is your jobfile with the resource specifications and the commands to
executed.

```bash
#!/bin/bash
#SBATCH --time=00:05:00
#SBATCH --ntasks=1

# prepare environment; load module
module purge
module load release/24.04 Mathematica/13.0.1

# run the math kernel; perform calculations
math -script math_example.m &gt; math.output
```
</pre></div>
</div>
<p>??? example ‚Äú3. Submit the job‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Invoke the command `sbatch jobfile.sh` to submit the job to the scheduler. The scheduler will
provide you the unqiue job id.

```
marie@login$ sbatch jobfile.sh
Submitted batch job 10705392
```

All output of the `math` command  will be saved in the file `math.output`.
</pre></div>
</div>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Mathematica licenses are limited.
</pre></div>
</div>
<p>There exist two types, <em>MathKernel</em> and <em>SubMathKernel</em> licenses. Every sequential job you start
will consume a MathKernel license of which we only have 61. We do have, however, 488 SubMathKernel
licenses, so please, don‚Äôt start many sequential jobs but try to parallelize your calculation,
utilizing multiple SubMathKernel licenses per job, in order to achieve a more reasonable license
usage.</p>
</section>
</section>
<section id="matlab">
<h2>MATLAB<a class="headerlink" href="#matlab" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://de.mathworks.com/products/matlab.html">MATLAB</a> is a numerical computing environment and
programming language. Created by The MathWorks, MATLAB allows easy matrix manipulation, plotting of
functions and data, implementation of algorithms, creation of user interfaces, and interfacing with
programs in other languages.  Although it specializes in numerical computing, an optional toolbox
interfaces with the Maple symbolic engine, allowing it to be part of a full computer algebra system.</p>
<p>Running MATLAB via the batch system could look like this (for 2 Gb RAM per core and 12 cores
reserved). Please adapt this to your needs!</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>MATLAB
<span class="gp">marie@login$ </span>srun<span class="w"> </span>--time<span class="o">=</span><span class="m">8</span>:00<span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">12</span><span class="w"> </span>--mem-per-cpu<span class="o">=</span><span class="m">2000</span><span class="w"> </span>--pty<span class="w"> </span>--x11<span class="o">=</span>first<span class="w"> </span>bash
<span class="gp">marie@compute$ </span>matlab
</pre></div>
</div>
<p>With following command you can see a list of installed software - also
the different versions of MATLAB.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>avail<span class="w"> </span>MATLAB
</pre></div>
</div>
<p>Please choose one of these, then load the chosen software with the command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@login$<span class="w"> </span>module<span class="w"> </span>load<span class="w"> </span>MATLAB/&lt;version&gt;
</pre></div>
</div>
<p>Or use:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>MATLAB
</pre></div>
</div>
<p>(then you will get the most recent MATLAB version.
<span class="xref myst">Refer to the modules page for details.</span>)</p>
<section id="interactive-matlab-gui">
<h3>Interactive MATLAB-GUI<a class="headerlink" href="#interactive-matlab-gui" title="Permalink to this heading">#</a></h3>
<p>If you have a connection with X11 forwarding enabled.</p>
<section id="interactive">
<h4>Interactive<a class="headerlink" href="#interactive" title="Permalink to this heading">#</a></h4>
<p>You should allocate a CPU for your working with command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>srun<span class="w"> </span>--time<span class="o">=</span><span class="m">01</span>:00:00<span class="w"> </span>--pty<span class="w"> </span>--x11<span class="o">=</span>first<span class="w"> </span>bash
</pre></div>
</div>
<ul class="simple">
<li><p>now you can call ‚Äúmatlab‚Äù (you have 1h to work with the MATLAB-GUI)</p></li>
</ul>
</section>
<section id="matlab-container">
<h4>MATLAB container<a class="headerlink" href="#matlab-container" title="Permalink to this heading">#</a></h4>
<p>We provide MATLAB containers that can be started as following:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>start_matlab.sh
</pre></div>
</div>
</section>
</section>
<section id="non-interactive">
<h3>Non-interactive<a class="headerlink" href="#non-interactive" title="Permalink to this heading">#</a></h3>
<p>Using Scripts</p>
<p>You have to start matlab-calculation as a Batch-Job via command</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>srun<span class="w"> </span>--pty<span class="w"> </span>matlab<span class="w"> </span>-batch<span class="w"> </span>&lt;basename_of_your_matlab_script&gt;
<span class="gp"># </span>NOTE:<span class="w"> </span>you<span class="w"> </span>must<span class="w"> </span>omit<span class="w"> </span>the<span class="w"> </span>file<span class="w"> </span>extension<span class="w"> </span><span class="s2">&quot;.m&quot;</span><span class="w"> </span>here,<span class="w"> </span>because<span class="w"> </span>-r<span class="w"> </span>expects<span class="w"> </span>a<span class="w"> </span>matlab<span class="w"> </span><span class="nb">command</span><span class="w"> </span>or<span class="w"> </span><span class="k">function</span><span class="w"> </span>call,<span class="w"> </span>not<span class="w"> </span>a<span class="w"> </span>file-name.
</pre></div>
</div>
<p>!!! info ‚ÄúLicense occupying‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>While running your calculations as a script this way is possible, it is generally frowned upon,
because you are occupying MATLAB licenses for the entire duration of your calculation when doing so.
Since the available licenses are limited, it is highly recommended you first compile your script via
the MATLAB Compiler (`mcc`) before running it for a longer period of time on our systems.  That way,
you only need to check-out a license during compile time (which is relatively short) and can run as
many instances of your calculation as you&#39;d like, since it does not need a license during runtime
when compiled to a binary.
</pre></div>
</div>
<p>You can find detailed documentation on the MATLAB compiler at
<a class="reference external" href="https://de.mathworks.com/help/compiler/">MathWorks‚Äô help pages</a>.</p>
</section>
<section id="using-the-matlab-compiler">
<h3>Using the MATLAB Compiler<a class="headerlink" href="#using-the-matlab-compiler" title="Permalink to this heading">#</a></h3>
<p>Compile your <code class="docutils literal notranslate"><span class="pre">.m</span></code> script into a binary:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@login$<span class="w"> </span>mcc<span class="w"> </span>-m<span class="w"> </span>name_of_your_matlab_script.m<span class="w"> </span>-o<span class="w"> </span>compiled_executable<span class="w"> </span>-R<span class="w"> </span>-nodisplay<span class="w"> </span>-R<span class="w"> </span>-nosplash
</pre></div>
</div>
<p>This will also generate a wrapper script called <code class="docutils literal notranslate"><span class="pre">run_compiled_executable.sh</span></code> which sets the required
library path environment variables in order to make this work. It expects the path to the MATLAB
installation as an argument, you can use the environment variable <code class="docutils literal notranslate"><span class="pre">$EBROOTMATLAB</span></code> as set by the
module file for that.</p>
<p>Then run the binary via the wrapper script in a job (just a simple example, you should be using an
<span class="xref myst">sbatch script</span> for that)</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@login$<span class="w"> </span>srun<span class="w"> </span>./run_compiled_executable.sh<span class="w"> </span><span class="si">${</span><span class="nv">EBROOTMATLAB</span><span class="si">}</span>
</pre></div>
</div>
</section>
<section id="parallel-matlab">
<h3>Parallel MATLAB<a class="headerlink" href="#parallel-matlab" title="Permalink to this heading">#</a></h3>
<section id="with-local-configuration">
<h4>With ‚Äòlocal‚Äô Configuration<a class="headerlink" href="#with-local-configuration" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>If you want to run your code in parallel, please request as many cores as you need!</p></li>
<li><p>Start a batch job with the number <code class="docutils literal notranslate"><span class="pre">N</span></code> of processes, e.g., <code class="docutils literal notranslate"><span class="pre">srun</span> <span class="pre">--cpus-per-task=4</span> <span class="pre">--pty</span> <span class="pre">--x11=first</span> <span class="pre">bash</span> <span class="pre">-l</span></code></p></li>
<li><p>Run MATLAB with the GUI or the CLI or with a script</p></li>
<li><p>Inside MATLAB use <code class="docutils literal notranslate"><span class="pre">parpool</span> <span class="pre">open</span> <span class="pre">4</span></code> to start parallel processing</p></li>
</ul>
<p>!!! example ‚ÄúExample for 1000*1000 matrix-matrix multiplication‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
R = distributed.rand(1000);
D = R * R
```
</pre></div>
</div>
<ul class="simple">
<li><p>Close parallel task using <code class="docutils literal notranslate"><span class="pre">delete(gcp('nocreate'))</span></code></p></li>
</ul>
</section>
<section id="with-parfor">
<h4>With parfor<a class="headerlink" href="#with-parfor" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Start a batch job with the number <code class="docutils literal notranslate"><span class="pre">N</span></code> of processes (,e.g., <code class="docutils literal notranslate"><span class="pre">N=12</span></code>)</p></li>
<li><p>Inside use <code class="docutils literal notranslate"><span class="pre">matlabpool</span> <span class="pre">open</span> <span class="pre">N</span></code> or <code class="docutils literal notranslate"><span class="pre">matlabpool(N)</span></code> to start parallel processing. It will use
the ‚Äòlocal‚Äô configuration by default.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">parfor</span></code> for a parallel loop, where the <strong>independent</strong> loop iterations are processed by <code class="docutils literal notranslate"><span class="pre">N</span></code>
processes</p></li>
</ul>
<p>!!! example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
parfor i = 1:3
    c(:,i) = eig(rand(1000));
end
```
</pre></div>
</div>
<p>Please refer to the documentation <code class="docutils literal notranslate"><span class="pre">help</span> <span class="pre">parfor</span></code> for further information.</p>
</section>
</section>
<section id="matlab-parallel-computing-toolbox">
<h3>MATLAB Parallel Computing Toolbox<a class="headerlink" href="#matlab-parallel-computing-toolbox" title="Permalink to this heading">#</a></h3>
<p>In the following, the steps to configure MATLAB to submit jobs to a cluster, retrieve results, and
debug errors are outlined.</p>
<section id="configuration-matlab-client-on-the-cluster">
<h4>Configuration ‚Äì MATLAB client on the cluster<a class="headerlink" href="#configuration-matlab-client-on-the-cluster" title="Permalink to this heading">#</a></h4>
<p>After logging into the HPC system, you configure MATLAB to run parallel jobs on the HPC system by
calling the shell script <code class="docutils literal notranslate"><span class="pre">configCluster.sh</span></code>.  This only needs to be called once per version of
MATLAB.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>MATLAB
<span class="gp">marie@login$ </span>configCluster.sh
</pre></div>
</div>
<p>Jobs will now default to the HPC system rather than submit to the local machine.</p>
</section>
<section id="installation-and-configuration-matlab-client-off-the-cluster">
<h4>Installation and Configuration ‚Äì MATLAB client off the cluster<a class="headerlink" href="#installation-and-configuration-matlab-client-off-the-cluster" title="Permalink to this heading">#</a></h4>
<p>The MATLAB support package for ZIH Systems can be found as follows:</p>
<ul class="simple">
<li><p>Windows:</p>
<ul>
<li><p><span class="xref myst">tud.nonshared.R2021b.zip</span></p></li>
<li><p><span class="xref myst">tud.nonshared.R2022a.zip</span></p></li>
</ul>
</li>
<li><p>Linux/Mac:</p>
<ul>
<li><p><span class="xref myst">tud.nonshared.R2021b.tar.gz</span></p></li>
<li><p><span class="xref myst">tud.nonshared.R2022a.tar.gz</span></p></li>
</ul>
</li>
</ul>
<p>Download the appropriate archive file and start MATLAB. The archive file should be extracted
in the location returned by calling</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="nb">userpath</span>
</pre></div>
</div>
<p>Configure MATLAB to run parallel jobs on ZIH Systems by calling <code class="docutils literal notranslate"><span class="pre">configCluster</span></code>. <code class="docutils literal notranslate"><span class="pre">configCluster</span></code>
only needs to be called once per version of MATLAB.</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="n">configCluster</span>
</pre></div>
</div>
<p>Submission to the remote cluster requires SSH credentials. You will be prompted for your SSH
username and password or identity file (private key). The username and location of the private key
will be stored in MATLAB for future sessions. Jobs will now default to the cluster rather than
submit to the local machine.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you would like to submit to the local machine then run the following command:

```matlab
&gt;&gt; % Get a handle to the local resources
&gt;&gt; c = parcluster(&#39;local&#39;);
```
</pre></div>
</div>
</section>
<section id="configuring-jobs">
<h4>Configuring Jobs<a class="headerlink" href="#configuring-jobs" title="Permalink to this heading">#</a></h4>
<p>Prior to submitting the job, you can specify various parameters to pass to your jobs, such as queue,
e-mail, walltime, etc. <em>Only <code class="docutils literal notranslate"><span class="pre">MemPerCpu</span></code> and <code class="docutils literal notranslate"><span class="pre">QueueName</span></code> are required</em>.</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="c">% Get a handle to the cluster</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">parcluster</span><span class="p">;</span>

<span class="go">[REQUIRED]</span>

<span class="gp">&gt;&gt; </span><span class="c">% Specify memory to use, per core (default: 2gb)</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span><span class="p">.</span><span class="n">MemPerCpu</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&#39;4gb&#39;</span><span class="p">;</span>

<span class="gp">&gt;&gt; </span><span class="c">% Specify the walltime (e.g., 5 hours)</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span><span class="p">.</span><span class="n">WallTime</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&#39;05:00:00&#39;</span><span class="p">;</span>

<span class="go">[OPTIONAL]</span>

<span class="gp">&gt;&gt; </span><span class="c">% Specify the account to use</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span><span class="p">.</span><span class="n">Account</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&#39;account-name&#39;</span><span class="p">;</span>

<span class="gp">&gt;&gt; </span><span class="c">% Request constraint</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span><span class="p">.</span><span class="n">Constraint</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&#39;a-constraint&#39;</span><span class="p">;</span>

<span class="gp">&gt;&gt; </span><span class="c">% Request job to run on exclusive node(s) (default: false)</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span><span class="p">.</span><span class="n">EnableExclusive</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>

<span class="gp">&gt;&gt; </span><span class="c">% Request email notification of job status</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span><span class="p">.</span><span class="n">EmailAddress</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&#39;user-id@tu-dresden.de&#39;</span><span class="p">;</span>

<span class="gp">&gt;&gt; </span><span class="c">% Specify number of GPUs to use (GpuType is optional)</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span><span class="p">.</span><span class="n">GpusPerNode</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span><span class="p">.</span><span class="n">GpuType</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&#39;gpu-card&#39;</span><span class="p">;</span>

<span class="gp">&gt;&gt; </span><span class="c">% Specify the queue to use</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span><span class="p">.</span><span class="n">Partition</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&#39;queue-name&#39;</span><span class="p">;</span>

<span class="gp">&gt;&gt; </span><span class="c">% Specify a reservation to use</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span><span class="p">.</span><span class="n">Reservation</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&#39;a-reservation&#39;</span><span class="p">;</span>
</pre></div>
</div>
<p>Save changes after modifying <code class="docutils literal notranslate"><span class="pre">AdditionalProperties</span></code> for the above changes to persist between MATLAB
sessions.</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="n">c</span><span class="p">.</span><span class="n">saveProfile</span>
</pre></div>
</div>
<p>To see the values of the current configuration options, display <code class="docutils literal notranslate"><span class="pre">AdditionalProperties</span></code>.</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="c">% To view current properties</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span>
</pre></div>
</div>
<p>You can unset a value when no longer needed.</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="c">% Turn off email notifications</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="p">.</span><span class="n">AdditionalProperties</span><span class="p">.</span><span class="n">EmailAddress</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&#39;&#39;</span><span class="p">;</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="p">.</span><span class="n">saveProfile</span>
</pre></div>
</div>
</section>
<section id="interactive-jobs-matlab-client-on-the-cluster">
<h4>Interactive Jobs - MATLAB Client on the Cluster<a class="headerlink" href="#interactive-jobs-matlab-client-on-the-cluster" title="Permalink to this heading">#</a></h4>
<p>To run an interactive pool job on the ZIH systems, continue to use <code class="docutils literal notranslate"><span class="pre">parpool</span></code> as you‚Äôve done before.</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="c">% Get a handle to the cluster</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">parcluster</span><span class="p">;</span>

<span class="gp">&gt;&gt; </span><span class="c">% Open a pool of 64 workers on the cluster</span>
<span class="gp">&gt;&gt; </span><span class="n">pool</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">c</span><span class="p">.</span><span class="n">parpool</span><span class="p">(</span><span class="mi">64</span><span class="p">);</span>
</pre></div>
</div>
<p>Rather than running local on your machine, the pool can now run across multiple nodes on the
cluster.</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="c">% Run a parfor over 1000 iterations</span>
<span class="gp">&gt;&gt; </span><span class="k">parfor</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="mi">1000</span>
<span class="go">      a(idx) = ‚Ä¶</span>
<span class="go">   end</span>
</pre></div>
</div>
<p>Once you are done with the pool, delete it.</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="c">% Delete the pool</span>
<span class="gp">&gt;&gt; </span><span class="n">pool</span><span class="p">.</span><span class="n">delete</span>
</pre></div>
</div>
</section>
<section id="independent-batch-job">
<h4>Independent Batch Job<a class="headerlink" href="#independent-batch-job" title="Permalink to this heading">#</a></h4>
<p>Use the batch command to submit asynchronous jobs to the HPC system. The <code class="docutils literal notranslate"><span class="pre">batch</span></code> command will return
a job object which is used to access the output of the submitted job. See the MATLAB documentation
for more help on <code class="docutils literal notranslate"><span class="pre">batch</span></code>.</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="c">% Get a handle to the cluster</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">parcluster</span><span class="p">;</span>

<span class="gp">&gt;&gt; </span><span class="c">% Submit job to query where MATLAB is running on the cluster</span>
<span class="gp">&gt;&gt; </span><span class="n">job</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">c</span><span class="p">.</span><span class="n">batch</span><span class="p">(@</span><span class="nb">pwd</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="p">{},</span><span class="w">  </span><span class="k">...</span>
<span class="gp">   </span><span class="w">    </span><span class="s">&#39;CurrentFolder&#39;</span><span class="p">,</span><span class="s">&#39;.&#39;</span><span class="p">,</span><span class="w"> </span><span class="s">&#39;AutoAddClientPath&#39;</span><span class="p">,</span><span class="nb">false</span><span class="p">);</span>

<span class="gp">&gt;&gt; </span><span class="c">% Query job for state</span>
<span class="gp">&gt;&gt; </span><span class="n">job</span><span class="p">.</span><span class="n">State</span>

<span class="gp">&gt;&gt; </span><span class="c">% If state is finished, fetch the results</span>
<span class="gp">&gt;&gt; </span><span class="n">job</span><span class="p">.</span><span class="n">fetchOutputs</span><span class="p">{:}</span>

<span class="gp">&gt;&gt; </span><span class="c">% Delete the job after results are no longer needed</span>
<span class="gp">&gt;&gt; </span><span class="n">job</span><span class="p">.</span><span class="n">delete</span>
</pre></div>
</div>
<p>To retrieve a list of currently running or completed jobs, call <code class="docutils literal notranslate"><span class="pre">parcluster</span></code> to retrieve the cluster
object. The cluster object stores an array of jobs that were run, are running, or are queued to
run. This allows us to fetch the results of completed jobs. Retrieve and view the list of jobs as
shown below.</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="n">c</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">parcluster</span><span class="p">;</span>
<span class="gp">&gt;&gt; </span><span class="n">jobs</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">c</span><span class="p">.</span><span class="n">Jobs</span><span class="p">;</span>
</pre></div>
</div>
<p>Once you have identified the job you want, you can retrieve the results as done previously.</p>
<p><code class="docutils literal notranslate"><span class="pre">fetchOutputs</span></code> is used to retrieve function output arguments; if calling <code class="docutils literal notranslate"><span class="pre">batch</span></code> with a script, use
<code class="docutils literal notranslate"><span class="pre">load</span></code> instead. Data that has been written to files on the cluster needs be retrieved directly
from the filesystem (e.g. via ftp). To view results of a previously completed job:</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="c">% Get a handle to the job with ID 2</span>
<span class="gp">&gt;&gt; </span><span class="n">job2</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">c</span><span class="p">.</span><span class="n">Jobs</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span>
</pre></div>
</div>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>You can view a list of your jobs, as well as their IDs, using the above `c.Jobs` command.

```matlabsession
&gt;&gt; % Fetch results for job with ID 2
&gt;&gt; job2.fetchOutputs{:}
```
</pre></div>
</div>
</section>
<section id="parallel-batch-job">
<h4>Parallel Batch Job<a class="headerlink" href="#parallel-batch-job" title="Permalink to this heading">#</a></h4>
<p>You can also submit parallel workflows with the <code class="docutils literal notranslate"><span class="pre">batch</span></code> command. Let‚Äôs use the following example
for a parallel job, which is saved as <code class="docutils literal notranslate"><span class="pre">parallel_example.m</span></code>.</p>
<div class="highlight-matlab notranslate"><div class="highlight"><pre><span></span><span class="k">function</span><span class="w"> </span><span class="nf">[t, A] = parallel_example</span><span class="p">(</span>iter<span class="p">)</span>

<span class="k">if</span><span class="w"> </span><span class="nb">nargin</span><span class="o">==</span><span class="mi">0</span>
<span class="w">    </span><span class="n">iter</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="mi">8</span><span class="p">;</span>
<span class="k">end</span>

<span class="nb">disp</span><span class="p">(</span><span class="s">&#39;Start sim&#39;</span><span class="p">)</span>

<span class="n">t0</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="nb">tic</span><span class="p">;</span>
<span class="k">parfor</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="n">iter</span>
<span class="w">    </span><span class="n">A</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">idx</span><span class="p">;</span>
<span class="w">    </span><span class="nb">pause</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="w">    </span><span class="n">idx</span>
<span class="k">end</span>
<span class="n">t</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="nb">toc</span><span class="p">(</span><span class="n">t0</span><span class="p">);</span>

<span class="nb">disp</span><span class="p">(</span><span class="s">&#39;Sim completed&#39;</span><span class="p">)</span>

<span class="nb">save</span><span class="w"> </span><span class="n">RESULTS</span><span class="w"> </span><span class="n">A</span>

<span class="k">end</span>
</pre></div>
</div>
<p>This time when you use the <code class="docutils literal notranslate"><span class="pre">batch</span></code> command, to run a parallel job, you will also specify a MATLAB
Pool.</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="c">% Get a handle to the cluster</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">parcluster</span><span class="p">;</span>

<span class="gp">&gt;&gt; </span><span class="c">% Submit a batch pool job using 4 workers for 16 simulations</span>
<span class="gp">&gt;&gt; </span><span class="n">job</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">c</span><span class="p">.</span><span class="n">batch</span><span class="p">(@</span><span class="n">parallel_example</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="mi">16</span><span class="p">},</span><span class="w"> </span><span class="s">&#39;Pool&#39;</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="k">...</span>
<span class="gp">   </span><span class="w">    </span><span class="s">&#39;CurrentFolder&#39;</span><span class="p">,</span><span class="s">&#39;.&#39;</span><span class="p">,</span><span class="w"> </span><span class="s">&#39;AutoAddClientPath&#39;</span><span class="p">,</span><span class="nb">false</span><span class="p">);</span>

<span class="gp">&gt;&gt; </span><span class="c">% View current job status</span>
<span class="gp">&gt;&gt; </span><span class="n">job</span><span class="p">.</span><span class="n">State</span>

<span class="gp">&gt;&gt; </span><span class="c">% Fetch the results after a finished state is retrieved</span>
<span class="gp">&gt;&gt; </span><span class="n">job</span><span class="p">.</span><span class="n">fetchOutputs</span><span class="p">{:}</span>
<span class="go">ans =</span>
<span class="go">  8.8872</span>
</pre></div>
</div>
<p>The job ran in 8.89 seconds using four workers. Note that these jobs will always request N+1 CPU
cores, since one worker is required to manage the batch job and pool of workers. For example, a
job that needs eight workers will consume nine CPU cores.</p>
<p>You might run the same simulation but increase the Pool size. This time, to retrieve the results later,
you will keep track of the job ID.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>For some applications, there will be a diminishing return when allocating too many workers, as
the overhead may exceed computation time.

```matlabsession
&gt;&gt; % Get a handle to the cluster
&gt;&gt; c = parcluster;

&gt;&gt; % Submit a batch pool job using 8 workers for 16 simulations
&gt;&gt; job = c.batch(@parallel_example, 1, {16}, &#39;Pool&#39;, 8, ...
       &#39;CurrentFolder&#39;,&#39;.&#39;, &#39;AutoAddClientPath&#39;,false);

&gt;&gt; % Get the job ID
&gt;&gt; id = job.ID
id =
  4
&gt;&gt; % Clear job from workspace (as though you quit MATLAB)
&gt;&gt; clear job
```
</pre></div>
</div>
<p>Once you have a handle to the cluster, you can call the <code class="docutils literal notranslate"><span class="pre">findJob</span></code> method to search for the job with
the specified job ID.</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="c">% Get a handle to the cluster</span>
<span class="gp">&gt;&gt; </span><span class="n">c</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">parcluster</span><span class="p">;</span>

<span class="gp">&gt;&gt; </span><span class="c">% Find the old job</span>
<span class="gp">&gt;&gt; </span><span class="n">job</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">c</span><span class="p">.</span><span class="n">findJob</span><span class="p">(</span><span class="s">&#39;ID&#39;</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">);</span>

<span class="gp">&gt;&gt; </span><span class="c">% Retrieve the state of the job</span>
<span class="gp">&gt;&gt; </span><span class="n">job</span><span class="p">.</span><span class="n">State</span>
<span class="go">ans =</span>
<span class="go">  finished</span>
<span class="gp">&gt;&gt; </span><span class="c">% Fetch the results</span>
<span class="gp">&gt;&gt; </span><span class="n">job</span><span class="p">.</span><span class="n">fetchOutputs</span><span class="p">{:};</span>
<span class="go">ans =</span>
<span class="go">  4.7270</span>
</pre></div>
</div>
<p>The job now runs in 4.73 seconds using eight workers. Run code with different number of workers to
determine the ideal number to use. Alternatively, to retrieve job results via a graphical user
interface, use the Job Monitor (Parallel &gt; Monitor Jobs).</p>
<p><img alt="Job monitor" src="63_chat_with_docs/misc/matlab_monitor_jobs.png" />
{: summary=‚ÄùRetrieve job results via GUI using the Job Monitor.‚Äù align=‚Äùcenter‚Äù}</p>
</section>
<section id="id51">
<h4>Debugging<a class="headerlink" href="#id51" title="Permalink to this heading">#</a></h4>
<p>If a serial job produces an error, call the <code class="docutils literal notranslate"><span class="pre">getDebugLog</span></code> method to view the error log file.  When
submitting independent jobs, with multiple tasks, specify the task number.</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="n">c</span><span class="p">.</span><span class="n">getDebugLog</span><span class="p">(</span><span class="n">job</span><span class="p">.</span><span class="n">Tasks</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
<p>For Pool jobs, only specify the job object.</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="n">c</span><span class="p">.</span><span class="n">getDebugLog</span><span class="p">(</span><span class="n">job</span><span class="p">)</span>
</pre></div>
</div>
<p>When troubleshooting a job, the cluster admin may request the scheduler ID of the job.  This can be
derived by calling <code class="docutils literal notranslate"><span class="pre">schedID</span></code>.</p>
<div class="highlight-matlabsession notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt; </span><span class="n">schedID</span><span class="p">(</span><span class="n">job</span><span class="p">)</span>
<span class="go">ans =</span>
<span class="go">  25539</span>
</pre></div>
</div>
</section>
<section id="further-reading">
<h4>Further Reading<a class="headerlink" href="#further-reading" title="Permalink to this heading">#</a></h4>
<p>To learn more about the MATLAB Parallel Computing Toolbox, check out these resources:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.mathworks.com/help/parallel-computing/examples.html">Parallel Computing Coding
Examples</a></p></li>
<li><p><a class="reference external" href="http://www.mathworks.com/help/distcomp/index.html">Parallel Computing Documentation</a></p></li>
<li><p><a class="reference external" href="http://www.mathworks.com/products/parallel-computing/index.html">Parallel Computing Overview</a></p></li>
<li><p><a class="reference external" href="http://www.mathworks.com/products/parallel-computing/tutorials.html">Parallel Computing
Tutorials</a></p></li>
<li><p><a class="reference external" href="http://www.mathworks.com/products/parallel-computing/videos.html">Parallel Computing Videos</a></p></li>
<li><p><a class="reference external" href="http://www.mathworks.com/products/parallel-computing/webinars.html">Parallel Computing Webinars</a></p></li>
<li><p><a class="reference external" href="https://event.zih.tu-dresden.de/nhr/matlab/module1/materials">MATLAB NHR Tutorial Slides: Parallel Computing with MATLAB</a></p></li>
<li><p><a class="reference external" href="https://event.zih.tu-dresden.de/nhr/matlab/module2/materials">MATLAB NHR Tutorial Slides: Machine Learning with MATLAB</a></p></li>
<li><p><a class="reference external" href="https://event.zih.tu-dresden.de/nhr/matlab/module3/materials">MATLAB NHR Tutorial Slides: Deep Learning with MATLAB</a></p></li>
<li><p><a class="reference external" href="https://event.zih.tu-dresden.de/nhr/matlab/module4/materials">MATLAB NHR Tutorial Slides: Interoperability of MATLAB and Python</a></p></li>
</ul>
</section>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="mathematics-libraries">
<h1>Mathematics Libraries<a class="headerlink" href="#mathematics-libraries" title="Permalink to this heading">#</a></h1>
<p>Many software heavily relies on math libraries, e.g., for linear algebra or FFTW calculations.
Writing portable and fast math functions is a really challenging task. You can try it for fun, but you
really should avoid writing you own matrix-matrix multiplication. Thankfully, there are several
high quality math libraries available at ZIH systems.</p>
<p>In the following, a few often-used interfaces/specifications and libraries are described. All
libraries are available as <span class="xref myst">modules</span>.</p>
<section id="blas-lapack-and-scalapack">
<h2>BLAS, LAPACK and ScaLAPACK<a class="headerlink" href="#blas-lapack-and-scalapack" title="Permalink to this heading">#</a></h2>
<p>Over the last decades, the three de-facto standard specifications BLAS, LAPACK and ScaLAPACK for
basic linear algebra routines have been emerged.</p>
<p>The <a class="reference external" href="https://www.netlib.org/blas/">BLAS</a> (Basic Linear Algebra Subprograms) specification contains routines
for common linear algebra operations such as vector addition, matrix-vector multiplication, and dot
product. BLAS routines can be understood as basic building blocks for advanced numerical algorithms.</p>
<p>The <a class="reference external" href="https://www.netlib.org/lapack/">Linear Algebra PACKage</a> (LAPACK) provides more
sophisticated numerical algorithms, such as solving linear systems of equations, matrix
factorization, and eigenvalue problems.</p>
<!--With [libFlame](#amd-optimizing-cpu-libraries-aocl) and [MKL](#math-kernel-library-mkl) there are-->
<!--two highly optimised LAPACK implementations aiming for AMD and Intel architecture, respectively.-->
<p>The <a class="reference external" href="https://www.netlib.org/scalapack">Scalable Linear Algebra PACKage</a> (ScaLAPACK) takes the
idea of high-performance linear algebra routines to parallel distributed memory machines. It offers
functionality to solve dense and banded linear systems, least squares problems, eigenvalue
problems, and singular value problems.</p>
<!--There is also an [optimized implementation](https://developer.amd.com/amd-aocl/scalapack/) addressing-->
<!--AMD architectures.-->
<p>Many concrete implementations, often tuned and optimized for specific hardware architectures, have
been developed over the last decades. The two hardware vendors Intel and AMD each offer their own math
library - <span class="xref myst">Intel MKL</span> and <span class="xref myst">AOCL</span>.
Both libraries are worth to consider from a users point of view, since they provide extensive math
functionality ranging from BLAS and LAPACK to random number generators and Fast Fourier
Transformation with consistent interfaces and the ‚Äúpromises‚Äù to be highly tuned and optimized and
continuously developed further.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.netlib.org/blas/">BLAS reference implementation</a> in Fortran</p></li>
<li><p><a class="reference external" href="https://www.netlib.org/lapack/">LAPACK reference implementation</a></p></li>
<li><p><a class="reference external" href="https://www.netlib.org/scalapack/">ScaLAPACK reference implementation</a></p></li>
<li><p><a class="reference external" href="http://www.openblas.net">OpenBlas</a></p></li>
<li><p>For GPU implementations, refer to the <span class="xref myst">GPU section</span></p></li>
</ul>
</section>
<section id="amd-optimizing-cpu-libraries-aocl">
<h2>AMD Optimizing CPU Libraries (AOCL)<a class="headerlink" href="#amd-optimizing-cpu-libraries-aocl" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://developer.amd.com/amd-aocl/">AMD Optimizing CPU Libraries</a> (AOCL) is a set of numerical
libraries tuned specifically for AMD EPYC processor family. AOCL offers linear algebra libraries
(<a class="reference external" href="https://developer.amd.com/amd-cpu-libraries/blas-library/">BLIS</a>,
<a class="reference external" href="https://developer.amd.com/amd-cpu-libraries/blas-library/#libflame">libFLAME</a>,
<a class="reference external" href="https://developer.amd.com/amd-aocl/scalapack/">ScaLAPACK</a>,
<a class="reference external" href="https://developer.amd.com/amd-aocl/aocl-sparse/">AOCL-Sparse</a>,
<a class="reference external" href="https://developer.amd.com/amd-aocl/fftw/">FFTW routines</a>,
<a class="reference external" href="https://developer.amd.com/amd-cpu-libraries/amd-math-library-libm/">AMD Math Library (LibM)</a>,
as well as
<a class="reference external" href="https://developer.amd.com/amd-cpu-libraries/rng-library/">AMD Random Number Generator Library</a>
and
<a class="reference external" href="https://developer.amd.com/amd-cpu-libraries/rng-library/#securerng">AMD Secure RNG Library</a>.</p>
</section>
<section id="math-kernel-library-mkl">
<h2>Math Kernel Library (MKL)<a class="headerlink" href="#math-kernel-library-mkl" title="Permalink to this heading">#</a></h2>
<p>The
<a class="reference external" href="https://software.intel.com/content/www/us/en/develop/documentation/get-started-with-mkl-for-dpcpp/top.html">Intel Math Kernel Library</a>
(Intel MKL) provides extensively threaded math routines which are highly optimized for Intel CPUs.
It contains routines for linear algebra, direct and iterative sparse solvers, random number
generators and Fast Fourier Transformation (FFT).</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>MKL comes in an OpenMP-parallel version. If you want to use it, make sure you know how
to place your jobs. [^1]
[^1]: In \[c&#39;t 18, 2010\], Andreas Stiller proposes the usage of
`GOMP_CPU_AFFINITY` to allow the mapping of AMD cores. KMP_AFFINITY works only for Intel processors.
</pre></div>
</div>
<p>The available MKL modules can be queried as follows</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>avail<span class="w"> </span>imkl
</pre></div>
</div>
<section id="linking">
<h3>Linking<a class="headerlink" href="#linking" title="Permalink to this heading">#</a></h3>
<p>For linker flag combinations, we highly recommend the
<a class="reference external" href="http://software.intel.com/en-us/articles/intel-mkl-link-line-advisor/">MKL Link Line Advisor</a>
(please make sure that JavaScript is enabled for this page).</p>
</section>
</section>
<section id="libraries-for-gpus">
<h2>Libraries for GPUs<a class="headerlink" href="#libraries-for-gpus" title="Permalink to this heading">#</a></h2>
<p>GPU implementations of math functions and routines are often much faster compared to CPU
implementations. This also holds for basic routines from BLAS and LAPACK. You should consider using
GPU implementations in order to obtain better performance.</p>
<p>There are several math libraries for Nvidia GPUs, e.g.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html">cuBLAS</a></p></li>
<li><p><a class="reference external" href="https://developer.nvidia.com/cusolver">cuSOLVER</a> (reduced set of LAPACK routines)</p></li>
<li><p><a class="reference external" href="https://developer.nvidia.com/cusparse">cuSPARSE</a> (sparse matrix library)</p></li>
<li><p><a class="reference external" href="https://developer.nvidia.com/cufft">cuFFT</a></p></li>
</ul>
<p>Nvidia provides a
<a class="reference external" href="https://developer.nvidia.com/gpu-accelerated-libraries#linear-algebra">comprehensive overview and starting point</a>.</p>
<section id="magma">
<h3>MAGMA<a class="headerlink" href="#magma" title="Permalink to this heading">#</a></h3>
<p>The project <a class="reference external" href="http://icl.cs.utk.edu/magma/">Matrix Algebra on GPU and Multicore Architectures</a> (MAGMA)
aims to develop a dense linear algebra library similar to LAPACK but for heterogeneous/hybrid
architectures, starting with current ‚ÄúMulticore+GPU‚Äù systems. <code class="docutils literal notranslate"><span class="pre">MAGMA</span></code> is available at ZIH systems in
different versions. You can list the available modules using</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>spider<span class="w"> </span>magma
<span class="go">[...]</span>
<span class="go">        magma/2.5.4-fosscuda-2019b</span>
<span class="go">        magma/2.5.4</span>
</pre></div>
</div>
</section>
</section>
<section id="fftw">
<h2>FFTW<a class="headerlink" href="#fftw" title="Permalink to this heading">#</a></h2>
<p>FFTW is a C subroutine library for computing the discrete Fourier transform (DFT) in one or more
dimensions, of arbitrary input size, and of both real and complex data (as well as of even/odd data,
i.e. the discrete cosine/sine transforms or DCT/DST). Before using this library, please check out
the functions of vendor-specific libraries such as <span class="xref myst">AOCL</span>
or <span class="xref myst">Intel MKL</span></p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="environment-modules">
<h1>Environment Modules<a class="headerlink" href="#environment-modules" title="Permalink to this heading">#</a></h1>
<p>Usage of software on HPC systems is managed by a <strong>modules system</strong>.</p>
<p>!!! note ‚ÄúModule‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>A module is a user interface that provides utilities for the dynamic modification of a user&#39;s
environment, e.g. prepending paths to

* `PATH`
* `LD_LIBRARY_PATH`
* `MANPATH`
* and more

to help you to access compilers, loader, libraries and utilities.

By using modules, you can smoothly switch between different versions of
installed software packages and libraries.
</pre></div>
</div>
<section id="module-commands">
<h2>Module Commands<a class="headerlink" href="#module-commands" title="Permalink to this heading">#</a></h2>
<p>Using modules is quite straightforward and the following table lists the basic commands.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Command</p></th>
<th class="head text-left"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">help</span></code></p></td>
<td class="text-left"><p>Show all module options</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">list</span></code></p></td>
<td class="text-left"><p>List active modules in the user environment</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">purge</span></code></p></td>
<td class="text-left"><p>Remove modules from the user environment</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">avail</span> <span class="pre">[modname]</span></code></p></td>
<td class="text-left"><p>List all available modules</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">spider</span> <span class="pre">[modname]</span></code></p></td>
<td class="text-left"><p>Search for modules across all environments</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">load</span> <span class="pre">&lt;modname&gt;</span></code></p></td>
<td class="text-left"><p>Load module <code class="docutils literal notranslate"><span class="pre">modname</span></code> in the user environment</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">unload</span> <span class="pre">&lt;modname&gt;</span></code></p></td>
<td class="text-left"><p>Remove module <code class="docutils literal notranslate"><span class="pre">modname</span></code> from the user environment</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">switch</span> <span class="pre">&lt;mod1&gt;</span> <span class="pre">&lt;mod2&gt;</span></code></p></td>
<td class="text-left"><p>Replace module <code class="docutils literal notranslate"><span class="pre">mod1</span></code> with module <code class="docutils literal notranslate"><span class="pre">mod2</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">show</span> <span class="pre">&lt;modname&gt;</span></code></p></td>
<td class="text-left"><p>Show the commands in the module file</p></td>
</tr>
</tbody>
</table>
<p>Module files are ordered by their topic on ZIH systems. By default, with <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">avail</span></code> you will
see all topics and their available module files. If you just wish to see the installed versions of a
certain module, you can use <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">avail</span> <span class="pre">softwarename</span></code> and it will display the available versions of
<code class="docutils literal notranslate"><span class="pre">softwarename</span></code> only.</p>
<section id="examples">
<h3>Examples<a class="headerlink" href="#examples" title="Permalink to this heading">#</a></h3>
<p>???+ example ‚ÄúSearching for software‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The process of searching for a particular software you want to use on an HPC system consits of
two steps: Login to the target HPC system and invoke `module spider` command to search for the
software and list available versions.

For example, if you want to search for available MATLAB versions on `Barnard`, the steps might
be:

```console
marie@login.barnard$ module spider matlab

---------------------------------------------------------------------------------------------------------------------------------------------------------
  MATLAB: MATLAB/2022b
---------------------------------------------------------------------------------------------------------------------------------------------------------
Description:
  MATLAB is a high-level language and interactive environment that enables you to perform computationally intensive tasks faster than with
  traditional programming languages such as C, C++, and Fortran.


You will need to load all module(s) on any one of the lines below before the &quot;MATLAB/2022b&quot; module is available to load.

  release/23.04
  release/23.10
  [...]
```

As you can see, `MATLAB` in version `2022b` is available on Barnard within the releases `23.04`
and`23.10`. Additionally, the output provides the information how to load it:

```console
marie@login.barnard$ module load release/23.10 MATLAB/2022b
Module MATLAB/2022b and 1 dependency loaded.
```
</pre></div>
</div>
<p>???+ example ‚ÄúFinding available software‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>This examples illustrates the usage of the command `module avail` to search for available MATLAB
installations.

```console
marie@compute$ module avail matlab

------------------------------ /sw/modules/scs5/math ------------------------------
   MATLAB/2017a    MATLAB/2018b    MATLAB/2020a
   MATLAB/2018a    MATLAB/2019b    MATLAB/2021a (D)

  Wo:
   D:  Standard Modul.

Verwenden Sie &quot;module spider&quot; um alle verf√ºgbaren Module anzuzeigen.
Verwenden Sie &quot;module keyword key1 key2 ...&quot;, um alle verf√ºgbaren Module
anzuzeigen, die mindestens eines der Schl√ºsselworte enth√§lt.
```
</pre></div>
</div>
<p>???+ example ‚ÄúLoading and removing modules‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>A particular module or several modules are loaded into your environment using the `module load`
command. The counter part to remove a module or several modules is `module unload`.

```console
marie@compute$ module load Python/3.8.6
Module Python/3.8.6-GCCcore-10.2.0 and 11 dependencies loaded.
```
</pre></div>
</div>
<p>???+ example ‚ÄúRemoving all modules‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>To remove all loaded modules from your environment with one keystroke, invoke

```console
marie@compute$ module purge
Die folgenden Module wurden nicht entladen:
  (Benutzen Sie &quot;module --force purge&quot; um alle Module zu entladen):

  1) release/23.04
Module Python/3.8.6-GCCcore-10.2.0 and 11 dependencies unloaded.
```
</pre></div>
</div>
<p>???+ example ‚ÄúShow the command in module file‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The option `show &lt;modname&gt;` will output the commands in the module file. Using this command,
you can find out what paths are prepended and what environment variables are set.

```console
marie@login$ module show GCCcore
---------------------------------------------------------------------------------------------------------------------------------------------------------
</pre></div>
</div>
<p>/sw/modules/scs5/compiler/GCCcore/11.2.0.lua:
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
help([[
Description
===========
The GNU Compiler Collection includes front ends for C, C++, Objective-C, Fortran, Java, and Ada,
as well as libraries for these languages (libstdc++, libgcj,‚Ä¶).</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>[...]
conflict(&quot;GCCcore&quot;)
prepend_path(&quot;CMAKE_LIBRARY_PATH&quot;,&quot;/sw/installed/GCCcore/11.2.0/lib64&quot;)
prepend_path(&quot;CMAKE_PREFIX_PATH&quot;,&quot;/sw/installed/GCCcore/11.2.0&quot;)
prepend_path(&quot;LD_LIBRARY_PATH&quot;,&quot;/sw/installed/GCCcore/11.2.0/lib64&quot;)
prepend_path(&quot;MANPATH&quot;,&quot;/sw/installed/GCCcore/11.2.0/share/man&quot;)
prepend_path(&quot;PATH&quot;,&quot;/sw/installed/GCCcore/11.2.0/bin&quot;)
prepend_path(&quot;XDG_DATA_DIRS&quot;,&quot;/sw/installed/GCCcore/11.2.0/share&quot;)
setenv(&quot;EBROOTGCCCORE&quot;,&quot;/sw/installed/GCCcore/11.2.0&quot;)
setenv(&quot;EBVERSIONGCCCORE&quot;,&quot;11.2.0&quot;)
setenv(&quot;EBDEVELGCCCORE&quot;,&quot;/sw/installed/GCCcore/11.2.0/easybuild/GCCcore-11.2.0-easybuild-devel&quot;)
```
</pre></div>
</div>
</section>
<section id="front-end-ml">
<h3>Front-End ml<a class="headerlink" href="#front-end-ml" title="Permalink to this heading">#</a></h3>
<p>There is a front end for the module command, which helps you to type less. It is <code class="docutils literal notranslate"><span class="pre">ml</span></code>.
Any module command can be given after <code class="docutils literal notranslate"><span class="pre">ml</span></code>:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>ml Command</p></th>
<th class="head text-left"><p>module Command</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">ml</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">list</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">ml</span> <span class="pre">foo</span> <span class="pre">bar</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">load</span> <span class="pre">foo</span> <span class="pre">bar</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">ml</span> <span class="pre">-foo</span> <span class="pre">-bar</span> <span class="pre">baz</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">unload</span> <span class="pre">foo</span> <span class="pre">bar;</span> <span class="pre">module</span> <span class="pre">load</span> <span class="pre">baz</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">ml</span> <span class="pre">purge</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">purge</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">ml</span> <span class="pre">show</span> <span class="pre">foo</span></code></p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">show</span> <span class="pre">foo</span></code></p></td>
</tr>
</tbody>
</table>
<p>???+ example ‚ÄúUsage of front-end ml‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@compute$ ml +Python/3.8.6
Module Python/3.8.6-GCCcore-10.2.0 and 11 dependencies loaded.
marie@compute$ ml

Derzeit geladene Module:
  1) release/23.04                (S)   5) bzip2/1.0.8-GCCcore-10.2.0       9) SQLite/3.33.0-GCCcore-10.2.0  13) Python/3.8.6-GCCcore-10.2.0
  2) GCCcore/10.2.0                     6) ncurses/6.2-GCCcore-10.2.0      10) XZ/5.2.5-GCCcore-10.2.0
  3) zlib/1.2.11-GCCcore-10.2.0         7) libreadline/8.0-GCCcore-10.2.0  11) GMP/6.2.0-GCCcore-10.2.0
  4) binutils/2.35-GCCcore-10.2.0       8) Tcl/8.6.10-GCCcore-10.2.0       12) libffi/3.3-GCCcore-10.2.0

  Wo:
   S:  Das Modul ist angeheftet. Verwenden Sie &quot;--force&quot;, um das Modul zu entladen.

marie@compute$ ml -Python/3.8.6 +ANSYS/2020R2
Module Python/3.8.6-GCCcore-10.2.0 and 11 dependencies unloaded.
Module ANSYS/2020R2 loaded.
```
</pre></div>
</div>
</section>
</section>
<section id="module-environments">
<h2>Module Environments<a class="headerlink" href="#module-environments" title="Permalink to this heading">#</a></h2>
<p>On ZIH systems, there exist different <strong>module environments</strong>, each containing a set of software
modules.
They are activated via the meta module <code class="docutils literal notranslate"><span class="pre">release</span></code> which has different versions,
one of which is loaded by default.
You can switch between them by simply loading the desired version, e.g.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>load<span class="w"> </span>release/23.10
</pre></div>
</div>
<section id="searching-for-software">
<h3>Searching for Software<a class="headerlink" href="#searching-for-software" title="Permalink to this heading">#</a></h3>
<p>The command <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">spider</span> <span class="pre">&lt;modname&gt;</span></code> allows searching for a specific software across all module
environments.
It will also display information on how to load a particular module when giving a
precise module (with version) as the parameter.</p>
<p>??? example ‚ÄúSpider command‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ module spider p7zip

----------------------------------------------------------------------------------------------------------------------------------------------------------
  p7zip:
----------------------------------------------------------------------------------------------------------------------------------------------------------
    Beschreibung:
      p7zip is a quick port of 7z.exe and 7za.exe (command line version of 7zip) for Unix. 7-Zip is a file archiver with highest compression ratio.

     Versionen:
        p7zip/9.38.1
        p7zip/17.03-GCCcore-10.2.0
        p7zip/17.03

----------------------------------------------------------------------------------------------------------------------------------------------------------
  Um detaillierte Informationen √ºber ein bestimmtes &quot;p7zip&quot;-Modul zu erhalten (auch wie das Modul zu laden ist), verwenden sie den vollst√§ndigen Namen des Moduls.
  Zum Beispiel:
    $ module spider p7zip/17.03
----------------------------------------------------------------------------------------------------------------------------------------------------------
```
</pre></div>
</div>
<p>In some cases a desired software is available as an extension of a module.</p>
<p>??? example ‚ÄúExtension module‚Äù
```console  hl_lines=‚Äù9‚Äù
marie&#64;login$ module spider tensorboard</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>--------------------------------------------------------------------------------------------------------------------------------
tensorboard:
--------------------------------------------------------------------------------------------------------------------------------
Versions:
    tensorboard/2.4.1 (E)

Names marked by a trailing (E) are extensions provided by another module.
[...]
```

You retrieve further information using the `spider` command.

```console
marie@login$  module spider tensorboard/2.4.1

--------------------------------------------------------------------------------------------------------------------------------
tensorboard: tensorboard/2.4.1 (E)
--------------------------------------------------------------------------------------------------------------------------------
This extension is provided by the following modules. To access the extension you must load one of the following modules. Note that any module names in parentheses show the module location in the software hierarchy.

    TensorFlow/2.4.1 (release/23.04 GCC/10.2.0 CUDA/11.1.1 OpenMPI/4.0.5)

Names marked by a trailing (E) are extensions provided by another module.
```

Finaly, you can load the dependencies and `tensorboard/2.4.1` and check the version.

```console
marie@login$ module load release/23.04  GCC/11.3.0  OpenMPI/4.1.4

Modules GCC/10.2.0, CUDA/11.1.1, OpenMPI/4.0.5 and 15 dependencies loaded.
marie@login$ module load TensorFlow/2.11.0-CUDA-11.7.0

Aktiviere Module:
  1) CUDA/11.7.0     2) GDRCopy/2.3

Module TensorFlow/2.11.0-CUDA-11.7.0 and 39 dependencies loaded.

marie@login$ tensorboard --version
2.11.1
```
</pre></div>
</div>
</section>
</section>
<section id="toolchains">
<h2>Toolchains<a class="headerlink" href="#toolchains" title="Permalink to this heading">#</a></h2>
<p>A program or library may break in various ways (e.g. not starting, crashing or producing wrong
results) when it is used with a software of a different version than it <a class="reference external" href="http://expects.So">expects.So</a> each module
specifies the exact other modules it depends on. They get loaded automatically when the dependent
module is loaded.</p>
<p>Loading a single module is easy as there can‚Äôt be any conflicts between dependencies. However when
loading multiple modules they can require different versions of the same software. This conflict is
currently handled in that loading the same software with a different version automatically unloads
the earlier loaded module.  As the dependents of that module are <strong>not</strong> automatically unloaded this
means they now have a wrong dependency (version) which can be a problem (see above).</p>
<p>To avoid this there are (versioned) toolchains and for each toolchain there is (usually) at most
one version of each software.
A ‚Äútoolchain‚Äù is a set of modules used to build the software for other modules.
The most common one is the <code class="docutils literal notranslate"><span class="pre">foss</span></code>-toolchain consisting of <code class="docutils literal notranslate"><span class="pre">GCC</span></code>, <code class="docutils literal notranslate"><span class="pre">OpenMPI</span></code>, <code class="docutils literal notranslate"><span class="pre">OpenBLAS</span></code> &amp; <code class="docutils literal notranslate"><span class="pre">FFTW</span></code>.</p>
<p>This toolchain can be broken down into a sub-toolchain called <code class="docutils literal notranslate"><span class="pre">gompi</span></code> consisting of only
<code class="docutils literal notranslate"><span class="pre">GCC</span></code> &amp; <code class="docutils literal notranslate"><span class="pre">OpenMPI</span></code>, or further to <code class="docutils literal notranslate"><span class="pre">GCC</span></code> (the compiler and linker)
and even further to <code class="docutils literal notranslate"><span class="pre">GCCcore</span></code> which is only the runtime libraries required to run programs built
with the GCC standard library.</p>
<p>!!! hint</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>As toolchains are regular modules you can display their parts via `module show foss/2019a`.
</pre></div>
</div>
<p>This way the toolchains form a hierarchy and adding more modules makes them ‚Äúhigher‚Äù than another.</p>
<p>Examples:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Toolchain</p></th>
<th class="head"><p>Components</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">foss</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GCC</span></code> <code class="docutils literal notranslate"><span class="pre">OpenMPI</span></code> <code class="docutils literal notranslate"><span class="pre">OpenBLAS</span></code> <code class="docutils literal notranslate"><span class="pre">FFTW</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">gompi</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GCC</span></code> <code class="docutils literal notranslate"><span class="pre">OpenMPI</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">GCC</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GCCcore</span></code> <code class="docutils literal notranslate"><span class="pre">binutils</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">GCCcore</span></code></p></td>
<td><p>none</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">intel</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">intel-compilers</span></code> <code class="docutils literal notranslate"><span class="pre">impi</span></code> <code class="docutils literal notranslate"><span class="pre">imkl</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">iimpi</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">intel-compilers</span></code> <code class="docutils literal notranslate"><span class="pre">impi</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">intel-compilers</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GCCcore</span></code> <code class="docutils literal notranslate"><span class="pre">binutils</span></code></p></td>
</tr>
</tbody>
</table>
<p>As you can see <code class="docutils literal notranslate"><span class="pre">GCC</span></code> and <code class="docutils literal notranslate"><span class="pre">intel-compilers</span></code> are on the same level, as are <code class="docutils literal notranslate"><span class="pre">gompi</span></code> and <code class="docutils literal notranslate"><span class="pre">iimpi</span></code>,
although they are one level higher than the former.</p>
<p>You can load and use modules from a lower toolchain with modules from
one of its parent toolchains.
For example <code class="docutils literal notranslate"><span class="pre">Python/3.6.6-foss-2019a</span></code> can be used with <code class="docutils literal notranslate"><span class="pre">Boost/1.70.0-gompi-2019a</span></code>.</p>
<p>But you cannot combine toolchains or toolchain versions.
So <code class="docutils literal notranslate"><span class="pre">QuantumESPRESSO/6.5-intel-2019a</span></code> and <code class="docutils literal notranslate"><span class="pre">OpenFOAM/8-foss-2020a</span></code>
are both incompatible with <code class="docutils literal notranslate"><span class="pre">Python/3.6.6-foss-2019a</span></code>.
However <code class="docutils literal notranslate"><span class="pre">LLVM/7.0.1-GCCcore-8.2.0</span></code> can be used with either
<code class="docutils literal notranslate"><span class="pre">QuantumESPRESSO/6.5-intel-2019a</span></code> or <code class="docutils literal notranslate"><span class="pre">Python/3.6.6-foss-2019a</span></code>
because <code class="docutils literal notranslate"><span class="pre">GCCcore-8.2.0</span></code> is a sub-toolchain of <code class="docutils literal notranslate"><span class="pre">intel-2019a</span></code> and <code class="docutils literal notranslate"><span class="pre">foss-2019a</span></code>.</p>
<p>With the hierarchical module scheme we use at ZIH modules from other toolchains cannot be directly
loaded and don‚Äôt show up in <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">av</span></code> which avoids loading incompatible modules.
So the concept if this hierarchical toolchains is already built into this module environment.</p>
<p>!!! info</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The toolchains usually have a year and letter as their version corresponding to their release.
So `2019a` and `2020b` refer to the first half of 2019 and the 2nd half of 2020 respectively.
</pre></div>
</div>
</section>
<section id="per-architecture-builds">
<h2>Per-Architecture Builds<a class="headerlink" href="#per-architecture-builds" title="Permalink to this heading">#</a></h2>
<p>Since we have a heterogeneous cluster, we do individual builds of the software for each
architecture present.
This ensures that, no matter what partition/cluster the software runs on, a build
optimized for the host architecture is used automatically.</p>
<p>However, not every module will be available on all clusters.
Use <code class="docutils literal notranslate"><span class="pre">ml</span> <span class="pre">av</span></code> or <code class="docutils literal notranslate"><span class="pre">ml</span> <span class="pre">spider</span></code> to search for modules available on the sub-cluster you are on.</p>
</section>
<section id="advanced-usage">
<h2>Advanced Usage<a class="headerlink" href="#advanced-usage" title="Permalink to this heading">#</a></h2>
<p>For writing your own module files please have a look at the
<span class="xref myst">Guide for writing project and private module files</span>.</p>
</section>
<section id="id52">
<h2>Troubleshooting<a class="headerlink" href="#id52" title="Permalink to this heading">#</a></h2>
<section id="when-i-log-in-the-wrong-modules-are-loaded-by-default">
<h3>When I log in, the wrong modules are loaded by default<a class="headerlink" href="#when-i-log-in-the-wrong-modules-are-loaded-by-default" title="Permalink to this heading">#</a></h3>
<p>Reset your currently loaded modules with <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">purge</span></code>.
Then run <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">save</span></code> to overwrite the
list of modules you load by default when logging in.</p>
</section>
<section id="i-can-t-load-module-tensorflow">
<h3>I can‚Äôt load module TensorFlow<a class="headerlink" href="#i-can-t-load-module-tensorflow" title="Permalink to this heading">#</a></h3>
<p>Check the dependencies by e.g. calling <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">spider</span> <span class="pre">TensorFlow/2.4.1</span></code>
it will list a number of modules that need to be loaded
before the TensorFlow module can be loaded.</p>
<p>??? example ‚ÄúLoading the dependencies‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@compute$ module load TensorFlow/2.4.1
Lmod hat den folgenden Fehler erkannt:  Diese Module existieren, aber
k√∂nnen nicht wie gew√ºnscht geladen werden: &quot;TensorFlow/2.4.1&quot;
   Versuchen Sie: &quot;module spider TensorFlow/2.4.1&quot; um anzuzeigen, wie die Module
geladen werden.


marie@compute$ module spider TensorFlow/2.4.1

----------------------------------------------------------------------------------
  TensorFlow: TensorFlow/2.4.1
----------------------------------------------------------------------------------
    Beschreibung:
      An open-source software library for Machine Intelligence


    Sie m√ºssen alle Module in einer der nachfolgenden Zeilen laden bevor Sie das Modul &quot;TensorFlow/2.4.1&quot; laden k√∂nnen.

      release/23.04  GCC/10.2.0  CUDA/11.1.1  OpenMPI/4.0.5
     This extension is provided by the following modules. To access the extension you must load one of the following modules. Note that any module names in parentheses show the module location in the software hierarchy.


       TensorFlow/2.4.1 (release/23.04 GCC/10.2.0 CUDA/11.1.1 OpenMPI/4.0.5)


    This module provides the following extensions:

       absl-py/0.10.0 (E), astunparse/1.6.3 (E), cachetools/4.2.0 (E), dill/0.3.3 (E), gast/0.3.3 (E), google-auth-oauthlib/0.4.2 (E), google-auth/1.24.0 (E), google-pasta/0.2.0 (E), grpcio/1.32.0 (E), gviz-api/1.9.0 (E), h5py/2.10.0 (E), Keras-Preprocessing/1.1.2 (E), Markdown/3.3.3 (E), oauthlib/3.1.0 (E), opt-einsum/3.3.0 (E), portpicker/1.3.1 (E), pyasn1-modules/0.2.8 (E), requests-oauthlib/1.3.0 (E), rsa/4.7 (E), tblib/1.7.0 (E), tensorboard-plugin-profile/2.4.0 (E), tensorboard-plugin-wit/1.8.0 (E), tensorboard/2.4.1 (E), tensorflow-estimator/2.4.0 (E), TensorFlow/2.4.1 (E), termcolor/1.1.0 (E), Werkzeug/1.0.1 (E), wrapt/1.12.1 (E)

    Help:
      Description
      ===========
      An open-source software library for Machine Intelligence


      More information
      ================
       - Homepage: https://www.tensorflow.org/


      Included extensions
      ===================
      absl-py-0.10.0, astunparse-1.6.3, cachetools-4.2.0, dill-0.3.3, gast-0.3.3,
      google-auth-1.24.0, google-auth-oauthlib-0.4.2, google-pasta-0.2.0,
      grpcio-1.32.0, gviz-api-1.9.0, h5py-2.10.0, Keras-Preprocessing-1.1.2,
      Markdown-3.3.3, oauthlib-3.1.0, opt-einsum-3.3.0, portpicker-1.3.1,
      pyasn1-modules-0.2.8, requests-oauthlib-1.3.0, rsa-4.7, tblib-1.7.0,
      tensorboard-2.4.1, tensorboard-plugin-profile-2.4.0, tensorboard-plugin-
      wit-1.8.0, TensorFlow-2.4.1, tensorflow-estimator-2.4.0, termcolor-1.1.0,
      Werkzeug-1.0.1, wrapt-1.12.1


Names marked by a trailing (E) are extensions provided by another module.



marie@compute$ ml +GCC/10.2.0  +CUDA/11.1.1 +OpenMPI/4.0.5 +TensorFlow/2.4.1

Die folgenden Module wurden in einer anderen Version erneut geladen:
  1) GCC/7.3.0-2.30 =&gt; GCC/10.2.0        3) binutils/2.30-GCCcore-7.3.0 =&gt; binutils/2.35
  2) GCCcore/7.3.0 =&gt; GCCcore/10.2.0

Module GCCcore/7.3.0, binutils/2.30-GCCcore-7.3.0, GCC/7.3.0-2.30, GCC/7.3.0-2.30 and 3 dependencies unloaded.
Module GCCcore/7.3.0, GCC/7.3.0-2.30, GCC/10.2.0, CUDA/11.1.1, OpenMPI/4.0.5, TensorFlow/2.4.1 and 50 dependencies loaded.
marie@compute$ module list

Derzeit geladene Module:
  1) release/23.04              (S)  28) Tcl/8.6.10
  2) GCCcore/10.2.0                  29) SQLite/3.33.0
  3) zlib/1.2.11                     30) GMP/6.2.0
  4) binutils/2.35                   31) libffi/3.3
  5) GCC/10.2.0                      32) Python/3.8.6
  6) CUDAcore/11.1.1                 33) pybind11/2.6.0
  7) CUDA/11.1.1                     34) SciPy-bundle/2020.11
  8) numactl/2.0.13                  35) Szip/2.1.1
  9) XZ/5.2.5                        36) HDF5/1.10.7
 10) libxml2/2.9.10                  37) cURL/7.72.0
 11) libpciaccess/0.16               38) double-conversion/3.1.5
 12) hwloc/2.2.0                     39) flatbuffers/1.12.0
 13) libevent/2.1.12                 40) giflib/5.2.1
 14) Check/0.15.2                    41) ICU/67.1
 15) GDRCopy/2.1-CUDA-11.1.1         42) JsonCpp/1.9.4
 16) UCX/1.9.0-CUDA-11.1.1           43) NASM/2.15.05
 17) libfabric/1.11.0                44) libjpeg-turbo/2.0.5
 18) PMIx/3.1.5                      45) LMDB/0.9.24
 19) OpenMPI/4.0.5                   46) nsync/1.24.0
 20) OpenBLAS/0.3.12                 47) PCRE/8.44
 21) FFTW/3.3.8                      48) protobuf/3.14.0
 22) ScaLAPACK/2.1.0                 49) protobuf-python/3.14.0
 23) cuDNN/8.0.4.30-CUDA-11.1.1      50) flatbuffers-python/1.12
 24) NCCL/2.8.3-CUDA-11.1.1          51) typing-extensions/3.7.4.3
 25) bzip2/1.0.8                     52) libpng/1.6.37
 26) ncurses/6.2                     53) snappy/1.1.8
 27) libreadline/8.0                 54) TensorFlow/2.4.1

  Wo:
   S:  Das Modul ist angeheftet. Verwenden Sie &quot;--force&quot;, um das Modul zu entladen.
```
</pre></div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="check-mpi-correctness-with-must">
<h1>Check MPI Correctness with MUST<a class="headerlink" href="#check-mpi-correctness-with-must" title="Permalink to this heading">#</a></h1>
<p>MPI as the de-facto standard for parallel applications of the message passing paradigm offers
more than one hundred different API calls with complex restrictions. As a result, developing
applications with this interface is error prone and often time consuming. Some usage errors of MPI
may only manifest on some platforms or some application runs, which further complicates the
detection of these errors. Thus, special debugging tools for MPI applications exist that
automatically check whether an application conforms to the MPI standard and whether its MPI calls
are safe. At ZIH, we maintain and support <strong>MUST</strong> for this task, though different types of these
tools exist (see last section).</p>
<section id="must">
<h2>MUST<a class="headerlink" href="#must" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://itc.rwth-aachen.de/must/">MUST</a> checks if your application conforms to the MPI
standard and will issue warnings if there are errors or non-portable constructs. You can apply MUST
without modifying your source code, though we suggest to add the debugging flag <code class="docutils literal notranslate"><span class="pre">-g</span></code> during
compilation.</p>
<p>See also <span class="xref myst">MUST Introduction Slides</span> for a starting point.</p>
<section id="setup-and-modules">
<h3>Setup and Modules<a class="headerlink" href="#setup-and-modules" title="Permalink to this heading">#</a></h3>
<p>You need to load a module file in order to use MUST. Each MUST installation uses a specific
combination of a compiler and an MPI library, make sure to use a combination that fits your needs.
Right now we provide two combinations, <span class="xref myst">contact us</span> if you need further
combinations. You can query for the available modules with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>avail<span class="w"> </span>must
<span class="go">   MUST/1.6.0-rc3-intel-2018a    MUST/1.7.2-intel-2020a (D)</span>
</pre></div>
</div>
<p>You can load a MUST module as follows:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>MUST
<span class="go">Module MUST/1.7.2-intel-2020a and 16 dependencies loaded.</span>
</pre></div>
</div>
<p>Besides loading a MUST module, no further changes are needed during compilation and linking.</p>
</section>
<section id="running-your-application-with-must">
<h3>Running your Application with MUST<a class="headerlink" href="#running-your-application-with-must" title="Permalink to this heading">#</a></h3>
<p>In order to launch your application with MUST you need to replace the <code class="docutils literal notranslate"><span class="pre">srun</span></code> command with
<code class="docutils literal notranslate"><span class="pre">mustrun</span> <span class="pre">--must:mpiexec</span> <span class="pre">srun</span> <span class="pre">--must:np</span> <span class="pre">--ntasks</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>mustrun<span class="w"> </span>--must:mpiexec<span class="w"> </span>srun<span class="w"> </span>--must:np<span class="w"> </span>--ntasks<span class="w"> </span>--ntasks<span class="w"> </span>&lt;number<span class="w"> </span>of<span class="w"> </span>MPI<span class="w"> </span>processes&gt;<span class="w"> </span>./&lt;your<span class="w"> </span>binary&gt;
</pre></div>
</div>
<p>Besides replacing the <code class="docutils literal notranslate"><span class="pre">srun</span></code> command you need to be aware that <strong>MUST always allocates an extra
process</strong>, i.e. if you issue a
<code class="docutils literal notranslate"><span class="pre">mustrun</span> <span class="pre">--must:mpiexec</span> <span class="pre">srun</span> <span class="pre">--must:np</span> <span class="pre">--ntasks</span> <span class="pre">--ntasks</span> <span class="pre">4</span> <span class="pre">./&lt;your</span> <span class="pre">binary&gt;</span></code> then
MUST will start <strong>5 processes</strong> instead. This is usually not critical. However, in interactive and
batch jobs <strong>make sure to allocate an extra CPU for this task</strong>.</p>
<p>Suppose your application is called <code class="docutils literal notranslate"><span class="pre">fancy-program</span></code> and is normally run with 4 processes.
The MUST workflow should then be</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>MUST

<span class="gp"># </span>Compile<span class="w"> </span>your<span class="w"> </span>application<span class="w"> </span>with<span class="w"> </span>the<span class="w"> </span>debugging<span class="w"> </span>flag<span class="w"> </span><span class="s2">&quot;-g&quot;</span><span class="w"> </span>on<span class="w"> </span>the<span class="w"> </span>correct<span class="w"> </span>architecture,<span class="w"> </span>e.g.:
<span class="gp">marie@login$ </span>srun<span class="w"> </span>--ntasks<span class="w"> </span><span class="m">1</span><span class="w"> </span>--partition<span class="w"> </span>&lt;partition&gt;<span class="w"> </span>mpicc<span class="w"> </span>-g<span class="w"> </span>-o<span class="w"> </span>fancy-program<span class="w"> </span>fancy-program.c

<span class="gp"># </span>Allocate<span class="w"> </span>interactive<span class="w"> </span>session<span class="w"> </span>with<span class="w"> </span><span class="m">1</span><span class="w"> </span>extra<span class="w"> </span>process<span class="w"> </span><span class="k">for</span><span class="w"> </span>MUST
<span class="gp">marie@login$ </span>salloc<span class="w"> </span>--ntasks<span class="w"> </span><span class="m">5</span><span class="w"> </span>--partition<span class="w"> </span>&lt;partition&gt;

<span class="gp">marie@login$ </span>mustrun<span class="w"> </span>--must:mpiexec<span class="w"> </span>srun<span class="w"> </span>--must:np<span class="w"> </span>--ntasks<span class="w"> </span>--must:stacktrace<span class="w"> </span>backward<span class="w"> </span>--ntasks<span class="w"> </span><span class="m">4</span><span class="w"> </span>./fancy-program
<span class="go">[MUST] MUST configuration ... centralized checks with fall-back application crash handling (very slow)</span>
<span class="go">[MUST] Weaver ... success</span>
<span class="go">[MUST] Code generation ... success</span>
<span class="go">[MUST] Build file generation ... success</span>
<span class="go">[MUST] Configuring intermediate build ... success</span>
<span class="go">[MUST] Building intermediate sources ... success</span>
<span class="go">[MUST] Installing intermediate modules ... success</span>
<span class="go">[MUST] Generating P^nMPI configuration ... success</span>
<span class="go">[MUST] Search for linked P^nMPI ... not found ... using LD_PRELOAD to load P^nMPI ... success</span>
<span class="go">[MUST] Executing application:</span>
<span class="go">{...}</span>
<span class="go">[MUST] Execution finished, inspect &quot;/home/marie/MUST_Output.html&quot;!</span>
</pre></div>
</div>
<p>??? hint ‚ÄúTwice <code class="docutils literal notranslate"><span class="pre">--ntasks</span></code>‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>You might wonder about the two `--ntasks` arguments in the above outlined `mustrun` comannd.
Mustrun is able to use invoke another command instead of mpiexec. For ZIH systems, this will be
`srun` (`--must-mpiexec: srun`). Now, you need to specify what argument of the MPI run arguments
holds the number of application processes. For Slurm, it is `--ntasks &lt;N&gt;`. Thus, you need to
specify `--must:np --ntasks --ntasks &lt;N&gt;`.
</pre></div>
</div>
<p>With the additional flag <code class="docutils literal notranslate"><span class="pre">--must:stacktrace</span> <span class="pre">backward</span></code> you can produce an additional stacktrace
with line number of the error location which allows to pinpoint the error location in your code.
This might slow down code execution slightly.</p>
<p>Finally, MUST assumes that your application may crash at any time. To still gather correctness
results under this assumption is extremely expensive in terms of performance overheads. Thus, if
your application does not crash, you should add <code class="docutils literal notranslate"><span class="pre">--must:nocrash</span></code> to the <code class="docutils literal notranslate"><span class="pre">mustrun</span></code> command to make
MUST aware of this knowledge. Overhead is drastically reduced with this switch.
Further details on alternative launch modes are described in the MUST documentation.</p>
</section>
<section id="result-files">
<h3>Result Files<a class="headerlink" href="#result-files" title="Permalink to this heading">#</a></h3>
<p>After running your application with MUST you will have its output in the working directory of your
application. The output is named <code class="docutils literal notranslate"><span class="pre">MUST_Output.html</span></code>. Open this files in a browser to analyze the
results. The HTML file is color coded:</p>
<ul class="simple">
<li><p>Entries in green represent notes and useful information</p></li>
<li><p>Entries in yellow represent warnings</p></li>
<li><p>Entries in red represent errors</p></li>
</ul>
</section>
<section id="example-usage-of-must">
<h3>Example Usage of MUST<a class="headerlink" href="#example-usage-of-must" title="Permalink to this heading">#</a></h3>
<p>In this section, we provide a detailed example explaining the usage of MUST. The example is taken
from the <a class="reference external" href="https://hpc.rwth-aachen.de/must/files/Documentation-1.7.2.pdf">MUST documentation v1.7.2</a>.</p>
<p>??? example ‚Äúexample.c‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>This C programm contains three MPI usage errors. Save it as `example.c`.

```
#include &lt;stdio.h&gt;
#include &lt;mpi.h&gt;

int main (int argc , char ** argv) {
  int rank ,
      size ,
      sBuf [ 2 ] = { 1 , 2 } ,
      rBuf [ 2 ] ;
  MPI_Status status ;
  MPI_Datatype newType ;

  MPI_Init(&amp;argc ,&amp;argv ) ;
  MPI_Comm_rank (MPI_COMM_WORLD, &amp;rank ) ;
  MPI_Comm_size (MPI_COMM_WORLD, &amp;size ) ;

   // Enough tasks?
  if ( size &lt; 2 ) {
    printf(&quot;This test needs at least 2 processes ! \n&quot;);
    MPI_Finalize();
    return 1 ;
  }

  // Say hello
  printf(&quot;Hello, I am rank %d of %d processes. \n&quot;, rank , size);

  //) Create a datatype
  MPI_Type_contiguous( 2, MPI_INT, &amp;newType);
  MPI_Type_commit(&amp;newType);

  // 2) Use MPI Sendrecv to perform a ring communication
  MPI_Sendrecv(sBuf, 1, newType, (rank+1)%size, 123,
               rBuf, sizeof(int)*2, MPI_BYTE, (rank=1+size) %size, 123 , MPI_COMM_WORLD, &amp;status ) ;

  // 3) Use MPI Send and MPI Recv to perform a ring communication
  MPI_Send(sBuf, 1, newType, (rank+1)%size, 456, MPI_COMM_WORLD);
  MPI_Recv(rBuf, sizeof(int)*2, MPI_BYTE, (rank=1+size)%size, 456, MPI_COMM_WORLD, &amp;status);

  // Say bye bye
  printf(&quot;Signing off, rank %d. \n&quot; , rank);

  MPI_Finalize();
  return 0 ;
}
/*EOF*/
```
</pre></div>
</div>
<p>??? example ‚ÄúCompile and execute‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The first step is to prepare the environment by loading a MUST module.

```console
marie@login$ module purge
marie@login$ module load MUST
Module MUST/1.7.2-intel-2020a and 16 dependencies loaded.
```

Now, you compile the `example.c` program using the MPI compiler wrapper. The compiled binary is
called `example`.

```console
marie@login$ mpicc example.c -g -o example
```

Finally, you execute the example application on the compute nodes. As you can see, the following
command line will submit a job to the batch system.

```
marie@login $ mustrun --must:mpiexec srun --must:np --ntasks --ntasks 4 --time 00:10:00 example
[MUST] MUST configuration ... centralized checks with fall-back application crash handling (very slow)
[MUST] Information: overwritting old intermediate data in directory &quot;/scratch/ws/0/marie-must/must_temp&quot;!
[MUST] Using prebuilt infrastructure at /sw/installed/MUST/1.7.2-intel-2020a/modules/mode1-layer2
[MUST] Weaver ... success
[MUST] Generating P^nMPI configuration ... success
[MUST] Search for linked P^nMPI ... not found ... using LD_PRELOAD to load P^nMPI ... success
[MUST] Executing application:
srun: job 32765491 queued and waiting for resources
srun: job 32778008 has been allocated resources
Hello , I am rank 2 of 4 processes.
Hello , I am rank 3 of 4 processes.
Hello , I am rank 0 of 4 processes.
Hello , I am rank 1 of 4 processes.
============MUST===============
ERROR: MUST detected a deadlock, detailed information is available in the MUST output file. You should either investigate details with a debugger or abort, the operation of MUST will stop from now.
===============================
```
</pre></div>
</div>
<p>??? example ‚ÄúAnalysis of MUST output files and MPI usage errors‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>MUST produces an `MUST_Output.html` file and a directory `MUST_Output-files` with additional
html files. Copy the files to your local host, e.g.

```console
marie@local$ scp -r dataport1.hpc.tu-dresden.de:/data/horse/ws/marie-must/{MUST_Output-files,MUST_Output.html}
```

and open the file `MUST_Output.html` using a webbrowser. Alternativly, you can open the html file with a
`firefox` instance on the HPC sytems. This requires to [forward the X11 support via SSH](../access/ssh_login.md#x11-forwarding).

MUST detects all three MPI usage errors within this example:

* A type mismatch
* A send-send deadlock
* A leaked datatype

The type mismatch is reported as follows:

![MUST error](misc/must-error-01.png)
{: align=&quot;center&quot; summary=&quot;Type mismatch error report from MUST.&quot;}

MUST also offers a detailed page for the type mismatch error.

![MUST error](misc/must-error-02.png)
{: summary=&quot;Retrieve job results via GUI using the Job Monitor.&quot; align=&quot;center&quot;}

In order not to exceed the scope of this example, we do not explain the MPI usage errors in more
details. Please, feel free to deep-dive into the error description provided in the official
[MUST documentation v1.7.2](https://hpc.rwth-aachen.de/must/files/Documentation-1.7.2.pdf) (Sec.
4).
</pre></div>
</div>
</section>
</section>
<section id="further-mpi-correctness-tools">
<h2>Further MPI Correctness Tools<a class="headerlink" href="#further-mpi-correctness-tools" title="Permalink to this heading">#</a></h2>
<p>Besides MUST, there exist further MPI correctness tools, these are:</p>
<ul class="simple">
<li><p>Marmot (predecessor of MUST)</p></li>
<li><p>MPI checking library of the Intel Trace Collector</p></li>
<li><p>ISP (From Utah)</p></li>
<li><p>Umpire (predecessor of MUST)</p></li>
</ul>
<p>ISP provides a more thorough deadlock detection as it investigates alternative execution paths,
however its overhead is drastically higher as a result. Contact our support if you have a specific
use cases that needs one of these tools.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="nanoscale-simulations">
<h1>Nanoscale Simulations<a class="headerlink" href="#nanoscale-simulations" title="Permalink to this heading">#</a></h1>
<section id="abinit">
<h2>ABINIT<a class="headerlink" href="#abinit" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="http://www.abinit.org">ABINIT</a> is a package whose main program allows one to find the total energy,
charge density and electronic structure of systems made of electrons and nuclei (molecules and
periodic solids) within Density Functional Theory (DFT), using pseudopotentials and a planewave
basis. ABINIT also includes options to optimize the geometry according to the DFT forces and
stresses, or to perform molecular dynamics simulations using these forces, or to generate dynamical
matrices, Born effective charges, and dielectric tensors. Excited states can be computed within the
Time-Dependent Density Functional Theory (for molecules), or within Many-Body Perturbation Theory
(the GW approximation).</p>
<p>ABINIT is available as <span class="xref myst">modules</span>. Installed versions can be listed and loaded with the
following commands</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>avail<span class="w"> </span>ABINIT
<span class="go">---------------------------- /sw/modules/scs5/chem -----------------------------</span>
<span class="go">   ABINIT/8.6.3-intel-2018a         Wannier90/2.0.1.1-foss-2018b-abinit</span>
<span class="go">   ABINIT/8.10.3-intel-2018b        Wannier90/2.0.1.1-intel-2018b-abinit</span>
<span class="go">   ABINIT/9.2.1-intel-2020a  (D)</span>
<span class="go">[...]</span>
<span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>ABINIT
<span class="go">Module ABINIT/9.2.1-intel-2020a and 16 dependencies loaded.</span>
</pre></div>
</div>
</section>
<section id="cp2k">
<h2>CP2K<a class="headerlink" href="#cp2k" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="http://cp2k.berlios.de/">CP2K</a> performs atomistic and molecular simulations of solid state, liquid,
molecular and biological systems. It provides a general framework for different methods such as e.g.
density functional theory (DFT) using a mixed Gaussian and plane waves approach (GPW), and classical
pair and many-body potentials.</p>
<p>CP2K is available as <span class="xref myst">modules</span>. Available packages can be listed and loaded with the
following commands:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>avail<span class="w"> </span>CP2K
<span class="go">---------------------------- /sw/modules/scs5/chem -----------------------------</span>
<span class="go">   CP2K/5.1-intel-2018a          CP2K/6.1-intel-2018a-spglib</span>
<span class="go">   CP2K/6.1-foss-2019a-spglib    CP2K/6.1-intel-2018a        (D)</span>
<span class="go">   CP2K/6.1-foss-2019a</span>
<span class="go">[...]</span>
<span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>CP2K
<span class="go">Module CP2K/6.1-intel-2018a and 25 dependencies loaded.</span>
</pre></div>
</div>
</section>
<section id="cpmd">
<h2>CPMD<a class="headerlink" href="#cpmd" title="Permalink to this heading">#</a></h2>
<p>The CPMD code is a plane wave/pseudopotential implementation of Density Functional Theory,
particularly designed for ab-initio molecular dynamics. For examples and documentations, see
<a class="reference external" href="https://www.lcrc.anl.gov/for-users/software/available-software/cpmd/">CPMD homepage</a>.</p>
<p>CPMD is currently not installed as a module.
Please, contact <a class="reference external" href="mailto:hpc-support&#37;&#52;&#48;tu-dresden&#46;de">hpc-support<span>&#64;</span>tu-dresden<span>&#46;</span>de</a> if you need assistance.</p>
</section>
<section id="gamess">
<h2>GAMESS<a class="headerlink" href="#gamess" title="Permalink to this heading">#</a></h2>
<p>GAMESS is an ab-initio quantum mechanics program, which provides many methods for computation of the
properties of molecular systems using standard quantum chemical methods. For a detailed description,
please look at the <a class="reference external" href="https://www.msg.chem.iastate.edu/gamess/index.html">GAMESS home page</a>.</p>
<p>GAMESS is available as <span class="xref myst">modules</span> within the classic environment. Available packages can
be listed and loaded with the following commands:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$</span>:~&gt;<span class="w"> </span>module<span class="w"> </span>avail<span class="w"> </span>gamess
<span class="go">----------------------- /sw/modules/taurus/applications ------------------------</span>
<span class="go">   gamess/2013</span>
<span class="go">[...]</span>
<span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>gamess
<span class="go">Start gamess like this:</span>
<span class="go"> rungms.slurm &lt;inputfile&gt; [scratch_path]</span>
<span class="go">Module gamess/2013 and 2 dependencies loaded.</span>
</pre></div>
</div>
<p>For runs with <span class="xref myst">Slurm</span>, please use a script like this:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --time=120</span>
<span class="c1">#SBATCH --ntasks=8</span>
<span class="c1">#SBATCH --ntasks-per-node=2</span>
<span class="c1">## you have to make sure that an even number of tasks runs on each node !!</span>
<span class="c1">#SBATCH --mem-per-cpu=1900</span>

module<span class="w"> </span>load<span class="w"> </span>gamess
rungms.slurm<span class="w"> </span>cTT_M_025.inp<span class="w"> </span>/data/horse/ws/marie-gamess
<span class="c1">#                          the third parameter is the location of your horse directory</span>
</pre></div>
</div>
<p><em>GAMESS should be cited as:</em> ‚ÄúGeneral Atomic and Molecular Electronic Structure System‚Äù,
M.W.Schmidt, K.K.Baldridge, J.A.Boatz, S.T.Elbert, M.S.Gordon, J.H.Jensen, S.Koseki, N.Matsunaga,
K.A.Nguyen, <a class="reference external" href="http://S.J.Su">S.J.Su</a>, T.L.Windus, M.Dupuis, J.A.Montgomery, J.Comput.Chem. 14, 1347-1363(1993).</p>
</section>
<section id="gaussian">
<h2>Gaussian<a class="headerlink" href="#gaussian" title="Permalink to this heading">#</a></h2>
<p>Starting from the basic laws of quantum mechanics, <a class="reference external" href="http://www.gaussian.com">Gaussian</a> predicts the
energies, molecular structures, and vibrational frequencies of molecular systems, along with
numerous molecular properties derived from these basic computation types. It can be used to study
molecules and reactions under a wide range of conditions, including both stable species and
compounds which are difficult or impossible to observe experimentally such as short-lived
intermediates and transition structures.</p>
<p>Access to the Gaussian installation on our system is limited to members
of the  UNIX group <code class="docutils literal notranslate"><span class="pre">s_gaussian</span></code>. Please, contact
<a class="reference external" href="mailto:hpc-support&#37;&#52;&#48;tu-dresden&#46;de">hpc-support<span>&#64;</span>tu-dresden<span>&#46;</span>de</a> if you can‚Äôt
access it, yet wish to use it.</p>
<section id="guidance-on-data-management-with-gaussian">
<h3>Guidance on Data Management with Gaussian<a class="headerlink" href="#guidance-on-data-management-with-gaussian" title="Permalink to this heading">#</a></h3>
<p>We have a general description about
<span class="xref myst">how to utilize workspaces for your I/O intensive jobs</span>.
However hereafter we have an example on how that might look like for Gaussian:</p>
<p>???+ example ‚ÄúUsing workspaces with Gaussian‚Äù</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#SBATCH --time=04:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=16
#SBATCH --mem=68000
## good default on Barnard: set mem = 4000 (for gaussian executable) + cpus-per-task * 4000 (for gaussian data)

# Adjust the path to where your input file is located
INPUTFILE=&quot;/path/to/my/inputfile.gjf&quot;

# Unexpected errors result in instant script termination
set -e

# Load the software you need here
module purge
module load release/23.10
module load Gaussian/16.C.01

# Check existance of input file
if test ! -f &quot;${INPUTFILE}&quot;; then
   echo &quot;Error: could not find the input file ${INPUTFILE}&quot;
   exit 1
fi

# Allocate workspace. Adjust time span to time limit of the job (-d &lt;N&gt;).
COMPUTE_WS=gaussian_${SLURM_JOB_ID}
export GAUSS_SCRDIR=$(ws_allocate --name ${COMPUTE_WS} --duration 7)
echo ${GAUSS_SCRDIR}

# Check if workspace allocation was successful
if [ ! -d &quot;${GAUSS_SCRDIR}&quot; ]; then
   echo &quot;Error: cannot allocate workspace ${COMPUTE_WS}&quot;
   exit 1
fi

# Check consistency of resource allocation (memory &amp; cores). The Slurm and Gaussian configuration should match.
if grep -i -m 3 -e &quot;%mem&quot; -e &quot;%cpu&quot; -e &quot;%nprocshared&quot; &quot;${INPUTFILE}&quot;; then
   echo &quot;Info: are the above parameters in your input file within your Slurm job parameters SLURM_CPUS_PER_TASK=${SLURM_CPUS_PER_TASK} and SLURM_MEM_PER_NODE=${SLURM_MEM_PER_NODE}?&quot;
fi

# Change to workspace directory and execute application
cp &quot;${INPUTFILE}&quot; ${GAUSS_SCRDIR}/inputfile.gjf
cd ${GAUSS_SCRDIR}
# m -4000 ensures that gaussian binary and runtime itself fits into memory
if ! g16 -p=${SLURM_CPUS_PER_TASK} -m=$(( ${SLURM_MEM_PER_NODE} - 4000 ))MB &lt;./inputfile.gjf &gt;logfile.log; then
   echo &quot;Error: gaussian terminated with error code $?&quot;
fi

# Move compressed result files to user home
if ! bzip2 --compress --stdout logfile.log &gt;${HOME}/gaussian_job-${SLURM_JOB_ID}.bz2; then
   echo &quot;Error: compression of results failed!&quot;
   echo &quot;Please check ${GAUSS_SCRDIR} for uncompressed results.&quot;
   exit 1
fi

# Clean and release temporary workspace
if test -d ${GAUSS_SCRDIR}; then
   rm -rf ${GAUSS_SCRDIR}/*
   ws_release ${COMPUTE_WS}
fi
</pre></div>
</div>
</section>
</section>
<section id="gromacs">
<h2>GROMACS<a class="headerlink" href="#gromacs" title="Permalink to this heading">#</a></h2>
<p>GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations
of motion for systems with hundreds to millions of particles. It is primarily designed for
biochemical molecules like proteins, lipids and nucleic acids that have a lot of complicated bonded
interactions, but since GROMACS is extremely fast at calculating the nonbonded interactions (that
usually dominate simulations), many groups are also using it for research on non-biological systems,
e.g., polymers. For documentations see <a class="reference external" href="https://www.gromacs.org/">GROMACS homepage</a>.</p>
<p>GROMACS is available as <span class="xref myst">modules</span>. Available packages can be listed and loaded with the
following commands:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$</span>:~&gt;<span class="w"> </span>module<span class="w"> </span>avail<span class="w"> </span>GROMACS
<span class="go">----------------------------- /sw/modules/scs5/bio -----------------------------</span>
<span class="go">   GROMACS/2018.2-foss-2018a-CUDA-9.2.88    GROMACS/2019.4-fosscuda-2019a</span>
<span class="go">   GROMACS/2018.2-intel-2018a               GROMACS/2020-fosscuda-2019b   (D)</span>
<span class="go">[...]</span>
<span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>GROMACS
<span class="go">Module GROMACS/2020-fosscuda-2019b and 17 dependencies loaded.</span>
</pre></div>
</div>
</section>
<section id="lammps">
<h2>LAMMPS<a class="headerlink" href="#lammps" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://www.lammps.org">LAMMPS</a> is a classical molecular dynamics code that models an ensemble of
particles in a liquid, solid, or gaseous state. It can model atomic, polymeric, biological,
metallic, granular, and coarse-grained systems using a variety of force fields and boundary
conditions. For examples of LAMMPS simulations, documentations, and more visit
<a class="reference external" href="https://www.lammps.org">LAMMPS sites</a>.</p>
<p>LAMMPS is available as <span class="xref myst">modules</span>. Available packages can be listed and loaded with the
following commands:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$</span>:~&gt;<span class="w"> </span>module<span class="w"> </span>avail<span class="w"> </span>LAMMPS
<span class="go">---------------------------- /sw/modules/scs5/chem -----------------------------</span>
<span class="go">   LAMMPS/3Mar2020-foss-2020a-Python-3.8.2-kokkos</span>
<span class="go">   LAMMPS/3Mar2020-intel-2020a-Python-3.8.2-kokkos</span>
<span class="go">   LAMMPS/7Aug19-foss-2019a-Python-2.7.15</span>
<span class="go">   LAMMPS/12Dec2018-foss-2019a                     (D)</span>
<span class="go">   LAMMPS/20180316-foss-2018a-Python-3.6.4</span>
<span class="go">[...]</span>
<span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>LAMMPS
<span class="go">[...]</span>
<span class="go">Module LAMMPS/12Dec2018-foss-2019a and 33 dependencies loaded.</span>
</pre></div>
</div>
</section>
<section id="namd">
<h2>NAMD<a class="headerlink" href="#namd" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://www.ks.uiuc.edu/Research/namd">NAMD</a> is a parallel molecular dynamics code designed for
high-performance simulation of large biomolecular systems.</p>
<p>NAMD can be started as parallel program with <code class="docutils literal notranslate"><span class="pre">srun</span></code>. Since
the parallel performance strongly depends on the size of the given problem, one cannot give a general
advice for the optimum number of CPUs to use. (Please check this by running NAMD with your molecules
and just a few time steps.)</p>
<p>NAND is available as <span class="xref myst">modules</span>. Available packages can be listed and loaded with the
following commands:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$</span>:~&gt;<span class="w"> </span>module<span class="w"> </span>avail<span class="w"> </span>NAMD
<span class="go">---------------------------- /sw/modules/scs5/chem -----------------------------</span>
<span class="go">   NAMD/2.12-intel-2018a-mpi</span>
<span class="go">[...]</span>
<span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>NAMD
<span class="go">[...]</span>
<span class="go">Module NAMD/2.12-intel-2018a-mpi and 12 dependencies loaded.</span>
</pre></div>
</div>
<p>Any published work which utilizes NAMD shall include the following reference:</p>
<p><em>James C. Phillips, Rosemary Braun, Wei Wang, James Gumbart, Emad Tajkhorshid, Elizabeth Villa, Christophe
Chipot, Robert D.  Skeel, Laxmikant Kale, and Klaus Schulten. Scalable molecular dynamics with NAMD.
Journal of Computational Chemistry, 26:1781-1802, 2005.</em></p>
<p>Electronic documents will include a direct link to the <a class="reference external" href="https://www.ks.uiuc.edu/Research/namd">official NAMD page</a></p>
</section>
<section id="orca">
<h2>ORCA<a class="headerlink" href="#orca" title="Permalink to this heading">#</a></h2>
<p>ORCA is a flexible, efficient and easy-to-use general purpose tool for quantum chemistry with
specific emphasis on spectroscopic properties of open-shell molecules. It features a wide variety of
standard quantum chemical methods ranging from semiempirical methods to DFT to single- and
multireference correlated ab initio methods. It can also treat environmental and relativistic
effects.</p>
<p>To run ORCA jobs in parallel, you have to specify the number of processes in your input file (here
for example 16 processes):</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>%pal<span class="w"> </span>nprocs<span class="w"> </span><span class="m">16</span><span class="w"> </span>end
</pre></div>
</div>
<p>Note, that ORCA spawns MPI processes itself, so you must not use <code class="docutils literal notranslate"><span class="pre">srun</span></code> to launch it in your batch
file. Just set <code class="docutils literal notranslate"><span class="pre">--ntasks</span></code> to the same number as in your input file and call the <code class="docutils literal notranslate"><span class="pre">orca</span></code> executable
directly. For parallel runs, it must be called with the full path:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --ntasks=16</span>
<span class="c1">#SBATCH --nodes=1</span>
<span class="c1">#SBATCH --mem-per-cpu=2000M</span>

<span class="nv">$ORCA_ROOT</span>/orca<span class="w"> </span>example.inp
</pre></div>
</div>
<p>ORCA is available as <span class="xref myst">modules</span>. Available packages can be listed and loaded with the
following commands:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$</span>:~&gt;<span class="w"> </span>module<span class="w"> </span>avail<span class="w"> </span>ORCA
<span class="go">---------------------------- /sw/modules/scs5/chem -----------------------------</span>
<span class="go">   ORCA/4.1.1-OpenMPI-2.1.5    ORCA/4.2.1-gompi-2019b (D)</span>
<span class="go">[...]</span>
<span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>ORCA
<span class="go">[...]</span>
<span class="go">Module ORCA/4.2.1-gompi-2019b and 11 dependencies loaded.</span>
</pre></div>
</div>
</section>
<section id="siesta">
<h2>Siesta<a class="headerlink" href="#siesta" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://siesta-project.org/siesta">Siesta</a> (Spanish Initiative for Electronic Simulations with
Thousands of Atoms) is both a method and its computer program implementation,
to perform electronic structure calculations and ab initio
molecular dynamics simulations of molecules and solids.</p>
<p>Siesta is available as <span class="xref myst">modules</span>. Available packages can be listed and loaded with the
following commands:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$</span>:~&gt;<span class="w"> </span>module<span class="w"> </span>avail<span class="w"> </span>Siesta
<span class="go">---------------------------- /sw/modules/scs5/phys -----------------------------</span>
<span class="go">   Siesta/4.1-b3-intel-2018a    Siesta/4.1-b4-intel-2019b</span>

<span class="go">---------------------------- /sw/modules/scs5/chem -----------------------------</span>
<span class="go">   Siesta/4.1-MaX-1.0-intel-2019b (D)</span>
<span class="go">[...]</span>
<span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>Siesta
<span class="go">[...]</span>
<span class="go">Module Siesta/4.1-MaX-1.0-intel-2019b and 26 dependencies loaded.</span>
</pre></div>
</div>
<p>In any paper or other academic publication containing results wholly or partially derived from the
results of use of the SIESTA package, the following papers must be cited in the normal manner:</p>
<ol class="arabic simple">
<li><p>‚ÄúSelf-consistent order-N density-functional calculations for very large systems‚Äù,
P.  Ordejon, E. Artacho and J. M. Soler, Phys. Rev. B (Rapid Comm.) 53, R10441-10443 (1996).</p></li>
<li><p>‚ÄúThe SIESTA method for ab initio order-N materials simulation‚Äù, J. M. Soler, E. Artacho,
J. D. Gale, A. Garcia, J. Junquera, P. Ordejon, and D. Sanchez-Portal, J. Phys.: Condens. Matt. 14,
2745-2779 (2002).</p></li>
</ol>
</section>
<section id="vasp">
<h2>VASP<a class="headerlink" href="#vasp" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>VAMP/VASP is a package for performing ab-initio quantum-mechanical molecular dynamics (MD) using
pseudopotentials and a plane wave basis set. (see <a class="reference external" href="https://www.vasp.at">VASP</a>).</p>
</div></blockquote>
<p>VASP is available as <span class="xref myst">modules</span>. Available packages can be listed and loaded with the
following commands:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$</span>:~&gt;<span class="w"> </span>module<span class="w"> </span>avail<span class="w"> </span>VASP
<span class="go">---------------------------- /sw/modules/scs5/phys -----------------------------</span>
<span class="go">   VASP/5.4.4-intel-2018a-optics    VASP/5.4.4-intel-2019b (L,D)</span>
<span class="go">   VASP/5.4.4-intel-2018a</span>
<span class="go">[...]</span>
<span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>VASP
<span class="go">[...]</span>
<span class="go">Module VASP/5.4.4-intel-2019b loaded.</span>
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="gpu-accelerated-containers-for-deep-learning-ngc-containers">
<h1>GPU-accelerated Containers for Deep Learning (NGC Containers)<a class="headerlink" href="#gpu-accelerated-containers-for-deep-learning-ngc-containers" title="Permalink to this heading">#</a></h1>
<p>A <span class="xref myst">container</span> is an executable and portable unit of software.
On ZIH systems, <a class="reference external" href="https://sylabs.io/">Singularity</a> is used as a standard container solution.</p>
<p><a class="reference external" href="https://developer.nvidia.com/ai-hpc-containers">NGC</a>,
a registry of highly GPU-optimized software,
has been enabling scientists and researchers by providing regularly updated
and validated containers of HPC and AI applications.
NGC containers are <strong>GPU-optimized</strong> containers
for deep learning, machine learning, visualization:</p>
<ul class="simple">
<li><p>Built-in libraries and dependencies;</p></li>
<li><p>Faster training with Automatic Mixed Precision (AMP);</p></li>
<li><p>Opportunity to scale up from single-node to multi-node systems;</p></li>
<li><p>Performance optimized.</p></li>
</ul>
<p>!!! note ‚ÄúAdvantages of NGC containers‚Äù
- NGC containers were highly optimized for cluster usage.
The performance provided by NGC containers is comparable to the performance
provided by the modules on the ZIH system (which is potentially the most performant way).
NGC containers are a quick and efficient way to apply the best models
on your dataset on a ZIH system;
- NGC containers allow using an exact version of the software
without installing it with all prerequisites manually.
Manual installation can result in poor performance (e.g. using conda to install a software).</p>
<section id="run-ngc-containers-on-the-zih-system">
<h2>Run NGC Containers on the ZIH System<a class="headerlink" href="#run-ngc-containers-on-the-zih-system" title="Permalink to this heading">#</a></h2>
<p>The first step is a choice of the necessary software (container) to run.
The <a class="reference external" href="https://ngc.nvidia.com/catalog">NVIDIA NGC catalog</a>
contains a host of GPU-optimized containers for deep learning,
machine learning, visualization, and HPC applications that are tested
for performance, security, and scalability.
It is necessary to register to have full access to the catalog.</p>
<p>To find a container that fits the requirements of your task, please check
the <a class="reference external" href="https://github.com/NVIDIA/DeepLearningExamples">official examples page</a>
with the list of main containers with their features and peculiarities.</p>
<section id="run-ngc-container-on-a-single-gpu">
<h3>Run NGC container on a Single GPU<a class="headerlink" href="#run-ngc-container-on-a-single-gpu" title="Permalink to this heading">#</a></h3>
<p>!!! note
Almost all NGC containers can work with a single GPU.</p>
<p>To use NGC containers, it is necessary to understand the main Singularity commands.</p>
<p>If you are not familiar with Singularity‚Äôs syntax, please find the information on the
<a class="reference external" href="https://sylabs.io/guides/3.0/user-guide/quick_start.html#interact-with-images">official page</a>.
However, some main commands will be explained.</p>
<p>Create a container from the image from the NGC catalog.
(For this example, the cluster alpha is used):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login.alpha$ </span>srun<span class="w"> </span>--nodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--ntasks-per-node<span class="o">=</span><span class="m">1</span><span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span><span class="w"> </span>--gres<span class="o">=</span>gpu:1<span class="w"> </span>--time<span class="o">=</span><span class="m">08</span>:00:00<span class="w"> </span>--pty<span class="w"> </span>--mem<span class="o">=</span><span class="m">50000</span><span class="w"> </span>bash
<span class="go">[...]</span>
<span class="gp">marie@alpha$ </span><span class="nb">cd</span><span class="w"> </span>/data/horse/ws/&lt;name_of_your_workspace&gt;/containers<span class="w">   </span><span class="c1">#please create a Workspace</span>
<span class="go">[...]</span>
<span class="gp">marie@alpha$ </span>singularity<span class="w"> </span>pull<span class="w"> </span>pytorch:21.08-py3.sif<span class="w"> </span>docker://nvcr.io/nvidia/pytorch:21.08-py3
</pre></div>
</div>
<p>Now, you have a fully functional PyTorch container.</p>
<p>Please pay attention, using <code class="docutils literal notranslate"><span class="pre">srun</span></code> directly on the shell will lead to
background by using batch jobs.
For that, you can conveniently put the parameters directly into the job file,
which you can submit using <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> command.</p>
<p>In the majority of cases, the container doesn‚Äôt contain the dataset for training models.
To download the dataset, please follow the
<a class="reference external" href="https://github.com/NVIDIA/DeepLearningExamples">instructions</a> for the exact container.
Also, you can find the instructions in a README file which you can find inside the container:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@alpha$ </span>singularity<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>pytorch:21.06-py3_beegfs<span class="w"> </span>vim<span class="w"> </span>/workspace/examples/resnet50v1.5/README.md
</pre></div>
</div>
<p>It is recommended to run the container with a single command.
However, for the educational purpose, the separate commands will be presented below:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login.alpha$ </span>srun<span class="w"> </span>--nodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--ntasks-per-node<span class="o">=</span><span class="m">1</span><span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span><span class="w"> </span>--gres<span class="o">=</span>gpu:1<span class="w"> </span>--time<span class="o">=</span><span class="m">08</span>:00:00<span class="w"> </span>--pty<span class="w"> </span>--mem<span class="o">=</span><span class="m">50000</span><span class="w"> </span>bash
</pre></div>
</div>
<p>Run a shell within a container with the <code class="docutils literal notranslate"><span class="pre">singularity</span> <span class="pre">shell</span></code> command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@alpha$ </span>singularity<span class="w"> </span>shell<span class="w"> </span>--nv<span class="w"> </span>-B<span class="w"> </span>/data/horse/imagenet:/data/imagenet<span class="w"> </span>pytorch:21.06-py3
</pre></div>
</div>
<p>The flag <code class="docutils literal notranslate"><span class="pre">--nv</span></code> in the command above was used to enable Nvidia support for GPU usage
and a flag <code class="docutils literal notranslate"><span class="pre">-B</span></code> for a user-bind path specification.</p>
<p>Run the training inside the container:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@container$ </span>python<span class="w"> </span>/workspace/examples/resnet50v1.5/multiproc.py<span class="w"> </span>--nnodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--nproc_per_node<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">                </span>--node_rank<span class="o">=</span><span class="m">0</span><span class="w"> </span>/workspace/examples/resnet50v1.5/main.py<span class="w"> </span>--data-backend<span class="w"> </span>dali-cpu<span class="w"> </span><span class="se">\</span>
<span class="w">                </span>--raport-file<span class="w"> </span>raport.json<span class="w"> </span>-j16<span class="w"> </span>-p<span class="w"> </span><span class="m">100</span><span class="w"> </span>--lr<span class="w"> </span><span class="m">2</span>.048<span class="w"> </span>--optimizer-batch-size<span class="w"> </span><span class="m">2048</span><span class="w"> </span>--warmup<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">                </span>--arch<span class="w"> </span>resnet50<span class="w"> </span>-c<span class="w"> </span>fanin<span class="w"> </span>--label-smoothing<span class="w"> </span><span class="m">0</span>.1<span class="w"> </span>--lr-schedule<span class="w"> </span>cosine<span class="w"> </span>--mom<span class="w"> </span><span class="m">0</span>.875<span class="w"> </span><span class="se">\</span>
<span class="w">                </span>--wd<span class="w"> </span><span class="m">3</span>.0517578125e-05<span class="w"> </span>-b<span class="w"> </span><span class="m">256</span><span class="w"> </span>--epochs<span class="w"> </span><span class="m">90</span><span class="w"> </span>/data/imagenet
</pre></div>
</div>
<p>!!! warning
Please keep in mind that it is necessary to specify the amount of resources that you use inside
the container, especially if you have allocated more resources in the cluster. Regularly, you
can do it with flags such as <code class="docutils literal notranslate"><span class="pre">--nproc_per_node</span></code>. You can find more information in the README
file inside the container.</p>
<p>As an example, please find the full command to run the ResNet50 model
on the ImageNet dataset inside the PyTorch container:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login.alpha$ </span>srun<span class="w"> </span>--nodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--ntasks-per-node<span class="o">=</span><span class="m">1</span><span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span><span class="w"> </span>--gres<span class="o">=</span>gpu:1<span class="w"> </span>--time<span class="o">=</span><span class="m">08</span>:00:00<span class="w"> </span>--pty<span class="w"> </span>--mem<span class="o">=</span><span class="m">50000</span><span class="w"> </span><span class="se">\</span>
<span class="w">                </span>singularity<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--nv<span class="w"> </span>-B<span class="w"> </span>/data/horse/ws/anpo879a-ImgNet/imagenet:/data/imagenet<span class="w"> </span>pytorch:21.06-py3<span class="w"> </span><span class="se">\</span>
<span class="w">                </span>python<span class="w"> </span>/workspace/examples/resnet50v1.5/multiproc.py<span class="w"> </span>--nnodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--nproc_per_node<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">                </span>--node_rank<span class="o">=</span><span class="m">0</span><span class="w"> </span>/workspace/examples/resnet50v1.5/main.py<span class="w"> </span>--data-backend<span class="w"> </span>dali-cpu<span class="w"> </span>--raport-file<span class="w"> </span>raport.json<span class="w"> </span><span class="se">\</span>
<span class="w">                </span>-j16<span class="w"> </span>-p<span class="w"> </span><span class="m">100</span><span class="w"> </span>--lr<span class="w"> </span><span class="m">2</span>.048<span class="w"> </span>--optimizer-batch-size<span class="w"> </span><span class="m">2048</span><span class="w"> </span>--warmup<span class="w"> </span><span class="m">8</span><span class="w"> </span>--arch<span class="w"> </span>resnet50<span class="w"> </span>-c<span class="w"> </span>fanin<span class="w"> </span>--label-smoothing<span class="w"> </span><span class="m">0</span>.1<span class="w"> </span><span class="se">\</span>
<span class="w">                </span>--lr-schedule<span class="w"> </span>cosine<span class="w"> </span>--mom<span class="w"> </span><span class="m">0</span>.875<span class="w"> </span>--wd<span class="w"> </span><span class="m">3</span>.0517578125e-05<span class="w"> </span>-b<span class="w"> </span><span class="m">256</span><span class="w"> </span>--epochs<span class="w"> </span><span class="m">90</span><span class="w"> </span>/data/imagenet
</pre></div>
</div>
</section>
<section id="multi-gpu-usage">
<h3>Multi-GPU Usage<a class="headerlink" href="#multi-gpu-usage" title="Permalink to this heading">#</a></h3>
<p>The majority of the NGC containers allow you to use multiple GPUs from one node
to run the model inside the container.
However, the NGC containers were made by Nvidia for the Nvidia cluster,
which is not ZIH system.
Moreover, editing NGC containers requires root privileges,
which can be done only with <span class="xref myst">containers</span> on ZIH systems.
Thus, there is no guarantee that all NGC containers work right out of the box.</p>
<p>However, PyTorch and TensorFlow containers support multi-GPU usage.</p>
<p>An example of using the PyTorch container for the training of the ResNet50 model
on the classification task on the ImageNet dataset is presented below:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login.alpha$ </span>srun<span class="w"> </span>--nodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--ntasks-per-node<span class="o">=</span><span class="m">8</span><span class="w"> </span>--ntasks<span class="o">=</span><span class="m">8</span><span class="w"> </span>--gres<span class="o">=</span>gpu:8<span class="w"> </span>--time<span class="o">=</span><span class="m">08</span>:00:00<span class="w"> </span>--pty<span class="w"> </span>--mem<span class="o">=</span>700G<span class="w"> </span>bash
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@alpha$ </span>singularity<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--nv<span class="w"> </span>-B<span class="w"> </span>/data/horse/ws/marie-ImgNet/imagenet:/data/imagenet<span class="w"> </span>pytorch:21.06-py3<span class="w"> </span><span class="se">\</span>
<span class="w">                </span>python<span class="w"> </span>/workspace/examples/resnet50v1.5/multiproc.py<span class="w"> </span>--nnodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--nproc_per_node<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">                </span>--node_rank<span class="o">=</span><span class="m">0</span><span class="w"> </span>/workspace/examples/resnet50v1.5/main.py<span class="w"> </span>--data-backend<span class="w"> </span>dali-cpu<span class="w"> </span><span class="se">\</span>
<span class="w">                </span>--raport-file<span class="w"> </span>raport.json<span class="w"> </span>-j16<span class="w"> </span>-p<span class="w"> </span><span class="m">100</span><span class="w"> </span>--lr<span class="w"> </span><span class="m">2</span>.048<span class="w"> </span>--optimizer-batch-size<span class="w"> </span><span class="m">2048</span><span class="w"> </span>--warmup<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">                </span>--arch<span class="w"> </span>resnet50<span class="w"> </span>-c<span class="w"> </span>fanin<span class="w"> </span>--label-smoothing<span class="w"> </span><span class="m">0</span>.1<span class="w"> </span>--lr-schedule<span class="w"> </span>cosine<span class="w"> </span>--mom<span class="w"> </span><span class="m">0</span>.875<span class="w"> </span><span class="se">\</span>
<span class="w">                </span>--wd<span class="w"> </span><span class="m">3</span>.0517578125e-05<span class="w"> </span>-b<span class="w"> </span><span class="m">256</span><span class="w"> </span>--epochs<span class="w"> </span><span class="m">90</span><span class="w"> </span>/data/imagenet
</pre></div>
</div>
<p>Please pay attention to the parameter <code class="docutils literal notranslate"><span class="pre">--nproc_per_node</span></code>.
The value is equal to 8 because 8 GPUs per node were allocated with <code class="docutils literal notranslate"><span class="pre">--gres=gpu:8</span></code>.</p>
</section>
<section id="multi-node-usage">
<h3>Multi-node Usage<a class="headerlink" href="#multi-node-usage" title="Permalink to this heading">#</a></h3>
<p>There are few NGC containers with Multi-node support
<a class="reference external" href="https://github.com/NVIDIA/DeepLearningExamples">available</a>.
Moreover, the realization of the multi-node usage depends on the authors
of the exact container.
Thus, right now, it is not possible to run NGC containers with multi-node support
on the ZIH system without changing the source code inside the container.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="environment-and-software">
<h1>Environment and Software<a class="headerlink" href="#environment-and-software" title="Permalink to this heading">#</a></h1>
<p>A joyful and efficient usage of ZIH systems bases on a profound understanding of the working
environment, which comprises your personal <em>user environment</em> and the <em>software environment</em>.</p>
<section id="user-environment">
<h2>User Environment<a class="headerlink" href="#user-environment" title="Permalink to this heading">#</a></h2>
<p>All ZIH systems use global home directories to provide homogeneous user environments across all
systems. The default login shell is <code class="docutils literal notranslate"><span class="pre">bash</span></code>. Personal additions and modifications can be put into
so called dotfiles in your home directory, e.g., <code class="docutils literal notranslate"><span class="pre">~/.bashrc</span></code> or <code class="docutils literal notranslate"><span class="pre">~/.bash_profile</span></code>.</p>
</section>
<section id="id53">
<h2>Software Environment<a class="headerlink" href="#id53" title="Permalink to this heading">#</a></h2>
<p>There are different options to work with software on ZIH systems: <span class="xref myst">modules</span>,
<span class="xref myst">Jupyter Notebook</span> and <span class="xref myst">containers</span>. Brief descriptions and related
links on these options are provided below.</p>
</section>
<section id="id54">
<h2>Modules<a class="headerlink" href="#id54" title="Permalink to this heading">#</a></h2>
<p>Usage of software on ZIH systems, e.g., frameworks, compilers, loader and libraries, is
almost always managed by a <strong>modules system</strong>. Thus, it is crucial to be familiar with the
<span class="xref myst">modules concept and its commands</span>.  A module is a user interface that provides
utilities for the dynamic modification of a user‚Äôs environment without manual modifications.</p>
<p>Modules are used to set up the environment when working on ZIH systems via batch system (e.g.,
<code class="docutils literal notranslate"><span class="pre">srun</span></code> or <code class="docutils literal notranslate"><span class="pre">sbatch</span></code>), and the <span class="xref myst">JupyterHub</span>.</p>
</section>
<section id="id55">
<h2>Jupyter Notebook<a class="headerlink" href="#id55" title="Permalink to this heading">#</a></h2>
<p>The <a class="reference external" href="https://jupyter.org/">Jupyter Notebook</a> is an open-source web application that allows creating
documents containing live code, equations, visualizations, and narrative text. There is a
<span class="xref myst">JupyterHub</span> service on ZIH systems, where you can simply run your Jupyter
notebook on compute nodes using <span class="xref myst">modules</span>, preloaded or custom virtual environments.
Moreover, you can run a <span class="xref myst">manually created remote Jupyter server</span>
for more specific cases.</p>
</section>
<section id="id56">
<h2>Containers<a class="headerlink" href="#id56" title="Permalink to this heading">#</a></h2>
<p>Some tasks require using containers. It can be done on ZIH Systems by <span class="xref myst">Singularity</span>.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="read-cpu-performance-counters-with-papi">
<h1>Read CPU Performance Counters with PAPI<a class="headerlink" href="#read-cpu-performance-counters-with-papi" title="Permalink to this heading">#</a></h1>
<section id="id57">
<h2>Introduction<a class="headerlink" href="#id57" title="Permalink to this heading">#</a></h2>
<p>The <strong>P</strong>erformance <strong>A</strong>pplication <strong>P</strong>rogramming <strong>I</strong>nterface (PAPI) provides tool designers and
application engineers with a consistent interface and methodology for the use of low-level
performance counter hardware found across the entire compute system (i.e. CPUs, GPUs, on/off-chip
memory, interconnects, I/O system, energy/power, etc.). PAPI enables users to see, in near real
time, the relations between software performance and hardware events across the entire computer
system.</p>
<p>Only the basic usage is outlined in this compendium. For a comprehensive PAPI user manual please
refer to the <a class="reference external" href="https://bitbucket.org/icl/papi/wiki/Home">PAPI wiki website</a>.</p>
</section>
<section id="papi-counter-interfaces">
<h2>PAPI Counter Interfaces<a class="headerlink" href="#papi-counter-interfaces" title="Permalink to this heading">#</a></h2>
<p>To collect performance events, PAPI provides two APIs, the <em>high-level</em> and <em>low-level</em> API.</p>
<section id="high-level-api">
<h3>High-Level API<a class="headerlink" href="#high-level-api" title="Permalink to this heading">#</a></h3>
<p>The high-level API provides the ability to record performance events inside instrumented regions of
serial, multi-processing (MPI, SHMEM) and thread (OpenMP, Pthreads) parallel applications. It is
designed for simplicity, not flexibility. More details can be found in the
<a class="reference external" href="https://bitbucket.org/icl/papi/wiki/PAPI-HL.md">PAPI wiki High-Level API description</a>.</p>
<p>The following code example shows the use of the high-level API by marking a code section.</p>
<p>??? example ‚ÄúC‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```C
#include &quot;papi.h&quot;

int main()
{
    int retval;

    retval = PAPI_hl_region_begin(&quot;computation&quot;);
    if ( retval != PAPI_OK )
        handle_error(1);

    /* Do some computation here */

    retval = PAPI_hl_region_end(&quot;computation&quot;);
    if ( retval != PAPI_OK )
        handle_error(1);
}
```
</pre></div>
</div>
<p>??? example ‚ÄúFortran‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```fortran
#include &quot;fpapi.h&quot;

program main
integer retval

call PAPIf_hl_region_begin(&quot;computation&quot;, retval)
if ( retval .NE. PAPI_OK ) then
   write (*,*) &quot;PAPIf_hl_region_begin failed!&quot;
end if

!do some computation here

call PAPIf_hl_region_end(&quot;computation&quot;, retval)
if ( retval .NE. PAPI_OK ) then
   write (*,*) &quot;PAPIf_hl_region_end failed!&quot;
end if

end program main
```
</pre></div>
</div>
<p>Events to be recorded are determined via the environment variable <code class="docutils literal notranslate"><span class="pre">PAPI_EVENTS</span></code> that lists comma
separated events for any component (see example below). The output is generated in the current
directory by default. However, it is recommended to specify an output directory for larger
measurements, especially for MPI applications via environment variable <code class="docutils literal notranslate"><span class="pre">PAPI_OUTPUT_DIRECTORY</span></code>.</p>
<p>!!! example ‚ÄúSetting performance events and output directory‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
export PAPI_EVENTS=&quot;PAPI_TOT_INS,PAPI_TOT_CYC&quot;
export PAPI_OUTPUT_DIRECTORY=&quot;/data/horse/measurement&quot;
```
</pre></div>
</div>
<p>This will generate a directory called <code class="docutils literal notranslate"><span class="pre">papi_hl_output</span></code> in <code class="docutils literal notranslate"><span class="pre">/data/horse/measurement</span></code> that contains
one or more output files in JSON format.</p>
</section>
<section id="low-level-api">
<h3>Low-Level API<a class="headerlink" href="#low-level-api" title="Permalink to this heading">#</a></h3>
<p>The low-level API manages hardware events in user-defined groups called Event Sets. It is meant for
experienced application programmers and tool developers wanting fine-grained measurement and
control of the PAPI interface. It provides access to both PAPI preset and native events, and
supports all installed components. The PAPI wiki contains also a page with more details on the
<a class="reference external" href="https://bitbucket.org/icl/papi/wiki/PAPI-LL.md">low-level API</a>.</p>
</section>
</section>
<section id="usage-on-zih-systems">
<h2>Usage on ZIH Systems<a class="headerlink" href="#usage-on-zih-systems" title="Permalink to this heading">#</a></h2>
<p>Before you start a PAPI measurement, check which events are available on the desired architecture.
For this purpose, PAPI offers the tools <code class="docutils literal notranslate"><span class="pre">papi_avail</span></code> and <code class="docutils literal notranslate"><span class="pre">papi_native_avail</span></code>. If you want to measure
multiple events, please check which events can be measured concurrently using the tool
<code class="docutils literal notranslate"><span class="pre">papi_event_chooser</span></code>. The PAPI wiki contains more details on
<a class="reference external" href="https://bitbucket.org/icl/papi/wiki/PAPI-Overview.md#markdown-header-papi-utilities">the PAPI tools</a>
.</p>
<p>!!! hint</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The PAPI tools must be run on the compute node, using an interactive shell or job.
</pre></div>
</div>
<p>!!! example ‚ÄúExample: Determine the events on the cluster <code class="docutils literal notranslate"><span class="pre">romeo</span></code> from a login node‚Äù
Let us assume, that you are in project <code class="docutils literal notranslate"><span class="pre">p_number_crunch</span></code>. Then, use the following commands:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login.romeo$ module load PAPI
marie@login.romeo$ salloc --account=p_number_crunch
[...]
marie@romeo$ srun papi_avail
marie@romeo$ srun papi_native_avail
[...]
# Exit with Ctrl+D
```
</pre></div>
</div>
<p>Instrument your application with either the high-level or low-level API. Load the PAPI module and
compile your application against the  PAPI library.</p>
<p>!!! example
Assuming that you are in project <code class="docutils literal notranslate"><span class="pre">p_number_crunch</span></code>, use the following commands:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login.romeo$ module load PAPI
marie@login.romeo$ gcc app.c -o app -lpapi
marie@login.romeo$ salloc --account=p_number_crunch
marie@romeo$ srun ./app
[...]
# Exit with Ctrl+D
```
</pre></div>
</div>
<p>!!! hint</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The PAPI modules on ZIH systems are only installed with the default `perf_event` component. If you
want to measure, e.g., GPU events, you have to install your own PAPI. Please see the
[external instructions on how to download and install PAPI](https://bitbucket.org/icl/papi/wiki/Downloading-and-Installing-PAPI.md).
To install PAPI with additional components, you have to specify them during configure as
described for the [Installation of Components](https://bitbucket.org/icl/papi/wiki/PAPI-Overview.md#markdown-header-components).
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="search-boost-450-0">
<h2>search:
boost: 450.0<a class="headerlink" href="#search-boost-450-0" title="Permalink to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="performance-engineering-overview">
<h1>Performance Engineering Overview<a class="headerlink" href="#performance-engineering-overview" title="Permalink to this heading">#</a></h1>
<p>!!! cite ‚ÄúWalter J. Doherty, 1970 <a class="footnote-reference brackets" href="#id77" id="id58" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Fundamentally, performance is the degree to which a computing system meets the expectations of
the person involved with it.
</pre></div>
</div>
<p>Performance engineering encompasses the techniques applied during a systems development life cycle
to ensure the non-functional requirements for performance (such as throughput, latency, or memory
usage) will be met.
Often, it is also referred to as systems performance engineering within systems engineering, and
software performance engineering or application performance engineering within software engineering
<a class="reference external" href="https://en.wikipedia.org/wiki/Performance_engineering">[Wikipedia]</a>.</p>
<section id="objectives">
<h2>Objectives<a class="headerlink" href="#objectives" title="Permalink to this heading">#</a></h2>
<p>??? hint ‚ÄúSome good reasons to think about performance in HPC‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- Increase research output by ensuring the system can process transactions within the requisite time
  frame
- Eliminate system failure requiring scrapping and writing off the system development effort due to
  performance objective failure
- Eliminate avoidable system tuning efforts
- Avoid additional and unnecessary hardware acquisition costs
- Reduce increased software maintenance costs due to performance problems in production
- Reduce additional operational overhead for handling system issues due to performance problems
- Identify future bottlenecks by simulation over prototype
</pre></div>
</div>
</section>
<section id="installed-tools-in-a-nutshell">
<h2>Installed Tools in a Nutshell<a class="headerlink" href="#installed-tools-in-a-nutshell" title="Permalink to this heading">#</a></h2>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Tool</p></th>
<th class="head"><p>Task</p></th>
<th class="head"><p>Easiness</p></th>
<th class="head"><p>Details</p></th>
<th class="head"><p>Overhead</p></th>
<th class="head"><p>Re-compilation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="xref myst">lo2s</span></p></td>
<td><p>Create performance <span class="xref myst">trace</span></p></td>
<td><p>easy</p></td>
<td><p>medium</p></td>
<td><p>low</p></td>
<td><p>(no)<a class="footnote-reference brackets" href="#id78" id="id59" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a></p></td>
</tr>
<tr class="row-odd"><td><p><span class="xref myst">MUST</span></p></td>
<td><p>Check MPI correctness</p></td>
<td><p>medium</p></td>
<td><p>medium</p></td>
<td><p>variable</p></td>
<td><p>no</p></td>
</tr>
<tr class="row-even"><td><p><span class="xref myst">PAPI</span></p></td>
<td><p>Read portable CPU counters</p></td>
<td><p>advanced</p></td>
<td><p>medium</p></td>
<td><p>variable</p></td>
<td><p>yes</p></td>
</tr>
<tr class="row-odd"><td><p><span class="xref myst">Perf</span></p></td>
<td><p>Produce and visualize <span class="xref myst">profile</span></p></td>
<td><p>easy</p></td>
<td><p>medium</p></td>
<td><p>low</p></td>
<td><p>(no)<a class="footnote-reference brackets" href="#id78" id="id60" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a></p></td>
</tr>
<tr class="row-even"><td><p><span class="xref myst">PIKA</span></p></td>
<td><p>Show performance <span class="xref myst">profile</span> and <span class="xref myst">trace</span></p></td>
<td><p>very easy</p></td>
<td><p>low</p></td>
<td><p>very low</p></td>
<td><p>no</p></td>
</tr>
<tr class="row-odd"><td><p><span class="xref myst">Score-P</span></p></td>
<td><p>Create performance <span class="xref myst">trace</span></p></td>
<td><p>complex</p></td>
<td><p>high</p></td>
<td><p>variable</p></td>
<td><p>yes</p></td>
</tr>
<tr class="row-even"><td><p><span class="xref myst">Vampir</span></p></td>
<td><p>Visualize performance <span class="xref myst">trace</span></p></td>
<td><p>complex</p></td>
<td><p>high</p></td>
<td><p>n.a.</p></td>
<td><p>n.a.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="approach-and-terminology">
<h2>Approach and Terminology<a class="headerlink" href="#approach-and-terminology" title="Permalink to this heading">#</a></h2>
<p>Performance engineering typically is a cyclic process.
The following figure shows such a process and its potential stages.</p>
<p><img alt="Performance engineering cycle" src="63_chat_with_docs/misc/performance_engineering_cycle.svg" /></p>
<section id="instrumentation">
<h3>Instrumentation<a class="headerlink" href="#instrumentation" title="Permalink to this heading">#</a></h3>
<p>!!! hint ‚ÄúInstrumentation is a common term for preparing the performance measurement‚Äù</p>
<p>The engineering process typically begins with the original application in its unmodified state.
First, this application needs to be instrumented, i.e. it must be prepared to enable the
measurement of the performance properties.
There are different ways to do this, including manual instrumentation of the source code by the
user, automatic instrumentation by the compiler, linking against pre-instrumented libraries, or
interrupt-driven sampling during run time.</p>
</section>
<section id="measurement">
<h3>Measurement<a class="headerlink" href="#measurement" title="Permalink to this heading">#</a></h3>
<p>!!! note ‚ÄúDuring measurement, raw performance data is collected‚Äù</p>
<p>When an instrumented application is executed, the additional instructions introduced during the
instrumentation phase collect and record the data required to evaluate the performance properties
of the code.
Unfortunately, the measurement itself has a certain influence on the performance of the instrumented
code.
Whether the perturbations introduced have a significant effect on the behavior depends on the
specific structure of the code to be investigated.
In many cases, the perturbations will be rather small, so that the overall results can be considered
to be a realistic approximation of the corresponding properties of the non-instrumented code.
Yet, it is always advisable to compare the runtime of instrumented applications with their original
non-instrumented counterpart.</p>
<section id="profile">
<h4>Profile<a class="headerlink" href="#profile" title="Permalink to this heading">#</a></h4>
<p>!!! hint ‚ÄúPerformance profiles hold aggregated data (e.g. total time spent in function <code class="docutils literal notranslate"><span class="pre">foo()</span></code>)‚Äù</p>
<p>A performance profile provides aggregated metrics like <em>time</em> or <em>number of calls</em> for a list of
functions, loops or similar as depicted in the following table:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Function</p></th>
<th class="head text-right"><p>Total Time</p></th>
<th class="head text-right"><p>Calls</p></th>
<th class="head text-right"><p>Percentage</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">main()</span></code></p></td>
<td class="text-right"><p>2 s</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>1%</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">foo()</span></code></p></td>
<td class="text-right"><p>80 s</p></td>
<td class="text-right"><p>100</p></td>
<td class="text-right"><p>40%</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">bar()</span></code></p></td>
<td class="text-right"><p>118 s</p></td>
<td class="text-right"><p>9000</p></td>
<td class="text-right"><p>59%</p></td>
</tr>
</tbody>
</table>
</section>
<section id="trace">
<h4>Trace<a class="headerlink" href="#trace" title="Permalink to this heading">#</a></h4>
<!-- markdownlint-disable-next-line line-length -->
<p>!!! hint ‚ÄúTraces consist of a sorted list of timed application events/samples (e.g. enter function <code class="docutils literal notranslate"><span class="pre">foo()</span></code> at 0.11 s).‚Äù</p>
<p>In contrast to performance <span class="xref myst">profiles</span>, performance traces consist of individual
application samples or events that are recorded with a timestamp.
A trace that corresponds to the profile recording above could look as follows:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-right"><p>Timestamp</p></th>
<th class="head"><p>Data Type</p></th>
<th class="head"><p>Parameter</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-right"><p>0.10 s</p></td>
<td><p>Enter Function</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">main()</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>0.11 s</p></td>
<td><p>Enter Function</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">foo()</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>0.12 s</p></td>
<td><p>Enter Function</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">bar()</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>0.15 s</p></td>
<td><p>Exit Function</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">bar()</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>0.16 s</p></td>
<td><p>Enter Function</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">bar()</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>0.17 s</p></td>
<td><p>Exit Function</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">bar()</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-right"><p></p></td>
<td><p><em>many more events‚Ä¶</em></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>200.00 s</p></td>
<td><p>Exit Function</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">main()</span></code></p></td>
</tr>
</tbody>
</table>
<!-- markdownlint-disable-next-line line-length -->
<p>!!! hint ‚ÄúTraces enable more sophisticated analysis at the cost of potentially very large amounts of raw data.‚Äù</p>
<p>Apparently, the size of a performance trace depends on the recorded time whereas a profile does not.
Likewise, a trace can tell you when a specific action in your application happened whereas a profile
will tell you how much time in total a class of actions takes.</p>
</section>
</section>
<section id="analysis">
<h3>Analysis<a class="headerlink" href="#analysis" title="Permalink to this heading">#</a></h3>
<p>!!! note ‚ÄúWell defined performance metrics are derived from raw performance data during analysis‚Äù</p>
<p>The collected raw data is typically processed by a analysis tool (profiler, consistency checker, you
name it) to derive meaningful, well-defined performance metrics like data rates, data dependencies,
performance events of interest, etc.
This step is typically hidden to the user and taken care of automatically once the raw data was
collected.
Some tools, however, provide an independent analysis front-end that allows specifying the type of
analysis to carry out on the raw data.</p>
</section>
<section id="presentation">
<h3>Presentation<a class="headerlink" href="#presentation" title="Permalink to this heading">#</a></h3>
<p>!!! note ‚ÄúPresenting performance metrics graphically fosters human intuition‚Äù</p>
<p>After processing the raw performance data, the resulting metrics are usually presented in the form
of a report that makes use of tables or charts known from programs like Excel.
In this step, the reduction of the data complexity simplifies the evaluation of the data by software
developers.
Yet, data reductions have the potential to hide important facts or details.</p>
</section>
<section id="evaluation">
<h3>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this heading">#</a></h3>
<p>!!! note ‚ÄúThe evaluation of performance metrics requires tools and lots of thinking‚Äù</p>
<p>During the evaluation phase, the metrics and findings in a performance report are compared to the
behavior/performance as expected by software developers.
This step typically requires a fair amount of knowledge about the application under test or software
performance in general.
The application is considered to behave sufficiently well or weaknesses have been identified which
potentially can be improved.
An application or its configuration is changed in the later case.
After evaluating an application‚Äôs performance, the cyclic engineering process is either completed or
restarted from beginning.</p>
</section>
</section>
<section id="installed-tools-summary">
<h2>Installed Tools Summary<a class="headerlink" href="#installed-tools-summary" title="Permalink to this heading">#</a></h2>
<p>At ZIH, the following performance engineering tools are installed and maintained:</p>
<section id="lo2s">
<h3>lo2s<a class="headerlink" href="#lo2s" title="Permalink to this heading">#</a></h3>
<p>!!! hint ‚ÄúEasy to use application and system performance trace recorder supporting Vampir‚Äù</p>
<p><span class="xref myst">lo2s</span> records the status of an application at fixed intervals (statistical sampling).
It does not require any <span class="xref myst">instrumentation</span>.
The <span class="xref myst">measurement</span> of a given application is done by pre-fixing the application‚Äôs
executable with <code class="docutils literal notranslate"><span class="pre">lo2s</span></code>.
The data analysis of the fixed metrics is fully integrated and does not require any user actions.
Performance data is written to a <span class="xref myst">traces</span> repository at the current directory.
See <span class="xref myst">lo2s</span> for further details.
Once the data have been recorded, the tool <span class="xref myst">Vampir</span> needs to be invoked to study the data
graphically.</p>
</section>
<section id="id61">
<h3>MUST<a class="headerlink" href="#id61" title="Permalink to this heading">#</a></h3>
<!-- markdownlint-disable-next-line line-length -->
<p>!!! hint ‚ÄúAdvanced communication error detection for applications using the Message Passing Interface (MPI) standard.‚Äù</p>
<p><span class="xref myst">MUST</span> checks your application for communication errors if the MPI
library is used.
It does not require any <span class="xref myst">instrumentation</span>.
The checks of a given MPI application are done by simply replacing <code class="docutils literal notranslate"><span class="pre">srun</span></code> with <code class="docutils literal notranslate"><span class="pre">mustrun</span></code> when the
application is started.
The data analysis of the fixed metrics is fully integrated and does not require any user actions.
The correctness results are written to an HTML-formatted output file, which can be inspected with a
web browser.</p>
</section>
<section id="papi">
<h3>PAPI<a class="headerlink" href="#papi" title="Permalink to this heading">#</a></h3>
<p>!!! hint ‚ÄúPortable reading of CPU performance metrics like FLOPS‚Äù</p>
<p>The <span class="xref myst">PAPI</span> library allows software developers to read CPU performance counters in a
platform-independent way.
Native usage of the library requires to manually <span class="xref myst">instrument</span> an application by
adding library calls to the source code of the application under investigation.
Data <span class="xref myst">measurement</span> happens whenever the PAPI library is called.
The data obtained is raw data.
Software developers have to process the data by themselves to obtain meaningful metrics.
Tools like <span class="xref myst">Score-P</span> have built-in support for PAPI.
Therefore, native usage of the PAPI library is usually not needed.</p>
</section>
<section id="perf-tools">
<h3>Perf Tools<a class="headerlink" href="#perf-tools" title="Permalink to this heading">#</a></h3>
<p>!!! hint ‚ÄúEasy to use Linux-integrated performance data recording and analysis‚Äù</p>
<p><span class="xref myst">Linux perf</span> reads and analyses CPU performance counters for any given application.
It does not require any <span class="xref myst">instrumentation</span>.
The <span class="xref myst">measurement</span> of a given application is done by simply prefixing the application
executable with <code class="docutils literal notranslate"><span class="pre">perf</span></code>.
Perf has two modes of operation (<code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">stat</span></code>, <code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">record</span></code>), which both record <span class="xref myst">profile</span>
raw data.
While the first mode is very basic, the second mode records more data.
Use <code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">report</span></code> to analyze the raw output data of <code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">record</span></code> and produce a performance report.
See <span class="xref myst">Linux perf</span> for further details.</p>
</section>
<section id="pika">
<h3>PIKA<a class="headerlink" href="#pika" title="Permalink to this heading">#</a></h3>
<p>!!! hint ‚ÄúVery easy to use performance visualization of entire batch jobs‚Äù</p>
<p><span class="xref myst">PIKA</span> allows users to study their active and completed
<span class="xref myst">batch jobs</span>.
It does not require any <span class="xref myst">instrumentation</span>.
The <span class="xref myst">measurement</span> of batch jobs happens automatically in the background for all batch
jobs.
The data analysis of the given set of metrics is fully integrated and does not require any user
actions.
Performance metrics are accessible via the
<a class="reference external" href="https://pika.zih.tu-dresden.de/">PIKA web service</a>.</p>
</section>
<section id="score-p">
<h3>Score-P<a class="headerlink" href="#score-p" title="Permalink to this heading">#</a></h3>
<p>!!! hint ‚ÄúComplex and powerful performance data recording and analysis of parallel applications‚Äù</p>
<p><span class="xref myst">Score-P</span> is an advanced tool that measures configurable performance event data.
It generates both <span class="xref myst">profiles</span> and detailed <span class="xref myst">traces</span> for subsequent analysis.
It supports automated <span class="xref myst">instrumentation</span> of an application (involves
re-compilation) prior to the <span class="xref myst">measurement</span> step.
The data analysis of the raw performance data can be carried out with the tools <code class="docutils literal notranslate"><span class="pre">scalasca</span></code>
(advanced MPI metrics), <code class="docutils literal notranslate"><span class="pre">cube</span></code> (<span class="xref myst">profile</span> viewer), <code class="docutils literal notranslate"><span class="pre">scorep-score</span></code> (<span class="xref myst">profile</span>
command line viewer), or <span class="xref myst">Vampir</span> (<span class="xref myst">trace</span> viewer).
Many raw data sources are supported by Score-P.
It requires some time, training, and practice to fully benefit from the tool‚Äôs features.
See <span class="xref myst">Score-P</span> for further details.</p>
</section>
<section id="vampir">
<h3>Vampir<a class="headerlink" href="#vampir" title="Permalink to this heading">#</a></h3>
<p>!!! hint ‚ÄúComplex and powerful performance data visualization of parallel applications‚Äù</p>
<p><span class="xref myst">Vampir</span> is a graphical analysis tool that provides a large set of different chart
representations for performance data <span class="xref myst">traces</span> generated by tools such as
<span class="xref myst">Score-P</span> or <span class="xref myst">lo2s</span>.
Complex statistics, timelines, and state diagrams can be used by software developers to obtain a
better understanding of the inner working of a parallel application.
The tool requires some time, training, and practice to fully benefit from its rich set of features.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="produce-performance-overview-with-perf">
<h1>Produce Performance Overview with Perf<a class="headerlink" href="#produce-performance-overview-with-perf" title="Permalink to this heading">#</a></h1>
<p>The Linux <code class="docutils literal notranslate"><span class="pre">perf</span></code> command provides support for sampling applications and reading performance
counters. <code class="docutils literal notranslate"><span class="pre">perf</span></code> consists of two parts: the kernel space implementation and the userland tools.
This compendium page focusses on the latter.</p>
<p>For detailed information, please refer to the <a class="reference external" href="https://perf.wiki.kernel.org/index.php/Main_Page">perf
documentation</a> and the comprehensive
<a class="reference external" href="https://www.brendangregg.com/perf.html">perf examples page</a> of Brendan Gregg.</p>
<section id="configuration">
<h2>Configuration<a class="headerlink" href="#configuration" title="Permalink to this heading">#</a></h2>
<p>Admins can change the behaviour of the perf tools kernel part via the
following interfaces</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>File Name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">/proc/sys/kernel/perf_event_max_sample_rate</span></code></p></td>
<td><p>Describes the maximal sample rate for perf record and native access. This is used to limit the performance influence of sampling.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">/proc/sys/kernel/perf_event_mlock_kb</span></code></p></td>
<td><p>Defines the number of pages that can be used for sampling via perf record or the native interface</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">/proc/sys/kernel/perf_event_paranoid</span></code></p></td>
<td><p>Defines access rights:</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>-1 - Not paranoid at all</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>0 - Disallow raw tracepoint access for unpriv</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>1 - Disallow cpu events for unpriv</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>2 - Disallow kernel profiling for unpriv</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">/proc/sys/kernel/kptr_restrict</span></code></p></td>
<td><p>Defines whether the kernel address maps are restricted</p></td>
</tr>
</tbody>
</table>
</section>
<section id="perf-stat">
<h2>Perf Stat<a class="headerlink" href="#perf-stat" title="Permalink to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">stat</span></code> provides a general performance statistic for a program. You
can attach to a running (own) process, monitor a new process or monitor
the whole system. The latter is only available for root user, as the
performance data can provide hints on the internals of the application.</p>
<section id="for-users">
<h3>For Users<a class="headerlink" href="#for-users" title="Permalink to this heading">#</a></h3>
<p>Run <code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">stat</span> <span class="pre">&lt;Your</span> <span class="pre">application&gt;</span></code>. This will provide you with a general
overview on some counters. The following listing holds an exemplary output for sampling the <code class="docutils literal notranslate"><span class="pre">ls</span></code>
command.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>perf<span class="w"> </span>stat<span class="w"> </span>ls
<span class="go">[...]</span>
<span class="go">Performance counter stats for &#39;ls&#39;:=</span>
<span class="go">          2,524235 task-clock                #    0,352 CPUs utilized</span>
<span class="go">                15 context-switches          #    0,006 M/sec</span>
<span class="go">                 0 CPU-migrations            #    0,000 M/sec</span>
<span class="go">               292 page-faults               #    0,116 M/sec</span>
<span class="go">         6.431.241 cycles                    #    2,548 GHz</span>
<span class="go">         3.537.620 stalled-cycles-frontend   #   55,01% frontend cycles idle</span>
<span class="go">         2.634.293 stalled-cycles-backend    #   40,96% backend  cycles idle</span>
<span class="go">         6.157.440 instructions              #    0,96  insns per cycle</span>
<span class="gp">                                             #    </span><span class="m">0</span>,57<span class="w">  </span>stalled<span class="w"> </span>cycles<span class="w"> </span>per<span class="w"> </span>insn
<span class="go">         1.248.527 branches                  #  494,616 M/sec</span>
<span class="go">            34.044 branch-misses             #    2,73% of all branches</span>
<span class="go">       0,007167707 seconds time elapsed</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Generally speaking <strong>task clock</strong> tells you how parallel your job
has been/how many cpus were used.</p></li>
<li><p><a class="reference external" href="http://en.wikipedia.org/wiki/Context_switch">Context switches</a>
are an information about how the scheduler treated the application.  Also interrupts cause context
switches. Lower is better.</p></li>
<li><p><strong>CPU migrations</strong> are an information on whether the scheduler moved
the application between cores. Lower is better. Please pin your programs to CPUs to avoid
migrations. This can be done with environment variables for OpenMP and MPI, with <code class="docutils literal notranslate"><span class="pre">likwid-pin</span></code>,
<code class="docutils literal notranslate"><span class="pre">numactl</span></code> and <code class="docutils literal notranslate"><span class="pre">taskset</span></code>.</p></li>
<li><p><a class="reference external" href="http://en.wikipedia.org/wiki/Page_fault">Page faults</a> describe
how well the Translation Lookaside Buffers fit for the program.  Lower is better.</p></li>
<li><p><strong>Cycles</strong> tells you how many CPU cycles have been spent in
executing the program. The normalized value tells you the actual average frequency of the CPU(s)
running the application.</p></li>
<li><p><strong>stalled-cycles-‚Ä¶</strong> tell you how well the processor can execute
your code. Every stall cycle is a waste of CPU time and energy. The reason for such stalls can be
numerous. It can be wrong branch predictions, cache misses, occupation of CPU resources by long
running instructions and so on. If these stall cycles are to high you might want to review your
code.</p></li>
<li><p>The normalized <strong>instructions</strong> number tells you how well your code
is running. More is better. Current x86 CPUs can run 3 to 5 instructions per cycle, depending on
the instruction mix. A count of less then 1 is not favorable. In such a case you might want to
review your code.</p></li>
<li><p><strong>branches</strong> and <strong>branch-misses</strong> tell you how many jumps and loops
are performed in your code. Correctly <a class="reference external" href="http://en.wikipedia.org/wiki/Branch_prediction">predicted</a>
branches should not hurt your performance, <strong>branch-misses</strong> on the other hand hurt your
performance very badly and lead to stall cycles.</p></li>
<li><p>Other events can be passed with the <code class="docutils literal notranslate"><span class="pre">-e</span></code> flag. For a full list of
predefined events run <code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">list</span></code></p></li>
<li><p>PAPI runs on top of the same infrastructure as <code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">stat</span></code>, so you
might want to use their meaningful event names. Otherwise you can use raw events, listed in the
processor manuals.</p></li>
</ul>
</section>
<section id="for-admins">
<h3>For Admins<a class="headerlink" href="#for-admins" title="Permalink to this heading">#</a></h3>
<p>Administrators can run a system wide performance statistic, e.g., with <code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">stat</span> <span class="pre">-a</span> <span class="pre">sleep</span> <span class="pre">1</span></code> which
measures the performance counters for the whole computing node over one second.</p>
</section>
</section>
<section id="perf-record">
<h2>Perf Record<a class="headerlink" href="#perf-record" title="Permalink to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">record</span></code> provides the possibility to sample an application or a system. You can find
performance issues and hot parts of your code. By default <code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">record</span></code> samples your program at 4000
Hz. It records CPU, Instruction Pointer and, if you specify it, the call chain. If your code runs
long (or often) enough, you can find hot spots in your application and external libraries.
Use <span class="xref myst">perf report</span> to evaluate the result. You should have debug symbols available,
otherwise you won‚Äôt be able to see the name of the functions that are responsible for your load. You
can pass one or multiple events to define the <strong>sampling event</strong>.</p>
<p>!!! note ‚ÄúWhat is a sampling event?‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Sampling reads values at a specific sampling frequency. This frequency is usually static and
given in Hz, so you have for example 4000 events per second and a sampling frequency of 4000 Hz
and a sampling rate of 250 microseconds. With the sampling event, the concept of a static
sampling frequency in time is somewhat redefined. Instead of a constant factor in time (sampling
rate) you define a constant factor in events. So instead of a sampling rate of 250 microseconds,
you have a sampling rate of 10,000 floating point operations.
</pre></div>
</div>
<p>!!! note ‚ÄúWhy would you need sampling events?‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Passing an event allows you to find the functions that produce cache misses, floating point
operations, ... Again, you can use events defined in `perf list` and raw events.
</pre></div>
</div>
<p>Use the <code class="docutils literal notranslate"><span class="pre">-g</span></code> flag to receive a call graph.</p>
<section id="id62">
<h3>For Users<a class="headerlink" href="#id62" title="Permalink to this heading">#</a></h3>
<p>Just run <code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">record</span> <span class="pre">./myapp</span></code> or attach to a running process.</p>
<section id="using-perf-with-mpi">
<h4>Using Perf with MPI<a class="headerlink" href="#using-perf-with-mpi" title="Permalink to this heading">#</a></h4>
<p>Perf can also be used to record data for indivdual MPI processes. This requires a wrapper script
(<code class="docutils literal notranslate"><span class="pre">perfwrapper</span></code>) with the following content. Also make sure that the wrapper script is executable
(<code class="docutils literal notranslate"><span class="pre">chmod</span> <span class="pre">+x</span></code>).</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
perf<span class="w"> </span>record<span class="w"> </span>-o<span class="w"> </span>perf.data.<span class="nv">$SLURM_JOB_ID</span>.<span class="nv">$SLURM_PROCID</span><span class="w"> </span><span class="nv">$@</span>
</pre></div>
</div>
<p>To start the MPI program type <code class="docutils literal notranslate"><span class="pre">srun</span> <span class="pre">./perfwrapper</span> <span class="pre">./myapp</span></code> on your command line. The result will be
n independent <code class="docutils literal notranslate"><span class="pre">perf.data</span></code> files that can be analyzed individually using <code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">report</span></code>.</p>
</section>
</section>
<section id="id63">
<h3>For Admins<a class="headerlink" href="#id63" title="Permalink to this heading">#</a></h3>
<p>This tool is very effective, if you want to help users find performance problems and hot-spots in
their code but also helps to find OS daemons that disturb such applications. You would start <code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">record</span> <span class="pre">-a</span> <span class="pre">-g</span></code> to monitor the whole node.</p>
</section>
</section>
<section id="perf-report">
<h2>Perf Report<a class="headerlink" href="#perf-report" title="Permalink to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">report</span></code> is a command line UI for evaluating the results from perf record. It creates something
like a profile from the recorded samplings.  These profiles show you what the most used have been.
If you added a callchain, it also gives you a callchain profile.</p>
<p>!!! note ‚ÄúDisclaimer‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Sampling is not an appropriate way to gain exact numbers. So this is merely a rough overview and
not guaranteed to be absolutely correct.
</pre></div>
</div>
<section id="on-zih-systems">
<h3>On ZIH Systems<a class="headerlink" href="#on-zih-systems" title="Permalink to this heading">#</a></h3>
<p>On ZIH systems, users are not allowed to see the kernel functions. If you have multiple events
defined, then the first thing you select in <code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">report</span></code> is the type of event. Press the right
arrow key:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>Available<span class="w"> </span>samples
<span class="m">96</span><span class="w"> </span>cycles
<span class="m">11</span><span class="w"> </span>cache-misse
</pre></div>
</div>
<p>!!! hint</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>* The more samples you have, the more exact is the profile. 96 or
11 samples is not enough by far.
* Repeat the measurement and set `-F 50000` to increase the sampling frequency.
* The higher the frequency, the higher the influence on the measurement.
</pre></div>
</div>
<p>If you‚Äôd select cycles, you would get such a screen:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>Events:<span class="w"> </span><span class="m">96</span><span class="w">  </span>cycles
+<span class="w">  </span><span class="m">49</span>,13%<span class="w">  </span>test_gcc_perf<span class="w">  </span>test_gcc_perf<span class="w">      </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>main.omp_fn.0
+<span class="w">  </span><span class="m">34</span>,48%<span class="w">  </span>test_gcc_perf<span class="w">  </span>test_gcc_perf<span class="w">      </span><span class="o">[</span>.<span class="o">]</span>
+<span class="w">   </span><span class="m">6</span>,92%<span class="w">  </span>test_gcc_perf<span class="w">  </span>test_gcc_perf<span class="w">      </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>omp_get_thread_num@plt
+<span class="w">   </span><span class="m">5</span>,20%<span class="w">  </span>test_gcc_perf<span class="w">  </span>libgomp.so.1.0.0<span class="w">   </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>omp_get_thread_num
+<span class="w">   </span><span class="m">2</span>,25%<span class="w">  </span>test_gcc_perf<span class="w">  </span>test_gcc_perf<span class="w">      </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>main.omp_fn.1
+<span class="w">   </span><span class="m">2</span>,02%<span class="w">  </span>test_gcc_perf<span class="w">  </span><span class="o">[</span>kernel.kallsyms<span class="o">]</span><span class="w">  </span><span class="o">[</span>k<span class="o">]</span><span class="w"> </span>0xffffffff8102e9ea
</pre></div>
</div>
<p>With increased sample frequency, it might look like this:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>Events:<span class="w"> </span>7K<span class="w"> </span>cycles
+<span class="w">  </span><span class="m">42</span>,61%<span class="w">  </span>test_gcc_perf<span class="w">  </span>test_gcc_perf<span class="w">      </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>p
+<span class="w">  </span><span class="m">40</span>,28%<span class="w">  </span>test_gcc_perf<span class="w">  </span>test_gcc_perf<span class="w">      </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>main.omp_fn.0
+<span class="w">   </span><span class="m">6</span>,07%<span class="w">  </span>test_gcc_perf<span class="w">  </span>test_gcc_perf<span class="w">      </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>omp_get_thread_num@plt
+<span class="w">   </span><span class="m">5</span>,95%<span class="w">  </span>test_gcc_perf<span class="w">  </span>libgomp.so.1.0.0<span class="w">   </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>omp_get_thread_num
+<span class="w">   </span><span class="m">4</span>,14%<span class="w">  </span>test_gcc_perf<span class="w">  </span>test_gcc_perf<span class="w">      </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>main.omp_fn.1
+<span class="w">   </span><span class="m">0</span>,69%<span class="w">  </span>test_gcc_perf<span class="w">  </span><span class="o">[</span>kernel.kallsyms<span class="o">]</span><span class="w">  </span><span class="o">[</span>k<span class="o">]</span><span class="w"> </span>0xffffffff8102e9ea
+<span class="w">   </span><span class="m">0</span>,04%<span class="w">  </span>test_gcc_perf<span class="w">  </span>ld-2.12.so<span class="w">         </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>check_match.12442
+<span class="w">   </span><span class="m">0</span>,03%<span class="w">  </span>test_gcc_perf<span class="w">  </span>libc-2.12.so<span class="w">       </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span><span class="nb">printf</span>
+<span class="w">   </span><span class="m">0</span>,03%<span class="w">  </span>test_gcc_perf<span class="w">  </span>libc-2.12.so<span class="w">       </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>vfprintf
+<span class="w">   </span><span class="m">0</span>,03%<span class="w">  </span>test_gcc_perf<span class="w">  </span>libc-2.12.so<span class="w">       </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>__strchrnul
+<span class="w">   </span><span class="m">0</span>,03%<span class="w">  </span>test_gcc_perf<span class="w">  </span>libc-2.12.so<span class="w">       </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>_dl_addr
+<span class="w">   </span><span class="m">0</span>,02%<span class="w">  </span>test_gcc_perf<span class="w">  </span>ld-2.12.so<span class="w">         </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>do_lookup_x
+<span class="w">   </span><span class="m">0</span>,01%<span class="w">  </span>test_gcc_perf<span class="w">  </span>libc-2.12.so<span class="w">       </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>_int_malloc
+<span class="w">   </span><span class="m">0</span>,01%<span class="w">  </span>test_gcc_perf<span class="w">  </span>libc-2.12.so<span class="w">       </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>free
+<span class="w">   </span><span class="m">0</span>,01%<span class="w">  </span>test_gcc_perf<span class="w">  </span>libc-2.12.so<span class="w">       </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>__sigprocmask
+<span class="w">   </span><span class="m">0</span>,01%<span class="w">  </span>test_gcc_perf<span class="w">  </span>libgomp.so.1.0.0<span class="w">   </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>0x87de
+<span class="w">   </span><span class="m">0</span>,01%<span class="w">  </span>test_gcc_perf<span class="w">  </span>libc-2.12.so<span class="w">       </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>__sleep
+<span class="w">   </span><span class="m">0</span>,01%<span class="w">  </span>test_gcc_perf<span class="w">  </span>ld-2.12.so<span class="w">         </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>_dl_check_map_versions
+<span class="w">   </span><span class="m">0</span>,01%<span class="w">  </span>test_gcc_perf<span class="w">  </span>ld-2.12.so<span class="w">         </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>local_strdup
+<span class="w">   </span><span class="m">0</span>,00%<span class="w">  </span>test_gcc_perf<span class="w">  </span>libc-2.12.so<span class="w">       </span><span class="o">[</span>.<span class="o">]</span><span class="w"> </span>__execvpe
</pre></div>
</div>
<p>Now you select the most often sampled function and zoom into it by pressing the right arrow key. If
debug symbols are not available, <code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">report</span></code> will show which assembly instruction is hit most often
when sampling. If debug symbols are available, it will also show you the source code lines for
these assembly instructions. You can also go back and check which instruction caused the cache
misses or whatever event you were passing to <code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">record</span></code>.</p>
</section>
</section>
<section id="perf-script">
<h2>Perf Script<a class="headerlink" href="#perf-script" title="Permalink to this heading">#</a></h2>
<p>If you need a trace of the sampled data, you can use <code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">script</span></code> command, which by default prints
all samples to stdout. You can use various interfaces (e.g., Python) to process such a trace.</p>
</section>
<section id="perf-top">
<h2>Perf Top<a class="headerlink" href="#perf-top" title="Permalink to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">perf</span> <span class="pre">top</span></code> is only available for admins, as long as the paranoid flag is not changed (see
configuration).</p>
<p>It behaves like the <code class="docutils literal notranslate"><span class="pre">top</span></code> command, but gives you not only an overview of the processes and the time
they are consuming but also on the functions that are processed by these.</p>
</section>
<hr class="docutils" />
<section id="search-boost-4-0">
<h2>search:
boost: 4.0<a class="headerlink" href="#search-boost-4-0" title="Permalink to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="track-slurm-jobs-with-pika">
<h1>Track Slurm Jobs with PIKA<a class="headerlink" href="#track-slurm-jobs-with-pika" title="Permalink to this heading">#</a></h1>
<p>PIKA is a hardware performance monitoring stack to identify inefficient HPC jobs. Users of ZIH
systems have the possibility to visualize and analyze the efficiency of their jobs via the
<a class="reference external" href="https://pika.zih.tu-dresden.de">PIKA web interface</a>.</p>
<p>!!! hint</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>To understand this guide, it is recommended that you open the
[web interface](https://pika.zih.tu-dresden.de)
in a separate window. Furthermore, you should have submitted at least one real HPC job at ZIH
systems.

If you are outside the TUD network, you will need to establish a VPN connection. For more
information on our VPN and how to set it up, please visit the corresponding
[ZIH service catalog
page](https://tu-dresden.de/zih/dienste/service-katalog/arbeitsumgebung/zugang_datennetz/vpn).
</pre></div>
</div>
<section id="id64">
<h2>Overview<a class="headerlink" href="#id64" title="Permalink to this heading">#</a></h2>
<p>PIKA consists of several components and tools. It uses the collection daemon collectd, InfluxDB to
store time-series data and MariaDB to store job metadata. Furthermore, it provides a powerful
<a class="reference external" href="https://pika.zih.tu-dresden.de">web interface</a>
for the visualization and analysis of job performance data.</p>
</section>
<section id="table-view-and-job-search">
<h2>Table View and Job Search<a class="headerlink" href="#table-view-and-job-search" title="Permalink to this heading">#</a></h2>
<p>The analysis of HPC jobs in PIKA is designed as a top-down approach. Starting from the table view,
you can either analyze running or completed jobs. You can navigate from groups of jobs with the
same name to the metadata of an individual job and finally investigate the job‚Äôs runtime metrics in
a timeline view.</p>
<p>To find jobs with specific properties, you can sort the table by any column, e.g., by consumed CPU
hours to find jobs where an optimization has a large impact on the system utilization. Additionally,
there is a filter mask to find jobs that match several properties. When a job has been selected, the
timeline view opens.</p>
</section>
<section id="timeline-visualization">
<h2>Timeline Visualization<a class="headerlink" href="#timeline-visualization" title="Permalink to this heading">#</a></h2>
<p>PIKA provides timeline charts to visualize the resource utilization of a job over time. After a job
is completed, timeline charts can help you to identify periods of inefficient resource usage.
However, they are also suitable for the live assessment of performance during the job‚Äôs runtime. In
case of unexpected performance behavior, you can cancel the job, thus avoiding long execution with
subpar performance.</p>
<p>The following timeline visualization shows a job with 840 cores, spread over 35 (dual-socket
Haswell) nodes that have been allocated for exclusive use.</p>
<p><img alt="Timeline Visualization" src="63_chat_with_docs/misc/pika_timelines.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>PIKA provides the following runtime metrics:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Metric</p></th>
<th class="head"><p>Hardware Unit</p></th>
<th class="head text-right"><p>Sampling Frequency</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>CPU Usage</p></td>
<td><p>CPU core (average across hardware threads)</p></td>
<td class="text-right"><p>30s</p></td>
</tr>
<tr class="row-odd"><td><p>IPC (instructions per cycle)</p></td>
<td><p>CPU core (sum over hardware threads)</p></td>
<td class="text-right"><p>60s</p></td>
</tr>
<tr class="row-even"><td><p>FLOPS (normalized to single precision)</p></td>
<td><p>CPU core (sum over hardware threads)</p></td>
<td class="text-right"><p>60s</p></td>
</tr>
<tr class="row-odd"><td><p>Main Memory Bandwidth</p></td>
<td><p>CPU socket</p></td>
<td class="text-right"><p>60s</p></td>
</tr>
<tr class="row-even"><td><p>CPU Power</p></td>
<td><p>CPU socket</p></td>
<td class="text-right"><p>60s</p></td>
</tr>
<tr class="row-odd"><td><p>Main Memory Utilization</p></td>
<td><p>node</p></td>
<td class="text-right"><p>30s</p></td>
</tr>
<tr class="row-even"><td><p>I/O Bandwidth (local, Lustre)</p></td>
<td><p>node</p></td>
<td class="text-right"><p>30s</p></td>
</tr>
<tr class="row-odd"><td><p>I/O Metadata (local, Lustre)</p></td>
<td><p>node</p></td>
<td class="text-right"><p>30s</p></td>
</tr>
<tr class="row-even"><td><p>Network Bandwidth</p></td>
<td><p>node</p></td>
<td class="text-right"><p>30s</p></td>
</tr>
<tr class="row-odd"><td><p>GPU Usage</p></td>
<td><p>GPU device</p></td>
<td class="text-right"><p>30s</p></td>
</tr>
<tr class="row-even"><td><p>GPU Memory Utilization</p></td>
<td><p>GPU device</p></td>
<td class="text-right"><p>30s</p></td>
</tr>
<tr class="row-odd"><td><p>GPU Power Consumption</p></td>
<td><p>GPU device</p></td>
<td class="text-right"><p>30s</p></td>
</tr>
<tr class="row-even"><td><p>GPU Temperature</p></td>
<td><p>GPU device</p></td>
<td class="text-right"><p>30s</p></td>
</tr>
</tbody>
</table>
<p>Each monitored metric is represented by a timeline, whereby metrics with the same unit and data
source are displayed in a common chart, e.g., different Lustre metadata operations. Each metric is
measured with a certain granularity concerning the hardware, e.g. per hardware thread, per CPU
socket or per node.
Most metrics are recorded every 30 seconds except IPC, FLOPS, Main Memory Bandwidth and Power
Consumption. The latter are determined every 60 seconds, as they are a combination of different
hardware counters, which leads to a higher measurement overhead. Depending on the architecture,
metrics such as normalized FLOPS (2 x double-precision + 1 x single-precision) can require
multiplexing, since single and double precision FLOPS cannot be measured simultaneously.
The sampling frequency cannot be changed by the user.</p>
<p>!!! hint</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Be aware that CPU socket or node metrics can share the resources of other jobs running on the
same CPU socket or node. This can result e.g., in cache perturbation and thus a sub-optimal
performance. To get valid performance data for those metrics, it is recommended to submit an
exclusive job (`--exclusive`)!
</pre></div>
</div>
<p>If the current partition supports simultaneous multithreading (SMT) the maximum number of hardware
threads per physical core is displayed in the SMT column. The Slurm configuration on ZIH systems
disables SMT by default. Therefore, in the example below, only a maximum CPU usage of 0.5 can be
achieved, as PIKA determines the average value over two hardware threads per physical core.
If you want to use SMT, you must set the Slurm environment variable <code class="docutils literal notranslate"><span class="pre">SLURM_HINT=multithread</span></code>.
In this case, <code class="docutils literal notranslate"><span class="pre">srun</span></code> distributes the tasks to all available hardware threads, thus a CPU usage of 1
can be reached. However, the SMT configuration only refers to the <code class="docutils literal notranslate"><span class="pre">srun</span></code> command. For single node
jobs without <code class="docutils literal notranslate"><span class="pre">srun</span></code> command the tasks are automatically distributed to all available hardware
threads.</p>
<p><img alt="SMT Mode" src="63_chat_with_docs/misc/pika_smt_2.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>To reduce the amount of recorded data, PIKA summarizes per hardware thread metrics to the
corresponding physical core. In terms of simultaneous multithreading (SMT), PIKA only provides
performance data per physical core. For CPU usage, the average value per measurement point across
all hardware threads is calculated, while for IPC and FLOPS, the sum per measurement point is determined.
</pre></div>
</div>
<p>The following table explains different timeline visualization modes.
By default, each timeline shows the average value over all hardware units (HUs) per measured
interval.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Visualization Mode</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Maximum</p></td>
<td><p>maximal value across all HUs per measured interval</p></td>
</tr>
<tr class="row-odd"><td><p>Mean</p></td>
<td><p>mean value across all HUs per measured interval</p></td>
</tr>
<tr class="row-even"><td><p>Minimum</p></td>
<td><p>minimal value across all HUs per measured interval</p></td>
</tr>
<tr class="row-odd"><td><p>Mean + Standard Deviation</p></td>
<td><p>mean value across all HUs including standard deviation per measured interval</p></td>
</tr>
<tr class="row-even"><td><p>Best</p></td>
<td><p>best average HU over time</p></td>
</tr>
<tr class="row-odd"><td><p>Lowest</p></td>
<td><p>lowest average HU over time</p></td>
</tr>
</tbody>
</table>
<p>The visualization modes <em>Maximum</em>, <em>Mean</em>, and <em>Minimum</em> reveal the range in the utilization of
individual HUs per measured interval. A high deviation of the extrema from the mean value is a
reason for further investigation, since not all HUs are equally utilized.</p>
<p>To identify imbalances between HUs over time, the visualization modes <em>Best</em> and <em>Lowest</em> are a
first indicator how much the HUs differ in terms of resource usage. The timelines <em>Best</em> and
<em>Lowest</em> show the recorded performance data of the best/lowest average HU over time.</p>
<p>!!! note ‚ÄúMore Details‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you want to conduct further analysis, you can download the job data as json-file(s) via the
button in the top right section:

![Downlaod Jobdata](misc/pika_download_jobdata.png){ align=left}
The options are

- Metadata: Data shown in table (project, start, end, ...), jobscript, min/max/mean statistics
- Performance Data: Data records of all metrics of every distinct device (CPU cores, GPUs, ...)
- Cluster Data: Metadata of used partition

&lt;br&gt;

??? example &quot;Example: Visualize every CPU core that was allocated for the Job&quot;

    ```python
    #in JupyterLab/Jupyter Notebook, using pandas and matplotlib
    #download the &quot;Performance Data&quot; and save as &quot;jobdata.json&quot;

    %pylab widget
    from pandas import read_json

    data = read_json(&#39;/tmp/jobdata.json&#39;, lines=True)
    for cpu in data[&#39;cpu_used&#39;][0][&#39;core&#39;][&#39;series&#39;]:
        plot(cpu[&#39;data&#39;], lw=0.5)
    ```
</pre></div>
</div>
</section>
<section id="footprint-visualization">
<h2>Footprint Visualization<a class="headerlink" href="#footprint-visualization" title="Permalink to this heading">#</a></h2>
<p>Complementary to the timeline visualization of one specific job, statistics on metadata and
footprints over multiple jobs or a group of jobs with the same name can be displayed with the
footprint view.  The performance footprint is a set of summarized run-time metrics that is generated
from the time series data for each job.  To limit the jobs displayed, a time period can be
specified.</p>
<p>To analyze the footprints of a larger number of jobs, a visualization with histograms and scatter
plots can be used. PIKA uses histograms to illustrate the number of jobs that fit into a category or
bin. For job states and job tags there is a fixed number of categories or values. For other
footprint metrics PIKA uses a binning with a user-configurable bin size, since the value range
usually contains an unlimited number of values.  A scatter plot enables the combined view of two
footprint metrics (except for job states and job tags), which is particularly useful for
investigating their correlation.</p>
<p><img alt="Footprint" src="63_chat_with_docs/misc/pika_footprint.png" />
{: align=‚Äùcenter‚Äù}</p>
</section>
<section id="hints">
<h2>Hints<a class="headerlink" href="#hints" title="Permalink to this heading">#</a></h2>
<p>If you wish to perform your own measurement of performance counters using performance tools other
than PIKA, it is recommended to disable PIKA monitoring. This can be done using the following Slurm
flags in the job script:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span><span class="c1">#SBATCH --exclusive</span>
<span class="c1">#SBATCH --constraint=no_monitoring</span>
</pre></div>
</div>
<p><strong>Note:</strong> Disabling PIKA monitoring is possible only for exclusive jobs!</p>
</section>
<section id="case-studies">
<h2>Case Studies<a class="headerlink" href="#case-studies" title="Permalink to this heading">#</a></h2>
<section id="idle-cpus">
<h3>Idle CPUs<a class="headerlink" href="#idle-cpus" title="Permalink to this heading">#</a></h3>
<p><img alt="CPU Idle" src="63_chat_with_docs/misc/pika_cpu_idle.png" />
{: align=‚Äùcenter‚Äù}</p>
</section>
<section id="blocking-i-o-operations">
<h3>Blocking I/O Operations<a class="headerlink" href="#blocking-i-o-operations" title="Permalink to this heading">#</a></h3>
<p><img alt="I/O Blocking" src="63_chat_with_docs/misc/pika_io_block.png" />
{: align=‚Äùcenter‚Äù}</p>
</section>
<section id="memory-leaks">
<h3>Memory Leaks<a class="headerlink" href="#memory-leaks" title="Permalink to this heading">#</a></h3>
<p><img alt="Memory Leaking" src="63_chat_with_docs/misc/pika_mem_leak.png" />
{: align=‚Äùcenter‚Äù}</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="machine-learning-with-powerai">
<h1>Machine Learning with PowerAI<a class="headerlink" href="#machine-learning-with-powerai" title="Permalink to this heading">#</a></h1>
<p>There are different documentation sources for users to learn more about
the PowerAI Framework for Machine Learning. In the following the links
are valid for PowerAI version 1.5.4.</p>
<p>!!! warning
The information provided here is available from IBM and can be used on the <code class="docutils literal notranslate"><span class="pre">Power9</span></code> cluster only!</p>
<section id="general-overview">
<h2>General Overview<a class="headerlink" href="#general-overview" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://www.ibm.com/support/knowledgecenter/en/SS5SF7_1.5.3/welcome/welcome.htm">PowerAI Introduction</a>
(note that you can select different PowerAI versions with the drop down menu
‚ÄúChange Product or version‚Äù)</p></li>
<li><p><a class="reference external" href="https://developer.ibm.com/linuxonpower/deep-learning-powerai/">PowerAI Developer Portal</a>
(Some Use Cases and examples)</p></li>
<li><p><a class="reference external" href="https://www.ibm.com/support/knowledgecenter/en/SS5SF7_1.5.4/navigation/pai_software_pkgs.html">Included Software Packages</a>
(note that you can select different PowerAI versions with the drop down menu ‚ÄúChange Product
or version‚Äù)</p></li>
</ul>
</section>
<section id="specific-user-guides">
<h2>Specific User Guides<a class="headerlink" href="#specific-user-guides" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://www.ibm.com/support/knowledgecenter/SS5SF7_1.5.4/navigation/pai_getstarted.htm">Getting Started with PowerAI</a></p></li>
<li><p><a class="reference external" href="https://www.ibm.com/support/knowledgecenter/SS5SF7_1.5.4/navigation/pai_getstarted_caffe.html">Caffe</a></p></li>
<li><p><a class="reference external" href="https://www.ibm.com/support/knowledgecenter/SS5SF7_1.5.4/navigation/pai_getstarted_tensorflow.html?view=kc">TensorFlow</a></p></li>
<li><p><a class="reference external" href="https://www.ibm.com/support/knowledgecenter/SS5SF7_1.5.4/navigation/pai_getstarted_tensorflow_prob.html?view=kc">TensorFlow Probability</a>
This release of PowerAI includes TensorFlow Probability. TensorFlow Probability is a library
for probabilistic reasoning and statistical analysis in TensorFlow.</p></li>
<li><p><a class="reference external" href="https://www.ibm.com/support/knowledgecenter/SS5SF7_1.5.4/navigation/pai_getstarted_tensorboard.html?view=kc">TensorBoard</a></p></li>
<li><p><a class="reference external" href="https://www.ibm.com/support/knowledgecenter/SS5SF7_1.5.4/navigation/pai_getstarted_snapml.html">Snap ML</a>
This release of PowerAI includes Snap Machine Learning (Snap ML). Snap ML is a library for
training generalized linear models. It is being developed at IBM with the
vision to remove training time as a bottleneck for machine learning
applications. Snap ML supports many classical machine learning
models and scales gracefully to data sets with billions of examples
or features. It also offers distributed training, GPU acceleration,
and supports sparse data structures.</p></li>
<li><p><a class="reference external" href="https://www.ibm.com/support/knowledgecenter/SS5SF7_1.5.4/navigation/pai_getstarted_pytorch.html">PyTorch</a>
This release of PowerAI includes
the community development preview of PyTorch 1.0 (rc1). PowerAI‚Äôs
PyTorch includes support for IBM‚Äôs Distributed Deep Learning (DDL)
and Large Model Support (LMS).</p></li>
<li><p><a class="reference external" href="https://www.ibm.com/support/knowledgecenter/SS5SF7_1.5.4/navigation/pai_getstarted_caffe2ONNX.html">Caffe2 and ONNX</a>
This release of PowerAI includes a Technology Preview of Caffe2 and ONNX. Caffe2 is a
companion to PyTorch. PyTorch is great for experimentation and rapid
development, while Caffe2 is aimed at production environments. ONNX
(Open Neural Network Exchange) provides support for moving models
between those frameworks.</p></li>
<li><p><a class="reference external" href="https://www.ibm.com/support/knowledgecenter/SS5SF7_1.5.4/navigation/pai_getstarted_ddl.html?view=kc">Distributed Deep Learning</a>
Distributed Deep Learning (DDL). Works on up to 4 nodes on cluster <code class="docutils literal notranslate"><span class="pre">Power9</span></code>.</p></li>
</ul>
</section>
<section id="powerai-container">
<h2>PowerAI Container<a class="headerlink" href="#powerai-container" title="Permalink to this heading">#</a></h2>
<p>We have converted the official Docker container to Singularity. Here is
a documentation about the Docker base container, including a table with
the individual software versions of the packages installed within the
container: <a class="reference external" href="https://hub.docker.com/r/ibmcom/powerai/">PowerAI Docker Container</a>.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="private-modules">
<h1>Private Modules<a class="headerlink" href="#private-modules" title="Permalink to this heading">#</a></h1>
<p>Private module files allow you to load your own installed software packages into your environment
and to handle different versions without getting into conflicts. Private modules can be setup for a
<strong>single user</strong> as well as <strong>all users of a project group</strong>. The workflow and settings for user
private as well as project private module files are described in the following.</p>
<section id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h2>
<section id="build-and-install-software">
<h3>0. Build and Install Software<a class="headerlink" href="#build-and-install-software" title="Permalink to this heading">#</a></h3>
<p>Obviously the first step is to build and install the software you‚Äôd like to use. Please follow the
instructions and tips provided on the page <span class="xref myst">building_software</span>.
For consistency, we use the placeholder variable <code class="docutils literal notranslate"><span class="pre">&lt;sw_name&gt;</span></code> in this documentation. When following this
instructions, please substitute it with the actual software name within the commands.</p>
</section>
<section id="create-directory">
<h3>1. Create Directory<a class="headerlink" href="#create-directory" title="Permalink to this heading">#</a></h3>
<p>Now, create the directory <code class="docutils literal notranslate"><span class="pre">privatemodules</span></code> to store all your private module files and the directory
<code class="docutils literal notranslate"><span class="pre">sw_name</span></code> therein. All module files for different versions or build options of <code class="docutils literal notranslate"><span class="pre">sw_name</span></code> should be
located in this directory.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ cd $</span>HOME
<span class="gp">marie@compute$ </span>mkdir<span class="w"> </span>--verbose<span class="w"> </span>--parents<span class="w"> </span>privatemodules/&lt;sw_name&gt;
<span class="gp">marie@compute$ </span><span class="nb">cd</span><span class="w"> </span>privatemodules/&lt;sw_name&gt;
</pre></div>
</div>
<p>Project private module files for software that can be used by all members of your group should be
located in your global projects directory, e.g., <code class="docutils literal notranslate"><span class="pre">/projects/p_number_crunch/privatemodules</span></code>. Thus, create
this directory:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>mkdir<span class="w"> </span>--verbose<span class="w"> </span>--parents<span class="w"> </span>/projects/p_number_crunch/privatemodules/&lt;sw_name&gt;
<span class="gp">marie@compute$ </span><span class="nb">cd</span><span class="w"> </span>/projects/p_number_crunch/privatemodules/&lt;sw_name&gt;
</pre></div>
</div>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Make sure, that the directory is group-readable.
</pre></div>
</div>
</section>
<section id="create-modulefile">
<h3>2. Create Modulefile<a class="headerlink" href="#create-modulefile" title="Permalink to this heading">#</a></h3>
<p>Within the directory <code class="docutils literal notranslate"><span class="pre">&lt;sw_name&gt;</span></code> create the module file. The file can either be a TCL or a Lua. We
recommend to use Lua. The module file name should reflect the particular version of the software,
e.g., <code class="docutils literal notranslate"><span class="pre">1.4.lua</span></code>.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you create a group private module file, make sure it is group-readable.
</pre></div>
</div>
<p>A template module file is:</p>
<div class="highlight-lua notranslate"><div class="highlight"><pre><span></span>help([[

Description
===========
&lt;sw_name&gt; is ...

More Information
================
For detailed instructions, go to:
   https://...

]])

whatis(&quot;Version: 1.4&quot;)
whatis(&quot;Keywords: [System, Utility, ...]&quot;)
whatis(&quot;URL: &lt;...&gt;&quot;)
whatis(&quot;Description: &lt;...&gt;&quot;)

conflict(&quot;&lt;sw_name&gt;&quot;)

local root = &quot;&lt;/path/to/installation&gt;&quot;
prepend_path( &quot;PATH&quot;,            pathJoin(root, &quot;bin&quot;))
prepend_path( &quot;LD_LIBRARY_PATH&quot;, pathJoin(root, &quot;lib&quot;))
prepend_path( &quot;LIBRARY_PATH&quot;, pathJoin(root, &quot;lib&quot;))

setenv(       &quot;&lt;SOME_ENV&gt;&quot;,        &quot;&lt;value&gt;&quot;)
</pre></div>
</div>
<p>The most important functions to adjust the environment are listed and described in the following
table.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Function</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">help([[</span> <span class="pre">help</span> <span class="pre">string</span> <span class="pre">]])</span> </code></p></td>
<td><p>Message when the help command is called.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">conflict(‚Äúname1‚Äù,</span> <span class="pre">‚Äúname2‚Äù)</span></code></p></td>
<td><p>The current modulefile will only load if all listed modules are NOT loaded.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">depends_on(‚ÄúpkgA‚Äù,</span> <span class="pre">‚ÄúpkgB‚Äù,</span> <span class="pre">‚ÄúpkgC‚Äù)</span></code></p></td>
<td><p>Loads all modules. When unloading only dependent modules are unloaded.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">load(‚ÄúpkgA‚Äù,</span> <span class="pre">‚ÄúpkgB‚Äù,</span> <span class="pre">‚ÄúpkgC‚Äù)</span></code></p></td>
<td><p>Load all modules. Report error if unable to load.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">prepend_path(‚ÄùPATH‚Äù,</span> <span class="pre">‚Äú/path/to/pkg/bin‚Äù)</span></code></p></td>
<td><p>Prepend the value to a path-like variable.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">setenv(‚ÄúNAME‚Äù,</span> <span class="pre">‚Äúvalue‚Äù):</span></code></p></td>
<td><p>Assign the value to the environment variable <code class="docutils literal notranslate"><span class="pre">NAME</span></code>.</p></td>
</tr>
</tbody>
</table>
<p>Please refer to the official documentation of Lmod on
<a class="reference external" href="https://lmod.readthedocs.io/en/latest/015_writing_modules.html">writing modules</a> and
<a class="reference external" href="https://lmod.readthedocs.io/en/latest/050_lua_modulefiles.html">Lua Modulefile functions</a>
for detailed information.
You can also have a look at present module files at the system.</p>
</section>
</section>
<section id="id65">
<h2>Usage<a class="headerlink" href="#id65" title="Permalink to this heading">#</a></h2>
<p>In order to use private module files and the corresponding software, you need to expand the module
search path. This is done by invoking the command</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>use<span class="w"> </span><span class="nv">$HOME</span>/privatemodules
</pre></div>
</div>
<p>for your private module files and</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>use<span class="w"> </span>/projects/p_number_crunch/privatemodules
</pre></div>
</div>
<p>for group private module files, respectively.</p>
<p>Afterwards, you can use the <span class="xref myst">module commands</span> to, e.g., load and unload your private modules
as usual.</p>
</section>
<section id="caveats">
<h2>Caveats<a class="headerlink" href="#caveats" title="Permalink to this heading">#</a></h2>
<p>An automated backup system provides security for the home directories on the cluster on a daily
basis. This is the reason why we urge users to store (large) temporary data (like checkpoint files)
on the <code class="docutils literal notranslate"><span class="pre">/scratch</span></code> filesystem or at local scratch disks.</p>
<p>This is also why we have set <code class="docutils literal notranslate"><span class="pre">ulimit</span> <span class="pre">-c</span> <span class="pre">0</span></code> as a default setting to prevent users from filling the
home directories with dumps of crashed programs. In particular, <code class="docutils literal notranslate"><span class="pre">ulimit</span> <span class="pre">-c</span> <span class="pre">0</span></code> sets the core file
size (blocks) to 0, which disables creation of core dumps in case an application crashes.</p>
<p>!!! note ‚ÄúEnable core files for debugging‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you use `bash` as shell and you need these core files for analysis, set `ulimit -c
unlimited`.
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id66">
<h1>Python Virtual Environments<a class="headerlink" href="#id66" title="Permalink to this heading">#</a></h1>
<p>Virtual environments allow users to install additional Python packages and
create an isolated run-time environment. We recommend using <code class="docutils literal notranslate"><span class="pre">virtualenv</span></code> for
this purpose. In your virtual environment, you can use packages from the
<span class="xref myst">modules list</span> or if you didn‚Äôt find what you need you can install
required packages with the command: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span></code>. With the command
<code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">list</span></code>, you can see a list of all installed packages and their versions.</p>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Note that you cannot install additional Python packages with `pip`
without an activated virtual environment on our systems.
Doing so will abort with the following error error:
&gt; ERROR: Could not find an activated virtualenv (required).
</pre></div>
</div>
<p>There are two methods of how to work with virtual environments on ZIH systems:</p>
<ol class="arabic simple">
<li><p><strong>virtualenv</strong> is a standard Python tool to create isolated Python
environments. It is the preferred interface for managing installations and
virtual environments on ZIH system and part of the Python modules.</p></li>
<li><p><strong>conda</strong> is an alternative method for managing installations and
virtual environments on ZIH system. conda is an open-source package
management system and environment management system from Anaconda. The
conda manager is included in all versions of Anaconda and Miniconda.</p></li>
</ol>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Keep in mind that you **cannot** use virtualenv for working
with the virtual environments previously created with conda tool and
vice versa! Prefer virtualenv whenever possible.
</pre></div>
</div>
<section id="python-virtual-environment">
<h2>Python Virtual Environment<a class="headerlink" href="#python-virtual-environment" title="Permalink to this heading">#</a></h2>
<p>This example shows how to start working with <strong>virtualenv</strong> and Python virtual
environment (using the module system).</p>
<p>!!! hint</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>We recommend to use [workspaces](../data_lifecycle/workspaces.md) for your
virtual environments.
</pre></div>
</div>
<p>At first, we check available Python modules and load the preferred version:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">[marie@login.barnard ~]$ </span>module<span class="w"> </span>load<span class="w"> </span>release/23.10<span class="w"> </span>GCCcore/11.3.0
<span class="go">Module GCCcore/11.3.0 loaded.</span>
<span class="gp">[marie@login.barnard ~]$ </span>module<span class="w"> </span>avail<span class="w"> </span>Python<span class="w"> </span><span class="c1"># check available Python modules</span>

<span class="go">---------------------------- Software build with Compiler GCCcore version 11.3.0 (HMNS Level Two) -----------------------------</span>
<span class="go">   flatbuffers-python/2.0    pkgconfig/1.5.5-python    protobuf-python/4.21.9 (D)    Python/3.10.4-bare</span>
<span class="go">   IPython/8.5.0             protobuf-python/3.19.4    Python/2.7.18-bare            Python/3.10.4      (D)</span>

<span class="go">  Where:</span>
<span class="go">   D:  Default Module</span>
<span class="go">   *Module:  Some Toolchain, load to access other modules that depend on it</span>
<span class="go">   &gt;Module:  Recommended toolchain version, load to access other modules that depend on it</span>

<span class="gp">[marie@login.barnard ~]$ </span>module<span class="w"> </span>load<span class="w"> </span>Python<span class="w"> </span><span class="c1"># load default Python</span>
<span class="go">Module Python/3.10.4 and 11 dependencies loaded.</span>
<span class="gp">[marie@login.barnard ~]$ </span>which<span class="w"> </span>python<span class="w"> </span><span class="c1"># check with version you are Python version you are using</span>
<span class="go">/software/rapids/r23.10/Python/3.10.4-GCCcore-11.3.0/bin/python</span>
</pre></div>
</div>
<p>Then create the virtual environment and activate it.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">[marie@login.barnard ~]$ </span>ws_allocate<span class="w"> </span>python_virtual_environment<span class="w"> </span><span class="m">1</span>
<span class="go">Info: creating workspace.</span>
<span class="go">/data/horse/ws/marie-python_virtual_environment</span>
<span class="go">remaining extensions  : 10</span>
<span class="go">remaining time in days: 1</span>
<span class="gp">[marie@login.barnard ~]$ </span>python3<span class="w"> </span>-m<span class="w"> </span>venv<span class="w"> </span>--system-site-package<span class="w"> </span>/data/horse/ws/marie-python_virtual_environment<span class="w"> </span><span class="c1"># create a Python virtual environment</span>
<span class="gp">[marie@login.barnard ~]$ </span><span class="nb">source</span><span class="w"> </span>/data/horse/ws/marie-python_virtual_environment/bin/activate
<span class="gp gp-VirtualEnv">(marie-python_virtual_environment)</span> <span class="gp">[marie@login.barnard ~]$ </span>python<span class="w"> </span>--version
<span class="go">Python 3.10.4</span>
</pre></div>
</div>
<p>Now you can work in this isolated environment, without interfering with other
tasks running on the system. Note that the inscription (env) at the beginning of
each line represents that you are in the virtual environment. You can deactivate
the environment as follows:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp gp-VirtualEnv">(env)</span> <span class="gp">marie@compute$ deactivate    #</span>Leave<span class="w"> </span>the<span class="w"> </span>virtual<span class="w"> </span>environment
</pre></div>
</div>
<p>??? example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>This is an example on cluster `Alpha`. The example creates a python virtual environment, and
installs the package `torchvision` with pip.
```console
marie@login.alpha$ srun --nodes=1 --gres=gpu:1 --time=01:00:00 --pty bash
marie@alpha$ ws_allocate my_python_virtualenv 100    # use a workspace for the environment
marie@alpha$ cd /data/horse/ws/marie-my_python_virtualenv
[marie@alpha ]$ module load release/23.04 GCC/11.3.0 OpenMPI/4.1.4 CUDAcore/11.5.1 PyTorch/1.12.1
Module GCC/11.3.0, OpenMPI/4.1.4, CUDAcore/11.5.1, PyTorch/1.12.1 and 58 dependencies loaded.
[marie@alpha ]$ which python
/software/rome/r23.04/Python/3.10.4-GCCcore-11.3.0/bin/python
[marie@alpha ]$ pip list
[...]
[marie@alpha ]$ python -m venv --system-site-packages my-torch-env
created virtual environment CPython3.10.4.final.0-64 in 3621ms
  creator CPython3Posix(dest=/data/horse/ws/marie/marie-my_python_virtualenv/my-torch-env, clear=False, no_vcs_ignore=False, global=True)
  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/h0/marie/.local/share/virtualenv)
    added seed packages: pip==23.3.2, setuptools==69.0.3, wheel==0.42.0
  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
[marie@alpha ]$ source my-torch-env/bin/activate
(my-torch-env) [marie@alpha ]$ pip install torchvision==0.12.0
Collecting torchvision==0.12.0
[...]
Successfully installed torch-1.11.0 torchvision-0.12.0
[...]
(my-torch-env) marie@alpha$ python -c &quot;import torchvision; print(torchvision.__version__)&quot;
0.10.0+cu102
(my-torch-env) marie@alpha$ deactivate
```
</pre></div>
</div>
<section id="persistence-of-python-virtual-environment">
<h3>Persistence of Python Virtual Environment<a class="headerlink" href="#persistence-of-python-virtual-environment" title="Permalink to this heading">#</a></h3>
<p>To persist a virtualenv, you can store the names and versions of installed
packages in a file. Then you can restore this virtualenv by installing the
packages from this file. Use the <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">freeze</span></code> command for storing:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp gp-VirtualEnv">(env)</span> <span class="gp">marie@compute$ </span>pip<span class="w"> </span>freeze<span class="w"> </span>&gt;<span class="w"> </span>requirements.txt<span class="w">    </span><span class="c1">#Store the currently installed packages</span>
</pre></div>
</div>
<p>In order to recreate python virtual environment, use the <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span></code> command to install the
packages from the file:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>load<span class="w"> </span>Python<span class="w">    </span><span class="c1">#Load default Python</span>
<span class="go">[...]</span>
<span class="gp">marie@compute$ </span>python<span class="w"> </span>-m<span class="w"> </span>venv<span class="w"> </span>--system-site-packages<span class="w"> </span>/data/horse/ws/marie-python_virtual_environment/env_post<span class="w">  </span><span class="c1">#Create virtual environment</span>
<span class="go">[...]</span>
<span class="gp">marie@compute$ </span><span class="nb">source</span><span class="w"> </span>/data/horse/ws/marie-python_virtual_environment/env/bin/activate<span class="w">    </span><span class="c1">#Activate virtual environment. Example output: (env_post) bash-4.2$</span>
<span class="gp gp-VirtualEnv">(env_post)</span> <span class="gp">marie@compute$ </span>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt<span class="w">    </span><span class="c1">#Install packages from the created requirements.txt file</span>
</pre></div>
</div>
</section>
</section>
<section id="conda-virtual-environment">
<h2>Conda Virtual Environment<a class="headerlink" href="#conda-virtual-environment" title="Permalink to this heading">#</a></h2>
<p>!!!
We were informed that the manufacturer of Anaconda has changed its license conditions
and that the use of Anaconda/conda is also subject to licensing at universities
with more than 200 employees.
<a class="reference external" href="https://legal.anaconda.com/policies/en/?name=terms-of-service#anaconda-terms-of-service">https://legal.anaconda.com/policies/en/?name=terms-of-service#anaconda-terms-of-service</a>
The TU Dresden does not plan to procure a license centrally.</p>
<p><strong>Prerequisite:</strong> Before working with conda, your shell needs to be configured
initially. Therefore login to the ZIH system, load the Anaconda module and run
<code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">$EBROOTANACONDA3/etc/profile.d/conda.sh</span></code>. Note that you must run the
previous command each time you want to activate your virtual environment and
they are not automatically loaded after re-opening your shell.</p>
<p>!!! warning
We recommend to <strong>not</strong> use the <code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">init</span></code> command, since it may cause unexpected behavior
when working with the ZIH system.</p>
<p>??? example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@compute$ module load Anaconda3    #load Anaconda module
Module Anaconda3/2019.03 loaded.
marie@compute$ sh $EBROOTANACONDA3/etc/profile.d/conda.sh    #init conda
[...]
```
</pre></div>
</div>
<p>This example shows how to start working with <strong>conda</strong> and virtual environment
(with using module system). At first, we use an interactive job and create a
directory for the conda virtual environment:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>ws_allocate<span class="w"> </span>conda_virtual_environment<span class="w"> </span><span class="m">1</span>
<span class="go">Info: creating workspace.</span>
<span class="go">/data/horse/ws/marie-conda_virtual_environment</span>
<span class="go">[...]</span>
</pre></div>
</div>
<p>Then, we load Anaconda, create an environment in our directory and activate the
environment:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>load<span class="w"> </span>Anaconda3<span class="w">    </span><span class="c1">#load Anaconda module</span>
<span class="gp">marie@compute$ </span>conda<span class="w"> </span>create<span class="w"> </span>--prefix<span class="w"> </span>/data/horse/ws/marie-conda_virtual_environment/conda-env<span class="w"> </span><span class="nv">python</span><span class="o">=</span><span class="m">3</span>.6<span class="w">    </span><span class="c1">#create virtual environment with Python version 3.6</span>
<span class="gp">marie@compute$ </span>conda<span class="w"> </span>activate<span class="w"> </span>/data/horse/ws/marie-conda_virtual_environment/conda-env<span class="w">    </span><span class="c1">#activate conda-env virtual environment</span>
</pre></div>
</div>
<p>Now you can work in this isolated environment, without interfering with other
tasks running on the system. Note that the inscription (conda-env) at the
beginning of each line represents that you are in the virtual environment. You
can deactivate the conda environment as follows:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp gp-VirtualEnv">(conda-env)</span> <span class="gp">marie@compute$ </span>conda<span class="w"> </span>deactivate<span class="w">    </span><span class="c1">#Leave the virtual environment</span>
</pre></div>
</div>
<p>!!! warning
When installing conda packages via <code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">install</span></code>, ensure to have enough main memory requested
in your job allocation.</p>
<p>!!! hint
We do not recommend to use conda environments together with EasyBuild modules due to
dependency conflicts. Nevertheless, if you need EasyBuild modules, consider installing conda
packages via <code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">install</span> <span class="pre">--no-deps</span> <span class="pre">[...]</span></code> to prevent conda from installing dependencies.</p>
<p>??? example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>This is an example on cluster `Alpha`. The example creates a conda virtual environment, and
installs the package `torchvision` with conda.
```console
marie@login.alpha$ srun --nodes=1 --gres=gpu:1 --time=01:00:00 --pty bash
marie@alpha$ ws_allocate my_conda_virtualenv 100    # use a workspace for the environment
marie@alpha$ cd /data/horse/ws/marie-my_conda_virtualenv
marie@alpha$ module load Anaconda3
Module Anaconda3/2022.05 loaded.
marie@alpha$ conda create --prefix my-torch-env python=3.8
Collecting package metadata (current_repodata.json): done
Solving environment: done
[...]
Proceed ([y]/n)? y
[...]
marie@alpha$ source $EBROOTANACONDA3/etc/profile.d/conda.sh
marie@alpha$ conda activate my-torch-env
(my-torch-env) marie@alpha$ conda install -c pytorch torchvision
Collecting package metadata (current_repodata.json): done
[...]
Preparing transaction: done
Verifying transaction: done
(my-torch-env) marie@alpha$ which python    # ensure to use the correct Python
(my-torch-env) marie@alpha$ python -c &quot;import torchvision; print(torchvision.__version__)&quot;
0.12.0
(my-torch-env) marie@alpha$ conda deactivate
```
</pre></div>
</div>
<section id="persistence-of-conda-virtual-environment">
<h3>Persistence of Conda Virtual Environment<a class="headerlink" href="#persistence-of-conda-virtual-environment" title="Permalink to this heading">#</a></h3>
<p>To persist a conda virtual environment, you can define an <code class="docutils literal notranslate"><span class="pre">environments.yml</span></code>
file. Have a look a the <a class="reference external" href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html?highlight=environment.yml#create-env-file-manually">conda docs</a>
for a description of the syntax. See an example for the <code class="docutils literal notranslate"><span class="pre">environments.yml</span></code> file
below.</p>
<p>??? example
<code class="docutils literal notranslate"><span class="pre">yml</span>&#160;&#160;&#160;&#160; <span class="pre">name:</span> <span class="pre">workshop_env</span>&#160;&#160;&#160;&#160; <span class="pre">channels:</span>&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">conda-forge</span>&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">defaults</span>&#160;&#160;&#160;&#160; <span class="pre">dependencies:</span>&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">python&gt;=3.7</span>&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">pip</span>&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">colorcet</span>&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">'geoviews-core=1.8.1'</span>&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">'ipywidgets=7.6.*'</span>&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">geopandas</span>&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">hvplot</span>&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">pyepsg</span>&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">python-dotenv</span>&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">'shapely=1.7.1'</span>&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">pip:</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">python-hll</span>&#160;&#160;&#160;&#160; </code></p>
<p>After specifying the <code class="docutils literal notranslate"><span class="pre">name</span></code>, the conda <a class="reference external" href="https://docs.conda.io/projects/conda/en/latest/user-guide/concepts/channels.html">channel priority</a>
is defined. In the example above, packages will be first installed from the
<code class="docutils literal notranslate"><span class="pre">conda-forge</span></code> channel, and if not found, from the <code class="docutils literal notranslate"><span class="pre">default</span></code> Anaconda channel.</p>
<p>Below, dependencies can be specified. Optionally, <abbr title="Pinning is a
process that allows you to remain on a stable release while grabbing packages
from a more recent version."> pinning</abbr> can be used to delimit the packages
installed to compatible package versions.</p>
<p>Finally, packages not available on conda can be specified (indented) below
<code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">pip:</span></code></p>
<p>Recreate the conda virtual environment with the packages from the created
<code class="docutils literal notranslate"><span class="pre">environment.yml</span></code> file:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>mkdir<span class="w"> </span>/data/horse/ws/marie-conda_virtual_environment/conda-env<span class="w">    </span><span class="c1">#Create directory for environment</span>
<span class="gp">marie@compute$ </span>module<span class="w"> </span>load<span class="w"> </span>Anaconda3<span class="w">    </span><span class="c1">#Load Anaconda</span>
<span class="gp">marie@compute$ </span>conda<span class="w"> </span>config<span class="w"> </span>--set<span class="w"> </span>channel_priority<span class="w"> </span>strict
<span class="gp">marie@compute$ </span>conda<span class="w"> </span>env<span class="w"> </span>create<span class="w"> </span>--prefix<span class="w"> </span>/data/horse/ws/marie-conda_virtual_environment/conda-env<span class="w"> </span>--file<span class="w"> </span>environment.yml<span class="w">    </span><span class="c1">#Create conda env in directory with packages from environment.yml file</span>
</pre></div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="neural-networks-with-pytorch">
<h1>Neural Networks with PyTorch<a class="headerlink" href="#neural-networks-with-pytorch" title="Permalink to this heading">#</a></h1>
<p><a class="reference external" href="https://pytorch.org/">PyTorch</a> is an open-source machine learning framework.
It is an optimized tensor library for deep learning using GPUs and CPUs.
PyTorch is a machine learning tool developed by Facebook‚Äôs AI division to process large-scale
object detection, segmentation, classification, etc.
PyTorch provides a core data structure, the tensor, a multi-dimensional array that shares many
similarities with NumPy arrays.</p>
<p>Please check the software modules list via</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>spider<span class="w"> </span>pytorch
</pre></div>
</div>
<p>to find out, which PyTorch modules are available.</p>
<p>We recommend using the cluster <code class="docutils literal notranslate"><span class="pre">Alpha</span></code>, <code class="docutils literal notranslate"><span class="pre">Capella</span></code> and/or <code class="docutils literal notranslate"><span class="pre">Power9</span></code> when
working with machine learning workflows and the PyTorch library.
You can find detailed hardware specification in our
<span class="xref myst">hardware documentation</span>.</p>
<section id="pytorch-console">
<h2>PyTorch Console<a class="headerlink" href="#pytorch-console" title="Permalink to this heading">#</a></h2>
<p>On the cluster <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, load the module environment:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>Job<span class="w"> </span>submission<span class="w"> </span>on<span class="w"> </span>alpha<span class="w"> </span>nodes<span class="w"> </span>with<span class="w"> </span><span class="m">1</span><span class="w"> </span>gpu<span class="w"> </span>on<span class="w"> </span><span class="m">1</span><span class="w"> </span>node<span class="w"> </span>with<span class="w"> </span><span class="m">800</span><span class="w"> </span>Mb<span class="w"> </span>per<span class="w"> </span>CPU

<span class="gp">marie@login.alpha$ </span>srun<span class="w"> </span>--gres<span class="o">=</span>gpu:1<span class="w"> </span>-n<span class="w"> </span><span class="m">1</span><span class="w"> </span>-c<span class="w"> </span><span class="m">7</span><span class="w"> </span>--pty<span class="w"> </span>--mem-per-cpu<span class="o">=</span><span class="m">800</span><span class="w"> </span>bash
<span class="gp">marie@alpha$ </span>module<span class="w"> </span>load<span class="w"> </span>release/23.04<span class="w"> </span>GCCcore/11.3.0<span class="w"> </span>GCC/11.3.0<span class="w"> </span>OpenMPI/4.1.4<span class="w"> </span>Python/3.10.4
<span class="go">Module GCC/11.3.0, OpenMPI/4.1.4, Python/3.10.4 and 21 dependencies loaded.</span>
<span class="gp">marie@alpha$ </span>module<span class="w"> </span>load<span class="w"> </span>PyTorch/1.12.1-CUDA-11.7.0
<span class="go">Module PyTorch/1.12.1-CUDA-11.7.0 and 42 dependencies loaded.</span>
</pre></div>
</div>
<p>??? hint ‚ÄúTorchvision on the cluster <code class="docutils literal notranslate"><span class="pre">alpha</span></code>‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>On the cluster `alpha`, the module torchvision is not yet available within the module
system. (19.08.2021)
Torchvision can be made available by using a virtual environment:

```console
marie@alpha$ virtualenv --system-site-packages python-environments/torchvision_env
marie@alpha$ source python-environments/torchvision_env/bin/activate
marie@alpha$ pip install torchvision --no-deps
```

Using the **--no-deps** option for &quot;pip install&quot; is necessary here as otherwise the PyTorch
version might be replaced and you will run into trouble with the CUDA drivers.
</pre></div>
</div>
<p>On the cluster <code class="docutils literal notranslate"><span class="pre">Power9</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>Job<span class="w"> </span>submission<span class="w"> </span><span class="k">in</span><span class="w"> </span>power<span class="w"> </span>nodes<span class="w"> </span>with<span class="w"> </span><span class="m">1</span><span class="w"> </span>gpu<span class="w"> </span>on<span class="w"> </span><span class="m">1</span><span class="w"> </span>node<span class="w"> </span>with<span class="w"> </span><span class="m">800</span><span class="w"> </span>Mb<span class="w"> </span>per<span class="w"> </span>CPU
<span class="gp">marie@login.power9$ </span>srun<span class="w"> </span>--gres<span class="o">=</span>gpu:1<span class="w"> </span>-n<span class="w"> </span><span class="m">1</span><span class="w"> </span>-c<span class="w"> </span><span class="m">7</span><span class="w"> </span>--pty<span class="w"> </span>--mem-per-cpu<span class="o">=</span><span class="m">800</span><span class="w"> </span>bash
</pre></div>
</div>
<p>After calling</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login.power9$ </span>module<span class="w"> </span>spider<span class="w"> </span>pytorch
</pre></div>
</div>
<p>we know that we can load PyTorch (including torchvision) with</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@power9$ </span>module<span class="w"> </span>load<span class="w"> </span>release/23.04<span class="w">  </span>GCC/11.3.0<span class="w">  </span>OpenMPI/4.1.4<span class="w"> </span>torchvision/0.13.1
<span class="go">Modules GCC/11.3.0, OpenMPI/4.1.4, torchvision/0.13.1 and 62 dependencies loaded.</span>
</pre></div>
</div>
<p>Now, we check that we can access PyTorch:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">marie@power9 python -c &quot;import torch; print(torch.__version__)&quot;</span>
</pre></div>
</div>
<p>The following example shows how to create a python virtual environment and import PyTorch.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>Create<span class="w"> </span>folder
<span class="gp">marie@power9$ </span>mkdir<span class="w"> </span>python-environments
<span class="gp"># </span>Check<span class="w"> </span>which<span class="w"> </span>python<span class="w"> </span>are<span class="w"> </span>you<span class="w"> </span>using
<span class="gp">marie@power9$ </span>which<span class="w"> </span>python
<span class="go">/sw/installed/Python/3.7.4-GCCcore-8.3.0/bin/python</span>
<span class="gp"># </span>Create<span class="w"> </span>virtual<span class="w"> </span>environment<span class="w"> </span><span class="s2">&quot;env&quot;</span><span class="w"> </span>which<span class="w"> </span>inheriting<span class="w"> </span>with<span class="w"> </span>global<span class="w"> </span>site<span class="w"> </span>packages
<span class="gp">marie@power9$ </span>virtualenv<span class="w"> </span>--system-site-packages<span class="w"> </span>python-environments/env
<span class="go">[...]</span>
<span class="gp"># </span>Activate<span class="w"> </span>virtual<span class="w"> </span>environment<span class="w"> </span><span class="s2">&quot;env&quot;</span>.<span class="w"> </span>Example<span class="w"> </span>output:<span class="w"> </span><span class="o">(</span>env<span class="o">)</span><span class="w"> </span>bash-4.2$
<span class="gp">marie@power9$ </span><span class="nb">source</span><span class="w"> </span>python-environments/env/bin/activate
<span class="gp">marie@power9$ </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import torch; print(torch.__version__)&quot;</span>
</pre></div>
</div>
</section>
<section id="pytorch-in-jupyterhub">
<h2>PyTorch in JupyterHub<a class="headerlink" href="#pytorch-in-jupyterhub" title="Permalink to this heading">#</a></h2>
<p>In addition to using interactive and batch jobs, it is possible to work with PyTorch using
JupyterHub.  The production and test environments of JupyterHub contain Python kernels, that come
with a PyTorch support.</p>
<p><img alt="PyTorch module in JupyterHub" src="63_chat_with_docs/misc/Pytorch_jupyter_module.png" />
{: align=‚Äùcenter‚Äù}</p>
</section>
<section id="id67">
<h2>Distributed PyTorch<a class="headerlink" href="#id67" title="Permalink to this heading">#</a></h2>
<p>For details on how to run PyTorch with multiple GPUs and/or multiple nodes, see
<span class="xref myst">distributed training</span>.</p>
</section>
<section id="migrate-pytorch-script-from-cpu-to-gpu">
<h2>Migrate PyTorch-script from CPU to GPU<a class="headerlink" href="#migrate-pytorch-script-from-cpu-to-gpu" title="Permalink to this heading">#</a></h2>
<p>It is recommended to use GPUs when using large training data sets. While TensorFlow automatically
uses GPUs if they are available, in PyTorch you have to move your tensors manually.</p>
<p>First, you need to import <code class="docutils literal notranslate"><span class="pre">torch.CUDA</span></code>:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.CUDA</span>
</pre></div>
</div>
<p>Then you define a <code class="docutils literal notranslate"><span class="pre">device</span></code>-variable, which is set to ‚ÄòCUDA‚Äô automatically when a GPU is available
with this code:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;CUDA&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">CUDA</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>You then have to move all of your tensors to the selected device. This looks like this:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>Remember that this does not break backward compatibility when you port the script back to a computer
without GPU, because without GPU, <code class="docutils literal notranslate"><span class="pre">device</span></code> is set to ‚Äòcpu‚Äô.</p>
<section id="id68">
<h3>Caveats<a class="headerlink" href="#id68" title="Permalink to this heading">#</a></h3>
<section id="moving-data-back-to-the-cpu-memory">
<h4>Moving Data Back to the CPU-Memory<a class="headerlink" href="#moving-data-back-to-the-cpu-memory" title="Permalink to this heading">#</a></h4>
<p>The CPU cannot directly access variables stored on the GPU. If you want to use the variables, e.g.,
in a <code class="docutils literal notranslate"><span class="pre">print</span></code> statement or when editing with NumPy or anything that is not PyTorch, you have to move
them back to the CPU-memory again. This then may look like this:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">cpu_x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cpu_x_train</span><span class="p">)</span>
<span class="o">...</span>
<span class="n">error_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">y_prediction_train</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<p>Remember that, without <code class="docutils literal notranslate"><span class="pre">.detach()</span></code> before the CPU, if you change <code class="docutils literal notranslate"><span class="pre">cpu_x_train</span></code>, <code class="docutils literal notranslate"><span class="pre">x_train</span></code> will also
be changed.  If you want to treat them independently, use</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">cpu_x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</pre></div>
</div>
<p>Now you can change <code class="docutils literal notranslate"><span class="pre">cpu_x_train</span></code> without <code class="docutils literal notranslate"><span class="pre">x_train</span></code> being affected.</p>
</section>
<section id="speed-improvements-and-batch-size">
<h4>Speed Improvements and Batch Size<a class="headerlink" href="#speed-improvements-and-batch-size" title="Permalink to this heading">#</a></h4>
<p>When you have a lot of very small data points, the speed may actually decrease when you try to train
them on the GPU.  This is because moving data from the CPU-memory to the GPU-memory takes time. If
this occurs, please try using a very large batch size. This way, copying back and forth only takes
places a few times and the bottleneck may be reduced.</p>
</section>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="record-course-of-events-with-score-p">
<h1>Record Course of Events with Score-P<a class="headerlink" href="#record-course-of-events-with-score-p" title="Permalink to this heading">#</a></h1>
<p>The Score-P measurement infrastructure is a highly scalable and easy-to-use tool suite for
profiling, event tracing, and online analysis of HPC applications. Currently, it works with the
analysis tools Vampir, Scalasca, and Tau. Score-P supports lots of features e.g.</p>
<ul class="simple">
<li><p>MPI, SHMEM, OpenMP, Pthreads, and hybrid programs</p></li>
<li><p>Manual source code instrumentation</p></li>
<li><p>Monitoring of CUDA, OpenCL, and OpenACC applications</p></li>
<li><p>Recording hardware counter by using PAPI library</p></li>
<li><p>Function filtering and grouping</p></li>
</ul>
<p>Only the basic usage is shown in this Wiki. For a comprehensive Score-P user manual refer to the
<a class="reference external" href="https://score-p.org/">Score-P website</a>.</p>
<p>Before using Score-P, set up the correct environment with</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>Score-P
</pre></div>
</div>
<p>To make measurements with Score-P, the user‚Äôs application program needs to be instrumented, i.e., at
specific important points (‚Äúevents‚Äù) Score-P measurement calls have to be activated. By default,
Score-P handles this automatically. In order to enable instrumentation of function calls, MPI as
well as OpenMP events, the user only needs to prepend the Score-P wrapper to the usual compile and
link commands. The following sections show some examples depending on the parallelization type of
the program.</p>
<section id="serial-programs">
<h2>Serial Programs<a class="headerlink" href="#serial-programs" title="Permalink to this heading">#</a></h2>
<p>Original:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ifort<span class="w"> </span>a.f90<span class="w"> </span>b.f90<span class="w"> </span>-o<span class="w"> </span>myprog
</pre></div>
</div>
<p>With instrumentation:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>scorep<span class="w"> </span>ifort<span class="w"> </span>a.f90<span class="w"> </span>b.f90<span class="w"> </span>-o<span class="w"> </span>myprog
</pre></div>
</div>
<p>This will instrument user functions (if supported by the compiler) and link the Score-P library.</p>
</section>
<section id="mpi-parallel-programs">
<h2>MPI Parallel Programs<a class="headerlink" href="#mpi-parallel-programs" title="Permalink to this heading">#</a></h2>
<p>If your MPI implementation uses MPI compilers, Score-P will detect MPI parallelization
automatically:</p>
<p>Original:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>mpicc<span class="w"> </span>hello.c<span class="w"> </span>-o<span class="w"> </span>hello
</pre></div>
</div>
<p>With instrumentation:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>scorep<span class="w"> </span>mpicc<span class="w"> </span>hello.c<span class="w"> </span>-o<span class="w"> </span>hello
</pre></div>
</div>
<p>MPI implementations without own compilers require the user to link the MPI library
manually. Even in this case, Score-P will detect MPI parallelization automatically:</p>
<p>Original:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>icc<span class="w"> </span>hello.c<span class="w"> </span>-o<span class="w"> </span>hello<span class="w"> </span>-lmpi
</pre></div>
</div>
<p>With instrumentation:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>scorep<span class="w"> </span>icc<span class="w"> </span>hello.c<span class="w"> </span>-o<span class="w"> </span>hello<span class="w"> </span>-lmpi
</pre></div>
</div>
<p>However, if Score-P fails to detect MPI parallelization automatically you can manually select MPI
instrumentation:</p>
<p>Original:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>icc<span class="w"> </span>hello.c<span class="w"> </span>-o<span class="w"> </span>hello<span class="w"> </span>-lmpi
</pre></div>
</div>
<p>With instrumentation:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>scorep<span class="w"> </span>--mpp<span class="o">=</span>mpi<span class="w"> </span>icc<span class="w"> </span>hello.c<span class="w"> </span>-o<span class="w"> </span>hello<span class="w"> </span>-lmpi
</pre></div>
</div>
<p>If you want to instrument MPI events only (creates less overhead and smaller trace files) use the
option <code class="docutils literal notranslate"><span class="pre">--nocompiler</span></code> to disable automatic instrumentation of user functions.</p>
</section>
<section id="openmp-parallel-programs">
<h2>OpenMP Parallel Programs<a class="headerlink" href="#openmp-parallel-programs" title="Permalink to this heading">#</a></h2>
<p>When Score-P detects OpenMP flags on the command line, OPARI2 is invoked for automatic source code
instrumentation of OpenMP events:</p>
<p>Original:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ifort<span class="w"> </span>-openmp<span class="w"> </span>pi.f<span class="w"> </span>-o<span class="w"> </span>pi
</pre></div>
</div>
<p>With instrumentation:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>scorep<span class="w"> </span>ifort<span class="w"> </span>-openmp<span class="w"> </span>pi.f<span class="w"> </span>-o<span class="w"> </span>pi
</pre></div>
</div>
</section>
<section id="hybrid-mpi-openmp-parallel-programs">
<h2>Hybrid MPI/OpenMP Parallel Programs<a class="headerlink" href="#hybrid-mpi-openmp-parallel-programs" title="Permalink to this heading">#</a></h2>
<p>With a combination of the above mentioned approaches, hybrid applications can be instrumented:</p>
<p>Original:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>mpif90<span class="w"> </span>-openmp<span class="w"> </span>hybrid.F90<span class="w"> </span>-o<span class="w"> </span>hybrid
</pre></div>
</div>
<p>With instrumentation:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>scorep<span class="w"> </span>mpif90<span class="w"> </span>-openmp<span class="w"> </span>hybrid.F90<span class="w"> </span>-o<span class="w"> </span>hybrid
</pre></div>
</div>
</section>
<section id="score-p-instrumenter-option-overview">
<h2>Score-P Instrumenter Option Overview<a class="headerlink" href="#score-p-instrumenter-option-overview" title="Permalink to this heading">#</a></h2>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Type of instrumentation</p></th>
<th class="head"><p>Instrumenter switch</p></th>
<th class="head"><p>Default value</p></th>
<th class="head"><p>Runtime measurement control</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>MPI</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">--mpp=mpi</span></code></p></td>
<td><p>(auto)</p></td>
<td><p>(see Sec. Selection of MPI Groups )</p></td>
</tr>
<tr class="row-odd"><td><p>SHMEM</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">--mpp=shmem</span></code></p></td>
<td><p>(auto)</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p>OpenMP</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">--thread=omp</span></code></p></td>
<td><p>(auto)</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p>Pthread</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">--thread=pthread</span></code></p></td>
<td><p>(auto)</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p>Compiler (see Sec. Automatic Compiler Instrumentation )</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">--compiler/--nocompiler</span></code></p></td>
<td><p>enabled</p></td>
<td><p>Filtering (see Sec. Filtering )</p></td>
</tr>
<tr class="row-odd"><td><p>PDT instrumentation (see Sec. Source-Code Instrumentation Using PDT )</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">--pdt/--nopdt</span></code></p></td>
<td><p>disabled</p></td>
<td><p>Filtering (see Sec. Filtering)</p></td>
</tr>
<tr class="row-even"><td><p>POMP2 user regions (see Sec. Semi-Automatic Instrumentation of POMP2 User Regions )</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">--pomp/--nopomp</span></code></p></td>
<td><p>depends on OpenMP usage</p></td>
<td><p>Filtering (see Sec. Filtering )</p></td>
</tr>
<tr class="row-odd"><td><p>Manual (see Sec. Manual Region Instrumentation )</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">--user/--nouser</span></code></p></td>
<td><p>disabled</p></td>
<td><p>Filtering (see Sec. Filtering ) and selective recording (see Sec. Selective Recording )</p></td>
</tr>
</tbody>
</table>
</section>
<section id="application-measurement">
<h2>Application Measurement<a class="headerlink" href="#application-measurement" title="Permalink to this heading">#</a></h2>
<p>After the application run, you will find an experiment directory in your current working directory,
which contains all recorded data.  In general, you can record a profile and/or a event trace.
Whether a profile and/or a trace is recorded, is specified by the environment variables
<code class="docutils literal notranslate"><span class="pre">SCOREP_ENABLE_PROFILING</span></code> and <code class="docutils literal notranslate"><span class="pre">SCOREP_ENABLE_TRACING</span></code> (see
<a class="reference external" href="https://perftools.pages.jsc.fz-juelich.de/cicd/scorep/tags/latest/html/measurement.html">official Score-P documentation</a>).
If the value of this variables is zero or false, profiling/tracing is disabled. Otherwise Score-P
will record a profile and/or trace. By default, profiling is enabled and tracing is disabled. For
more information please see the list of Score-P measurement
<a class="reference external" href="https://perftools.pages.jsc.fz-juelich.de/cicd/scorep/tags/latest/html/scorepmeasurementconfig.html">configuration variables</a>.</p>
<p>You may start with a profiling run, because of its lower space requirements. According to profiling
results, you may configure the trace buffer limits, filtering or selective recording for recording
traces.  Score-P allows to configure several parameters via environment variables. After the
measurement run you can find a <code class="docutils literal notranslate"><span class="pre">scorep.cfg</span></code> file in your experiment directory which contains the
configuration of the measurement run. If you had not set configuration values explicitly, the file
will contain the default values.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="singularity-for-power9-architecture">
<h1>Singularity for Power9 Architecture<a class="headerlink" href="#singularity-for-power9-architecture" title="Permalink to this heading">#</a></h1>
<p>!!! note ‚ÄúRoot privileges‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Building Singularity containers from a recipe on ZIH system is normally not possible due to the
requirement of root (administrator) rights, see [Containers](containers.md). For obvious reasons
users cannot be granted root permissions.
</pre></div>
</div>
<p>The solution is to build your container on your local Linux workstation using Singularity and copy
it to ZIH systems for execution.</p>
<p><strong>This does not work on the cluster <code class="docutils literal notranslate"><span class="pre">power</span></code></strong> as it uses the Power9 architecture which your
workstation likely doesn‚Äôt.</p>
<p>For this, we provide a Virtual Machine (VM) on the cluster <code class="docutils literal notranslate"><span class="pre">power</span></code> which allows users to gain root
permissions in an isolated environment. The workflow to use this manually is described for
<span class="xref myst">virtual machines</span> but is quite cumbersome.</p>
<p>To make this easier, two programs are provided: <code class="docutils literal notranslate"><span class="pre">buildSingularityImage</span></code> and <code class="docutils literal notranslate"><span class="pre">startInVM</span></code>, which do
what they say. The latter is for more advanced use cases, so you should be fine using
<code class="docutils literal notranslate"><span class="pre">buildSingularityImage</span></code>, see the following section.</p>
<p>!!! note ‚ÄúSSH key without password‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>You need to have your default SSH key without a password for the scripts to work as
entering a password through the scripts is not supported.
</pre></div>
</div>
<p><strong>The recommended workflow</strong> is to create and test a definition file locally. You usually start from
a base Docker container. Those typically exist for different architectures but with a common name
(e.g.  <code class="docutils literal notranslate"><span class="pre">ubuntu:18.04</span></code>). Singularity automatically uses the correct Docker container for your current
architecture when building. So, in most cases, you can write your definition file, build it and test
it locally, then move it to ZIH systems and build it on Power9 (cluster <code class="docutils literal notranslate"><span class="pre">power</span></code>) without any further
changes. However, sometimes Docker containers for different architectures have different suffixes,
in which case you‚Äôd need to change that when moving to ZIH systems.</p>
<section id="build-a-singularity-container-in-a-job">
<h2>Build a Singularity Container in a Job<a class="headerlink" href="#build-a-singularity-container-in-a-job" title="Permalink to this heading">#</a></h2>
<p>To build a Singularity container for the Power9 architecture on ZIH systems simply run:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login.power$ </span>buildSingularityImage<span class="w"> </span>--arch<span class="o">=</span>power9<span class="w"> </span>myContainer.sif<span class="w"> </span>myDefinition.def
</pre></div>
</div>
<p>To build a singularity image on the x86-architecture, run:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login.power$ </span>buildSingularityImage<span class="w"> </span>--arch<span class="o">=</span>x86<span class="w"> </span>myContainer.sif<span class="w"> </span>myDefinition.def
</pre></div>
</div>
<p>These commands will submit a batch job and immediately return. If you want it to block while the
image is built and see live output, add the option <code class="docutils literal notranslate"><span class="pre">--interactive</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login.power$ </span>buildSingularityImage<span class="w"> </span>--arch<span class="o">=</span>power9<span class="w"> </span>--interactive<span class="w"> </span>myContainer.sif<span class="w"> </span>myDefinition.def
</pre></div>
</div>
<p>There are more options available, which can be shown by running <code class="docutils literal notranslate"><span class="pre">buildSingularityImage</span> <span class="pre">--help</span></code>. All
have reasonable defaults. The most important ones are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--time</span> <span class="pre">&lt;time&gt;</span></code>: Set a higher job time if the default time is not
enough to build your image and your job is canceled before completing. The format is the same as
for Slurm.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--tmp-size=&lt;size</span> <span class="pre">in</span> <span class="pre">GB&gt;</span></code>: Set a size used for the temporary
location of the Singularity container, basically the size of the extracted container.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--output=&lt;file&gt;</span></code>: Path to a file used for (log) output generated
while building your container.</p></li>
<li><p>Various Singularity options are passed through. E.g.
<code class="docutils literal notranslate"><span class="pre">--notest,</span> <span class="pre">--force,</span> <span class="pre">--update</span></code>. See, e.g., <code class="docutils literal notranslate"><span class="pre">singularity</span> <span class="pre">--help</span></code> for details.</p></li>
</ul>
<p>For <strong>advanced users</strong>, it is also possible to manually request a job with a VM (<code class="docutils literal notranslate"><span class="pre">srun</span> <span class="pre">-p</span> <span class="pre">power9</span> <span class="pre">--cloud=kvm</span> <span class="pre">...</span></code>) and then use this script to build a Singularity container from within the job. In
this case, the <code class="docutils literal notranslate"><span class="pre">--arch</span></code> and other Slurm related parameters are not required. The advantage of using
this script is that it automates the waiting for the VM and mounting of host directories into it
(can also be done with <code class="docutils literal notranslate"><span class="pre">startInVM</span></code>) and creates a temporary directory usable with Singularity inside
the VM controlled by the <code class="docutils literal notranslate"><span class="pre">--tmp-size</span></code> parameter.</p>
</section>
<section id="filesystem">
<h2>Filesystem<a class="headerlink" href="#filesystem" title="Permalink to this heading">#</a></h2>
<p><strong>Read here if you have problems like ‚ÄúFile not found‚Äù.</strong></p>
<p>As the build starts in a VM, you may not have access to all your files. It is usually bad practice
to refer to local files from inside a definition file anyway as this reduces reproducibility.
However, common directories are available by default. For others, care must be taken. In short:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">/home/$USER</span></code>, <code class="docutils literal notranslate"><span class="pre">/data/horse/$USER</span></code> are available and should be used <code class="docutils literal notranslate"><span class="pre">/data/horse/&lt;group&gt;</span></code> also
works for all groups the users is in</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">/projects/&lt;group&gt;</span></code> similar, but is read-only! So don‚Äôt use this to store your generated
container directly, but rather move it here afterwards</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">/tmp</span></code> is the VM local temporary directory. All files put here will be lost!</p></li>
</ul>
<p>If the current directory is inside (or equal to) one of the above (except <code class="docutils literal notranslate"><span class="pre">/tmp</span></code>), then relative
paths for container and definition work as the script changes to the VM equivalent of the current
directory.  Otherwise, you need to use absolute paths. Using <code class="docutils literal notranslate"><span class="pre">~</span></code> in place of <code class="docutils literal notranslate"><span class="pre">$HOME</span></code> does work too.</p>
<p>Under the hood, the filesystem of ZIH systems is mounted via SSHFS at <code class="docutils literal notranslate"><span class="pre">/host_data</span></code>. So if you need
any other files, they can be found there.</p>
<p>There is also a new SSH key named <code class="docutils literal notranslate"><span class="pre">kvm</span></code> which is created by the scripts and authorized inside the VM
to allow for password-less access to SSHFS. This is stored at <code class="docutils literal notranslate"><span class="pre">~/.ssh/kvm</span></code> and regenerated if it
does not exist. It is also added to <code class="docutils literal notranslate"><span class="pre">~/.ssh/authorized_keys</span></code>. Note that removing the key file does
not remove it from <code class="docutils literal notranslate"><span class="pre">authorized_keys</span></code>, so remove it manually if you need to. It can be easily
identified by the comment on the key. However, removing this key is <strong>NOT</strong> recommended, as it
needs to be re-generated on every script run.</p>
</section>
<section id="start-a-job-in-a-vm">
<h2>Start a Job in a VM<a class="headerlink" href="#start-a-job-in-a-vm" title="Permalink to this heading">#</a></h2>
<p>Especially when developing a Singularity definition file, it might be useful to get a shell directly
on a VM. To do so on the Power9 architecture, simply run:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">startInVM --arch=power9</span>
</pre></div>
</div>
<p>To do so on the x86-architecture, run:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">startInVM --arch=x86</span>
</pre></div>
</div>
<p>This will execute an <code class="docutils literal notranslate"><span class="pre">srun</span></code> command with the <code class="docutils literal notranslate"><span class="pre">--cloud=kvm</span></code> parameter, wait till the VM is ready,
mount all folders (just like <code class="docutils literal notranslate"><span class="pre">buildSingularityImage</span></code>, see the Filesystem section above) and come
back with a bash inside the VM. Inside that you are root, so you can directly execute <code class="docutils literal notranslate"><span class="pre">singularity</span> <span class="pre">build</span></code> commands.</p>
<p>As usual, more options can be shown by running <code class="docutils literal notranslate"><span class="pre">startInVM</span> <span class="pre">--help</span></code>, the most important one being
<code class="docutils literal notranslate"><span class="pre">--time</span></code>.</p>
<p>There are two special use cases for this script:</p>
<ol class="arabic simple">
<li><p>Execute an arbitrary command inside the VM instead of getting a bash by appending the command to
the script.
Example: <code class="docutils literal notranslate"><span class="pre">startInVM</span> <span class="pre">--arch=power9</span> <span class="pre">singularity</span> <span class="pre">build</span> <span class="pre">~/myContainer.sif</span>&#160; <span class="pre">~/myDefinition.de</span></code></p></li>
<li><p>Use the script in a job manually allocated via srun/sbatch. This will work the same as when
running outside a job but will <strong>not</strong> start a new job. This is useful for using it inside batch
scripts, when you already have an allocation or need special arguments for the job system. Again,
you can run an arbitrary command by passing it to the script.</p></li>
</ol>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="singularity-recipes-and-hints">
<h1>Singularity Recipes and Hints<a class="headerlink" href="#singularity-recipes-and-hints" title="Permalink to this heading">#</a></h1>
<section id="example-definitions">
<h2>Example Definitions<a class="headerlink" href="#example-definitions" title="Permalink to this heading">#</a></h2>
<section id="basic-example">
<h3>Basic Example<a class="headerlink" href="#basic-example" title="Permalink to this heading">#</a></h3>
<p>A usual workflow to create Singularity Definition consists of the following steps:</p>
<ul class="simple">
<li><p>Start from base image</p></li>
<li><p>Install dependencies</p>
<ul>
<li><p>Package manager</p></li>
<li><p>Other sources</p></li>
</ul>
</li>
<li><p>Build and install own binaries</p></li>
<li><p>Provide entry points and metadata</p></li>
</ul>
<p>An example doing all this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Bootstrap:<span class="w"> </span>docker
From:<span class="w"> </span>alpine

%post
<span class="w">  </span>.<span class="w"> </span>/.singularity.d/env/10-docker*.sh

<span class="w">  </span>apk<span class="w"> </span>add<span class="w"> </span>g++<span class="w"> </span>gcc<span class="w"> </span>make<span class="w"> </span>wget<span class="w"> </span>cmake

<span class="w">  </span>wget<span class="w"> </span>https://github.com/fmtlib/fmt/archive/5.3.0.tar.gz
<span class="w">  </span>tar<span class="w"> </span>-xf<span class="w"> </span><span class="m">5</span>.3.0.tar.gz
<span class="w">  </span>mkdir<span class="w"> </span>build<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>build
<span class="w">  </span>cmake<span class="w"> </span>../fmt-5.3.0<span class="w"> </span>-DFMT_TEST<span class="o">=</span>OFF
<span class="w">  </span>make<span class="w"> </span>-j<span class="k">$(</span>nproc<span class="k">)</span><span class="w"> </span>install
<span class="w">  </span><span class="nb">cd</span><span class="w"> </span>..
<span class="w">  </span>rm<span class="w"> </span>-r<span class="w"> </span>fmt-5.3.0*

<span class="w">  </span>cat<span class="w"> </span><span class="s">&lt;&lt;&#39;EOF&#39; &gt;&gt;  hello.cpp</span>

<span class="s">#include &lt;fmt/format.h&gt;  // literal</span>

<span class="s">int main(int argc, char** argv){</span>
<span class="s">  if(argc == 1) fmt::print(&quot;No arguments passed!\n&quot;);</span>
<span class="s">  else fmt::print(&quot;Hello {}!\n&quot;, argv[1]);</span>
<span class="s">}</span>
<span class="s">EOF</span>

<span class="w">  </span>g++<span class="w"> </span>hello.cpp<span class="w"> </span>-o<span class="w"> </span>hello<span class="w"> </span>-lfmt
<span class="w">  </span>mv<span class="w"> </span>hello<span class="w"> </span>/usr/bin/hello

%runscript
<span class="w">  </span>hello<span class="w"> </span><span class="s2">&quot;</span><span class="nv">$@</span><span class="s2">&quot;</span>

%labels
<span class="w">  </span>Author<span class="w"> </span>Alexander<span class="w"> </span>Grund
<span class="w">  </span>Version<span class="w"> </span><span class="m">1</span>.0.0

%help
<span class="w">  </span>Display<span class="w"> </span>a<span class="w"> </span>greeting<span class="w"> </span>using<span class="w"> </span>the<span class="w"> </span>fmt<span class="w"> </span>library

<span class="w">  </span>Usage:
<span class="w">    </span>./hello
</pre></div>
</div>
</section>
<section id="distributed-memory">
<h3>Distributed memory<a class="headerlink" href="#distributed-memory" title="Permalink to this heading">#</a></h3>
<section id="mpich">
<h4>MPICH<a class="headerlink" href="#mpich" title="Permalink to this heading">#</a></h4>
<p>Ubuntu+MPICH definition file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Bootstrap:<span class="w"> </span>docker
From:<span class="w"> </span>ubuntu:20.04

%files
<span class="w">    </span>mpitest.c<span class="w"> </span>/opt

%environment
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">MPICH_DIR</span><span class="o">=</span>/opt/mpich
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">SINGULARITY_MPICH_DIR</span><span class="o">=</span><span class="si">${</span><span class="nv">MPICH_DIR</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">SINGULARITYENV_APPEND_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">MPICH_DIR</span><span class="si">}</span>/bin
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">SINGULAIRTYENV_APPEND_LD_LIBRARY_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">MPICH_DIR</span><span class="si">}</span>/lib

%post
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Installing required packages...&quot;</span>
<span class="w">    </span>apt-get<span class="w"> </span>update<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>wget<span class="w"> </span>git<span class="w"> </span>bash<span class="w"> </span>gcc<span class="w"> </span>gfortran<span class="w"> </span>g++<span class="w"> </span>make<span class="w"> </span>file

<span class="w">    </span><span class="c1"># required for F90 bindings</span>
<span class="w">    </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>python3

<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Installing MPICH&quot;</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">MPICH_DIR</span><span class="o">=</span>/opt/mpich
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">MPICH_VERSION</span><span class="o">=</span><span class="m">4</span>.1
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">MPICH_URL</span><span class="o">=</span><span class="s2">&quot;https://www.mpich.org/static/downloads/</span><span class="si">${</span><span class="nv">MPICH_VERSION</span><span class="si">}</span><span class="s2">/mpich-</span><span class="si">${</span><span class="nv">MPICH_VERSION</span><span class="si">}</span><span class="s2">.tar.gz&quot;</span>
<span class="w">    </span>mkdir<span class="w"> </span>-p<span class="w"> </span>/tmp/mpich
<span class="w">    </span>mkdir<span class="w"> </span>-p<span class="w"> </span>/opt
<span class="w">    </span><span class="c1"># Download</span>
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span>/tmp/mpich<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>wget<span class="w"> </span>-O<span class="w"> </span>mpich-<span class="si">${</span><span class="nv">MPICH_VERSION</span><span class="si">}</span>.tar.gz<span class="w"> </span><span class="si">${</span><span class="nv">MPICH_URL</span><span class="si">}</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>tar<span class="w"> </span>-xf<span class="w"> </span>mpich-<span class="si">${</span><span class="nv">MPICH_VERSION</span><span class="si">}</span>.tar.gz

<span class="w">    </span><span class="c1"># Configure and compile/install</span>
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span>/tmp/mpich/mpich-<span class="si">${</span><span class="nv">MPICH_VERSION</span><span class="si">}</span>
<span class="w">    </span>./configure<span class="w"> </span>--prefix<span class="o">=</span><span class="si">${</span><span class="nv">MPICH_DIR</span><span class="si">}</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>make<span class="w"> </span>install


<span class="w">    </span><span class="c1"># Set env variables so we can compile our application</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">MPICH_DIR</span><span class="si">}</span>/bin:<span class="si">${</span><span class="nv">PATH</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">MPICH_DIR</span><span class="si">}</span>/lib:<span class="si">${</span><span class="nv">LD_LIBRARY_PATH</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">MANPATH</span><span class="o">=</span><span class="si">${</span><span class="nv">MPICH_DIR</span><span class="si">}</span>/share/man:<span class="si">${</span><span class="nv">MANPATH</span><span class="si">}</span>


<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Compiling the MPI application...&quot;</span>
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span>/opt<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>mpicc<span class="w"> </span>-o<span class="w"> </span>mpitest<span class="w"> </span>mpitest.c
</pre></div>
</div>
<p>At your local machine:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>sudo<span class="w"> </span>singularity<span class="w"> </span>build<span class="w"> </span>ubuntu_mpich.sif<span class="w"> </span>ubuntu_mpich.def
</pre></div>
</div>
<p>This will create the <code class="docutils literal notranslate"><span class="pre">ubuntu_mpich.sif</span></code> file that you have to copy to HPC system.</p>
<p>At the HPC system run as following:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>srun<span class="w"> </span>---nodes<span class="o">=</span><span class="m">4</span><span class="w"> </span>--ntasks-per-node<span class="o">=</span><span class="m">2</span><span class="w"> </span>--time<span class="o">=</span><span class="m">00</span>:10:00<span class="w"> </span>singularity<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>ubuntu_mpich.sif<span class="w"> </span>/opt/mpitest
</pre></div>
</div>
</section>
</section>
<section id="cuda-cudnn-open-mpi">
<h3>CUDA + CuDNN + Open MPI<a class="headerlink" href="#cuda-cudnn-open-mpi" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Chosen CUDA version depends on installed driver of host</p></li>
<li><p>Open MPI needs PMI for Slurm integration</p></li>
<li><p>Open MPI needs CUDA for GPU copy-support</p></li>
<li><p>Open MPI needs <code class="docutils literal notranslate"><span class="pre">ibverbs</span></code> library for InfiniBand</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">openmpi-mca-params.conf</span></code> required to avoid warnings on fork (OK on ZIH systems)</p></li>
<li><p>Environment variables <code class="docutils literal notranslate"><span class="pre">SLURM_VERSION</span></code> and <code class="docutils literal notranslate"><span class="pre">OPENMPI_VERSION</span></code> can be set to  choose different
version when building the container</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Bootstrap:<span class="w"> </span>docker
From:<span class="w"> </span>nvidia/cuda-ppc64le:10.1-cudnn7-devel-ubuntu18.04

%labels
<span class="w">    </span>Author<span class="w"> </span>ZIH
<span class="w">    </span>Requires<span class="w"> </span>CUDA<span class="w"> </span>driver<span class="w"> </span><span class="m">418</span>.39+.

%post
<span class="w">    </span>.<span class="w"> </span>/.singularity.d/env/10-docker*.sh

<span class="w">    </span>apt-get<span class="w"> </span>update
<span class="w">    </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>cuda-compat-10.1
<span class="w">    </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>libibverbs-dev<span class="w"> </span>ibverbs-utils
<span class="w">    </span><span class="c1"># Install basic development tools</span>
<span class="w">    </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>gcc<span class="w"> </span>g++<span class="w"> </span>make<span class="w"> </span>wget<span class="w"> </span>python
<span class="w">    </span>apt-get<span class="w"> </span>autoremove<span class="p">;</span><span class="w"> </span>apt-get<span class="w"> </span>clean

<span class="w">    </span><span class="nb">cd</span><span class="w"> </span>/tmp

<span class="w">    </span>:<span class="w"> </span><span class="si">${</span><span class="nv">SLURM_VERSION</span><span class="p">:=17-02-11-1</span><span class="si">}</span>
<span class="w">    </span>wget<span class="w"> </span>https://github.com/SchedMD/slurm/archive/slurm-<span class="si">${</span><span class="nv">SLURM_VERSION</span><span class="si">}</span>.tar.gz
<span class="w">    </span>tar<span class="w"> </span>-xf<span class="w"> </span>slurm-<span class="si">${</span><span class="nv">SLURM_VERSION</span><span class="si">}</span>.tar.gz
<span class="w">        </span><span class="nb">cd</span><span class="w"> </span>slurm-slurm-<span class="si">${</span><span class="nv">SLURM_VERSION</span><span class="si">}</span>
<span class="w">        </span>./configure<span class="w"> </span>--prefix<span class="o">=</span>/usr/<span class="w"> </span>--sysconfdir<span class="o">=</span>/etc/slurm<span class="w"> </span>--localstatedir<span class="o">=</span>/var<span class="w"> </span>--disable-debug
<span class="w">        </span>make<span class="w"> </span>-C<span class="w"> </span>contribs/pmi2<span class="w"> </span>-j<span class="k">$(</span>nproc<span class="k">)</span><span class="w"> </span>install
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span>..
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span>slurm-*

<span class="w">    </span>:<span class="w"> </span><span class="si">${</span><span class="nv">OPENMPI_VERSION</span><span class="p">:=3.1.4</span><span class="si">}</span>
<span class="w">    </span>wget<span class="w"> </span>https://download.open-mpi.org/release/open-mpi/v<span class="si">${</span><span class="nv">OPENMPI_VERSION</span><span class="p">%.*</span><span class="si">}</span>/openmpi-<span class="si">${</span><span class="nv">OPENMPI_VERSION</span><span class="si">}</span>.tar.gz
<span class="w">    </span>tar<span class="w"> </span>-xf<span class="w"> </span>openmpi-<span class="si">${</span><span class="nv">OPENMPI_VERSION</span><span class="si">}</span>.tar.gz
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span>openmpi-<span class="si">${</span><span class="nv">OPENMPI_VERSION</span><span class="si">}</span>/
<span class="w">    </span>./configure<span class="w"> </span>--prefix<span class="o">=</span>/usr/<span class="w"> </span>--with-pmi<span class="w"> </span>--with-verbs<span class="w"> </span>--with-cuda
<span class="w">    </span>make<span class="w"> </span>-j<span class="k">$(</span>nproc<span class="k">)</span><span class="w"> </span>install
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;mpi_warn_on_fork = 0&quot;</span><span class="w"> </span>&gt;&gt;<span class="w"> </span>/usr/etc/openmpi-mca-params.conf
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;btl_openib_warn_default_gid_prefix = 0&quot;</span><span class="w"> </span>&gt;&gt;<span class="w"> </span>/usr/etc/openmpi-mca-params.conf
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span>..
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span>openmpi-*
</pre></div>
</div>
</section>
</section>
<section id="id69">
<h2>Hints<a class="headerlink" href="#id69" title="Permalink to this heading">#</a></h2>
<section id="gui-x11-applications">
<h3>GUI (X11) Applications<a class="headerlink" href="#gui-x11-applications" title="Permalink to this heading">#</a></h3>
<p>Running GUI applications inside a singularity container is possible out of the box. Check the
following definition:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>Bootstrap:<span class="w"> </span>docker
From:<span class="w"> </span>centos:7

%post
yum<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>xeyes
</pre></div>
</div>
<p>This image may be run with</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">singularity exec xeyes.sif xeyes.</span>
</pre></div>
</div>
<p>This works because all the magic is done by Singularity already like setting <code class="docutils literal notranslate"><span class="pre">${DISPLAY}</span></code> to the
outside display and mounting <code class="docutils literal notranslate"><span class="pre">${HOME}</span></code> so <code class="docutils literal notranslate"><span class="pre">${HOME}/.Xauthority</span></code> (X11 authentication cookie) is
found. When you are using <code class="docutils literal notranslate"><span class="pre">--contain</span></code> or <code class="docutils literal notranslate"><span class="pre">--no-home</span></code> you have to set that cookie yourself or
mount/copy it inside the container. Similar for <code class="docutils literal notranslate"><span class="pre">--cleanenv</span></code> you have to set <code class="docutils literal notranslate"><span class="pre">${DISPLAY}</span></code>, e.g., via</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">export SINGULARITY_DISPLAY=${DISPLAY}</span>
</pre></div>
</div>
<p>When you run a container as root (via <code class="docutils literal notranslate"><span class="pre">sudo</span></code>) you may need to allow root for your local display
port: <code class="docutils literal notranslate"><span class="pre">xhost</span> <span class="pre">+local:root\</span></code></p>
</section>
<section id="hardware-acceleration">
<h3>Hardware Acceleration<a class="headerlink" href="#hardware-acceleration" title="Permalink to this heading">#</a></h3>
<p>If you want hardware acceleration, you <strong>may</strong> need <a class="reference external" href="https://virtualgl.org">VirtualGL</a>. An example
definition file is as follows:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>Bootstrap:<span class="w"> </span>docker
From:<span class="w"> </span>centos:7

%post
yum<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>glx-utils<span class="w"> </span><span class="c1"># for glxgears example app</span>

yum<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>curl
<span class="nv">VIRTUALGL_VERSION</span><span class="o">=</span><span class="m">2</span>.6.2<span class="w"> </span><span class="c1"># Replace by required (e.g. latest) version</span>

curl<span class="w"> </span>-sSL<span class="w"> </span>https://downloads.sourceforge.net/project/virtualgl/<span class="s2">&quot;</span><span class="si">${</span><span class="nv">VIRTUALGL_VERSION</span><span class="si">}</span><span class="s2">&quot;</span>/VirtualGL-<span class="s2">&quot;</span><span class="si">${</span><span class="nv">VIRTUALGL_VERSION</span><span class="si">}</span><span class="s2">&quot;</span>.x86_64.rpm<span class="w"> </span>-o<span class="w"> </span>VirtualGL-<span class="s2">&quot;</span><span class="si">${</span><span class="nv">VIRTUALGL_VERSION</span><span class="si">}</span><span class="s2">&quot;</span>.x86_64.rpm
yum<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>VirtualGL*.rpm
/opt/VirtualGL/bin/vglserver_config<span class="w"> </span>-config<span class="w"> </span>+s<span class="w"> </span>+f<span class="w"> </span>-t
rm<span class="w"> </span>VirtualGL-*.rpm

<span class="c1"># Install video drivers AFTER VirtualGL to avoid them being overwritten</span>
yum<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>mesa-dri-drivers<span class="w"> </span><span class="c1"># for e.g. intel integrated GPU drivers. Replace by your driver</span>
</pre></div>
</div>
<p>You can now run the application with <code class="docutils literal notranslate"><span class="pre">vglrun</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">singularity exec vgl.sif vglrun glxgears</span>
</pre></div>
</div>
<p>!!! warning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Using VirtualGL may not be required at all and could even decrease the performance.
</pre></div>
</div>
<p>To check install, e.g., <code class="docutils literal notranslate"><span class="pre">glxgears</span></code> as above and your graphics driver (or use the VirtualGL image
from above) and disable <code class="docutils literal notranslate"><span class="pre">vsync</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">vblank_mode=0 singularity exec vgl.sif glxgears</span>
</pre></div>
</div>
<p>Compare the FPS output with the <code class="docutils literal notranslate"><span class="pre">glxgears</span></code> prefixed by <code class="docutils literal notranslate"><span class="pre">vglrun</span></code> (see above) to see which produces more
FPS (or runs at all).</p>
<p><strong>NVIDIA GPUs</strong> need the <code class="docutils literal notranslate"><span class="pre">--nv</span></code> parameter for the Singularity command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">singularity exec --nv vgl.sif glxgears</span>
</pre></div>
</div>
</section>
<section id="singularity-temporary-and-cache-directories">
<h3>Singularity Temporary and Cache Directories<a class="headerlink" href="#singularity-temporary-and-cache-directories" title="Permalink to this heading">#</a></h3>
<p>Singularity uses <code class="docutils literal notranslate"><span class="pre">/tmp</span></code> to store temporary data, e. g., when you use <code class="docutils literal notranslate"><span class="pre">pull</span></code> or <code class="docutils literal notranslate"><span class="pre">build</span></code>. Because
there are also diskless nodes, you may use the environment variable <code class="docutils literal notranslate"><span class="pre">SINGULARITY_TMPDIR</span></code> to change
the storage place for temporary data. You can use the following line to indicate a different
location for temporary data:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">export SINGULARITY_TMPDIR=$SOME_WORKSPACE/singularity_tmp</span>
</pre></div>
</div>
<p>Singularity commands invoked afterwards store temporary data at the indicated location.</p>
<p>!!! warning ‚ÄúSingularity caches data in your home directory by default‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Another location where Singularity stores data is your home directory! This is problematic when
Singularity caches too many containers, because you cannot start Slurm jobs if you are over a
certain limit. To prevent that from happening, indicate a different location for cache space,
e. g., a [workspace](../data_lifecycle/workspaces.md):

```console
export SINGULARITY_CACHEDIR=$SOME_WORKSPACE/singularity_cache
```
</pre></div>
</div>
<p>Further information on both environment variables can be found on
<a class="reference external" href="https://docs.sylabs.io/guides/latest/user-guide/build_env.html#build-environment">the official Singularity documentation</a>.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="software-development-and-tools">
<h1>Software Development and Tools<a class="headerlink" href="#software-development-and-tools" title="Permalink to this heading">#</a></h1>
<p>This section provides you with the basic knowledge and tools for software development
on the ZIH systems.
It will tell you:</p>
<ul class="simple">
<li><p>How to compile your code</p>
<ul>
<li><p><span class="xref myst">General advises for building software</span></p></li>
<li><p><span class="xref myst">Using compilers</span></p></li>
<li><p><span class="xref myst">GPU programming</span></p></li>
</ul>
</li>
<li><p>How to use libraries</p>
<ul>
<li><p><span class="xref myst">Using mathematical libraries</span></p></li>
</ul>
</li>
<li><p>How to deal with (or even prevent) bugs</p>
<ul>
<li><p><span class="xref myst">Find caveats and hidden errors in MPI application codes</span></p></li>
<li><p><span class="xref myst">Using debuggers</span></p></li>
</ul>
</li>
<li><p><span class="xref myst">How to investigate the performance and efficiency of your code</span></p></li>
</ul>
<p>!!! hint ‚ÄúSome general, helpful hints‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- Stick to standards wherever possible, e.g. use the `-std` flag
  for CLANG, GNU and Intel C/C++ compilers. Computers are short living
  creatures, migrating between platforms can be painful. In addition,
  running your code on different platforms greatly increases the
  reliably. You will find many bugs on one platform that never will be
  revealed on another.
- Compile your code with optimization, e.g. `-O2` will turn on a moderate level of optimization
  where most optimization algorithms are applied. Please refer to the specific documentation of
  your compiler of choice for detailed information.
- Before and during performance tuning: Make sure that your code delivers the correct results.
</pre></div>
</div>
<p>!!! questions ‚ÄúSome questions you should ask yourself‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- Given that a code is parallel, are the results independent from the
  numbers of threads or processes?
- Have you ever run your Fortran code with array bound and subroutine argument checking (the
  `-check all` and `-traceback` flags for the Intel compilers)?
- Have you checked that your code is not causing floating point exceptions?
- Does your code work with a different link order of objects?
- Have you made any assumptions regarding storage of data objects in memory?
</pre></div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="compare-system-performance-with-spechpc">
<h1>Compare System Performance with SPEChpc<a class="headerlink" href="#compare-system-performance-with-spechpc" title="Permalink to this heading">#</a></h1>
<p>SPEChpc 2021 is a benchmark suite developed by the Standard Performance Evaluation Corporation
(SPEC) for the evaluation of various, heterogeneous HPC systems. Documentation and released
benchmark results can be found on their <a class="reference external" href="https://www.spec.org/hpc2021/">web page</a>. In fact, our
system <em>Taurus</em> (partition <code class="docutils literal notranslate"><span class="pre">haswell</span></code>) is the benchmark‚Äôs reference system and thus represents
the baseline score.</p>
<p>The tool includes nine real-world scientific applications (see
<a class="reference external" href="https://www.spec.org/hpc2021/docs/result-fields.html#benchmarks">benchmark table</a>)
with different workload sizes ranging from tiny, small, medium to large, and different
parallelization models including MPI only, MPI+OpenACC, MPI+OpenMP and MPI+OpenMP with target
offloading. With this benchmark suite you can compare the performance of different HPC systems and
furthermore, evaluate parallel strategies for applications on a target HPC system. When you e.g.
want to implement an algorithm, port an application to another platform or integrate acceleration
into your code, you can determine from which target system and parallelization model your
application performance could benefit most. Or this way you can check whether an acceleration scheme
can be deployed and run on a given system, since there could be software issues restricting a
capable hardware (see this <span class="xref myst">CUDA issue</span>).</p>
<p>Since TU Dresden is a member of the SPEC consortium, the HPC benchmarks can be requested by anyone
interested. Please contact
<a class="reference external" href="https://tu-dresden.de/zih/die-einrichtung/struktur/holger-brunst">Holger Brunst</a> for access.</p>
<section id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this heading">#</a></h2>
<p>The target partition determines which of the parallelization models can be used, and vice versa.
For example, if you want to run a model including acceleration, you would have to use a partition
with GPUs.</p>
<p>Once the target partition is determined, follow SPEC‚Äôs
<a class="reference external" href="https://www.spec.org/hpg/hpc2021/Docs/install-guide-linux.html">Installation Guide</a>.
It is straight-forward and easy to use.</p>
<p>???+ tip ‚ÄúBuilding for partition <code class="docutils literal notranslate"><span class="pre">ml</span></code>‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The partition `ml` is a Power9 architecture. Thus, you need to provide the `-e ppc64le` switch
when installing.
</pre></div>
</div>
<p>???+ tip ‚ÄúBuilding with NVHPC for partition <code class="docutils literal notranslate"><span class="pre">alpha</span></code>‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>To build the benchmark for partition `alpha`, you don&#39;t need an interactive session
on the target architecture. You can stay on the login nodes as long as you set the
flag `-tp=zen`. You can add this compiler flag to the configuration file.
</pre></div>
</div>
<p>If you are facing errors during the installation process, check the <span class="xref myst">solved</span> and
<span class="xref myst">unresolved issues</span> sections for our systems. The problem might already be
listed there.</p>
</section>
<section id="id70">
<h2>Configuration<a class="headerlink" href="#id70" title="Permalink to this heading">#</a></h2>
<p>The behavior in terms of how to build, run and report the benchmark in a particular environment is
controlled by a configuration file. There are a few examples included in the source code.
Here you can apply compiler tuning and porting, specify the runtime environment and describe the
system under test. SPEChpc 2021 has been deployed on the partitions <code class="docutils literal notranslate"><span class="pre">haswell</span></code>, <code class="docutils literal notranslate"><span class="pre">ml</span></code> and
<code class="docutils literal notranslate"><span class="pre">alpha</span></code>. Configurations are available, respectively:</p>
<ul class="simple">
<li><p><span class="xref myst">gnu-taurus.cfg</span></p></li>
<li><p><span class="xref myst">nvhpc-ppc.cfg</span></p></li>
<li><p><span class="xref myst">nvhpc-alpha.cfg</span></p></li>
</ul>
<p>No matter which one you choose as a starting point,
double-check the line that defines the submit command and make sure it says <code class="docutils literal notranslate"><span class="pre">srun</span> <span class="pre">[...]</span></code>, e.g.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">submit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>srun<span class="w"> </span><span class="nv">$command</span>
</pre></div>
</div>
<p>Otherwise this can cause trouble (see <span class="xref myst">Slurm Bug</span>).
You can also put Slurm options in the configuration but it is recommended to do this in a job
script (see chapter <span class="xref myst">Execution</span>). Use the following to apply your configuration to the
benchmark run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">runhpc</span> <span class="o">--</span><span class="n">config</span> <span class="o">&lt;</span><span class="n">configfile</span><span class="o">.</span><span class="n">cfg</span><span class="o">&gt;</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>
</pre></div>
</div>
<p>For more details about configuration settings check out the following links:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.spec.org/hpc2021/Docs/config.html">Config Files Description</a></p></li>
<li><p><a class="reference external" href="https://www.spec.org/hpc2021/results/res2021q4/hpc2021-20210917-00050.flags.html">Flag Description</a></p></li>
<li><p><a class="reference external" href="https://www.spec.org/hpc2021/docs/result-fields.html">Result File Fields Description</a></p></li>
</ul>
</section>
<section id="execution">
<h2>Execution<a class="headerlink" href="#execution" title="Permalink to this heading">#</a></h2>
<p>The SPEChpc 2021 benchmark suite is executed with the <code class="docutils literal notranslate"><span class="pre">runhpc</span></code> command, which also sets it‚Äôs
configuration and controls it‚Äôs runtime behavior. For all options, see SPEC‚Äôs documentation about
<a class="reference external" href="https://www.spec.org/hpc2021/Docs/runhpc.html"><code class="docutils literal notranslate"><span class="pre">runhpc</span></code> options</a>.
First, execute <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">shrc</span></code> in your SPEC installation directory. Then use a job script to submit a
job with the benchmark or parts of it.</p>
<p>In the following there are job scripts shown for partitions <code class="docutils literal notranslate"><span class="pre">haswell</span></code>, <code class="docutils literal notranslate"><span class="pre">ml</span></code> and <code class="docutils literal notranslate"><span class="pre">alpha</span></code>,
respectively. You can use them as a template in order to reproduce results or to transfer the
execution to a different partition.</p>
<ul class="simple">
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">&lt;p_number_crunch&gt;</span></code> (line 2) with your project name</p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">ws=&lt;/scratch/ws/spec/installation&gt;</span></code> (line 15/18) with your SPEC installation path</p></li>
</ul>
<section id="submit-spechpc-benchmarks-with-a-job-file">
<h3>Submit SPEChpc Benchmarks with a Job File<a class="headerlink" href="#submit-spechpc-benchmarks-with-a-job-file" title="Permalink to this heading">#</a></h3>
<p>=== ‚Äúsubmit_spec_haswell_mpi.sh‚Äù
```bash linenums=‚Äù1‚Äù
#!/bin/bash
#SBATCH ‚Äìaccount=&lt;p_number_crunch&gt;
#SBATCH ‚Äìpartition=haswell64
#SBATCH ‚Äìexclusive
#SBATCH ‚Äìnodes=1
#SBATCH ‚Äìntasks=24
#SBATCH ‚Äìcpus-per-task=1
#SBATCH ‚Äìmem-per-cpu=2541M
#SBATCH ‚Äìtime=16:00:00
#SBATCH ‚Äìconstraint=DA</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>module purge
module load gompi/2019a

ws=&lt;/scratch/ws/spec/installation&gt;
cd ${ws}
source shrc

# reportable run with all benchmarks
BENCH=&quot;tiny&quot;

runhpc --config gnu-taurus --define model=mpi --ranks=24 --reportable --tune=base --flagsurl=$SPEC/config/flags/gcc_flags.xml ${BENCH}
```
</pre></div>
</div>
<p>=== ‚Äúsubmit_spec_ml_openacc.sh‚Äù
```bash linenums=‚Äù1‚Äù
#!/bin/bash
#SBATCH ‚Äìaccount=&lt;p_number_crunch&gt;
#SBATCH ‚Äìpartition=ml
#SBATCH ‚Äìexclusive
#SBATCH ‚Äìnodes=1
#SBATCH ‚Äìntasks=6
#SBATCH ‚Äìcpus-per-task=7
#SBATCH ‚Äìgpus-per-task=1
#SBATCH ‚Äìgres=gpu:6
#SBATCH ‚Äìmem-per-cpu=5772M
#SBATCH ‚Äìtime=00:45:00
#SBATCH ‚Äìexport=ALL
#SBATCH ‚Äìhint=nomultithread</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>module --force purge
module load modenv/ml NVHPC OpenMPI/4.0.5-NVHPC-21.2-CUDA-11.2.1

ws=&lt;/scratch/ws/spec/installation&gt;
cd ${ws}
source shrc

export OMPI_CC=nvc
export OMPI_CXX=nvc++
export OMPI_FC=nvfortran

suite=&#39;tiny ^pot3d_t&#39;
cfg=nvhpc_ppc.cfg

# test run
runhpc -I --config ${cfg} --ranks ${SLURM_NTASKS} --define pmodel=acc --size=test --noreportable --tune=base --iterations=1 ${suite}

# reference run
runhpc --config ${cfg} --ranks ${SLURM_NTASKS} --define pmodel=acc --rebuild --tune=base --iterations=3 ${suite}
```
</pre></div>
</div>
<p>=== ‚Äúsubmit_spec_alpha_openacc.sh‚Äù
```bash linenums=‚Äù1‚Äù
#!/bin/bash
#SBATCH ‚Äìaccount=&lt;p_number_crunch&gt;
#SBATCH ‚Äìpartition=alpha
#SBATCH ‚Äìexclusive
#SBATCH ‚Äìnodes=1
#SBATCH ‚Äìntasks-per-node=8
#SBATCH ‚Äìcpus-per-task=6
#SBATCH ‚Äìgpus-per-task=1
#SBATCH ‚Äìgres=gpu:8
#SBATCH ‚Äìmem-per-cpu=20624M
#SBATCH ‚Äìtime=00:45:00
#SBATCH ‚Äìexport=ALL
#SBATCH ‚Äìhint=nomultithread</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>module --force purge
module load modenv/hiera NVHPC OpenMPI

ws=&lt;/scratch/ws/spec/installation&gt;
cd ${ws}
source shrc

suite=&#39;tiny&#39;
cfg=nvhpc_alpha.cfg

# test run
runhpc -I --config ${cfg} --ranks ${SLURM_NTASKS} --define pmodel=acc --size=test --noreportable --tune=base --iterations=1 ${suite}

# reference workload
runhpc --config ${cfg} --ranks ${SLURM_NTASKS} --define pmodel=acc --tune=base --iterations=3 ${suite}
```
</pre></div>
</div>
</section>
</section>
<section id="solved-issues">
<h2>Solved Issues<a class="headerlink" href="#solved-issues" title="Permalink to this heading">#</a></h2>
<section id="fortran-compilation-error">
<h3>Fortran Compilation Error<a class="headerlink" href="#fortran-compilation-error" title="Permalink to this heading">#</a></h3>
<p>!!! failure ‚ÄúPGF90-F-0004-Corrupt or Old Module file‚Äù</p>
<p>!!! note ‚ÄúExplanation‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If this error arises during runtime, it means that the benchmark binaries and the MPI module
do not fit together. This happens when you have built the benchmarks written in Fortran with a
different compiler than which was used to build the MPI module that was loaded for the run.
</pre></div>
</div>
<p>!!! success ‚ÄúSolution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1. Use the correct MPI module
    - The MPI module in use must be compiled with the same compiler that was used to build the
    benchmark binaries. Check the results of `module avail` and choose a corresponding module.
1. Rebuild the binaries
    - Rebuild the binaries using the same compiler as for the compilation of the MPI module of
    choice.
1. Request a new module
    - Ask the HPC support to install a compatible MPI module.
1. Build your own MPI module (as a last resort)
    - Download and build a private MPI module using the same compiler as for building the
    benchmark binaries.
</pre></div>
</div>
</section>
<section id="pmix-error">
<h3>pmix Error<a class="headerlink" href="#pmix-error" title="Permalink to this heading">#</a></h3>
<p>!!! failure ‚ÄúPMIX ERROR‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
It looks like the function `pmix_init` failed for some reason; your parallel process is
likely to abort. There are many reasons that a parallel process can
fail during pmix_init; some of which are due to configuration or
environment problems. This failure appears to be an internal failure;

mix_progress_thread_start failed
--&gt; Returned value -1 instead of PMIX_SUCCESS

*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
***    and potentially your MPI job)
```
</pre></div>
</div>
<p>!!! note ‚ÄúExplanation‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>This is most probably a MPI related issue. If you built your own MPI module, PMIX support might
be configured wrong.
</pre></div>
</div>
<p>!!! success ‚ÄúSolution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Use `configure --with-pmix=internal` during the `cmake` configuration routine.
</pre></div>
</div>
</section>
<section id="orte-error-too-many-processes">
<h3>ORTE Error (too many processes)<a class="headerlink" href="#orte-error-too-many-processes" title="Permalink to this heading">#</a></h3>
<p>!!! failure ‚ÄúError: system limit exceeded on number of processes that can be started‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ORTE_ERROR_LOG: The system limit on number of children a process can have was reached.
</pre></div>
</div>
<p>!!! note ‚ÄúExplanation‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>There are too many processes spawned, probably due to a wrong job allocation and/or invocation.
</pre></div>
</div>
<p>!!! success ‚ÄúSolution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Check the invocation command line in your job script. It must not say `srun runhpc [...]`
there, but only `runhpc [...]`. The submit command in the [configuration](#configuration) file
already contains `srun`. When `srun` is called in both places, too many parallel processes are
spawned.
</pre></div>
</div>
</section>
<section id="error-with-openfabrics-device">
<h3>Error with OpenFabrics Device<a class="headerlink" href="#error-with-openfabrics-device" title="Permalink to this heading">#</a></h3>
<p>!!! warning ‚ÄúThere was an error initializing an OpenFabrics device‚Äù</p>
<p>!!! note ‚ÄúExplanation‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;I think it‚Äôs just trying to find the InfiniBand libraries, which aren‚Äôt used, but can‚Äôt.
It‚Äôs probably safe to ignore.&quot;
&lt;p style=&#39;text-align: right;&#39;&gt; Matthew Colgrove, Nvidia &lt;/p&gt;
</pre></div>
</div>
<p>!!! success ‚ÄúSolution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>This is just a warning which cannot be suppressed, but can be ignored.
</pre></div>
</div>
</section>
<section id="out-of-memory">
<h3>Out of Memory<a class="headerlink" href="#out-of-memory" title="Permalink to this heading">#</a></h3>
<p>!!! failure ‚ÄúOut of memory‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```
Out of memory allocating [...] bytes of device memory
call to cuMemAlloc returned error 2: Out of memory
```
</pre></div>
</div>
<p>!!! note ‚ÄúExplanation‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- When running on a single node with all of its memory allocated, there is not enough memory
for the benchmark.
- When running on multiple nodes, this might be a wrong resource distribution caused by Slurm.
Check the `$SLURM_NTASKS_PER_NODE` environment variable. If it says something like `15,1` when
you requested 8 processes per node, Slurm was not able to hand over the resource distribution
to `mpirun`.
</pre></div>
</div>
<p>!!! success ‚ÄúSolution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- Expand your job from single node to multiple nodes.
- Reduce the workload (e.g. form small to tiny).
- Make sure to use `srun` instead of `mpirun` as the submit command in your
[configuration](#configuration) file.
</pre></div>
</div>
</section>
</section>
<section id="unresolved-issues">
<h2>Unresolved Issues<a class="headerlink" href="#unresolved-issues" title="Permalink to this heading">#</a></h2>
<section id="cuda-reduction-operation-error">
<h3>CUDA Reduction Operation Error<a class="headerlink" href="#cuda-reduction-operation-error" title="Permalink to this heading">#</a></h3>
<p>!!! failure ‚ÄúThere was a problem while initializing support for the CUDA reduction operations.‚Äù</p>
<p>!!! note ‚ÄúExplanation‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>For OpenACC, NVHPC was in the process of adding OpenMP array reduction support which is needed
for the `pot3d` benchmark. An Nvidia driver version of 450.80.00 or higher is required. Since
the driver version on partiton `ml` is 440.64.00, it is not supported and not possible to run
the `pot3d` benchmark in OpenACC mode here.
</pre></div>
</div>
<p>!!! note ‚ÄúWorkaround‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>As for the partition `ml`, you can only wait until the OS update to CentOS 8 is carried out,
as no driver update will be done beforehand. As a workaround, you can do one of the following:

- Exclude the `pot3d` benchmark.
- Switch the partition (e.g. to partition `alpha`).
</pre></div>
</div>
</section>
<section id="slurm-bug">
<h3>Slurm Bug<a class="headerlink" href="#slurm-bug" title="Permalink to this heading">#</a></h3>
<p>!!! warning ‚ÄúWrong resource distribution‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>When working with multiple nodes on partition `ml` or `alpha`, the Slurm parameter
`$SLURM_NTASKS_PER_NODE` does not work as intended when used in conjunction with `mpirun`.
</pre></div>
</div>
<p>!!! note ‚ÄúExplanation‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>In the described case, when setting e.g. `SLURM_NTASKS_PER_NODE=8` and calling `mpirun`, Slurm
is not able to pass on the allocation settings correctly. With two nodes, this leads to a
distribution of 15 processes on the first node and 1 process on the second node instead. In
fact, none of the proposed methods of Slurm&#39;s man page (like `--distribution=plane=8`) will
give the result as intended in this case.
</pre></div>
</div>
<p>!!! note ‚ÄúWorkaround‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- Use `srun` instead of `mpirun`.
- Use `mpirun` along with a rank-binding perl script (like
`mpirun -np &lt;ranks&gt; perl &lt;bind.pl&gt; &lt;command&gt;`) as seen on the bottom of the configurations
[here](https://www.spec.org/hpc2021/results/res2021q4/hpc2021-20210908-00012.cfg) and
[here](https://www.spec.org/hpc2021/results/res2021q4/hpc2021-20210917-00056.cfg)
in order to enforce the correct distribution of ranks as it was intended.
</pre></div>
</div>
</section>
<section id="benchmark-hangs-forever">
<h3>Benchmark Hangs Forever<a class="headerlink" href="#benchmark-hangs-forever" title="Permalink to this heading">#</a></h3>
<p>!!! warning ‚ÄúThe benchmark runs forever and produces a timeout.‚Äù</p>
<p>!!! note ‚ÄúExplanation‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The reason for this is not known, however, it is caused by the flag `-DSPEC_ACCEL_AWARE_MPI`.
</pre></div>
</div>
<p>!!! note ‚ÄúWorkaround‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Remove the flag `-DSPEC_ACCEL_AWARE_MPI` from the compiler options in your configuration file.
</pre></div>
</div>
</section>
<section id="other-issues">
<h3>Other Issues<a class="headerlink" href="#other-issues" title="Permalink to this heading">#</a></h3>
<p>For any further issues you can consult SPEC‚Äôs
<a class="reference external" href="https://www.spec.org/hpc2021/Docs/faq.html">FAQ page</a>, search through their
<a class="reference external" href="https://www.spec.org/hpc2021/Docs/known-problems.html">known issues</a> or contact their
<a class="reference external" href="https://www.spec.org/hpc2021/Docs/techsupport.html">support</a>.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="inspect-model-training-with-tensorboard">
<h1>Inspect Model Training with TensorBoard<a class="headerlink" href="#inspect-model-training-with-tensorboard" title="Permalink to this heading">#</a></h1>
<p>TensorBoard is a visualization toolkit for TensorFlow and offers a variety of functionalities such
as presentation of loss and accuracy, visualization of the model graph or profiling of the
application.</p>
<section id="using-jupyterhub">
<h2>Using JupyterHub<a class="headerlink" href="#using-jupyterhub" title="Permalink to this heading">#</a></h2>
<p>The easiest way to use TensorBoard is via <span class="xref myst">JupyterHub</span>. By default,
TensorBoard is configured to read log data from <code class="docutils literal notranslate"><span class="pre">/tmp/&lt;username&gt;/tf-logs</span></code> on the compute node on
which the Jupyter session is running. In order to show your own log data from a different directory,
soft-link this directory with <code class="docutils literal notranslate"><span class="pre">/tmp/&lt;username&gt;/tf-logs</span></code> in order to make TensorBoard reading your
log data. Note, that the directory <code class="docutils literal notranslate"><span class="pre">/tmp/&lt;username&gt;/tf-logs</span></code> might not exist and you have to
create it first. Therefore, open a ‚ÄúNew Launcher‚Äù (<code class="docutils literal notranslate"><span class="pre">Ctrl+Shift+L</span></code>) and select ‚ÄúTerminal‚Äù session.
It will start a new terminal on the respective compute node. Then you can create the directory
<code class="docutils literal notranslate"><span class="pre">/tmp/&lt;username&gt;/tf-logs</span></code> and link it with the directory where your own log data is located.
Assuming you use a line like the following in your code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tensorboard_callback</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;/home/marie/logs&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>You can then make the TensorBoard available from the Jupyter terminal with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>/tmp/<span class="si">${</span><span class="nv">USER</span><span class="si">}</span>/tf-logs
ln<span class="w"> </span>-s<span class="w"> </span>/home/marie/logs<span class="w"> </span>/tmp/<span class="si">${</span><span class="nv">USER</span><span class="si">}</span>/tf-logs
</pre></div>
</div>
<p>Update TensorBoard tab if needed with <code class="docutils literal notranslate"><span class="pre">F5</span></code>.</p>
</section>
<section id="using-tensorboard-from-module-environment">
<h2>Using TensorBoard from Module Environment<a class="headerlink" href="#using-tensorboard-from-module-environment" title="Permalink to this heading">#</a></h2>
<p>On ZIH systems, TensorBoard is also available as an extension of the TensorFlow module. To check
whether a specific TensorFlow module provides TensorBoard, use the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>spider<span class="w"> </span>TensorFlow/2.3.1
<span class="go">[...]</span>
<span class="go">        Included extensions</span>
<span class="go">        ===================</span>
<span class="go">        absl-py-0.10.0, astor-0.8.0, astunparse-1.6.3, cachetools-4.1.1, gast-0.3.3,</span>
<span class="go">        google-auth-1.21.3, google-auth-oauthlib-0.4.1, google-pasta-0.2.0,</span>
<span class="go">        grpcio-1.32.0, Keras-Preprocessing-1.1.2, Markdown-3.2.2, oauthlib-3.1.0, opt-</span>
<span class="go">        einsum-3.3.0, pyasn1-modules-0.2.8, requests-oauthlib-1.3.0, rsa-4.6,</span>
<span class="go">        tensorboard-2.3.0, tensorboard-plugin-wit-1.7.0, TensorFlow-2.3.1, tensorflow-</span>
<span class="go">        estimator-2.3.0, termcolor-1.1.0, Werkzeug-1.0.1, wrapt-1.12.1</span>
</pre></div>
</div>
<p>If TensorBoard occurs in the <code class="docutils literal notranslate"><span class="pre">Included</span> <span class="pre">extensions</span></code> section of the output, TensorBoard is available.</p>
<p>To use TensorBoard, you have to connect via ssh to the ZIH system as usual, schedule an interactive
job and load a TensorFlow module:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>load<span class="w"> </span>TensorFlow/2.3.1
<span class="go">Module TensorFlow/2.3.1-fosscuda-2019b-Python-3.7.4 and 47 dependencies loaded.</span>
</pre></div>
</div>
<p>Then, create a workspace for the event data, that should be visualized in TensorBoard. If you
already have an event data directory, you can skip that step.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>ws_allocate<span class="w"> </span>-F<span class="w"> </span>/data/horse<span class="w"> </span>tensorboard_logdata<span class="w"> </span><span class="m">1</span>
<span class="go">Info: creating workspace.</span>
<span class="go">/data/horse/ws/marie-tensorboard_logdata</span>
<span class="go">[...]</span>
</pre></div>
</div>
<p>Now, you can run your TensorFlow application. Note that you might have to adapt your code to make it
accessible for TensorBoard. Please find further information on the official <a class="reference external" href="https://www.tensorflow.org/tensorboard/get_started">TensorBoard website</a>
Then, you can start TensorBoard and pass the directory of the event data:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>tensorboard<span class="w"> </span>--logdir<span class="w"> </span>/data/horse/ws/marie-tensorboard_logdata<span class="w"> </span>--bind_all
<span class="go">[...]</span>
<span class="go">TensorBoard 2.3.0 at http://taurusi8034.taurus.hrsk.tu-dresden.de:6006/</span>
<span class="go">[...]</span>
</pre></div>
</div>
<p>TensorBoard then returns a server address on Taurus, e.g. <code class="docutils literal notranslate"><span class="pre">taurusi8034.taurus.hrsk.tu-dresden.de:6006</span></code></p>
<p>For accessing TensorBoard now, you have to set up some port forwarding via ssh to your local
machine:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>ssh<span class="w"> </span>-N<span class="w"> </span>-f<span class="w"> </span>-L<span class="w"> </span><span class="m">6006</span>:taurusi8034:6006<span class="w"> </span>taurus
</pre></div>
</div>
<p>!!! important ‚ÄúSSH command‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The previous SSH command requires that you have already set up your [SSH configuration
](../access/ssh_login.md#configuring-default-parameters-for-ssh).
</pre></div>
</div>
<p>Now, you can see the TensorBoard in your browser at <code class="docutils literal notranslate"><span class="pre">http://localhost:6006/</span></code>.</p>
<p>Note that you can also use TensorBoard in an <span class="xref myst">sbatch file</span>.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="neural-networks-with-tensorflow">
<h1>Neural Networks with TensorFlow<a class="headerlink" href="#neural-networks-with-tensorflow" title="Permalink to this heading">#</a></h1>
<p><a class="reference external" href="https://www.tensorflow.org">TensorFlow</a> is a free end-to-end open-source software library for data
flow and differentiable programming across many tasks. It is a symbolic math library, used primarily
for machine learning applications. It has a comprehensive, flexible ecosystem of tools, libraries
and community resources.</p>
<p>Please check the software modules list via</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>spider<span class="w"> </span>TensorFlow
<span class="go">[...]</span>
</pre></div>
</div>
<p>to find out, which TensorFlow modules are available on your cluster.</p>
<p>On ZIH systems, TensorFlow 2 is the default module version. For compatibility hints between
TensorFlow 2 and TensorFlow 1, see the corresponding <span class="xref myst">section below</span>.</p>
<p>We recommend using the clusters <code class="docutils literal notranslate"><span class="pre">Alpha</span></code>, <code class="docutils literal notranslate"><span class="pre">Capella</span></code> and/or <code class="docutils literal notranslate"><span class="pre">Power9</span></code> when working with machine
learning workflows and the TensorFlow library. You can find detailed hardware specification in our
<span class="xref myst">Hardware</span> documentation.
Available software may differ among the clusters.</p>
<section id="tensorflow-console">
<h2>TensorFlow Console<a class="headerlink" href="#tensorflow-console" title="Permalink to this heading">#</a></h2>
<p>On the cluster <code class="docutils literal notranslate"><span class="pre">Alpha</span></code>, load the module environment:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@alpha$ </span>module<span class="w"> </span>load<span class="w"> </span>release/23.04
</pre></div>
</div>
<p>Alternatively you can use <code class="docutils literal notranslate"><span class="pre">release/23.10</span></code> module environment, where the newest versions are
available</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">[marie@alpha ]$ </span>module<span class="w"> </span>load<span class="w"> </span>release/23.10<span class="w">  </span>GCC/11.3.0<span class="w">  </span>OpenMPI/4.1.4
<span class="go">Module GCC/11.3.0, OpenMPI/4.1.4 and 14 dependencies loaded.</span>

<span class="gp">[marie@alpha ]$ </span>module<span class="w"> </span>load<span class="w"> </span>TensorFlow/2.9.1
<span class="go">Module TensorFlow/2.9.1 and 35 dependencies loaded.</span>
<span class="gp">[marie@alpha ]$ </span>module<span class="w"> </span>avail<span class="w"> </span>TensorFlow

<span class="go">-------- /software/modules/rapids/r23.10/all/MPI/GCC/11.3.0/OpenMPI/4.1.4 --------</span>
<span class="go">   TensorFlow/2.9.1 (L)</span>

<span class="go">  Where:</span>
<span class="go">   L:  Module is loaded</span>
<span class="go">   *Module:  Some Toolchain, load to access other modules that depend on it</span>
<span class="go">   &gt;Module:  Recommended toolchain version, load to access other modules that depend on it</span>
</pre></div>
</div>
<p>This example shows how to install and start working with TensorFlow using the modules system.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@power$ </span>module<span class="w"> </span>load<span class="w"> </span>TensorFlow
<span class="go">Module TensorFlow/2.3.1-fosscuda-2019b-Python-3.7.4 and 47 dependencies loaded.</span>
</pre></div>
</div>
<p>Now we can use TensorFlow. Nevertheless when working with Python in an interactive job, we recommend
to use a virtual environment. In the following example, we create a python virtual environment and
import TensorFlow:</p>
<p>!!! example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@power$ ws_allocate -F horse python_virtual_environment 1
Info: creating workspace.
/data/horse/ws/python_virtual_environment
[...]
marie@power$ which python    #check which python are you using
/sw/installed/Python/3.7.2-GCCcore-8.2.0
marie@power$ virtualenv --system-site-packages /data/horse/ws/marie-python_virtual_environment/env
[...]
marie@power$ source /data/horse/ws/marie-python_virtual_environment/env/bin/activate
marie@power$ python -c &quot;import tensorflow as tf; print(tf.__version__)&quot;
[...]
2.3.1
```
</pre></div>
</div>
</section>
<section id="tensorflow-in-jupyterhub">
<h2>TensorFlow in JupyterHub<a class="headerlink" href="#tensorflow-in-jupyterhub" title="Permalink to this heading">#</a></h2>
<p>In addition to interactive and batch jobs, it is possible to work with TensorFlow using
JupyterHub, which contains a kernel named <code class="docutils literal notranslate"><span class="pre">Python</span> <span class="pre">3</span> <span class="pre">...</span> <span class="pre">TensorFlow</span></code>, that
come with TensorFlow support.</p>
<p><img alt="TensorFlow module in JupyterHub" src="63_chat_with_docs/misc/tensorflow_jupyter_module.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>!!! hint</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>You can also define your own Jupyter kernel for more specific tasks. Please read about Jupyter
kernels and virtual environments in our
[JupyterHub](../access/jupyterhub_custom_environments.md) documentation.
</pre></div>
</div>
</section>
<section id="tensorflow-in-containers">
<h2>TensorFlow in Containers<a class="headerlink" href="#tensorflow-in-containers" title="Permalink to this heading">#</a></h2>
<p>Another option to use TensorFlow are containers. In the HPC domain, the
<a class="reference external" href="https://singularity.hpcng.org/">Singularity</a> container system is a widely used tool. In the
following example, we use the tensorflow-test in a Singularity container:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@power$ </span>singularity<span class="w"> </span>shell<span class="w"> </span>--nv<span class="w"> </span>/data/horse/singularity/powerai-1.5.3-all-ubuntu16.04-py3.img
<span class="go">Singularity&gt;$ export PATH=/opt/anaconda3/bin:$PATH</span>
<span class="go">Singularity&gt;$ source activate /opt/anaconda3    #activate conda environment</span>
<span class="gp gp-VirtualEnv">(base)</span> <span class="go">Singularity&gt;$ . /opt/DL/tensorflow/bin/tensorflow-activate</span>
<span class="gp gp-VirtualEnv">(base)</span> <span class="go">Singularity&gt;$ tensorflow-test</span>
<span class="go">Basic test of tensorflow - A Hello World!!!...</span>
<span class="go">[...]</span>
</pre></div>
</div>
<p>!!! hint
In the above example, we create a conda virtual environment. To use conda, it is be necessary to
configure your shell as described in <span class="xref myst">Python virtual environments</span></p>
</section>
<section id="tensorflow-with-python-or-r">
<h2>TensorFlow with Python or R<a class="headerlink" href="#tensorflow-with-python-or-r" title="Permalink to this heading">#</a></h2>
<p>For further information on TensorFlow in combination with Python see
<span class="xref myst">data analytics with Python</span>, for R see
<span class="xref myst">data analytics with R</span>.</p>
</section>
<section id="id71">
<h2>Distributed TensorFlow<a class="headerlink" href="#id71" title="Permalink to this heading">#</a></h2>
<p>For details on how to run TensorFlow with multiple GPUs and/or multiple nodes, see
<span class="xref myst">distributed training</span>.</p>
</section>
<section id="compatibility-tf2-and-tf1">
<h2>Compatibility TF2 and TF1<a class="headerlink" href="#compatibility-tf2-and-tf1" title="Permalink to this heading">#</a></h2>
<p>TensorFlow 2.0 includes many API changes, such as reordering arguments, renaming symbols, and
changing default values for parameters. Thus in some cases, it makes code written for the TensorFlow
1.X not compatible with TensorFlow 2.X. However, If you are using the high-level APIs (<code class="docutils literal notranslate"><span class="pre">tf.keras</span></code>)
there may be little or no action you need to take to make your code fully
<a class="reference external" href="https://www.tensorflow.org/guide/migrate">TensorFlow 2.0</a> compatible. It is still possible to
run 1.X code, unmodified (except for <code class="docutils literal notranslate"><span class="pre">contrib</span></code>), in TensorFlow 2.0:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow.compat.v1</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">disable_v2_behavior</span><span class="p">()</span>    <span class="c1">#instead of &quot;import tensorflow as tf&quot;</span>
</pre></div>
</div>
<p>To make the transition to TensorFlow 2.0 as seamless as possible, the TensorFlow team has created
the tf_upgrade_v2 utility to help transition legacy code to the new API.</p>
</section>
<section id="keras">
<h2>Keras<a class="headerlink" href="#keras" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://keras.io">Keras</a> is a high-level neural network API, written in Python and capable
of running on top of TensorFlow. Please check the software modules list via</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>module<span class="w"> </span>spider<span class="w"> </span>Keras
<span class="go">[...]</span>
</pre></div>
</div>
<p>to find out, which Keras modules are available on your cluster. TensorFlow should be automatically
loaded as a dependency. After loading the module, you can use Keras as usual.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="utilities">
<h1>Utilities<a class="headerlink" href="#utilities" title="Permalink to this heading">#</a></h1>
<p>This page provides tools and utilities that make your life on ZIH systems more comfortable.</p>
<section id="tmux">
<h2>Tmux<a class="headerlink" href="#tmux" title="Permalink to this heading">#</a></h2>
<section id="best-practices">
<h3>Best Practices<a class="headerlink" href="#best-practices" title="Permalink to this heading">#</a></h3>
<p>Terminal multiplexers are particularly well-suited for aiding you as a computer scientist in your
daily trade. We generally favor <em>tmux</em> as it‚Äôs newer than certain others and allows for better
customization.</p>
<p>As there is already plenty of documentation on how to use tmux, we won‚Äôt repeat that here. But
instead, we would like to point you to those documents:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://manpages.org/tmux">Tmux man page</a></p></li>
<li><p><a class="reference external" href="https://tmuxguide.readthedocs.io/en/latest/tmux/tmux.html#tmux-conf">Tmux customization</a></p></li>
<li><p><a class="reference external" href="https://tao-of-tmux.readthedocs.io/en/latest/">Tao of Tmux</a></p></li>
<li><p><a class="reference external" href="https://tmuxcheatsheet.com/">Tmux Cheat Sheet</a></p></li>
</ul>
</section>
<section id="basic-usage">
<h3>Basic Usage<a class="headerlink" href="#basic-usage" title="Permalink to this heading">#</a></h3>
<p>Tmux is a terminal multiplexer. It lets you switch easily between several programs in one
terminal, detach them (they keep running in the background), and reattach them to a different
terminal.</p>
<p>The huge advantage is, that as long as your tmux session is running, you can connect to it and your
settings (e.g., loaded modules, current working directory, ‚Ä¶) are in place. This is
beneficial when working within an unstable network with connection losses (e.g., traveling by the
train in Germany), but also speed-ups your workflow in the daily routine.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>tmux<span class="w"> </span>new-session<span class="w"> </span>-s<span class="w"> </span>marie_is_testing<span class="w"> </span>-d
<span class="gp">marie@compute$ </span>tmux<span class="w"> </span>attach<span class="w"> </span>-t<span class="w"> </span>marie_is_testing
<span class="go">  echo &quot;hello world&quot;</span>
<span class="go">  ls -l</span>
<span class="go">Ctrl+b &amp; d</span>
</pre></div>
</div>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you want to jump out of your tmux session, hold the Control key and press &#39;b&#39;. After that,
release both keys and press &#39;d&#39;. With the first key combination, you address tmux itself, whereas
&#39;d&#39; is the tmux command to &quot;detach&quot; yourself from it. The tmux session will stay alive and
running. You can jump into it any time later by just using the aforementioned &quot;tmux attach&quot;
command again.
</pre></div>
</div>
</section>
<section id="using-a-more-recent-version">
<h3>Using a More Recent Version<a class="headerlink" href="#using-a-more-recent-version" title="Permalink to this heading">#</a></h3>
<p>More recent versions of tmux are available via the module system. Using the well know
<span class="xref myst">module commands</span>, you can query all available versions, load and unload
certain versions from your environment, e.g.,</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>tmux/3.2a
</pre></div>
</div>
</section>
<section id="error-protocol-version-mismatch">
<h3>Error: Protocol Version Mismatch<a class="headerlink" href="#error-protocol-version-mismatch" title="Permalink to this heading">#</a></h3>
<p>When trying to connect to tmux, you might encounter the following error message:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>tmux<span class="w"> </span>a<span class="w"> </span>-t<span class="w"> </span>juhu
<span class="go">protocol version mismatch (client 7, server 8)</span>
</pre></div>
</div>
<p>To solve this issue, make sure that the tmux version you invoke
is the same as the tmux server that is running.
In particular, you can determine your client‚Äôs version with the command <code class="docutils literal notranslate"><span class="pre">tmux</span> <span class="pre">-V</span></code>.
Try to <span class="xref myst">load the appropriate tmux version</span> to match with your
client‚Äôs tmux server like this:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>tmux<span class="w"> </span>-V
<span class="go">tmux 1.8</span>
<span class="gp">marie@compute$ </span>module<span class="w"> </span>load<span class="w"> </span>tmux/3.2a
<span class="go">Module tmux/3.2a-GCCcore-11.2.0 and 5 dependencies loaded.</span>
<span class="gp">marie@compute$ </span>tmux<span class="w"> </span>-V
<span class="go">tmux 3.2a</span>
</pre></div>
</div>
<p>!!! hint</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>When your client&#39;s version is newer than the server version, the aforementioned approach
won&#39;t help you. In that case, you need to unload the loaded tmux module to downgrade
the client to the client version that is supplied with the operating system (which
should have a lower version number).
</pre></div>
</div>
</section>
<section id="using-tmux-on-compute-nodes">
<h3>Using Tmux on Compute Nodes<a class="headerlink" href="#using-tmux-on-compute-nodes" title="Permalink to this heading">#</a></h3>
<p>At times it might be quite handy to have tmux sessions running inside your computation jobs,
such that you perform your computations within an interactive tmux session.
For this purpose, the following shorthand is to be placed inside the
<span class="xref myst">job file</span>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH [...]</span>

module<span class="w"> </span>load<span class="w"> </span>tmux/3.2a
tmux<span class="w"> </span>new-session<span class="w"> </span>-s<span class="w"> </span>marie_is_computing<span class="w"> </span>-d
sleep<span class="w"> </span><span class="m">1</span><span class="p">;</span>
tmux<span class="w"> </span>wait-for<span class="w"> </span>CHANNEL_NAME_MARIE

srun<span class="w"> </span><span class="o">[</span>...<span class="o">]</span>
</pre></div>
</div>
<p>You can then connect to the tmux session like this:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>ssh<span class="w"> </span>-t<span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>squeue<span class="w"> </span>--me<span class="w"> </span>--noheader<span class="w"> </span>--format<span class="o">=</span><span class="s2">&quot;%N&quot;</span><span class="w"> </span><span class="m">2</span>&gt;/dev/null<span class="w"> </span><span class="p">|</span><span class="w"> </span>tail<span class="w"> </span>-n<span class="w"> </span><span class="m">1</span><span class="k">)</span><span class="s2">&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">             </span><span class="s2">&quot;source /etc/profile.d/10_modules.sh; module load tmux/3.2a; tmux attach&quot;</span>
</pre></div>
</div>
</section>
<section id="where-is-my-tmux-session">
<h3>Where Is My Tmux Session?<a class="headerlink" href="#where-is-my-tmux-session" title="Permalink to this heading">#</a></h3>
<p>Please note that, as there are thousands of compute nodes available, there are also multiple login
nodes. Thus, try checking the other login nodes as well:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login3$ </span>tmux<span class="w"> </span>ls
<span class="go">failed to connect to server</span>
<span class="gp">marie@login3$ </span>ssh<span class="w"> </span>login4<span class="w"> </span>tmux<span class="w"> </span>ls
<span class="go">marie_is_testing: 1 windows (created Tue Mar 29 19:06:26 2022) [105x32]</span>
</pre></div>
</div>
</section>
</section>
<section id="architecture-information-lstopo">
<h2>Architecture Information (lstopo)<a class="headerlink" href="#architecture-information-lstopo" title="Permalink to this heading">#</a></h2>
<p>The page <span class="xref myst">HPC Resource Overview</span> holds a general and fast
overview about the available HPC resources at ZIH.
Sometime a closer look and deeper understanding of a particular architecture is needed. This is
where the tool <code class="docutils literal notranslate"><span class="pre">lstopo</span></code> comes into play.</p>
<p>The tool <a class="reference external" href="https://linux.die.net/man/1/lstopo">lstopo</a> displays the topology of a system in a variety
of output formats.</p>
<p><code class="docutils literal notranslate"><span class="pre">lstopo</span></code> and <code class="docutils literal notranslate"><span class="pre">lstopo-no-graphics</span></code> are available from the <code class="docutils literal notranslate"><span class="pre">hwloc</span></code> modules, e.g.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>hwloc/2.5.0-GCCcore-11.2.0
<span class="gp">marie@login$ </span>lstopo
</pre></div>
</div>
<p>The topology map is displayed in a graphical window if the <code class="docutils literal notranslate"><span class="pre">DISPLAY</span></code> environment variable is set.
Otherwise, a text summary is displayed. The displayed topology levels and granularity can be
controlled using the various options of <code class="docutils literal notranslate"><span class="pre">lstopo</span></code>. Please refer to the corresponding man page and
help message (<code class="docutils literal notranslate"><span class="pre">lstopo</span> <span class="pre">--help</span></code>).</p>
<p>It is also possible to run this command using a job file to retrieve the topology of a compute nodes.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>

<span class="c1">#SBATCH --job-name=topo_node</span>
<span class="c1">#SBATCH --ntasks=1</span>
<span class="c1">#SBATCH --cpus-per-task=1</span>
<span class="c1">#SBATCH --mem-per-cpu=300m</span>
<span class="c1">#SBATCH --time=00:05:00</span>
<span class="c1">#SBATCH --output=get_topo.out</span>
<span class="c1">#SBATCH --error=get_topo.err</span>

module<span class="w"> </span>purge
module<span class="w"> </span>load<span class="w"> </span>hwloc/2.5.0-GCCcore-11.2.0

srun<span class="w"> </span>lstopo
</pre></div>
</div>
</section>
<section id="working-with-large-archives-and-compressed-files">
<h2>Working with Large Archives and Compressed Files<a class="headerlink" href="#working-with-large-archives-and-compressed-files" title="Permalink to this heading">#</a></h2>
<section id="parallel-gzip-decompression">
<h3>Parallel Gzip Decompression<a class="headerlink" href="#parallel-gzip-decompression" title="Permalink to this heading">#</a></h3>
<p>There is a plethora of <code class="docutils literal notranslate"><span class="pre">gzip</span></code> tools but none of them can fully utilize multiple cores.
The fastest single-core decoder is <code class="docutils literal notranslate"><span class="pre">igzip</span></code> from the
<a class="reference external" href="https://github.com/intel/isa-l.git">Intelligent Storage Acceleration Library</a>.
In tests, it can reach ~500 MB/s compared to ~200 MB/s for the system-default <code class="docutils literal notranslate"><span class="pre">gzip</span></code>.
If you have very large files and need to decompress them even faster, you can use
<a class="reference external" href="https://github.com/mxmlnkn/rapidgzip">rapidgzip</a>.
Currently, it can reach ~1.5 GB/s using a 12-core processor in the above-mentioned tests.</p>
<p><a class="reference external" href="https://github.com/mxmlnkn/rapidgzip">rapidgzip</a> is available on PyPI and can be installed via pip.
It is recommended to install it inside a
<span class="xref myst">Python virtual environment</span>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>pip<span class="w"> </span>install<span class="w"> </span>rapidgzip
</pre></div>
</div>
<p>It can also be installed from its C++ source code.
If you prefer that over the version on PyPI, then you can build it like this:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/mxmlnkn/rapidgzip.git
<span class="gp">marie@compute$ </span><span class="nb">cd</span><span class="w"> </span>rapidgzip
<span class="gp">marie@compute$ </span>mkdir<span class="w"> </span>build
<span class="gp">marie@compute$ </span><span class="nb">cd</span><span class="w"> </span>build
<span class="gp">marie@compute$ </span>cmake<span class="w"> </span>..
<span class="gp">marie@compute$ </span>cmake<span class="w"> </span>--build<span class="w"> </span>.<span class="w"> </span>rapidgzip
<span class="gp">marie@compute$ </span>src/tools/rapidgzip<span class="w"> </span>--help
</pre></div>
</div>
<p>The built binary can then be used directly or copied inside a folder that is available in your
<code class="docutils literal notranslate"><span class="pre">PATH</span></code> environment variable.</p>
<p>Rapidgzip can be used like this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>marie@compute$<span class="w"> </span>rapidgzip<span class="w"> </span>-d<span class="w"> </span>&lt;file_to_decompress&gt;
</pre></div>
</div>
<p>For example, if you want to decompress a file called <code class="docutils literal notranslate"><span class="pre">data.gz</span></code>, use:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>rapidgzip<span class="w"> </span>-d<span class="w"> </span>data.gz
</pre></div>
</div>
<p>Furthermore, you can use it to speed up extraction of a file <code class="docutils literal notranslate"><span class="pre">my-archive.tar.gz</span></code> like this:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>tar<span class="w"> </span>--use-compress-program<span class="o">=</span>rapidgzip<span class="w"> </span>-xf<span class="w"> </span>my-archive.tar.gz
</pre></div>
</div>
<p>Rapidgzip is still in development, so if it crashes or if it is slower than the system <code class="docutils literal notranslate"><span class="pre">gzip</span></code>,
please <a class="reference external" href="https://github.com/mxmlnkn/rapidgzip/issues">open an issue</a> on GitHub.</p>
</section>
<section id="direct-archive-access-without-extraction-using-ratarmount">
<h3>Direct Archive Access Without Extraction Using Ratarmount<a class="headerlink" href="#direct-archive-access-without-extraction-using-ratarmount" title="Permalink to this heading">#</a></h3>
<p>In some cases of archives with millions of small files, it might not be feasible to extract the
whole archive to a filesystem.
The known <code class="docutils literal notranslate"><span class="pre">archivemount</span></code> tool has performance problems with such archives even if they are simply
uncompressed TAR files.
Furthermore, with <code class="docutils literal notranslate"><span class="pre">archivemount</span></code> the archive would have to be reanalyzed whenever a new job is started.</p>
<p><code class="docutils literal notranslate"><span class="pre">Ratarmount</span></code> is an alternative that solves these performance issues.
The archive will be analyzed and then can be accessed via a FUSE mountpoint showing the internal
folder hierarchy.
Access to files is consistently fast no matter the archive size while <code class="docutils literal notranslate"><span class="pre">archivemount</span></code> might take
minutes per file access.
Furthermore, the analysis results of the archive will be stored in a sidecar file alongside the
archive or in your home directory if the archive is in a non-writable location.
Subsequent mounts instantly load that sidecar file instead of reanalyzing the archive.
You will find further information on the <a class="reference external" href="https://github.com/mxmlnkn/ratarmount">Ratarmount GitHub page</a>.</p>
<section id="example-workflow">
<h4>Example Workflow<a class="headerlink" href="#example-workflow" title="Permalink to this heading">#</a></h4>
<p>The software Ratarmount is installed system-wide on the HPC system.</p>
<p>The first step is to create a tar archive to bundle your small files in a single file.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># On your local machine</span>
marie@local$<span class="w"> </span>tar<span class="w"> </span>cf<span class="w"> </span>dataset.tar<span class="w"> </span>folder_containing_my_small_files

<span class="c1"># If your small files are already on the HPC system</span>
marie@login$<span class="w"> </span>dttar<span class="w"> </span>cf<span class="w"> </span>dataset.tar<span class="w"> </span>folder_containing_my_small_files
</pre></div>
</div>
<p>For the latter, please make sure that you are on a <span class="xref myst">Datamover node</span>
and <strong>not</strong> on a login node.
Depending on the number of files, the tar bundle process may take some time.</p>
<p>We do not recommend to compress (e.g. Gzip) the archive, as this can decrease the read performance substantially
e.g. for images, audio and video files.</p>
<p>Once the tar archive has been created, you can mount it on the compute node using `ratarmount‚Äô.
All files in the mount points can be accessed as normal files or directories
in the filesystem without any special treatment.
Note that the tar archive must be mounted on every compute node in your job.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Mounting an archive for the first time can take some time  because Ratarmount has to create an index of its contents to access it efficiently.
The index, named `.&lt;name_of_the_archive&gt;.index.sqlite`, will be placed
in the same directory as the archive if the directory is writable,
otherwise ratarmount will try to place the index in your home directory.
This indexing step could be done in a separate job to save resources.
It also prevents conflicting indexing by more than one process at the same time.

```bash
# create index
sbatch --ntasks=1 --mem=10G --time=5:00:00 ratarmount dataset.tar
```
</pre></div>
</div>
<p>!!! example ‚ÄúExample job script using Ratarmount‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```bash
#!/bin/bash

#SBATCH --ntasks=3
#SBATCH --nodes=2
#SBATCH --time=00:05:00


# mount the dataset on every node one time
DATASET=/tmp/${SLURM_JOB_ID}
srun --ntasks-per-node=1 mkdir ${DATASET}
srun --ntasks-per-node=1 ratarmount dataset.tar ${DATASET}

# now it can be accessed like a normal directory
srun --ntasks=1 ls ${DATASET}

# start the application
srun ./my_application --input-directory ${DATASET}

# unmount it after all work is done
srun --ntasks-per-node=1 ratarmount -u ${DATASET}
```
</pre></div>
</div>
<p>!!! hint</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If you are starting many processes per node, Ratarmount could benefit from
having individual mount points for each process, rather than just one per node.
</pre></div>
</div>
<p>In case of Ratarmount issues
please <a class="reference external" href="https://github.com/mxmlnkn/ratarmount/issues">open an issue</a> on GitHub.</p>
<p>There also is a library interface called
<a class="reference external" href="https://github.com/mxmlnkn/ratarmount/tree/master/core#example">ratarmountcore</a> that works
fully without FUSE, which might make access to files from Python even faster.</p>
</section>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="study-course-of-events-with-vampir">
<h1>Study Course of Events with Vampir<a class="headerlink" href="#study-course-of-events-with-vampir" title="Permalink to this heading">#</a></h1>
<section id="id72">
<h2>Introduction<a class="headerlink" href="#id72" title="Permalink to this heading">#</a></h2>
<p>Vampir is a graphical analysis framework that provides a large set of different chart
representations of event based performance data generated through program instrumentation. These
graphical displays, including state diagrams, statistics, and timelines, can be used by developers
to obtain a better understanding of their parallel program inner working and to subsequently
optimize it. Vampir allows to focus on appropriate levels of detail, which allows the detection and
explanation of various performance bottlenecks such as load imbalances and communication
deficiencies. <a class="reference external" href="http://tu-dresden.de/die_tu_dresden/zentrale_einrichtungen/zih/forschung/projekte/vampir">ZIH‚Äôs Vampir overview page
</a> gives
further information.</p>
<p><span class="xref myst">Score-P</span> is the primary code instrumentation and run-time measurement framework for
Vampir and supports various instrumentation methods, including instrumentation at source level and
at compile/link time. The tool supports trace files in Open Trace Format (OTF, OTF2) that is
developed by ZIH and its partners and is especially designed for massively parallel programs.</p>
<p><img alt="Vampir Framework" src="63_chat_with_docs/misc/vampir-framework.png" />
{: align=‚Äùcenter‚Äù}</p>
</section>
<section id="starting-vampir">
<h2>Starting Vampir<a class="headerlink" href="#starting-vampir" title="Permalink to this heading">#</a></h2>
<p>Prior to using Vampir you need to set up the correct environment on one
the HPC systems with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>load<span class="w"> </span>Vampir
</pre></div>
</div>
<p>For members of TU Dresden the Vampir tool is also available as
<a class="reference external" href="http://tu-dresden.de/die_tu_dresden/zentrale_einrichtungen/zih/forschung/projekte/vampir/vampir_download_tu">download</a>
for installation on your personal computer.</p>
<p>Make sure, that compressed display forwarding (e.g., <code class="docutils literal notranslate"><span class="pre">ssh</span> <span class="pre">-YC</span> <span class="pre">taurus</span></code>) is
enabled. Start the GUI by typing</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>vampir
</pre></div>
</div>
<p>on your command line or by double-clicking the Vampir icon on your personal computer.</p>
<p>Please consult the
<a class="reference external" href="http://tu-dresden.de/die_tu_dresden/zentrale_einrichtungen/zih/forschung/projekte/vampir/dateien/Vampir-User-Manual.pdf">Vampir user manual</a>
for a tutorial on using the tool.</p>
</section>
<section id="using-vampirserver">
<h2>Using VampirServer<a class="headerlink" href="#using-vampirserver" title="Permalink to this heading">#</a></h2>
<p>VampirServer provides additional scalable analysis capabilities to the Vampir GUI mentioned above.
To use VampirServer on the ZIH Systems proceed as follows: start the Vampir GUI as
described above and use the <em>Open Remote</em> dialog with the parameters indicated in the following
figure to start and connect a VampirServer already instance running on the HPC system. Make sure
to fill in your personal ZIH login name.</p>
<p><img alt="Vampir Open Remote dialog" src="63_chat_with_docs/misc/vampir-open-remote-dialog.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>Click on the <em>Connect</em> button and wait until the connection is established. Enter your password when
requested. Depending on the available resources on the target system, this setup can take some time.
Please be patient and take a look at available resources beforehand.</p>
</section>
<section id="id73">
<h2>Advanced Usage<a class="headerlink" href="#id73" title="Permalink to this heading">#</a></h2>
<section id="manual-server-startup">
<h3>Manual Server Startup<a class="headerlink" href="#manual-server-startup" title="Permalink to this heading">#</a></h3>
<p>VampirServer is a parallel MPI program, which should be started by typing:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>vampirserver<span class="w"> </span>start
<span class="go">Launching VampirServer...</span>
<span class="go">Submitting slurm 30 minutes job (this might take a while)...</span>
</pre></div>
</div>
<p>This way, a job with a timelimit of 30 minutes and default resources is submitted. This might fit
your needs. If not, please feel free to request a <strong>customized job</strong> running VampirServer, e.g.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>vampirserver<span class="w"> </span>start<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">8</span><span class="w"> </span>--<span class="w"> </span>--time<span class="o">=</span><span class="m">01</span>:00:00<span class="w"> </span>--<span class="w"> </span>--mem-per-cpu<span class="o">=</span>3000M<span class="w"> </span>
<span class="go">Launching VampirServer...</span>
<span class="go">Submitting slurm 01:00:00 minutes job (this might take a while)...</span>
</pre></div>
</div>
<p>The above <code class="docutils literal notranslate"><span class="pre">vampirserver</span></code> command automatically allocates its resources via the respective batch
system (, i.e. <span class="xref myst">Slurm</span> on ZIH systems). As shown, you can customize
the resources requirements and time limit. This is especially useful, if you run into performance
issues handling very large trace files. Please refer to <code class="docutils literal notranslate"><span class="pre">vampirserver</span> <span class="pre">--help</span></code> for further options
and usage.</p>
<p>If you want to start</p>
<p>VampirServer without a batch allocation or from inside an interactive allocation, use</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@compute$ </span>vampirserver<span class="w"> </span>start<span class="w"> </span>srun
</pre></div>
</div>
<p>After scheduling this job the server prints out the port number it is serving on, like <code class="docutils literal notranslate"><span class="pre">Listen</span> <span class="pre">port:</span> <span class="pre">30088</span></code>.</p>
<p>Connecting to the most recently started server can be achieved by entering <code class="docutils literal notranslate"><span class="pre">auto-detect</span></code> as <em>Setup
name</em> in the <em>Open Remote</em> dialog of Vampir.</p>
<p><img alt="Vampir Open Remote Dialog (auto start)" src="63_chat_with_docs/misc/vampir-open-remote-dialog-auto-start.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>Please make sure you stop VampirServer after finishing your work with
the front-end (<em>File</em> ‚Üí <em>Shutdown Server‚Ä¶</em>) or with</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>vampirserver<span class="w"> </span>stop
</pre></div>
</div>
<p>Type</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>vampirserver<span class="w"> </span><span class="nb">help</span>
</pre></div>
</div>
<p>for further information. The <a class="reference external" href="http://tu-dresden.de/die_tu_dresden/zentrale_einrichtungen/zih/forschung/projekte/vampir/dateien/VampirServer-User-Manual.pdf">user manual</a>
of VampirServer can be found at <code class="docutils literal notranslate"><span class="pre">doc/vampirserver-manual.pdf</span></code> in the installation directory.
Type</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>which<span class="w"> </span>vampirserver
</pre></div>
</div>
<p>to find the revision dependent <em>installation directory</em>.</p>
</section>
<section id="port-forwarding">
<h3>Port Forwarding<a class="headerlink" href="#port-forwarding" title="Permalink to this heading">#</a></h3>
<p>VampirServer listens to a given socket port. It is possible to forward
this port (SSH tunnel) to a remote machine. This procedure is not
recommended and not needed at ZIH. However, the following example shows
the tunneling to a VampirServer on a compute node.</p>
<p>Start VampirServer on the ZIH system and wait for its scheduling:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>vampirserver<span class="w"> </span>start
<span class="go">Launching VampirServer...</span>
<span class="go">Submitting slurm 30 minutes job (this might take a while)...</span>
<span class="go">salloc: Granted job allocation 2753510</span>
<span class="go">VampirServer 8.1.0 (r8451)</span>
<span class="go">Licensed to ZIH, TU Dresden</span>
<span class="go">Running 4 analysis processes... (abort with vampirserver stop 594)</span>
<span class="go">VampirServer &lt;594&gt; listens on: taurusi1253:30055</span>
</pre></div>
</div>
<p>Or choose from an already running VampirServer:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>vampirserver<span class="w"> </span>list
<span class="go">594 taurusi1253:30055 [4x, slurm]</span>
</pre></div>
</div>
<p>Open a second console on your local computer and establish an SSH tunnel to the compute node with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>ssh<span class="w"> </span>-L<span class="w"> </span><span class="m">30000</span>:taurusi1253:30055<span class="w"> </span>taurus
</pre></div>
</div>
<p>!!! important ‚ÄúSSH command‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The previous SSH command requires that you have already set up your [SSH configuration
](../access/ssh_login.md#configuring-default-parameters-for-ssh).
</pre></div>
</div>
<p>Now, the port 30000 on your desktop is connected to the VampirServer port 30055 at the compute node
<code class="docutils literal notranslate"><span class="pre">taurusi1253</span></code> of the ZIH system. Finally, start your local Vampir client and establish a remote
connection to <code class="docutils literal notranslate"><span class="pre">localhost</span></code>, port 30000 as described in the manual.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@local$ </span>vampir
</pre></div>
</div>
<p><strong>Remark:</strong> Please substitute the ports given in this example with appropriate numbers and available
ports based on the output from <code class="docutils literal notranslate"><span class="pre">vampirserver</span> <span class="pre">start</span></code> or <code class="docutils literal notranslate"><span class="pre">vampirserver</span> <span class="pre">list</span></code>.</p>
</section>
<section id="nightly-builds-unstable">
<h3>Nightly Builds (unstable)<a class="headerlink" href="#nightly-builds-unstable" title="Permalink to this heading">#</a></h3>
<p>Expert users who subscribed to the development program can test new, unstable tool features. The
corresponding Vampir and VampirServer software releases are provided as nightly builds. Unstable
versions of VampirServer are also installed on the HPC systems. The most recent version can be
launched/connected by entering <code class="docutils literal notranslate"><span class="pre">unstable</span></code> as <em>Setup name</em> in the <em>Open Remote</em> dialog of Vampir.</p>
<p><img alt="Vampir Open Remote Dialog (unstable)" src="63_chat_with_docs/misc/vampir-open-remote-dialog-unstable.png" />
{: align=‚Äùcenter‚Äù}</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="virtual-desktops">
<h1>Virtual Desktops<a class="headerlink" href="#virtual-desktops" title="Permalink to this heading">#</a></h1>
<p>Use WebVNC or DCV to run GUI applications on HPC resources.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>WebVNC*</p></th>
<th class="head"><p>DCV</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>use case</strong></p></td>
<td><p>all GUI applications that do <strong>not need</strong> OpenGL</p></td>
<td><p>only GUI applications that <strong>need</strong> OpenGL</p></td>
</tr>
<tr class="row-odd"><td><p><strong>clusters</strong></p></td>
<td><p>all*</p></td>
<td><p>Visualization (Vis)</p></td>
</tr>
</tbody>
</table>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>WebVNC has GL support at the visualization nodes on cluster named Visualization (Vis).
</pre></div>
</div>
<section id="launch-a-virtual-desktop">
<h2>Launch a Virtual Desktop<a class="headerlink" href="#launch-a-virtual-desktop" title="Permalink to this heading">#</a></h2>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Step</p></th>
<th class="head text-center"><p>WebVNC</p></th>
<th class="head text-center"><p>DCV</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1  <td colspan=2 align="center"> Navigate to <a class="reference external" href="https://jupyterhub.hpc.tu-dresden.de">https://jupyterhub.hpc.tu-dresden.de</a>. There is our <span class="xref myst">JupyterHub</span> instance.</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-odd"><td><p>2  <td colspan=2 align="center"> Click on the ‚Äúadvanced‚Äù tab and choose a preset:</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td><p>3  <td colspan=2 align="center"> Optional: Fine tune your session with the available Slurm job parameters or assign a certain project or reservation. Then save your settings in a new preset for future use.</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-odd"><td><p>4  <td colspan=2 align="center"> Click on <code class="docutils literal notranslate"><span class="pre">Spawn</span></code>. JupyterHub starts now a Slurm job for you. If everything is ready the JupyterLab interface will appear to you.</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td class="text-center"><p>Click on <code class="docutils literal notranslate"><span class="pre">WebVNC</span></code> to start a virtual desktop.</p></td>
<td class="text-center"><p>Click on <code class="docutils literal notranslate"><span class="pre">DCV</span></code> to start a virtual desktop.</p></td>
</tr>
<tr class="row-odd"><td><p>6  <td colspan=2 align="center"> The virtual desktop starts in a new tab or window.</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
</tbody>
</table>
<section id="demonstration">
<h3>Demonstration<a class="headerlink" href="#demonstration" title="Permalink to this heading">#</a></h3>
<p><video src="63_chat_with_docs/misc/start-virtual-desktop-dcv.mp4" title="type:video"><a href="63_chat_with_docs/misc/start-virtual-desktop-dcv.mp4">type:video</a></video></p>
</section>
<section id="using-the-quickstart-feature">
<h3>Using the Quickstart Feature<a class="headerlink" href="#using-the-quickstart-feature" title="Permalink to this heading">#</a></h3>
<p>JupyterHub can start a job automatically if the URL contains certain
parameters.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head text-center"><p>WebVNC</p></th>
<th class="head text-center"><p>DCV</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Examples</p></td>
<td class="text-center"><p><a class="reference external" href="https://jupyterhub.hpc.tu-dresden.de/hub/spawn#/~(cluster~'vis~nodes~'1~ntasks~'1~cpuspertask~'1~mempercpu~'1536)">WebVNC</a></p></td>
<td class="text-center"><p><a class="reference external" href="https://jupyterhub.hpc.tu-dresden.de/hub/spawn#/~(cluster~'vis~nodes~'1~ntasks~'1~cpuspertask~'2~mempercpu~'2048)">DCV</a></p></td>
</tr>
<tr class="row-odd"><td><p>Description</p></td>
<td class="text-center"><p>cluster <code class="docutils literal notranslate"><span class="pre">vis</span></code>, 1 Node, 1 CPUs with 1,5 GB RAM, 1 GPU</p></td>
<td class="text-center"><p>cluster <code class="docutils literal notranslate"><span class="pre">vis</span></code>, 1 Node, 2 CPUs with 2 GB RAM per core, 1 GPU</p></td>
</tr>
<tr class="row-even"><td><p>Link creator <td colspan=2 align="center"> Use the spawn form to set your preferred options. The browser URL will be updated with the corresponding parameters.</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
</tbody>
</table>
<p>If you close the browser tabs or windows or log out from your local
machine, you are able to open the virtual desktop later again - as long
as the session runs. But please remember that a Slurm job is running in
the background which has a certain time limit.</p>
</section>
</section>
<section id="reconnecting-to-a-session">
<h2>Reconnecting to a Session<a class="headerlink" href="#reconnecting-to-a-session" title="Permalink to this heading">#</a></h2>
<p>In order to reconnect to an active instance of WebVNC, simply repeat the
steps required to start a session, beginning - if required - with the
login, then clicking <code class="docutils literal notranslate"><span class="pre">My</span> <span class="pre">Server</span></code>, then by pressing the <code class="docutils literal notranslate"><span class="pre">+</span></code> sign on the
upper left corner. Provided your server is still running and you simply
closed the window or logged out without stopping your server, you will
find your WebVNC desktop the way you left it.</p>
</section>
<section id="terminate-a-remote-session">
<h2>Terminate a Remote Session<a class="headerlink" href="#terminate-a-remote-session" title="Permalink to this heading">#</a></h2>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Step</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>Close the VNC viewer tab or window.</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>Click on File &gt; Log Out in the JupyterLab main menu. Now you get redirected to the JupyterLab control panel. If you don‚Äôt have your JupyterLab tab or window anymore, navigate directly to <a class="reference external" href="https://jupyterhub.hpc.tu-dresden.de/hub/home">https://jupyterhub.hpc.tu-dresden.de/hub/home</a></p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>Click on <code class="docutils literal notranslate"><span class="pre">Stop</span> <span class="pre">My</span> <span class="pre">Server</span></code>. This cancels the Slurm job and terminates your session.</p></td>
</tr>
</tbody>
</table>
<section id="id74">
<h3>Demonstration<a class="headerlink" href="#id74" title="Permalink to this heading">#</a></h3>
<p><video src="63_chat_with_docs/misc/terminate-virtual-desktop-dcv.mp4" title="type:video"><a href="63_chat_with_docs/misc/terminate-virtual-desktop-dcv.mp4">type:video</a></video></p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>This does not work if you click on the button `Logout` in your
virtual desktop. Instead this will just close your DCV session or cause
a black screen in your WebVNC window without a possibility to recover a
virtual desktop in the same Jupyter session. The solution for now would
be to terminate the whole Jupyter session and start a new one like
mentioned above.
</pre></div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="virtual-machines">
<h1>Virtual Machines<a class="headerlink" href="#virtual-machines" title="Permalink to this heading">#</a></h1>
<p>The following instructions are primarily aimed at users who want to build their own
<span class="xref myst">Singularity</span> containers on ZIH systems.</p>
<p>The Singularity container setup requires a Linux machine with root privileges, the same architecture
and a compatible kernel. If some of these requirements cannot be fulfilled, then there is also the
option of using the provided virtual machines (VM) on ZIH systems.</p>
<p>Currently, starting VMs is only possible on the cluster <code class="docutils literal notranslate"><span class="pre">power</span></code> (and <code class="docutils literal notranslate"><span class="pre">hpdlf</span></code>?). The VMs on the power
nodes are used to build Singularity containers for the Power9 architecture and the HPDLF nodes to
build Singularity containers for the x86 architecture.</p>
<section id="create-a-virtual-machine">
<h2>Create a Virtual Machine<a class="headerlink" href="#create-a-virtual-machine" title="Permalink to this heading">#</a></h2>
<p>The Slurm parameter <code class="docutils literal notranslate"><span class="pre">--cloud=kvm</span></code> specifies that a virtual machine should be started.</p>
<section id="on-power9-architecture">
<h3>On Power9 Architecture<a class="headerlink" href="#on-power9-architecture" title="Permalink to this heading">#</a></h3>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login.power$ </span>srun<span class="w"> </span>--nodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">4</span><span class="w"> </span>--hint<span class="o">=</span>nomultithread<span class="w"> </span>--cloud<span class="o">=</span>kvm<span class="w"> </span>--pty<span class="w"> </span>/bin/bash
<span class="go">srun: job 6969616 queued and waiting for resources</span>
<span class="go">srun: job 6969616 has been allocated resources</span>
<span class="go">bash-4.2$</span>
</pre></div>
</div>
</section>
<section id="on-x86-architecture">
<h3>On x86 Architecture<a class="headerlink" href="#on-x86-architecture" title="Permalink to this heading">#</a></h3>
<p><em>to be updated‚Ä¶.</em></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>srun<span class="w"> </span>--partition<span class="o">=</span>hpdlf<span class="w"> </span>--nodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">4</span><span class="w"> </span>--hint<span class="o">=</span>nomultithread<span class="w"> </span>--cloud<span class="o">=</span>kvm<span class="w"> </span>--pty<span class="w"> </span>/bin/bash
<span class="go">srun: job 2969732 queued and waiting for resources</span>
<span class="go">srun: job 2969732 has been allocated resources</span>
<span class="go">bash-4.2$</span>
</pre></div>
</div>
</section>
</section>
<section id="access-a-virtual-machine">
<h2>Access a Virtual Machine<a class="headerlink" href="#access-a-virtual-machine" title="Permalink to this heading">#</a></h2>
<p>After a security issue on ZIH systems, we restricted the filesystem permissions. Now, you have to
wait until the file <code class="docutils literal notranslate"><span class="pre">/tmp/${SLURM_JOB_USER}_${SLURM_JOB_ID}/activate</span></code> is created. Then, you can try
to connect via <code class="docutils literal notranslate"><span class="pre">ssh</span></code> into the virtual machine, but it could be that the virtual machine needs some
more seconds to boot and accept the connection. So you may need to try the <code class="docutils literal notranslate"><span class="pre">ssh</span></code> command multiple
times till it succeeds.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">bash-4.2$ cat /tmp/marie_2759627/activate</span>
<span class="gp">#</span>!/bin/bash

<span class="go">if ! grep -q -- &quot;Key for the VM on the cluster power&quot; &quot;/home/marie/.ssh/authorized_keys&quot; &gt; /dev/null; then</span>
<span class="go">  cat &quot;/tmp/marie_2759627/kvm.pub&quot; &gt;&gt; &quot;/home/marie/.ssh/authorized_keys&quot;</span>
<span class="go">else</span>
<span class="go">  sed -i &quot;s|.*Key for the VM on the cluster power.*|ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC3siZfQ6vQ6PtXPG0RPZwtJXYYFY73TwGYgM6mhKoWHvg+ZzclbBWVU0OoU42B3Ddofld7TFE8sqkHM6M+9jh8u+pYH4rPZte0irw5/27yM73M93q1FyQLQ8Rbi2hurYl5gihCEqomda7NQVQUjdUNVc6fDAvF72giaoOxNYfvqAkw8lFyStpqTHSpcOIL7pm6f76Jx+DJg98sXAXkuf9QK8MurezYVj1qFMho570tY+83ukA04qQSMEY5QeZ+MJDhF0gh8NXjX/6+YQrdh8TklPgOCmcIOI8lwnPTUUieK109ndLsUFB5H0vKL27dA2LZ3ZK+XRCENdUbpdoG2Czz Key for the VM on the cluster power|&quot; &quot;/home/marie/.ssh/authorized_keys&quot;</span>
<span class="go">fi</span>

<span class="go">ssh -i /tmp/marie_2759627/kvm root@192.168.0.6</span>
<span class="go">bash-4.2$ source /tmp/marie_2759627/activate</span>
<span class="go">Last login: Fri Jul 24 13:53:48 2020 from gateway</span>
<span class="gp">[root@marie_2759627 ~]#</span>
</pre></div>
</div>
</section>
<section id="example-usage">
<h2>Example Usage<a class="headerlink" href="#example-usage" title="Permalink to this heading">#</a></h2>
</section>
<section id="automation">
<h2>Automation<a class="headerlink" href="#automation" title="Permalink to this heading">#</a></h2>
<p>We provide <span class="xref myst">tools</span> to automate these steps. You may just type <code class="docutils literal notranslate"><span class="pre">startInVM</span> <span class="pre">--arch=power9</span></code> on a login node and you will be inside the VM with everything mounted.</p>
</section>
<section id="known-issues">
<h2>Known Issues<a class="headerlink" href="#known-issues" title="Permalink to this heading">#</a></h2>
<section id="temporary-memory">
<h3>Temporary Memory<a class="headerlink" href="#temporary-memory" title="Permalink to this heading">#</a></h3>
<p>The available space inside the VM can be queried with <code class="docutils literal notranslate"><span class="pre">df</span> <span class="pre">-h</span></code>. Currently the whole VM has 8 GB and
with the installed operating system, 6.6 GB of available space.</p>
<p>Sometimes, the Singularity build might fail because of a disk out-of-memory error. In this case, it
might be enough to delete leftover temporary files from Singularity:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">rm -rf /tmp/sbuild-*</span>
</pre></div>
</div>
<p>If that does not help, e.g., because one build alone needs more than the available disk memory, then
it will be necessary to use the <code class="docutils literal notranslate"><span class="pre">tmp</span></code> folder on <code class="docutils literal notranslate"><span class="pre">/data/horse</span></code>. In order to ensure that the files in the
temporary folder will be owned by root, it is necessary to set up an image inside <code class="docutils literal notranslate"><span class="pre">/data/horse/tmp</span></code>
instead of using it directly. E.g., to create a 25 GB of temporary memory image:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">tmpDir=&quot;$( mktemp -d --tmpdir=/host_data/tmp )&quot; &amp;&amp; tmpImg=&quot;$tmpDir/singularity-build-temp-dir&quot;</span>
<span class="go">export LANG_BACKUP=$LANG</span>
<span class="go">unset LANG</span>
<span class="go">truncate -s 25G &quot;$tmpImg.ext4&quot; &amp;&amp; echo yes | mkfs.ext4 &quot;$tmpImg.ext4&quot;</span>
<span class="go">export LANG=$LANG_BACKUP</span>
</pre></div>
</div>
<p>The image can now be mounted and with the <code class="docutils literal notranslate"><span class="pre">SINGULARITY_TMPDIR</span></code> environment variable can be
specified as the temporary directory for Singularity builds. Unfortunately, because of an open
Singularity <a class="reference external" href="https://github.com/sylabs/singularity/issues/32">bug</a> it is should be avoided to mount
the image using <code class="docutils literal notranslate"><span class="pre">/dev/loop0</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">mkdir -p &quot;$tmpImg&quot; &amp;&amp; i=1 &amp;&amp; while test -e &quot;/dev/loop$i&quot;; do (( ++i )); done &amp;&amp; mknod -m 0660 &quot;/dev/loop$i&quot; b 7 &quot;$i&quot;</span>
<span class="go">mount -o loop=&quot;/dev/loop$i&quot; &quot;$tmpImg&quot;{.ext4,}</span>

<span class="go">export SINGULARITY_TMPDIR=&quot;$tmpImg&quot;</span>
<span class="go">singularity build my-container.{sif,def}</span>
</pre></div>
</div>
<p>The architecture of the base image is automatically chosen when you use an image from DockerHub.
This may not work for Singularity Hub, so in order to build for the power architecture the
Bootstraps <strong>shub</strong> and <strong>library</strong> should be avoided.</p>
</section>
<section id="transport-endpoint-is-not-connected">
<h3>Transport Endpoint is not Connected<a class="headerlink" href="#transport-endpoint-is-not-connected" title="Permalink to this heading">#</a></h3>
<p>This happens when the SSHFS mount gets unmounted because it is not very stable. It is sufficient to
run <code class="docutils literal notranslate"><span class="pre">~/mount_host_data.sh</span></code> again or just the SSHFS command inside that script.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="visualization">
<h1>Visualization<a class="headerlink" href="#visualization" title="Permalink to this heading">#</a></h1>
<section id="paraview">
<h2>ParaView<a class="headerlink" href="#paraview" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://paraview.org">ParaView</a> is an open-source, multi-platform data analysis and visualization
application. The ParaView package comprises different tools which are designed to meet interactive,
batch and in-situ workflows.</p>
<p>ParaView can be used in <span class="xref myst">interactive mode</span> as well as in
<span class="xref myst">batch mode</span>. Both modes are documented in more details in the following
subsections.</p>
<p>!!! warning WLOG ParaView module and cluster</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Without loss of generality, we stick to a certain ParaView module (from a certain module
release) in the following documentation and provided examples. **Do not blind copy the
examples.**
Furthermore, please **adopt the commands to your needs**, e.g., the concrete ParaView module you
want to use.

The same holds for the cluster used in the documentation and examples. The documentation refers
to the cluster [`Barnard`](../jobs_and_resources/hardware_overview.md#barnard). If you want to
use ParaView on [one of the other clusters](../jobs_and_resources/hardware_overview.md), this
documentation should hold too.
</pre></div>
</div>
<section id="paraview-modules">
<h3>ParaView Modules<a class="headerlink" href="#paraview-modules" title="Permalink to this heading">#</a></h3>
<p>ParaView is available through the <span class="xref myst">module system</span>. The
following command lists the available versions</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>module<span class="w"> </span>spider<span class="w"> </span>ParaView
<span class="go">    [...]</span>
<span class="go">        Versions:</span>
<span class="go">            ParaView/5.10.1-mpi</span>
<span class="go">            ParaView/5.11.1-mpi</span>
<span class="go">            ParaView/5.11.2</span>
<span class="go">    [...]</span>
</pre></div>
</div>
<p>Please note, that not all ParaView modules are available in all
<span class="xref myst">module environments</span>.
The command <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">spider</span> <span class="pre">&lt;module-name&gt;</span></code> will show you, how to load a certain ParaView module.</p>
<p>??? example ‚ÄúExample on how to load a ParaView module‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>For example, to obtain information on how to properly load the module `ParaView/5.10.1-mpi`, you
need to invoke the `module spider` command as follows:

```console
marie@login$ module spider ParaView/5.10.1-mpi
[...]
You will need to load all module(s) on any one of the lines below before the &quot;ParaView/5.10.1-mpi&quot; module is available to load.

  release/23.04  GCC/11.3.0  OpenMPI/4.1.4
  release/23.10  GCC/11.3.0  OpenMPI/4.1.4
[...]
```

Obviously, the `ParaView/5.10.1-mpi` module is available within two releases and depends in
both cases on the two modules `GCC/11.3.0` and `OpenMPI/4.1.4`. Without loss of generality, a
valid command to load `ParaView/5.10.1-mpi` is

```console
marie@login$ module load release/23.10 GCC/11.3.0 OpenMPI/4.1.4
```
</pre></div>
</div>
</section>
<section id="id75">
<h3>Interactive Mode<a class="headerlink" href="#id75" title="Permalink to this heading">#</a></h3>
<p>There are two different ways of using ParaView interactively on ZIH systems, which are described
in more details in the following subsections:</p>
<ul class="simple">
<li><p><span class="xref myst">GUI via NICE DCV</span></p></li>
<li><p><span class="xref myst">Client-Server mode with MPI-parallel off-screen-rendering</span></p></li>
</ul>
<section id="using-the-gui-via-nice-dcv">
<h4>Using the GUI via NICE DCV<a class="headerlink" href="#using-the-gui-via-nice-dcv" title="Permalink to this heading">#</a></h4>
<p>This option provides hardware accelerated OpenGL and might provide the best performance and smooth
handling. First, you need to open a DCV session on the Visualization cluster (use the
<a class="reference external" href="https://jupyterhub.hpc.tu-dresden.de/hub/spawn">Jupyter spawner</a> and choose one of the <em>VIS</em> job
profiles, then click on the <em>DCV</em> tile in the lower section named <em>Other</em>). Please
find further instructions on how to start DCV on the <span class="xref myst">virtual desktops page</span>.
In your virtual desktop session, start a terminal (right-click on desktop -&gt;
Terminal or <em>Activities -&gt; Terminal</em>), then load the ParaView module as usual and start the GUI:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@dcv$ </span>module<span class="w"> </span>load<span class="w"> </span>release/23.10<span class="w"> </span>GCC/11.3.0<span class="w"> </span>OpenMPI/4.1.4<span class="w"> </span>ParaView/5.11.1-mpi
<span class="gp">marie@dcv$ </span>paraview
</pre></div>
</div>
<p>Since your DCV session already runs inside a job, which has been scheduled to a compute node, no
<code class="docutils literal notranslate"><span class="pre">srun</span></code> command is necessary here.</p>
</section>
<section id="using-client-server-mode-with-mpi-parallel-offscreen-rendering">
<h4>Using Client-Server Mode with MPI-parallel Offscreen-Rendering<a class="headerlink" href="#using-client-server-mode-with-mpi-parallel-offscreen-rendering" title="Permalink to this heading">#</a></h4>
<p>ParaView has a built-in client-server architecture, where you run the GUI locally on your local
workstation and connect to a ParaView server instance (so-called <em>pvserver</em>) on a cluster. The
<em>pvserver</em> performs the computationally intensive rendering.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The ParaView version of the client, i.e., your workstation, needs to be of the same version as
the server.

Otherwise, you will encounter the error message &quot;paraview client/server version hash mismatch&quot;
when connection.
</pre></div>
</div>
<p>The <em>pvserver</em> can be run in parallel using MPI. To do so, load the desired ParaView module and
start the <code class="docutils literal notranslate"><span class="pre">pvserver</span></code> executable in offscreen rendering mode within an interactive allocation via
<code class="docutils literal notranslate"><span class="pre">srun</span></code>.</p>
<p>???+ example ‚ÄúStart <code class="docutils literal notranslate"><span class="pre">pvserver</span></code>‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Here, we ask for 8 MPI tasks on one node for 4 hours within an interactive allocation. Please
adopt the time limit and ressources to your needs.

```console
marie@login$ module load release/23.10 GCC/11.3.0 OpenMPI/4.1.4 ParaView/5.11.1-mpi
marie@login$ srun --nodes=1 --ntasks=8 --mem-per-cpu=2500 --time=04:00:00 --pty pvserver --force-offscreen-rendering
srun: job 1730359 queued and waiting for resources
srun: job 1730359 has been allocated resources
Waiting for client...
Connection URL: cs://n1179:11111
Accepting connection(s): n1179:11111
```
</pre></div>
</div>
<p>Once the resources are allocated, the <code class="docutils literal notranslate"><span class="pre">pvserver</span></code> is started in parallel and connection information
are printed.</p>
<p>!!! tip ‚ÄúCustom port‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>If the default port `11111` is already in use, an alternative or custom port can be specified
via the commandline option `-sp=&lt;PORT&gt;` to `pvserver`.
</pre></div>
</div>
<p>The output from <code class="docutils literal notranslate"><span class="pre">pvserver</span></code> contains the node name which your job and server runs on. However, since
the node names of the cluster are not present in the public domain name system (only
cluster-internally), you cannot just use this line as-is for connection with your client. Instead,
you need to establish a so-called forward SSH tunnel to your local host. You first have to resolve
the name to an IP address on ZIH systems using <code class="docutils literal notranslate"><span class="pre">host</span></code> in another SSH session. Then, the SSH tunnel
can be created from your workstation. The following example will
depict both steps: Resolve the IP of the compute node and finally create a
forward SSH tunnel to local host on port 22222 (or what ever port is preferred).</p>
<p>???+ example ‚ÄúSSH tunnel‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ host n1179
n1179.barnard.hpc.tu-dresden.de has address 172.24.64.189
marie@login$ exit
Connection to login2.barnard.hpc.tu-dresden.de closed.
marie@local$ ssh -L 22222:172.24.64.189:11111 barnard
```
</pre></div>
</div>
<p>!!! important ‚ÄúSSH command‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The previous SSH command requires that you have already set up your SSH configuration to
`Barnard` as documented on our
[SSH configuration page](../access/ssh_login.md#configuring-default-parameters-for-ssh).
</pre></div>
</div>
<p>The <strong>final step</strong> is to start ParaView locally on your own machine and configure the connection to
the remote server. Click <code class="docutils literal notranslate"><span class="pre">File</span> <span class="pre">&gt;</span> <span class="pre">Connect</span></code> to bring up the <code class="docutils literal notranslate"><span class="pre">Choose</span> <span class="pre">Server</span> <span class="pre">Configuration</span></code> dialog. When
you open this dialog for the first time, you need to add a server. Click on <code class="docutils literal notranslate"><span class="pre">Add</span> <span class="pre">Server</span></code> and
configure as follows:</p>
<p><img alt="ParaView Edit Server Dialog" src="63_chat_with_docs/misc/paraview-edit-server.png" />
{: align=‚Äùcenter‚Äù}</p>
<p>In the <code class="docutils literal notranslate"><span class="pre">Configure</span></code> dialog, choose <code class="docutils literal notranslate"><span class="pre">Startup</span> <span class="pre">Type:</span> <span class="pre">Manual</span></code> and <code class="docutils literal notranslate"><span class="pre">Save</span></code>. Then, you can connect to the
remote <code class="docutils literal notranslate"><span class="pre">pvserver</span></code> via <code class="docutils literal notranslate"><span class="pre">Connect</span></code> button.</p>
<p>A successful connection is displayed by a <em>client connected</em> message displayed on the <code class="docutils literal notranslate"><span class="pre">pvserver</span></code>
process terminal, and within ParaView‚Äôs Pipeline Browser (instead of it saying builtin). You now are
connected to the <code class="docutils literal notranslate"><span class="pre">pvserver</span></code> running on a compute node at ZIH systems and can open files from its
filesystems.</p>
<section id="id76">
<h5>Caveats<a class="headerlink" href="#id76" title="Permalink to this heading">#</a></h5>
<p>Connecting to the compute nodes will only work when you are <strong>inside the TU Dresden campus network</strong>,
because otherwise, the private networks 172.24.* will not be routed. That‚Äôs why you either need to
use <a class="reference external" href="https://tu-dresden.de/zih/dienste/service-katalog/arbeitsumgebung/zugang_datennetz/vpn">VPN</a>
(recommended) or an SSH tunnel.</p>
<p>??? tip ‚ÄúSSH Tunnel‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>When coming via the ZIH login gateway (`login1.zih.tu-dresden.de`), you can use SSH tunneling.
For the example IP address from above, this could look like the following:

```console
marie@local$ ssh -f -N -L11111:172.24.64.189:11111 &lt;zihlogin&gt;@login1.zih.tu-dresden.de
```

This command opens the port 11111 locally and tunnels it via `login1` to the `pvserver` running on
the compute node. Note that you then must instruct your local ParaView client to connect to host
`localhost` instead. The recommendation, though, is to use VPN, which makes this extra step
unnecessary.
</pre></div>
</div>
</section>
</section>
</section>
<section id="batch-mode-pvbatch">
<h3>Batch Mode (<code class="docutils literal notranslate"><span class="pre">pvbatch</span></code>)<a class="headerlink" href="#batch-mode-pvbatch" title="Permalink to this heading">#</a></h3>
<p>ParaView can run in batch mode, i.e., without opening the ParaView GUI, executing a Python script.
This way, common visualization tasks can be automated. There are two Python interfaces: <code class="docutils literal notranslate"><span class="pre">pvpython</span></code>
and <code class="docutils literal notranslate"><span class="pre">pvbatch</span></code>. The interface <code class="docutils literal notranslate"><span class="pre">pvbatch</span></code> only accepts commands from input scripts, and it will run in
parallel, if it was built using MPI.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ParaView is shipped with a prebuild MPI library and **pvbatch has to be
invoked using this very mpiexec** command. Make sure to not use `srun`
or `mpiexec` from another MPI module, i.e., check what `mpiexec` is in
the path:

```console
marie@login$ module load release/23.10 GCC/11.3.0 OpenMPI/4.1.4 ParaView/5.11.1-mpi
marie@login$ which mpiexec
/software/rapids/r23.10/OpenMPI/4.1.4-GCC-11.3.0/bin/mpiexec
```
</pre></div>
</div>
<p>The resources for the MPI processes have to be allocated via the
<span class="xref myst">batch system</span> option <code class="docutils literal notranslate"><span class="pre">--cpus-per-task=&lt;NUM&gt;</span></code> (not <code class="docutils literal notranslate"><span class="pre">--ntasks=&lt;NUM&gt;</span></code>,
as it would be usual for MPI processes). It might be valuable in terms of runtime to bind/pin the
MPI processes to hardware. A convenient option is <code class="docutils literal notranslate"><span class="pre">--bind-to</span> <span class="pre">core</span></code>. All other options can be
obtained by</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">marie@login$ </span>mpiexec<span class="w"> </span>--help<span class="w"> </span>binding
</pre></div>
</div>
<p>or from
<a class="reference external" href="https://wiki.mpich.org/mpich/index.php/Using_the_Hydra_Process_Manager#Process-core_Binding%7Cwiki.mpich.org">mpich wiki</a>.</p>
<p>In the following, we provide two examples on how to use <code class="docutils literal notranslate"><span class="pre">pvbatch</span></code> from within a job file and an
interactive allocation.</p>
<p>??? example ‚ÄúExample job file‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```Bash
#!/bin/bash

#SBATCH --nodes=1
#SBATCH --cpus-per-task=12
#SBATCH --time=01:00:00

# Make sure to only use ParaView
module purge
module load release/23.10 GCC/11.3.0 OpenMPI/4.1.4 ParaView/5.11.1-mpi

pvbatch --mpi --force-offscreen-rendering pvbatch-script.py
```
</pre></div>
</div>
<p>??? example ‚ÄúExample of interactive allocation using <code class="docutils literal notranslate"><span class="pre">salloc</span></code>‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```console
marie@login$ salloc --nodes=1 --cpus-per-task=16 --time=01:00:00 bash
salloc: Pending job allocation 336202
salloc: job 336202 queued and waiting for resources
salloc: job 336202 has been allocated resources
[...]

# Make sure to only use ParaView
marie@compute$ module purge
marie@compute$ module load release/23.10 GCC/11.3.0 OpenMPI/4.1.4 ParaView/5.11.1-mpi

# Go to working directory, e.g., your workspace
marie@compute$ cd /path/to/workspace

# Execute pvbatch using 16 MPI processes in parallel on allocated resources
marie@compute$ pvbatch --mpi --force-offscreen-rendering pvbatch-script.py
```
</pre></div>
</div>
<section id="using-gpus">
<h4>Using GPUs<a class="headerlink" href="#using-gpus" title="Permalink to this heading">#</a></h4>
<p>ParaView <code class="docutils literal notranslate"><span class="pre">pvbatch</span></code> can render offscreen through the Native Platform Interface (EGL) on the graphics
cards (GPUs) specified by the device index. For that, make sure to use a cluster with GPUs
(e.g. <code class="docutils literal notranslate"><span class="pre">Alpha</span></code>, <code class="docutils literal notranslate"><span class="pre">Power9</span></code>; see <span class="xref myst">hardware overview</span>),
and pass the option <code class="docutils literal notranslate"><span class="pre">--displays</span> <span class="pre">$CUDA_VISIBLE_DEVICES</span></code> to <code class="docutils literal notranslate"><span class="pre">pvbatch</span></code>.</p>
<p>??? example ‚ÄúExample job file‚Äù</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>```Bash
#!/bin/bash

#SBATCH --nodes=1
#SBATCH --cpus-per-task=12
#SBATCH --gres=gpu:2
#SBATCH --time=01:00:00

# Make sure to only use ParaView
module purge
module load release/23.10 GCC/11.3.0 OpenMPI/4.1.4 ParaView/5.11.1-mpi

pvbatch --mpi --displays $CUDA_VISIBLE_DEVICES --force-offscreen-rendering pvbatch-script.py
```
</pre></div>
</div>
</section>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="zsh-as-alternative-shell">
<h1>ZSH as Alternative Shell<a class="headerlink" href="#zsh-as-alternative-shell" title="Permalink to this heading">#</a></h1>
<p>!!! warning
Though all efforts have been made to ensure the accuracy and
currency of the content on this website, please be advised that
some content might be out of date and there is no continuous
website support available. In case of any ambiguity or doubts,
users are advised to do their own research on the content‚Äôs
accuracy and currency.</p>
<p>The <a class="reference external" href="https://www.zsh.org">ZSH</a>, short for <code class="docutils literal notranslate"><span class="pre">z-shell</span></code>, is an alternative shell for Linux that offers
many convenience features for productive use that <code class="docutils literal notranslate"><span class="pre">bash</span></code>, the default shell, does not offer.</p>
<p>This should be a short introduction to <code class="docutils literal notranslate"><span class="pre">zsh</span></code> and offer some examples that are especially useful
on ZIH systems.</p>
<section id="oh-my-zsh">
<h2><code class="docutils literal notranslate"><span class="pre">oh-my-zsh</span></code><a class="headerlink" href="#oh-my-zsh" title="Permalink to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">oh-my-zsh</span></code> is a plugin that adds many features to the <code class="docutils literal notranslate"><span class="pre">zsh</span></code> with a very simple install. Simply run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>marie@login$ sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot;
</pre></div>
</div>
<p>and then, if it is not already your login shell, run <code class="docutils literal notranslate"><span class="pre">zsh</span></code> or re-login.</p>
<p>The rest of this document assumes that you have <code class="docutils literal notranslate"><span class="pre">oh-my-zsh</span></code> installed and running.</p>
</section>
<section id="features">
<h2>Features<a class="headerlink" href="#features" title="Permalink to this heading">#</a></h2>
<section id="themes">
<h3>Themes<a class="headerlink" href="#themes" title="Permalink to this heading">#</a></h3>
<p>There are many different themes for the <code class="docutils literal notranslate"><span class="pre">zsh</span></code>. See the
<a class="reference external" href="https://github.com/ohmyzsh/ohmyzsh">GitHub-page of <code class="docutils literal notranslate"><span class="pre">oh-my-zsh</span></code></a> for more details.</p>
</section>
<section id="auto-completion">
<h3>Auto-completion<a class="headerlink" href="#auto-completion" title="Permalink to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">zsh</span></code> offers more auto-completion features than <code class="docutils literal notranslate"><span class="pre">bash</span></code>. You can auto-complete programs, filenames, parameters,
<code class="docutils literal notranslate"><span class="pre">man</span></code>-pages and a lot more, and you can cycle through the suggestions with <code class="docutils literal notranslate"><span class="pre">TAB</span></code>-button.</p>
<p><img alt="Cycling through auto-completion for parameter names" src="63_chat_with_docs/misc/zsh_autocomplete_parameters.png" /></p>
</section>
<section id="syntax-highlighting">
<h3>Syntax-highlighting<a class="headerlink" href="#syntax-highlighting" title="Permalink to this heading">#</a></h3>
<p>When you add this line to your <code class="docutils literal notranslate"><span class="pre">~/.zshrc</span></code> with <code class="docutils literal notranslate"><span class="pre">oh-my-zsh</span></code> installed, you get syntax-highlighting directly
in the shell:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">plugins</span><span class="o">+=(</span>
<span class="w">  </span>zsh-syntax-highlighting
<span class="o">)</span>
</pre></div>
</div>
<p><img alt="Syntax-highlighting directly in the shell" src="63_chat_with_docs/misc/zsh_syntax_highlighting.png" /></p>
</section>
<section id="typo-correction">
<h3>Typo-correction<a class="headerlink" href="#typo-correction" title="Permalink to this heading">#</a></h3>
<p>With</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>setopt<span class="w"> </span>correct_all
<span class="nv">ENABLE_CORRECTION</span><span class="o">=</span><span class="s2">&quot;true&quot;</span>
</pre></div>
</div>
<p>in <code class="docutils literal notranslate"><span class="pre">~/.zshrc</span></code> you get correction suggestions when the shell thinks
that it might be what you want, e.g. when a command
is expected to be handed an existing file.</p>
<p><img alt="Correction suggestion" src="63_chat_with_docs/misc/zsh_typo.png" /></p>
</section>
<section id="automatic-cd">
<h3>Automatic <code class="docutils literal notranslate"><span class="pre">cd</span></code><a class="headerlink" href="#automatic-cd" title="Permalink to this heading">#</a></h3>
<p>Adding <code class="docutils literal notranslate"><span class="pre">AUTO_CD</span></code> to <code class="docutils literal notranslate"><span class="pre">~/.zshrc</span></code> file allows to leave out the <code class="docutils literal notranslate"><span class="pre">cd</span></code> when a folder name is provided.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>setopt<span class="w"> </span>AUTO_CD
</pre></div>
</div>
<p><img alt="Automatic cd" src="63_chat_with_docs/misc/zsh_autocd.png" /></p>
</section>
<section id="fish-like-auto-suggestions">
<h3><code class="docutils literal notranslate"><span class="pre">fish</span></code>-like auto-suggestions<a class="headerlink" href="#fish-like-auto-suggestions" title="Permalink to this heading">#</a></h3>
<p>Install <a class="reference external" href="https://github.com/zsh-users/zsh-autosuggestions"><code class="docutils literal notranslate"><span class="pre">zsh-autosuggestions</span></code></a> to get <code class="docutils literal notranslate"><span class="pre">fish</span></code>-shell-like
auto-suggestions of previous commands that start with the same letters and that you can complete with
the right arrow key.</p>
<p><img alt="Auto-suggestion" src="63_chat_with_docs/misc/zsh_autosuggestion.png" /></p>
<p>??? example ‚ÄúAddons for your shell‚Äù
=== ‚Äú<code class="docutils literal notranslate"><span class="pre">bash</span></code>‚Äù
```bash
# Create a new directory and directly <code class="docutils literal notranslate"><span class="pre">cd</span></code> into it
mcd () {
mkdir -p <span class="math notranslate nohighlight">\(1
            cd \)</span>1
}</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    # Find the largest files in the current directory easily
    function treesizethis {
        du -k --max-depth=1 | sort -nr | awk &#39;
         BEGIN {
        split(&quot;KB,MB,GB,TB&quot;, Units, &quot;,&quot;);
         }
         {
        u = 1;
        while ($1 &gt;= 1024) {
           $1 = $1 / 1024;
           u += 1
        }
        $1 = sprintf(&quot;%.1f %s&quot;, $1, Units[u]);
        print $0;
         }
        &#39;
    }

    #This allows you to run `slurmlogpath $SLURM_ID` and get the log-path directly in stdout:
    function slurmlogpath {
        scontrol show job $1 | sed -n -e &#39;s/^\s*StdOut=//p&#39;
    }

    # `ftails` follow-tails a slurm-log. Call it without parameters to tail the only running job or
    # get a list of running jobs or use `ftails $JOBID` to tail a specific job
    function ftails {
        JOBID=$1
        if [[ -z $JOBID ]]; then
             JOBS=$(squeue --format=&quot;%i \\&#39;%j\\&#39; &quot; --me | grep -v JOBID)
             NUMBER_OF_JOBS=$(echo &quot;$JOBS&quot; | wc -l)
             JOBID=
             if [[ &quot;$NUMBER_OF_JOBS&quot; -eq 1 ]]; then
                 JOBID=$(echo $JOBS | sed -e &quot;s/&#39;//g&quot; | sed -e &#39;s/ .*//&#39;)
             else
                 JOBS=$(echo $JOBS | tr -d &#39;\n&#39;)
                 JOBID=$(eval &quot;whiptail --title &#39;Choose jobs to tail&#39; --menu &#39;Choose Job to tail&#39; 25 78 16 $JOBS&quot; 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3)
             fi
        fi
        SLURMLOGPATH=$(slurmlogpath $JOBID)
        if [[ -e $SLURMLOGPATH ]]; then
            tail -n100 -f $SLURMLOGPATH
        else
            echo &quot;No slurm-log-file found&quot;
        fi
    }

    #With this, you only need to type `sq` instead of `squeue -u $USER`.
    alias sq=&quot;squeue --me&quot;
    ```
=== &quot;`zsh`&quot;
    ```bash
    # Create a new directory and directly `cd` into it
    mcd () {
        mkdir -p $1
        cd $1
    }

    # Find the largest files in the current directory easily
    function treesizethis {
        du -k --max-depth=1 | sort -nr | awk &#39;
         BEGIN {
        split(&quot;KB,MB,GB,TB&quot;, Units, &quot;,&quot;);
         }
         {
        u = 1;
        while ($1 &gt;= 1024) {
           $1 = $1 / 1024;
           u += 1
        }
        $1 = sprintf(&quot;%.1f %s&quot;, $1, Units[u]);
        print $0;
         }
        &#39;
    }

    #This allows you to run `slurmlogpath $SLURM_ID` and get the log-path directly in stdout:
    function slurmlogpath {
        scontrol show job $1 | sed -n -e &#39;s/^\s*StdOut=//p&#39;
    }

    # `ftails` follow-tails a slurm-log. Call it without parameters to tail the only running job or
    # get a list of running jobs or use `ftails $JOBID` to tail a specific job
    function ftails {
        JOBID=$1
        if [[ -z $JOBID ]]; then
             JOBS=$(squeue --format=&quot;%i \\&#39;%j\\&#39; &quot; --me | grep -v JOBID)
             NUMBER_OF_JOBS=$(echo &quot;$JOBS&quot; | wc -l)
             JOBID=
             if [[ &quot;$NUMBER_OF_JOBS&quot; -eq 1 ]]; then
                 JOBID=$(echo $JOBS | sed -e &quot;s/&#39;//g&quot; | sed -e &#39;s/ .*//&#39;)
             else
                 JOBS=$(echo $JOBS | tr -d &#39;\n&#39;)
                 JOBID=$(eval &quot;whiptail --title &#39;Choose jobs to tail&#39; --menu &#39;Choose Job to tail&#39; 25 78 16 $JOBS&quot; 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3)
             fi
        fi
        SLURMLOGPATH=$(slurmlogpath $JOBID)
        if [[ -e $SLURMLOGPATH ]]; then
            tail -n100 -f $SLURMLOGPATH
        else
            echo &quot;No slurm-log-file found&quot;
        fi
    }

    #With this, you only need to type `sq` instead of `squeue -u $USER`.
    alias sq=&quot;squeue --me&quot;

    #This will automatically replace `...` with `../..` and `....` with `../../..`
    # and so on (each additional `.` adding another `/..`) when typing commands:
    rationalise-dot() {
        if [[ $LBUFFER = *.. ]]; then
            LBUFFER+=/..
        else
            LBUFFER+=.
        fi
    }
    zle -N rationalise-dot
    bindkey . rationalise-dot

    # This allows auto-completion for `module load`:
    function _module {
        MODULE_COMMANDS=(
            &#39;-t:Show computer parsable output&#39;
            &#39;load:Load a module&#39;
            &#39;unload:Unload a module&#39;
            &#39;spider:Search for a module&#39;
            &#39;avail:Show available modules&#39;
            &#39;list:List loaded modules&#39;
        )

        MODULE_COMMANDS_STR=$(printf &quot;\n&#39;%s&#39;&quot; &quot;${MODULE_COMMANDS[@]}&quot;)

        eval &quot;_describe &#39;command&#39; \&quot;($MODULE_COMMANDS_STR)\&quot;&quot;
        _values -s &#39; &#39; &#39;flags&#39; $(ml -t avail | sed -e &#39;s#/$##&#39; | tr &#39;\n&#39; &#39; &#39;)
    }

    compdef _module &quot;module&quot;
    ```
</pre></div>
</div>
</section>
</section>
<section id="setting-zsh-as-default-shell">
<h2>Setting <code class="docutils literal notranslate"><span class="pre">zsh</span></code> as default-shell<a class="headerlink" href="#setting-zsh-as-default-shell" title="Permalink to this heading">#</a></h2>
<p>Please ask HPC support if you want to set the <code class="docutils literal notranslate"><span class="pre">zsh</span></code> as your default login shell.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="user-support">
<h1>User Support<a class="headerlink" href="#user-support" title="Permalink to this heading">#</a></h1>
<section id="create-a-ticket">
<h2>Create a Ticket<a class="headerlink" href="#create-a-ticket" title="Permalink to this heading">#</a></h2>
<p>The best way to ask for help send a message to
<a class="reference external" href="mailto:hpc-support&#37;&#52;&#48;tu-dresden&#46;de">hpc-support<span>&#64;</span>tu-dresden<span>&#46;</span>de</a> with a
detailed description of your problem.</p>
<p>It should include:</p>
<ul class="simple">
<li><p>Who is reporting? (login name)</p></li>
<li><p>Where have you seen the problem? (name of the HPC system and/or of the node)</p></li>
<li><p>When has the issue occurred? Maybe, when did it work last?</p></li>
<li><p>What exactly happened?</p></li>
</ul>
<p>If possible include</p>
<ul class="simple">
<li><p>job ID,</p></li>
<li><p>batch script,</p></li>
<li><p>filesystem path,</p></li>
<li><p>loaded modules and environment,</p></li>
<li><p>output and error logs,</p></li>
<li><p>steps to reproduce the error.</p></li>
</ul>
<p>This email automatically opens a trouble ticket which will be tracked by the HPC team. Please
always keep the ticket number in the subject on your answers so that our system can keep track
on our communication.</p>
<p>For a new request, please simply send a new email (without any ticket number).</p>
<p>!!! hint ‚ÄúPlease try to find an answer in this documentation first.‚Äù</p>
</section>
<section id="open-q-a-sessions">
<h2>Open Q&amp;A Sessions<a class="headerlink" href="#open-q-a-sessions" title="Permalink to this heading">#</a></h2>
<p>We invite you to join our public Q&amp;A sessions with any questions you may have:</p>
<ul>
<li><p>Open Q&amp;A session for users of the NHR&#64;TUD HPC systems.<br />
Biweekly on Mondays from 1.30 - 2.30 pm.</p>
<p>See <a class="reference external" href="https://tu-dresden.de/zih/die-einrichtung/termine">ZIH calendar</a>
for the next event or download the
<a class="reference external" href="https://tu-dresden.de/zih/die-einrichtung/termine/termine/qa-session-nhr-at-tud/ics_view">Q&amp;A event series</a>
to your calendar.</p>
</li>
<li><p>Open AI Q&amp;A session as a joint initiative for users of NHR and GCS centers.<br />
Every Thursday from 2:00 - 3:00 pm.</p>
<p>See <a class="reference external" href="https://www.nhr-verein.de/ki-auf-hochleistungsrechnern">NHR - AI on High Performance Computers</a>
for further details.<br />
Join the <a class="reference external" href="https://www.nhr-verein.de/en/ai-supercomputers">zoom session</a> now.</p>
</li>
</ul>
<hr class="footnotes docutils" />
<aside class="footnote brackets" id="id77" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id58">1</a><span class="fn-bracket">]</span></span>
<p>Scheduling TSS/360 for responsiveness. In: AFIPS ‚Äò70 (Fall): Proceedings of the November
17-19, 1970, fall joint computer conference, November 1970, Pages 97‚Äì111</p>
</aside>
<aside class="footnote brackets" id="id78" role="note">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id59">1</a>,<a role="doc-backlink" href="#id60">2</a>)</span>
<p>Re-compilation is not required. Yet, to obtain more details it is recommended to re-compile with the <code class="docutils literal notranslate"><span class="pre">-g</span></code> compiler option, which adds debugging information to the executable of an application.</p>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./63_chat_with_docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

            </article>
            

            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Erkl√§rung zur Barrierefreiheit
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#erstellung-dieser-erklarung-zur-barrierefreiheit">
     Erstellung dieser Erkl√§rung zur Barrierefreiheit
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stand-der-barrierefreiheit">
     Stand der Barrierefreiheit
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kontakt">
     Kontakt
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#durchsetzungsverfahren">
     Durchsetzungsverfahren
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#datenschutzerklarung">
   Datenschutzerkl√§rung
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#zih-hpc-documentation">
   ZIH HPC Documentation
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#contribution">
     Contribution
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#news">
     News
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-and-courses">
     Training and Courses
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#support-and-consultation">
     Support and Consultation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#legal-notice">
   Legal Notice
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#impressum">
     Impressum
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#ansprechpartner-betreiber">
       Ansprechpartner/Betreiber
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#konzeption-technische-umsetzung-anbieter">
       Konzeption, Technische Umsetzung, Anbieter
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#license">
     License
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#desktop-cloud-visualization-dcv">
   Desktop Cloud Visualization (DCV)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-with-jupyterhub">
     Access with JupyterHub
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#notes-on-gpu-support">
     Notes on GPU Support
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#graphical-applications-with-webvnc">
   Graphical Applications with WebVNC
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-via-jupyterhub">
     Access via JupyterHub
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-via-terminal">
     Access via terminal
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#step-1">
       Step 1
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#step-2">
       Step 2
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#step-3">
       Step 3
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#step-4">
       Step 4
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#jupyterhub">
   JupyterHub
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#disclaimer">
     Disclaimer
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access">
     Access
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#login-page">
     Login Page
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#start-a-session">
     Start a Session
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#standard-profiles">
       Standard Profiles
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#advanced-options">
       Advanced Options
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jupyterlab">
     JupyterLab
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jupyter-notebooks-in-general">
     Jupyter Notebooks in General
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#version-control-of-jupyter-notebooks-with-git">
       Version Control of Jupyter Notebooks with Git
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stop-a-session">
     Stop a Session
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#error-handling">
     Error Handling
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#error-message-in-jupyterlab">
       Error Message in JupyterLab
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#advanced-tips">
     Advanced Tips
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#loading-modules">
       Loading Modules
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#custom-kernels">
       Custom Kernels
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#custom-environments-for-jupyterhub">
   Custom Environments for JupyterHub
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preliminary-steps">
     Preliminary Steps
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#python-virtualenv">
     Python Virtualenv
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conda-environment">
     Conda Environment
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-your-custom-environment">
     Using your custom environment
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#jupyterhub-for-teaching">
   JupyterHub for Teaching
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clone-a-repository-with-a-link">
     Clone a Repository With a Link
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#spawn-options-pass-through-with-url-parameters">
     Spawn Options Pass-through with URL Parameters
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#combination-of-quickstart-and-git-pull-feature">
       Combination of Quickstart and Git-Pull Feature
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#open-a-notebook-automatically-with-a-single-link">
     Open a Notebook Automatically with a Single Link
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-a-shared-python-environment">
     Create a Shared Python Environment
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#jupyterhub-teaching-example">
   JupyterHub Teaching Example
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#context">
     Context
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prerequisites">
     Prerequisites
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preparation-on-the-lecturer-s-side">
     Preparation on the Lecturer‚Äôs Side
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#creating-a-custom-python-environment">
       1. Creating a custom Python environment
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#clone-the-repository-and-store-environment-setup">
       2. Clone the repository and store environment setup
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#prepare-an-activation-file">
       3. Prepare an activation file
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#prepare-the-spawn-link">
       4. Prepare the spawn link
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#usage-on-the-student-s-side">
     Usage on the Student‚Äôs Side
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#preparing-activation-of-the-custom-environment-in-notebooks">
       Preparing activation of the custom environment in notebooks
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#test-spawn-link-and-environment-activation">
     Test spawn link and environment activation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary">
     Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   JupyterLab
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-without-jupyterhub">
     Access without JupyterHub
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#access-with-port-forwarding">
       Access with port forwarding
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#access-with-x11-forwarding">
       Access with X11 forwarding
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#custom-jupyterlab">
   Custom JupyterLab
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Disclaimer
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prepare-the-installation">
     Prepare the Installation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#key-fingerprints">
   Key Fingerprints
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#barnard">
     Barnard
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#romeo">
     Romeo
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#capella">
     Capella
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alpha-centauri">
     Alpha Centauri
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#julia">
     Julia
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#power9">
     Power9
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataport-nodes">
     Dataport Nodes
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#access-to-zih-systems">
   Access to ZIH Systems
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#security-restrictions">
   Security Restrictions
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#connecting-via-terminal-linux-mac-windows">
   Connecting via Terminal (Linux, Mac, Windows)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#before-your-first-connection">
     Before Your First Connection
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#configuring-default-parameters-for-ssh">
       Configuring Default Parameters for SSH
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#x11-forwarding">
     X11-Forwarding
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#connecting-with-mobaxterm-windows">
   Connecting with MobaXterm (Windows)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#download-and-install">
     Download and install
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#configure-local-settings">
     Configure local settings
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#start-a-new-session">
     Start a new session
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#connecting-with-putty-windows">
   Connecting with PuTTY (Windows)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     Download and install
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#start-a-new-ssh-session">
     Start a new SSH session
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#connection-configuration-optional">
     Connection Configuration (optional)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acknowledgement">
   Acknowledgement
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#application-for-hpc-resources">
   Application for HPC Resources
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nhr-center">
     NHR Center
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#user-management-for-project-leaders">
   User Management for Project Leaders
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Access
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#projects">
     Projects
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#manage-project-members-dis-enable">
       Manage Project Members (dis-/enable)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#statistic">
       Statistic
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#terms-of-use">
   Terms of Use
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#history">
     History
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#content-rules">
   Content Rules
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#motivation-and-rationale">
     Motivation and Rationale
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#responsibility-and-license">
     Responsibility and License
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quick-overview">
     Quick Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#detailed-overview">
     Detailed Overview
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#writing-style">
       Writing Style
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pages-structure-and-new-page">
       Pages Structure and New Page
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#preserve-urls">
         Preserve URLs
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#markdown">
       Markdown
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#brief-how-to-on-markdown">
         Brief How-To on Markdown
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#attachments">
         Attachments
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#graphics-and-videos">
         Graphics and Videos
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#resizing-and-alignment-of-graphics">
           Resizing and Alignment of Graphics
          </a>
         </li>
        </ul>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#special-feature-admonitions">
         Special Feature: Admonitions
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#spelling-and-technical-wording">
       Spelling and Technical Wording
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#code-blocks-and-command-prompts">
       Code Blocks and Command Prompts
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#code-blocks-and-syntax-highlighting">
         Code Blocks and Syntax Highlighting
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#data-privacy-and-generic-names">
         Data Privacy and Generic Names
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#placeholders">
         Placeholders
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#mark-omissions">
         Mark Omissions
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#code-styling-rules">
         Code Styling Rules
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#list-of-prompts">
         List of Prompts
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#long-options">
         Long Options
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#equal-signs-in-command-line-options">
         Equal Signs in Command-Line Options
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#customize-search">
       Customize Search
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#contribute-via-browser">
   Contribute via Browser
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preparation">
     Preparation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-a-branch">
     Create a Branch
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#editing-existing-articles">
     Editing Existing Articles
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adding-new-article">
     Adding New Article
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#submitting-articles-for-publication">
     Submitting Articles for Publication
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#revision-of-articles">
     Revision of Articles
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#contribute-via-local-clone">
   Contribute via Local Clone
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#initial-setup-of-your-local-clone">
     Initial Setup of your Local Clone
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#working-with-your-local-clone">
     Working with your Local Clone
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#merging-of-forked-repositories">
     Merging of Forked Repositories
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tools-to-ensure-quality">
     Tools to Ensure Quality
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#working-with-the-docker-container">
     Working with the Docker Container
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#start-the-local-web-server">
       Start the Local Web Server
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#run-the-proposed-checks-inside-container">
       Run the Proposed Checks Inside Container
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#pre-commit-git-hook">
         Pre-commit Git Hook
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#linter">
         Linter
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#spell-checker">
         Spell Checker
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#check-pages-structure">
         Check Pages Structure
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#link-checker">
         Link Checker
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#single-file">
           Single File
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#all-modified-files">
           All Modified Files
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#all-files">
           All Files
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-to-contribute">
   How-To Contribute
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#technical-setup">
     Technical Setup
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#git-workflow">
     Git Workflow
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     Content Rules
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#contribute-via-issue">
     Contribute via Issue
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#contribute-via-web-ide">
     Contribute via Web IDE
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     Contribute via Local Clone
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ci-cd-pipeline">
     CI/CD Pipeline
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sharing-data">
   Sharing Data
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grant-access-on-some-file-or-directory-to-persons-in-your-project">
     Grant access on some file or directory to persons in your project
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grant-access-on-some-file-or-directory-to-persons-from-various-projects">
     Grant access on some file or directory to persons from various projects
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#filesystems">
   Filesystems
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recommendations-for-filesystem-usage">
     Recommendations for Filesystem Usage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cheat-sheet-for-debugging-filesystem-issues">
     Cheat Sheet for Debugging Filesystem Issues
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#general">
       General
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#long-term-preservation-of-research-data">
   Long-Term Preservation of Research Data
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-should-research-data-be-preserved">
     Why should research data be preserved?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#which-research-data-should-be-preserved">
     Which research data should be preserved?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-should-i-add-meta-data-to-my-data">
     Why should I add Meta-Data to my data?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-are-meta-data">
     What are Meta-Data?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#where-can-i-get-more-information-about-management-of-research-data">
     Where can I get more information about management of research data?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#i-want-to-archive-my-research-data-at-zih-safely-how-can-i-do-that">
     I want to archive my research data at ZIH safely. How can I do that?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#storing-very-infrequently-used-data-during-the-course-of-the-project">
       Storing very infrequently used data during the course of the project
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#archiving-data-beyond-the-project-lifetime-for-10-years-and-above">
       Archiving data beyond the project lifetime, for 10 years and above
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lustre">
   Lustre
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#good-practices">
     Good Practices
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#searching-the-directory-tree">
       Searching the Directory Tree
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#useful-commands-for-lustre">
     Useful Commands for Lustre
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#listing-disk-space-usage">
       Listing Disk Space Usage
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#listing-personal-disk-usages-and-limits">
       Listing Personal Disk Usages and Limits
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#listing-osts">
       Listing OSTs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#view-striping-information">
       View Striping Information
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-life-cycle-management">
   Data Life Cycle Management
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-storage-and-management">
     Data Storage and Management
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#backup">
       Backup
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#folder-structure-and-organizing-data">
       Folder Structure and Organizing Data
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#readme-recommendation">
         README Recommendation
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#metadata">
       Metadata
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#data-hygiene">
       Data Hygiene
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#access-rights">
       Access Rights
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#permanent-filesystems">
   Permanent Filesystems
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#global-home-filesystem">
     Global /home Filesystem
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#global-projects-filesystem">
     Global /projects Filesystem
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     Backup
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quotas">
     Quotas
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#working-filesystems">
   Working Filesystems
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     Recommendations for Filesystem Usage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     Cheat Sheet for Debugging Filesystem Issues
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       General
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#workspaces">
   Workspaces
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#workspace-management">
     Workspace Management
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#workspace-lifetimes">
       Workspace Lifetimes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#list-available-filesystems">
       List Available Filesystems
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#list-current-workspaces">
       List Current Workspaces
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#allocate-a-workspace">
       Allocate a Workspace
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#extension-of-a-workspace">
       Extension of a Workspace
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#send-reminder-for-workspace-expiration-date">
       Send Reminder for Workspace Expiration Date
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#send-daily-reminder">
         Send Daily Reminder
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#send-calendar-invitation">
         Send Calendar Invitation
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#deletion-of-a-workspace">
       Deletion of a Workspace
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#expire-process">
         Expire Process
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#restoring-expired-workspaces">
       Restoring Expired Workspaces
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linking-workspaces-in-home">
     Linking Workspaces in HOME
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-use-workspaces">
     How to use Workspaces
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#per-job-storage">
       Per-Job Storage
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#data-for-a-campaign">
       Data for a Campaign
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mid-term-storage">
       Mid-Term Storage
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cooperative-usage-group-workspaces">
     Cooperative Usage (Group Workspaces)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#faq-and-troubleshooting">
     FAQ and Troubleshooting
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transfer-data-inside-zih-systems-with-datamover">
   Transfer Data Inside ZIH Systems with Datamover
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#managing-transfer-jobs">
     Managing Transfer Jobs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#usage-of-datamover">
     Usage of Datamover
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transferring-files-between-zih-systems-and-group-drive">
     Transferring Files Between ZIH Systems and Group Drive
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transfer-data-to-from-zih-systems-via-dataport-nodes">
   Transfer Data to/from ZIH Systems via Dataport Nodes
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-from-linux">
     Access From Linux
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#scp">
       SCP
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sftp">
       SFTP
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#rsync">
       Rsync
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-from-windows">
     Access From Windows
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#command-line">
       Command Line
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gui-using-winscp">
       GUI - Using WinSCP
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transfer-data-between-zih-systems-and-object-storage-s3">
   Transfer Data between ZIH Systems and Object Storage (S3)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#initial-configuration">
     Initial Configuration
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#copying-data-from-to-object-storage">
     Copying Data from/to Object Storage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accessing-the-object-storage">
     Accessing the Object Storage
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#copying-a-file-from-object-storage-to-zih-systems">
       Copying a File from Object Storage to ZIH systems
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#copying-a-file-from-object-storage-to-your-workstation">
       Copying a File from Object Storage to Your Workstation
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#accessing-a-public-readable-file">
       Accessing a Public-Readable File
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-transfer">
   Data Transfer
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-transfer-to-from-zih-systems-dataport-nodes">
     Data Transfer to/from ZIH Systems: Dataport Nodes
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-transfer-inside-zih-systems-datamover">
     Data Transfer Inside ZIH Systems: Datamover
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gpu-cluster-alpha-centauri">
   GPU Cluster Alpha Centauri
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overview">
     Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hardware-specification">
     Hardware Specification
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     Filesystems
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#usage">
     Usage
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#modules">
       Modules
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#python-virtual-environments">
       Python Virtual Environments
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id12">
       JupyterHub
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#containers">
       Containers
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nvidia-arm-hpc-developer-kit">
   NVIDIA Arm HPC Developer Kit
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hardware">
     Hardware
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#further-information">
     Further Information
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#getting-access">
     Getting Access
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#running-applications">
     Running Applications
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cross-compiling-for-the-arm-architecture">
       Cross compiling for the Arm Architecture
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#binding-and-distribution-of-tasks">
   Binding and Distribution of Tasks
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     General
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#openmp-strategies">
     OpenMP Strategies
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mpi-strategies">
     MPI Strategies
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#default-binding-and-distribution-pattern">
       Default Binding and Distribution Pattern
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#core-bound">
       Core Bound
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#distribution-block-block">
         Distribution: block:block
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#distribution-cyclic-cyclic">
         Distribution: cyclic:cyclic
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#distribution-cyclic-block">
         Distribution: cyclic:block
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#socket-bound">
       Socket Bound
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#default-distribution">
         Default Distribution
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id14">
         Distribution: block:block
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#distribution-block-cyclic">
         Distribution: block:cyclic
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hybrid-strategies">
     Hybrid Strategies
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id15">
       Default Binding and Distribution Pattern
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id16">
       Core Bound
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id17">
         Distribution: block:block
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id18">
         Distribution: cyclic:block
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gpu">
     GPU
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gpu-cluster-capella">
   GPU Cluster Capella
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id19">
     Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hardware-specifications">
     Hardware Specifications
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-and-login-nodes">
     Access and Login Nodes
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id20">
     Filesystems
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cluster-specific-filesystem-cat">
       Cluster-Specific Filesystem
       <code class="docutils literal notranslate">
        <span class="pre">
         cat
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#software-and-modules">
     Software and Modules
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id21">
       Python Virtual Environments
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#batch-system">
     Batch System
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#virtual-gpus-mig">
     Virtual GPUs-MIG
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#checkpoint-restart">
   Checkpoint/Restart
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-w-r-t-chain-jobs">
     Using w.r.t. Chain Jobs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-dmtcp-manually">
     Using DMTCP Manually
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#signal-handler">
     Signal Handler
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hpc-resources">
   HPC Resources
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#architectural-design">
     Architectural Design
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#login-and-dataport-nodes">
     Login and Dataport Nodes
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id22">
     Barnard
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id23">
     Alpha Centauri
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id24">
     Capella
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id25">
     Romeo
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id26">
     Julia
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id27">
     Power9
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#smp-cluster-julia">
   SMP Cluster Julia
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id28">
     Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hardware-resources">
     Hardware Resources
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#local-temporary-on-nvme-storage">
     Local Temporary on NVMe Storage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hints-for-usage">
     Hints for Usage
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#known-issues-with-mpi">
   Known Issues with MPI
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#open-mpi">
     Open MPI
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#performance-loss-with-mpi-io-module-ompio">
       Performance Loss with MPI-IO-Module OMPIO
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mpirun-on-clusters-alpha-and-power9">
       Mpirun on clusters
       <code class="docutils literal notranslate">
        <span class="pre">
         alpha
        </span>
       </code>
       and
       <code class="docutils literal notranslate">
        <span class="pre">
         power9
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#r-parallel-library-on-multiple-nodes">
       R Parallel Library on Multiple Nodes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mpi-function-mpi-win-allocate">
       MPI Function
       <code class="docutils literal notranslate">
        <span class="pre">
         MPI_Win_allocate
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nvme-storage">
   NVMe Storage
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction-hpc-resources-and-jobs">
   Introduction HPC Resources and Jobs
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#selection-of-suitable-hardware">
     Selection of Suitable Hardware
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#which-cluster-do-i-need">
       Which Cluster Do I Need?
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-or-batch-mode">
       Interactive or Batch Mode
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#parallel-jobs">
       Parallel Jobs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#multithreading">
       Multithreading
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#what-do-i-need-a-cpu-or-gpu">
       What do I need, a CPU or GPU?
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#how-much-time-do-i-need">
       How much time do I need?
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#runtime-limits">
         Runtime limits
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#how-many-cores-do-i-need">
       How many cores do I need?
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#how-much-memory-do-i-need">
       How much memory do I need?
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#memory-limits">
         Memory Limits
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#which-software-is-required">
       Which software is required?
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#available-software">
         Available software
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#processing-of-data-for-input-and-output">
     Processing of Data for Input and Output
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exclusive-reservation-of-hardware">
     Exclusive Reservation of Hardware
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gpu-cluster-power9">
   GPU Cluster Power9
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id29">
     Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id30">
     Hardware Resources
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id31">
     Usage
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id32">
       Containers
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#power-ai">
       Power AI
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cpu-cluster-romeo">
   CPU Cluster Romeo
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id33">
     Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id34">
     Hardware Resources
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id35">
     Usage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-running-cp2k-on-rome">
     Example, running CP2K on Rome
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-the-intel-toolchain-on-rome">
     Using the Intel Toolchain on Rome
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#intel-mpi">
       Intel MPI
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#search-boost-2-0">
     search:
boost: 2.0
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#batch-system-slurm">
   Batch System Slurm
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#job-submission">
     Job Submission
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#options">
     Options
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#host-list">
       Host List
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#number-of-switches">
       Number of Switches
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interactive-jobs">
     Interactive Jobs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-x11-gui-jobs">
       Interactive X11/GUI Jobs
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#batch-jobs">
     Batch Jobs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#job-files">
       Job Files
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-simultaneous-multithreading-smt">
     Using Simultaneous Multithreading (SMT)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#heterogeneous-jobs">
     Heterogeneous Jobs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#limitations">
       Limitations
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#manage-and-control-jobs">
     Manage and Control Jobs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#job-and-slurm-monitoring">
       Job and Slurm Monitoring
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#editing-jobs">
       Editing Jobs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#canceling-jobs">
       Canceling Jobs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#evaluating-jobs">
       Evaluating Jobs
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jobs-at-reservations">
     Jobs at Reservations
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#node-local-storage-in-jobs">
     Node-Local Storage in Jobs
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#job-examples">
   Job Examples
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id36">
     Parallel Jobs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#openmp-jobs">
       OpenMP Jobs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mpi-jobs">
       MPI Jobs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#multiple-programs-running-simultaneously-in-a-job">
       Multiple Programs Running Simultaneously in a Job
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#request-resources-for-parallel-make">
       Request Resources for Parallel Make
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exclusive-jobs-for-benchmarking">
     Exclusive Jobs for Benchmarking
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#array-jobs">
     Array Jobs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#chain-jobs">
     Chain Jobs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#requesting-gpus">
     Requesting GPUs
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#job-examples-with-gpu">
   Job Examples with GPU
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id37">
     Requesting GPUs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#limitations-of-gpu-job-allocations">
       Limitations of GPU Job Allocations
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#running-multiple-gpu-applications-simultaneously-in-a-batch-job">
       Running Multiple GPU Applications Simultaneously in a Batch Job
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#solution">
         Solution
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#slurm-job-file-generator">
   Slurm Job File Generator
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#slurm-resource-limits">
   Slurm Resource Limits
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id38">
     Runtime Limits
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id39">
     Memory Limits
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#slurm-resource-limits-table">
     Slurm Resource Limits Table
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quick-start">
   Quick Start
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#introductory-instructions">
     Introductory Instructions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#obtaining-access">
     Obtaining Access
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accessing-zih-hpc-systems">
     Accessing ZIH HPC Systems
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id40">
       JupyterHub
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#ssh-connection-command-line">
       SSH Connection (Command Line)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-transfer-and-data-management">
     Data Transfer and Data Management
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#create-a-workspace">
       Create a Workspace
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transferring-data-within-zih-hpc-systems">
       Transferring Data
       <em>
        Within
       </em>
       ZIH HPC Systems
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transferring-data-to-from-zih-hpc-systems">
       Transferring Data
       <em>
        To/From
       </em>
       ZIH HPC Systems
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#permission-rights">
       Permission Rights
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#software-environment">
     Software Environment
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#running-a-program-job">
     Running a Program/Job
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#big-data-analytics">
   Big Data Analytics
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id41">
     Interactive Jobs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#default-configuration">
       Default Configuration
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#custom-configuration">
       Custom Configuration
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-hadoop-distributed-filesystem-hdfs">
       Using Hadoop Distributed Filesystem (HDFS)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id42">
     Batch Jobs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jupyter-notebook">
     Jupyter Notebook
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#spawning-a-notebook">
       Spawning a Notebook
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#faq">
     FAQ
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#building-software">
   Building Software
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#computational-fluid-dynamics-cfd">
   Computational Fluid Dynamics (CFD)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#openfoam">
     OpenFOAM
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ansys-cfx">
     Ansys CFX
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ansys-fluent">
     Ansys Fluent
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#star-ccm">
     STAR-CCM+
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ci-cd-on-hpc">
   CI/CD on HPC
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#requirements">
     Requirements
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#setup-process">
     Setup process
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gitlab-pipelines">
     GitLab pipelines
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#passing-slurm-parameters">
       Passing Slurm parameters
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#current-limitations">
     Current limitations
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pitfalls-and-recommendations">
     Pitfalls and Recommendations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#compilers-and-flags">
   Compilers and Flags
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compiler-flags">
     Compiler Flags
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#architecture-specific-optimizations">
       Architecture-specific Optimizations
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#singularity">
   Singularity
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#usage-of-singularity">
     Usage of Singularity
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#local-installation">
       Local Installation
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#container-creation">
       Container Creation
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#new-custom-container">
         New Custom Container
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#import-a-docker-container">
         Import a Docker Container
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#start-from-a-dockerfile">
         Start from a Dockerfile
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#use-the-containers">
       Use the Containers
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#enter-a-shell-in-your-container">
         Enter a Shell in Your Container
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#run-a-command-inside-the-container">
         Run a Command Inside the Container
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#use-cases">
       Use-Cases
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#software-installation-with-easybuild">
   Software Installation with EasyBuild
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id43">
     Prerequisites
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#set-up-a-custom-module-environment-and-build-your-own-modules">
     Set Up a Custom Module Environment and Build Your Own Modules
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id44">
       Prerequisites
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#step-by-step-guide">
       Step by Step Guide
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#troubleshooting">
     Troubleshooting
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-analytics">
   Data Analytics
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-analytics-with-python">
   Data Analytics with Python
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#python-console-and-virtual-environments">
     Python Console and Virtual Environments
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jupyter-notebooks">
     Jupyter Notebooks
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parallel-computing-with-python">
     Parallel Computing with Python
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pandas-with-pandarallel">
       Pandas with Pandarallel
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#dask">
       Dask
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#dask-modules-on-zih-systems">
         Dask Modules on ZIH Systems
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#scheduling-by-dask">
         Scheduling by Dask
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#distributed-scheduler">
           Distributed Scheduler
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#dask-mpi">
           Dask-mpi
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#dask-jobqueue">
           Dask-jobqueue
          </a>
          <ul class="nav section-nav flex-column">
           <li class="toc-h6 nav-item toc-entry">
            <a class="reference internal nav-link" href="#example-of-using-dask-jobqueue-with-slurmcluster">
             Example of Using Dask-Jobqueue with SLURMCluster
            </a>
           </li>
          </ul>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mpi4py-mpi-for-python">
       Mpi4py -  MPI for Python
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-analytics-with-r">
   Data Analytics with R
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#r-console">
     R Console
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#r-in-jupyterhub">
     R in JupyterHub
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rstudio">
     RStudio
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#install-packages-in-r">
     Install Packages in R
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#deep-learning-with-r">
     Deep Learning with R
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#r-interface-to-tensorflow">
       R Interface to TensorFlow
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parallel-computing-with-r">
     Parallel Computing with R
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#basic-lapply-based-parallelism">
       Basic lapply-Based Parallelism
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#shared-memory-parallelism">
       Shared-Memory Parallelism
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#distributed-memory-parallelism">
       Distributed-Memory Parallelism
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#mpi-cluster">
         MPI Cluster
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#psock-cluster">
         PSOCK cluster
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#fork-cluster">
         FORK Cluster
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#other-parallel-options">
       Other Parallel Options
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-analytics-with-rstudio">
   Data Analytics with RStudio
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#debugging">
   Debugging
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overview-of-available-debuggers-at-zih">
     Overview of available Debuggers at ZIH
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#general-advice">
     General Advice
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gnu-debugger-gdb">
     GNU Debugger (GDB)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#arm-ddt">
     Arm DDT
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#serial-program-example">
       Serial Program Example
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#multi-threaded-program-example">
       Multi-threaded Program Example
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mpi-parallel-program-example">
       MPI-Parallel Program Example
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#memory-debugging">
     Memory Debugging
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#valgrind-memcheck">
       Valgrind (Memcheck)
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#distributed-training">
   Distributed Training
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#internal-distribution">
     Internal Distribution
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#distributed-tensorflow">
       Distributed TensorFlow
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#distributed-pytorch">
       Distributed PyTorch
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-multiple-gpus-with-pytorch">
         Using Multiple GPUs with PyTorch
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#distributed-data-parallel">
         Distributed Data-Parallel
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#external-distribution">
     External Distribution
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#horovod">
       Horovod
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#why-use-horovod">
         Why use Horovod?
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#horovod-as-module">
         Horovod as Module
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#horovod-installation">
         Horovod Installation
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#install-horovod-for-tensorflow-with-python-and-pip">
           Install Horovod for TensorFlow with Python and Pip
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#verify-horovod-works">
           Verify Horovod Works
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measure-energy-consumption">
   Measure Energy Consumption
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary-of-measurement-interfaces">
     Summary of Measurement Interfaces
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#accuracy-temporal-and-spatial-resolution">
       Accuracy, Temporal and Spatial Resolution
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#command-line-interface">
     Command Line Interface
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#integration-in-application-performance-traces">
     Integration in Application Performance Traces
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-using-slurm-tools">
     Access Using Slurm Tools
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#post-mortem-per-job-accounting">
       Post-Mortem Per-Job Accounting
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#slurm-energy-profiling">
       Slurm Energy Profiling
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-the-hdeem-c-api">
     Using the HDEEM C API
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#further-information-and-citing">
     Further Information and Citing
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fem-software">
   FEM Software
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#abaqus">
     Abaqus
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#guide-by-user">
       Guide by User
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id45">
       General
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ansys">
     Ansys
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-workbench-interactively">
       Using Workbench Interactively
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-workbench-in-batch-mode">
       Using Workbench in Batch Mode
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#running-workbench-in-parallel">
       Running Workbench in Parallel
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#running-mapdl">
       Running MAPDL
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#shared-memory-mode">
         Shared-Memory Mode
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#interactive-mode">
           Interactive mode
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#batch-mode">
           Batch mode
          </a>
         </li>
        </ul>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#distributed-memory-mode">
         Distributed-Memory Mode
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id46">
           Interactive Mode
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id47">
           Batch Mode
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comsol-multiphysics">
     COMSOL Multiphysics
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#client-server-mode">
       Client-Server Mode
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id48">
       Usage
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-usage-with-x11-forwarding">
       Interactive Usage with X11 Forwarding
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ls-dyna">
     LS-DYNA
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gpu-programming">
   GPU Programming
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#available-gpus">
     Available GPUs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-gpus-with-slurm">
     Using GPUs with Slurm
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#directive-based-gpu-programming">
     Directive Based GPU Programming
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#openacc">
       OpenACC
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#introduction">
         Introduction
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-openacc-with-pgi-compilers">
         Using OpenACC with PGI compilers
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-openacc-with-nvidia-hpc-compilers">
         Using OpenACC with NVIDIA HPC compilers
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#openmp-target-offloading">
       OpenMP target offloading
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-openmp-target-offloading-with-nvidia-hpc-compilers">
         Using OpenMP target offloading with NVIDIA HPC compilers
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-openmp-target-offloading-with-the-ibm-xl-compilers">
         Using OpenMP target offloading with the IBM XL compilers
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#native-gpu-programming">
     Native GPU Programming
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cuda">
       CUDA
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#usage-of-the-cuda-compiler">
         Usage of the CUDA Compiler
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#performance-analysis">
     Performance Analysis
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nvidia-nvprof-visual-profiler">
       NVIDIA nvprof &amp; Visual Profiler
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nvidia-nsight-systems">
       NVIDIA Nsight Systems
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nvidia-nsight-compute">
       NVIDIA Nsight Compute
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyperparameter-optimization-omniopt">
   Hyperparameter Optimization (OmniOpt)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quick-start-with-omniopt">
     Quick start with OmniOpt
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#prepare-application-script-and-software-environment">
       Prepare Application Script and Software Environment
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#configure-and-run-omniopt">
       Configure and Run OmniOpt
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#check-and-evaluate-omniopt-results">
       Check and Evaluate OmniOpt Results
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#external-licenses">
   External Licenses
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-adjust-the-license-setting">
     How to adjust the license setting
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#record-course-of-events-with-lo2s">
   Record Course of Events with lo2s
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id49">
     Usage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#required-permissions">
     Required Permissions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#memory-requirements">
     Memory Requirements
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#advanced-topic-system-monitoring">
     Advanced Topic: System Monitoring
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#advanced-topic-metric-plugins">
     Advanced Topic: Metric Plugins
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning">
   Machine Learning
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id50">
     Modules
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-via-console">
     Machine Learning via Console
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#python-and-virtual-environments">
       Python and Virtual Environments
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#r">
       R
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-with-jupyter">
     Machine Learning with Jupyter
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-with-containers">
     Machine Learning with Containers
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#additional-libraries-for-machine-learning">
     Additional Libraries for Machine Learning
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#hpc-related-software">
       HPC-Related Software
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#datasets-for-machine-learning">
     Datasets for Machine Learning
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-imagenet-dataset">
       The ImageNet Dataset
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mathematics-applications">
   Mathematics Applications
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mathematica">
     Mathematica
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#fonts">
       Fonts
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#linux-workstation">
         Linux Workstation
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#windows-workstation">
         Windows Workstation
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-textual-interface-of-mathematica">
       Using Textual Interface of Mathematica
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mathematica-and-slurm">
       Mathematica and Slurm
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matlab">
     MATLAB
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-matlab-gui">
       Interactive MATLAB-GUI
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#interactive">
         Interactive
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#matlab-container">
         MATLAB container
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#non-interactive">
       Non-interactive
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-the-matlab-compiler">
       Using the MATLAB Compiler
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#parallel-matlab">
       Parallel MATLAB
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#with-local-configuration">
         With ‚Äòlocal‚Äô Configuration
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#with-parfor">
         With parfor
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#matlab-parallel-computing-toolbox">
       MATLAB Parallel Computing Toolbox
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#configuration-matlab-client-on-the-cluster">
         Configuration ‚Äì MATLAB client on the cluster
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#installation-and-configuration-matlab-client-off-the-cluster">
         Installation and Configuration ‚Äì MATLAB client off the cluster
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#configuring-jobs">
         Configuring Jobs
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#interactive-jobs-matlab-client-on-the-cluster">
         Interactive Jobs - MATLAB Client on the Cluster
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#independent-batch-job">
         Independent Batch Job
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#parallel-batch-job">
         Parallel Batch Job
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id51">
         Debugging
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#further-reading">
         Further Reading
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mathematics-libraries">
   Mathematics Libraries
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#blas-lapack-and-scalapack">
     BLAS, LAPACK and ScaLAPACK
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#amd-optimizing-cpu-libraries-aocl">
     AMD Optimizing CPU Libraries (AOCL)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#math-kernel-library-mkl">
     Math Kernel Library (MKL)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#linking">
       Linking
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#libraries-for-gpus">
     Libraries for GPUs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#magma">
       MAGMA
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fftw">
     FFTW
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#environment-modules">
   Environment Modules
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#module-commands">
     Module Commands
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#examples">
       Examples
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#front-end-ml">
       Front-End ml
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#module-environments">
     Module Environments
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#searching-for-software">
       Searching for Software
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#toolchains">
     Toolchains
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#per-architecture-builds">
     Per-Architecture Builds
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#advanced-usage">
     Advanced Usage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id52">
     Troubleshooting
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#when-i-log-in-the-wrong-modules-are-loaded-by-default">
       When I log in, the wrong modules are loaded by default
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#i-can-t-load-module-tensorflow">
       I can‚Äôt load module TensorFlow
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-mpi-correctness-with-must">
   Check MPI Correctness with MUST
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#must">
     MUST
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#setup-and-modules">
       Setup and Modules
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#running-your-application-with-must">
       Running your Application with MUST
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#result-files">
       Result Files
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-usage-of-must">
       Example Usage of MUST
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#further-mpi-correctness-tools">
     Further MPI Correctness Tools
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nanoscale-simulations">
   Nanoscale Simulations
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#abinit">
     ABINIT
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cp2k">
     CP2K
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cpmd">
     CPMD
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gamess">
     GAMESS
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gaussian">
     Gaussian
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#guidance-on-data-management-with-gaussian">
       Guidance on Data Management with Gaussian
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gromacs">
     GROMACS
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lammps">
     LAMMPS
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#namd">
     NAMD
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#orca">
     ORCA
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#siesta">
     Siesta
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vasp">
     VASP
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gpu-accelerated-containers-for-deep-learning-ngc-containers">
   GPU-accelerated Containers for Deep Learning (NGC Containers)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-ngc-containers-on-the-zih-system">
     Run NGC Containers on the ZIH System
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#run-ngc-container-on-a-single-gpu">
       Run NGC container on a Single GPU
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#multi-gpu-usage">
       Multi-GPU Usage
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#multi-node-usage">
       Multi-node Usage
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#environment-and-software">
   Environment and Software
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#user-environment">
     User Environment
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id53">
     Software Environment
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id54">
     Modules
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id55">
     Jupyter Notebook
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id56">
     Containers
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#read-cpu-performance-counters-with-papi">
   Read CPU Performance Counters with PAPI
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id57">
     Introduction
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#papi-counter-interfaces">
     PAPI Counter Interfaces
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#high-level-api">
       High-Level API
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#low-level-api">
       Low-Level API
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#usage-on-zih-systems">
     Usage on ZIH Systems
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#search-boost-450-0">
     search:
boost: 450.0
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#performance-engineering-overview">
   Performance Engineering Overview
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#objectives">
     Objectives
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#installed-tools-in-a-nutshell">
     Installed Tools in a Nutshell
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#approach-and-terminology">
     Approach and Terminology
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#instrumentation">
       Instrumentation
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#measurement">
       Measurement
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#profile">
         Profile
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#trace">
         Trace
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#analysis">
       Analysis
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#presentation">
       Presentation
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#evaluation">
       Evaluation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#installed-tools-summary">
     Installed Tools Summary
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#lo2s">
       lo2s
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id61">
       MUST
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#papi">
       PAPI
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#perf-tools">
       Perf Tools
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pika">
       PIKA
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#score-p">
       Score-P
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#vampir">
       Vampir
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#produce-performance-overview-with-perf">
   Produce Performance Overview with Perf
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#configuration">
     Configuration
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#perf-stat">
     Perf Stat
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#for-users">
       For Users
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#for-admins">
       For Admins
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#perf-record">
     Perf Record
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id62">
       For Users
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-perf-with-mpi">
         Using Perf with MPI
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id63">
       For Admins
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#perf-report">
     Perf Report
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#on-zih-systems">
       On ZIH Systems
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#perf-script">
     Perf Script
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#perf-top">
     Perf Top
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#search-boost-4-0">
     search:
boost: 4.0
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#track-slurm-jobs-with-pika">
   Track Slurm Jobs with PIKA
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id64">
     Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#table-view-and-job-search">
     Table View and Job Search
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#timeline-visualization">
     Timeline Visualization
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#footprint-visualization">
     Footprint Visualization
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hints">
     Hints
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#case-studies">
     Case Studies
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#idle-cpus">
       Idle CPUs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#blocking-i-o-operations">
       Blocking I/O Operations
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#memory-leaks">
       Memory Leaks
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning-with-powerai">
   Machine Learning with PowerAI
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#general-overview">
     General Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#specific-user-guides">
     Specific User Guides
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#powerai-container">
     PowerAI Container
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#private-modules">
   Private Modules
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#setup">
     Setup
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#build-and-install-software">
       0. Build and Install Software
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#create-directory">
       1. Create Directory
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#create-modulefile">
       2. Create Modulefile
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id65">
     Usage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#caveats">
     Caveats
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id66">
   Python Virtual Environments
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#python-virtual-environment">
     Python Virtual Environment
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#persistence-of-python-virtual-environment">
       Persistence of Python Virtual Environment
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conda-virtual-environment">
     Conda Virtual Environment
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#persistence-of-conda-virtual-environment">
       Persistence of Conda Virtual Environment
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#neural-networks-with-pytorch">
   Neural Networks with PyTorch
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pytorch-console">
     PyTorch Console
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pytorch-in-jupyterhub">
     PyTorch in JupyterHub
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id67">
     Distributed PyTorch
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#migrate-pytorch-script-from-cpu-to-gpu">
     Migrate PyTorch-script from CPU to GPU
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id68">
       Caveats
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#moving-data-back-to-the-cpu-memory">
         Moving Data Back to the CPU-Memory
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#speed-improvements-and-batch-size">
         Speed Improvements and Batch Size
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#record-course-of-events-with-score-p">
   Record Course of Events with Score-P
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#serial-programs">
     Serial Programs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mpi-parallel-programs">
     MPI Parallel Programs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#openmp-parallel-programs">
     OpenMP Parallel Programs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hybrid-mpi-openmp-parallel-programs">
     Hybrid MPI/OpenMP Parallel Programs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#score-p-instrumenter-option-overview">
     Score-P Instrumenter Option Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#application-measurement">
     Application Measurement
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#singularity-for-power9-architecture">
   Singularity for Power9 Architecture
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#build-a-singularity-container-in-a-job">
     Build a Singularity Container in a Job
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#filesystem">
     Filesystem
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#start-a-job-in-a-vm">
     Start a Job in a VM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#singularity-recipes-and-hints">
   Singularity Recipes and Hints
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-definitions">
     Example Definitions
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#basic-example">
       Basic Example
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#distributed-memory">
       Distributed memory
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#mpich">
         MPICH
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cuda-cudnn-open-mpi">
       CUDA + CuDNN + Open MPI
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id69">
     Hints
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gui-x11-applications">
       GUI (X11) Applications
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#hardware-acceleration">
       Hardware Acceleration
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#singularity-temporary-and-cache-directories">
       Singularity Temporary and Cache Directories
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#software-development-and-tools">
   Software Development and Tools
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#compare-system-performance-with-spechpc">
   Compare System Performance with SPEChpc
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#installation">
     Installation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id70">
     Configuration
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#execution">
     Execution
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#submit-spechpc-benchmarks-with-a-job-file">
       Submit SPEChpc Benchmarks with a Job File
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#solved-issues">
     Solved Issues
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#fortran-compilation-error">
       Fortran Compilation Error
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pmix-error">
       pmix Error
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#orte-error-too-many-processes">
       ORTE Error (too many processes)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#error-with-openfabrics-device">
       Error with OpenFabrics Device
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#out-of-memory">
       Out of Memory
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unresolved-issues">
     Unresolved Issues
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cuda-reduction-operation-error">
       CUDA Reduction Operation Error
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#slurm-bug">
       Slurm Bug
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#benchmark-hangs-forever">
       Benchmark Hangs Forever
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#other-issues">
       Other Issues
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inspect-model-training-with-tensorboard">
   Inspect Model Training with TensorBoard
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-jupyterhub">
     Using JupyterHub
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-tensorboard-from-module-environment">
     Using TensorBoard from Module Environment
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#neural-networks-with-tensorflow">
   Neural Networks with TensorFlow
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensorflow-console">
     TensorFlow Console
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensorflow-in-jupyterhub">
     TensorFlow in JupyterHub
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensorflow-in-containers">
     TensorFlow in Containers
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensorflow-with-python-or-r">
     TensorFlow with Python or R
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id71">
     Distributed TensorFlow
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compatibility-tf2-and-tf1">
     Compatibility TF2 and TF1
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#keras">
     Keras
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#utilities">
   Utilities
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tmux">
     Tmux
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#best-practices">
       Best Practices
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#basic-usage">
       Basic Usage
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-a-more-recent-version">
       Using a More Recent Version
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#error-protocol-version-mismatch">
       Error: Protocol Version Mismatch
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-tmux-on-compute-nodes">
       Using Tmux on Compute Nodes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#where-is-my-tmux-session">
       Where Is My Tmux Session?
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#architecture-information-lstopo">
     Architecture Information (lstopo)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#working-with-large-archives-and-compressed-files">
     Working with Large Archives and Compressed Files
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#parallel-gzip-decompression">
       Parallel Gzip Decompression
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#direct-archive-access-without-extraction-using-ratarmount">
       Direct Archive Access Without Extraction Using Ratarmount
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#example-workflow">
         Example Workflow
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#study-course-of-events-with-vampir">
   Study Course of Events with Vampir
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id72">
     Introduction
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#starting-vampir">
     Starting Vampir
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-vampirserver">
     Using VampirServer
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id73">
     Advanced Usage
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#manual-server-startup">
       Manual Server Startup
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#port-forwarding">
       Port Forwarding
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nightly-builds-unstable">
       Nightly Builds (unstable)
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#virtual-desktops">
   Virtual Desktops
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#launch-a-virtual-desktop">
     Launch a Virtual Desktop
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#demonstration">
       Demonstration
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-the-quickstart-feature">
       Using the Quickstart Feature
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reconnecting-to-a-session">
     Reconnecting to a Session
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#terminate-a-remote-session">
     Terminate a Remote Session
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id74">
       Demonstration
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#virtual-machines">
   Virtual Machines
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-a-virtual-machine">
     Create a Virtual Machine
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#on-power9-architecture">
       On Power9 Architecture
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#on-x86-architecture">
       On x86 Architecture
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-a-virtual-machine">
     Access a Virtual Machine
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-usage">
     Example Usage
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#automation">
     Automation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#known-issues">
     Known Issues
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#temporary-memory">
       Temporary Memory
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transport-endpoint-is-not-connected">
       Transport Endpoint is not Connected
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization">
   Visualization
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#paraview">
     ParaView
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#paraview-modules">
       ParaView Modules
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id75">
       Interactive Mode
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-the-gui-via-nice-dcv">
         Using the GUI via NICE DCV
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-client-server-mode-with-mpi-parallel-offscreen-rendering">
         Using Client-Server Mode with MPI-parallel Offscreen-Rendering
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id76">
           Caveats
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#batch-mode-pvbatch">
       Batch Mode (
       <code class="docutils literal notranslate">
        <span class="pre">
         pvbatch
        </span>
       </code>
       )
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#using-gpus">
         Using GPUs
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#zsh-as-alternative-shell">
   ZSH as Alternative Shell
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#oh-my-zsh">
     <code class="docutils literal notranslate">
      <span class="pre">
       oh-my-zsh
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#features">
     Features
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#themes">
       Themes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#auto-completion">
       Auto-completion
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#syntax-highlighting">
       Syntax-highlighting
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#typo-correction">
       Typo-correction
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#automatic-cd">
       Automatic
       <code class="docutils literal notranslate">
        <span class="pre">
         cd
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#fish-like-auto-suggestions">
       <code class="docutils literal notranslate">
        <span class="pre">
         fish
        </span>
       </code>
       -like auto-suggestions
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#setting-zsh-as-default-shell">
     Setting
     <code class="docutils literal notranslate">
      <span class="pre">
       zsh
      </span>
     </code>
     as default-shell
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#user-support">
   User Support
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-a-ticket">
     Create a Ticket
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#open-q-a-sessions">
     Open Q&amp;A Sessions
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Robert Haase
</p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    <p class="last-updated">
Last updated on 2025-07-09.<br>
</p>
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>
Copyright: Licensed <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC-BY 4.0</a> unless mentioned otherwise. 
Contributions and feedback are welcome.
</p>

</div>
  </div>
  
</div>
          </div>
        </footer>
        

      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  </body>
</html>