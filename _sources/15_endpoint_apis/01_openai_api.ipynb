{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e9c0e47-748c-44f7-a428-ab945196dafd",
   "metadata": {},
   "source": [
    "# OpenAI API\n",
    "The OpenAI Application Programming Interface (API) became a de-facto standard to communicate with LLMs programmatically. The Python interface is [open source](https://github.com/openai/openai-python).\n",
    "\n",
    "As the field is moving fast an APIs break sometimes, consider printing out the version of the library you used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82642255-0256-4296-9f7c-b931a174ad5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.102.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "openai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078253e4-5530-4c42-baa4-417ff0ff60d8",
   "metadata": {},
   "source": [
    "For accessing LLMs you create a client object first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33273854-c67c-4994-97fc-183bc6228b51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x19431b333d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = openai.OpenAI()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3646fb61-d525-4501-bb38-d5226816b7b0",
   "metadata": {},
   "source": [
    "The API expects messages in a certain format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b589e4-bd53-4334-b1c9-869fb56af07a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"What's the capital of France?\"}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_messages = []\n",
    "\n",
    "my_messages.append({\n",
    "    \"role\": \"user\", \n",
    "    \"content\": \"What's the capital of France?\"\n",
    "})\n",
    "my_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf12d91-e107-4d37-9804-89ae9f9748af",
   "metadata": {},
   "source": [
    "You can send a request to the server using the `chat.completions` API. If you're planning to use ChatGPT, possible OpenAI models and their prices can be found [here](https://openai.com/api/pricing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b1086f0-812d-4c38-a4bb-8ecc7d823568",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CCRczXAO5C4YgK7gf6Rbi11J9sUQA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Paris.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1757082173, model='gpt-5-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=12, total_tokens=23, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-5\", # or: \n",
    "        messages=my_messages\n",
    "    )\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279633a8-e694-4209-9d89-934d1ebc0785",
   "metadata": {
    "tags": []
   },
   "source": [
    "The answer comes in a similar format like the request was sent. It is a list of answers actually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be100506-9450-4d82-bedd-f88621f80ca2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Paris.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3234b00c-763a-4c62-817c-d62759781d19",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can access the text-answer like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2bc576c-4db0-4770-82e9-d131523dc52a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9f94dc-a586-475f-9c9d-1b5496af56ee",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "For using the API, it is highly recommended to write some helper functions such as this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70520b3a-9e68-49f8-8481-508f75c4e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_chatgpt(message:str, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"A prompt helper function that sends a message to openAI\n",
    "    and returns only the text response.\n",
    "    \"\"\"\n",
    "    # convert message in the right format if necessary\n",
    "    if isinstance(message, str):\n",
    "        message = [{\"role\": \"user\", \"content\": message}]\n",
    "        \n",
    "    # setup connection to the LLM\n",
    "    client = openai.OpenAI()\n",
    "    \n",
    "    # submit prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=message\n",
    "    )\n",
    "    \n",
    "    # extract answer\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944df69a-d98c-4c98-9038-fc37364165e8",
   "metadata": {},
   "source": [
    "This makes our life easier because we can easily access the LLM like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46f9a47b-887a-456b-9e00-11be1baed6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There are five 'o's in Woolloomoloo.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_chatgpt(\"How many o are in Woolloomoloo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "596d9c01-1f11-4474-8216-6ec7b6b26941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babbage-002\n",
      "chatgpt-4o-latest\n",
      "codex-mini-latest\n",
      "computer-use-preview\n",
      "computer-use-preview-2025-03-11\n",
      "dall-e-2\n",
      "dall-e-3\n",
      "davinci-002\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9VNFya3H:ckpt-step-77\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9VNFz3h3\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9VNFzOv6:ckpt-step-88\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9WlQiTl6:ckpt-step-77\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9WlQjtjc\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9WlQjz24:ckpt-step-88\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9Wmaf1H6:ckpt-step-77\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9Wmag9S6:ckpt-step-88\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9WmagblR\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9X70LxDH:ckpt-step-77\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9X70M36A\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9X70MopH:ckpt-step-88\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9X7CCAiE:ckpt-step-77\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9X7CCBSR:ckpt-step-88\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9X7CCzv4\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9X7PEBEk:ckpt-step-84\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9X7PEoLV:ckpt-step-72\n",
      "ft:gpt-3.5-turbo-0125:leipzig-university::9X7PFVgP\n",
      "ft:gpt-4o-2024-08-06:leipzig-university::9ydjMDl7:ckpt-step-45\n",
      "ft:gpt-4o-2024-08-06:leipzig-university::9ydjNWWH\n",
      "ft:gpt-4o-2024-08-06:leipzig-university::9ydjNinx:ckpt-step-90\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-4\n",
      "gpt-4-0125-preview\n",
      "gpt-4-0613\n",
      "gpt-4-1106-preview\n",
      "gpt-4-turbo\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-4-turbo-preview\n",
      "gpt-4.1\n",
      "gpt-4.1-2025-04-14\n",
      "gpt-4.1-mini\n",
      "gpt-4.1-mini-2025-04-14\n",
      "gpt-4.1-nano\n",
      "gpt-4.1-nano-2025-04-14\n",
      "gpt-4o\n",
      "gpt-4o-2024-05-13\n",
      "gpt-4o-2024-08-06\n",
      "gpt-4o-2024-11-20\n",
      "gpt-4o-audio-preview\n",
      "gpt-4o-audio-preview-2024-10-01\n",
      "gpt-4o-audio-preview-2024-12-17\n",
      "gpt-4o-audio-preview-2025-06-03\n",
      "gpt-4o-mini\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4o-mini-audio-preview\n",
      "gpt-4o-mini-audio-preview-2024-12-17\n",
      "gpt-4o-mini-realtime-preview\n",
      "gpt-4o-mini-realtime-preview-2024-12-17\n",
      "gpt-4o-mini-search-preview\n",
      "gpt-4o-mini-search-preview-2025-03-11\n",
      "gpt-4o-mini-transcribe\n",
      "gpt-4o-mini-tts\n",
      "gpt-4o-realtime-preview\n",
      "gpt-4o-realtime-preview-2024-10-01\n",
      "gpt-4o-realtime-preview-2024-12-17\n",
      "gpt-4o-realtime-preview-2025-06-03\n",
      "gpt-4o-search-preview\n",
      "gpt-4o-search-preview-2025-03-11\n",
      "gpt-4o-transcribe\n",
      "gpt-5\n",
      "gpt-5-2025-08-07\n",
      "gpt-5-chat-latest\n",
      "gpt-5-mini\n",
      "gpt-5-mini-2025-08-07\n",
      "gpt-5-nano\n",
      "gpt-5-nano-2025-08-07\n",
      "gpt-audio\n",
      "gpt-audio-2025-08-28\n",
      "gpt-image-1\n",
      "gpt-realtime\n",
      "gpt-realtime-2025-08-28\n",
      "o1\n",
      "o1-2024-12-17\n",
      "o1-mini\n",
      "o1-mini-2024-09-12\n",
      "o1-pro\n",
      "o1-pro-2025-03-19\n",
      "o3\n",
      "o3-2025-04-16\n",
      "o3-deep-research\n",
      "o3-deep-research-2025-06-26\n",
      "o3-mini\n",
      "o3-mini-2025-01-31\n",
      "o3-pro\n",
      "o3-pro-2025-06-10\n",
      "o4-mini\n",
      "o4-mini-2025-04-16\n",
      "o4-mini-deep-research\n",
      "o4-mini-deep-research-2025-06-26\n",
      "omni-moderation-2024-09-26\n",
      "omni-moderation-latest\n",
      "text-embedding-3-large\n",
      "text-embedding-3-small\n",
      "text-embedding-ada-002\n",
      "tts-1\n",
      "tts-1-1106\n",
      "tts-1-hd\n",
      "tts-1-hd-1106\n",
      "whisper-1\n"
     ]
    }
   ],
   "source": [
    "client = openai.OpenAI()\n",
    "\n",
    "print(\"\\n\".join(sorted([model.id for model in client.models.list().data])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e6138-54e9-419e-a9b3-cedcd1551af3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
