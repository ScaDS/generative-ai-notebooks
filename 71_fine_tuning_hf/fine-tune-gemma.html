
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Fine-tuning Gemma on local hardware &#8212; Generative Artificial Intelligence Notebooks</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '71_fine_tuning_hf/fine-tune-gemma';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Merging fine-tuned models" href="merging_model.html" />
    <link rel="prev" title="Listing available models" href="../70_fine_tuning/list_available_models.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../intro.html">

  
  
  
  
  
  
  

  
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../00_setup/readme.html">
                        Setting up your computer
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../10_prompting_basics/01_prompting.html">
                        Prompting basics
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../10_prompting_basics/02_use_cases.html">
                        Use cases
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../10_prompting_basics/03_prompt_engineering.html">
                        Basic prompt Engineering
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../15_endpoint_apis/01_openai_api.html">
                        OpenAI API
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../15_endpoint_apis/02_ollama_endpoint.html">
                        Ollama
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../15_endpoint_apis/03_blablador_endpoint.html">
                        Blablador endpoint
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../15_endpoint_apis/10_anthropic_api.html">
                        Anthropic Claude
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../15_endpoint_apis/20_google_gemini.html">
                        Gemini API
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../15_endpoint_apis/30_huggingface.html">
                        Huggingface API
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../20_chatbots/10_chatbot.html">
                        Programming an LLM-based chatbot
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../20_chatbots/gui.html">
                        A Chatbot GUI
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../30_function_calling/10_function_calling.html">
                        Function calling using ollama
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../30_function_calling/20_langchain.html">
                        Prompting tasks using LangChain
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../30_function_calling/30_langchain_bia.html">
                        Prompting bio-image analysis tasks using LangChain
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../30_function_calling/50_blablado.html">
                        blablado calls functions for you
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../30_function_calling/55_microscope_stage_demo.html">
                        Demo: Controlling a simulated microscope
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../64_github_interaction/solving_github_issues.html">
                        Solving github issues
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../40_image_generation_openai/10_generating_images_dall_e.html">
                        Generating images using DALL-E
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../40_image_generation_openai/20_generating_mri_images_dall_e.html">
                        Generating Magnetic Resonance images using DALL-E
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../41_image_generation_huggingface/30_generating_images_using_huggingface.html">
                        Generating images using Stable Diffusion
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../40_image_generation_openai/51_inpainting_dall-e.html">
                        Inpainting using Dall-E
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../41_image_generation_huggingface/50_inpainting_huggingface.html">
                        Inpainting using Stable Diffusion
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../41_image_generation_huggingface/60_image_variations_huggingface.html">
                        Image variations using Stable Diffusion
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../41_image_generation_huggingface/60_image_variations_pix2pix.html">
                        Image editing using instruct-pix2pix
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../42_video_generation/videogen.html">
                        Video generation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../44_generating_jupyter_books/generator.html">
                        Generating Jupyter books
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../45_pptx_generation/prompting_rdm.html">
                        Auto-generating PowerPoint files with chatGPT and Dall-E
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../47_vision/10_vision_CLIP.html">
                        CLIP transformer
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../47_vision/20_vision_ollama.html">
                        LLAVA
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../47_vision/21_vision_openai.html">
                        GPT4-omni VLM
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../47_vision/30_vision_models_structred_output.html">
                        Vision models with structured output
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/03_generating_code.html">
                        Generating code
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/04_generating_code_for_processing_images.html">
                        Generating code for processing images
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/06_system_messages.html">
                        Powerful system messages
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/10_reflection.html">
                        Reflection
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/20_bia-bob_demo.html">
                        BIA Bob demo
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/21_documenting_code.html">
                        Documenting code
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/22_bug_fixing.html">
                        Bug fixing
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/23_generate_notebooks.html">
                        Generating notebooks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/24_vision-microscopy.html">
                        Vision models for image interpretation and code generation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../60_rag/10_word-embeddings.html">
                        Word embeddings
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../60_rag/05_tokenization.html">
                        Tokenization
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../60_rag/20-simple-rag.html">
                        Simple retrieval augmented generation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../63_chat_with_docs/readme.html">
                        Simple Chat with Docs
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../63_chat_with_docs/chat-with-docs.html">
                        Chat with your PDFs!
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../70_fine_tuning/10_generate_qa.html">
                        Turning knowledge into a list of question and answers
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../70_fine_tuning/40_fine_tuning.html">
                        Fine-tuning a model from questions and answers
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../70_fine_tuning/50_model_testing.html">
                        Test fine-tuned models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../70_fine_tuning/checking_job_status.html">
                        Checking a fine-tuning job status
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../70_fine_tuning/list_available_models.html">
                        Listing available models
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="#">
                        Fine-tuning Gemma on local hardware
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="merging_model.html">
                        Merging fine-tuned models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="test_model.html">
                        Testing the model
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="hf_data_upload.html">
                        Uploading training data to the Huggingface Hub
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../80_benchmarking_llms/10_CLIP_scores.html">
                        Optimizing image generation prompting using CLIP scores
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../80_benchmarking_llms/20_vision_models.html">
                        Vision Large Language Models for Counting objects
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../80_benchmarking_llms/30_measuring_executability.html">
                        Measuring code executability
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../80_benchmarking_llms/40_summarize_error_messages.html">
                        Summarizing generated code failure reasons
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../imprint.html">
                        Imprint
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../00_setup/readme.html">
                        Setting up your computer
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../10_prompting_basics/01_prompting.html">
                        Prompting basics
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../10_prompting_basics/02_use_cases.html">
                        Use cases
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../10_prompting_basics/03_prompt_engineering.html">
                        Basic prompt Engineering
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../15_endpoint_apis/01_openai_api.html">
                        OpenAI API
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../15_endpoint_apis/02_ollama_endpoint.html">
                        Ollama
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../15_endpoint_apis/03_blablador_endpoint.html">
                        Blablador endpoint
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../15_endpoint_apis/10_anthropic_api.html">
                        Anthropic Claude
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../15_endpoint_apis/20_google_gemini.html">
                        Gemini API
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../15_endpoint_apis/30_huggingface.html">
                        Huggingface API
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../20_chatbots/10_chatbot.html">
                        Programming an LLM-based chatbot
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../20_chatbots/gui.html">
                        A Chatbot GUI
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../30_function_calling/10_function_calling.html">
                        Function calling using ollama
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../30_function_calling/20_langchain.html">
                        Prompting tasks using LangChain
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../30_function_calling/30_langchain_bia.html">
                        Prompting bio-image analysis tasks using LangChain
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../30_function_calling/50_blablado.html">
                        blablado calls functions for you
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../30_function_calling/55_microscope_stage_demo.html">
                        Demo: Controlling a simulated microscope
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../64_github_interaction/solving_github_issues.html">
                        Solving github issues
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../40_image_generation_openai/10_generating_images_dall_e.html">
                        Generating images using DALL-E
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../40_image_generation_openai/20_generating_mri_images_dall_e.html">
                        Generating Magnetic Resonance images using DALL-E
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../41_image_generation_huggingface/30_generating_images_using_huggingface.html">
                        Generating images using Stable Diffusion
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../40_image_generation_openai/51_inpainting_dall-e.html">
                        Inpainting using Dall-E
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../41_image_generation_huggingface/50_inpainting_huggingface.html">
                        Inpainting using Stable Diffusion
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../41_image_generation_huggingface/60_image_variations_huggingface.html">
                        Image variations using Stable Diffusion
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../41_image_generation_huggingface/60_image_variations_pix2pix.html">
                        Image editing using instruct-pix2pix
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../42_video_generation/videogen.html">
                        Video generation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../44_generating_jupyter_books/generator.html">
                        Generating Jupyter books
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../45_pptx_generation/prompting_rdm.html">
                        Auto-generating PowerPoint files with chatGPT and Dall-E
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../47_vision/10_vision_CLIP.html">
                        CLIP transformer
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../47_vision/20_vision_ollama.html">
                        LLAVA
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../47_vision/21_vision_openai.html">
                        GPT4-omni VLM
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../47_vision/30_vision_models_structred_output.html">
                        Vision models with structured output
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/03_generating_code.html">
                        Generating code
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/04_generating_code_for_processing_images.html">
                        Generating code for processing images
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/06_system_messages.html">
                        Powerful system messages
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/10_reflection.html">
                        Reflection
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/20_bia-bob_demo.html">
                        BIA Bob demo
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/21_documenting_code.html">
                        Documenting code
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/22_bug_fixing.html">
                        Bug fixing
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/23_generate_notebooks.html">
                        Generating notebooks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../50_code_generation/24_vision-microscopy.html">
                        Vision models for image interpretation and code generation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../60_rag/10_word-embeddings.html">
                        Word embeddings
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../60_rag/05_tokenization.html">
                        Tokenization
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../60_rag/20-simple-rag.html">
                        Simple retrieval augmented generation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../63_chat_with_docs/readme.html">
                        Simple Chat with Docs
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../63_chat_with_docs/chat-with-docs.html">
                        Chat with your PDFs!
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../70_fine_tuning/10_generate_qa.html">
                        Turning knowledge into a list of question and answers
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../70_fine_tuning/40_fine_tuning.html">
                        Fine-tuning a model from questions and answers
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../70_fine_tuning/50_model_testing.html">
                        Test fine-tuned models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../70_fine_tuning/checking_job_status.html">
                        Checking a fine-tuning job status
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../70_fine_tuning/list_available_models.html">
                        Listing available models
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="#">
                        Fine-tuning Gemma on local hardware
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="merging_model.html">
                        Merging fine-tuned models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="test_model.html">
                        Testing the model
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="hf_data_upload.html">
                        Uploading training data to the Huggingface Hub
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../80_benchmarking_llms/10_CLIP_scores.html">
                        Optimizing image generation prompting using CLIP scores
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../80_benchmarking_llms/20_vision_models.html">
                        Vision Large Language Models for Counting objects
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../80_benchmarking_llms/30_measuring_executability.html">
                        Measuring code executability
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../80_benchmarking_llms/40_summarize_error_messages.html">
                        Summarizing generated code failure reasons
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../imprint.html">
                        Imprint
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item">
  


<a class="navbar-brand logo" href="../intro.html">

  
  
  
  
  
  
  

  
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    </div>
    <div class="sidebar-start-items__item">
<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Generative Artificial Intelligence Notebooks
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../00_setup/readme.html">Setting up your computer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Prompting basics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../10_prompting_basics/01_prompting.html">Prompting basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10_prompting_basics/02_use_cases.html">Use cases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10_prompting_basics/03_prompt_engineering.html">Basic prompt Engineering</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Accessing LLMs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../15_endpoint_apis/01_openai_api.html">OpenAI API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../15_endpoint_apis/02_ollama_endpoint.html">Ollama</a></li>
<li class="toctree-l1"><a class="reference internal" href="../15_endpoint_apis/03_blablador_endpoint.html">Blablador endpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../15_endpoint_apis/10_anthropic_api.html">Anthropic Claude</a></li>
<li class="toctree-l1"><a class="reference internal" href="../15_endpoint_apis/20_google_gemini.html">Gemini API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../15_endpoint_apis/30_huggingface.html">Huggingface API</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chatbots</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../20_chatbots/10_chatbot.html">Programming an LLM-based chatbot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../20_chatbots/gui.html">A Chatbot GUI</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Function Calling</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../30_function_calling/10_function_calling.html">Function calling using ollama</a></li>
<li class="toctree-l1"><a class="reference internal" href="../30_function_calling/20_langchain.html">Prompting tasks using LangChain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../30_function_calling/30_langchain_bia.html">Prompting bio-image analysis tasks using LangChain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../30_function_calling/50_blablado.html"><code class="docutils literal notranslate"><span class="pre">blablado</span></code> calls functions for you</a></li>
<li class="toctree-l1"><a class="reference internal" href="../30_function_calling/55_microscope_stage_demo.html">Demo: Controlling a simulated microscope</a></li>

<li class="toctree-l1"><a class="reference internal" href="../64_github_interaction/solving_github_issues.html">Solving github issues</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Image Generation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../40_image_generation_openai/10_generating_images_dall_e.html">Generating images using DALL-E</a></li>
<li class="toctree-l1"><a class="reference internal" href="../40_image_generation_openai/20_generating_mri_images_dall_e.html">Generating Magnetic Resonance images using DALL-E</a></li>
<li class="toctree-l1"><a class="reference internal" href="../41_image_generation_huggingface/30_generating_images_using_huggingface.html">Generating images using Stable Diffusion</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Image Manipulation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../40_image_generation_openai/51_inpainting_dall-e.html">Inpainting using Dall-E</a></li>
<li class="toctree-l1"><a class="reference internal" href="../41_image_generation_huggingface/50_inpainting_huggingface.html">Inpainting using Stable Diffusion</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Image Variation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../41_image_generation_huggingface/60_image_variations_huggingface.html">Image variations using Stable Diffusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../41_image_generation_huggingface/60_image_variations_pix2pix.html">Image editing using instruct-pix2pix</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Video generation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../42_video_generation/videogen.html">Video generation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Generating content</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../44_generating_jupyter_books/generator.html">Generating Jupyter books</a></li>
<li class="toctree-l1"><a class="reference internal" href="../45_pptx_generation/prompting_rdm.html">Auto-generating PowerPoint files with chatGPT and Dall-E</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Vision Language Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../47_vision/10_vision_CLIP.html">CLIP transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../47_vision/20_vision_ollama.html">LLAVA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../47_vision/21_vision_openai.html">GPT4-omni VLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../47_vision/30_vision_models_structred_output.html">Vision models with structured output</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Code Generation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../50_code_generation/03_generating_code.html">Generating code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../50_code_generation/04_generating_code_for_processing_images.html">Generating code for processing images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../50_code_generation/06_system_messages.html">Powerful system messages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../50_code_generation/10_reflection.html">Reflection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../50_code_generation/20_bia-bob_demo.html">BIA Bob demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../50_code_generation/21_documenting_code.html">Documenting code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../50_code_generation/22_bug_fixing.html">Bug fixing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../50_code_generation/23_generate_notebooks.html">Generating notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../50_code_generation/24_vision-microscopy.html">Vision models for image interpretation and code generation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Retrieval Augmented Generation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../60_rag/10_word-embeddings.html">Word embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../60_rag/05_tokenization.html">Tokenization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../60_rag/20-simple-rag.html">Simple retrieval augmented generation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chat with PDFs!</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../63_chat_with_docs/readme.html">Simple Chat with Docs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../63_chat_with_docs/chat-with-docs.html">Chat with your PDFs!</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Model Fine-Tuning in the cloud</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../70_fine_tuning/10_generate_qa.html">Turning knowledge into a list of question and answers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../70_fine_tuning/40_fine_tuning.html">Fine-tuning a model from questions and answers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../70_fine_tuning/50_model_testing.html">Test fine-tuned models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../70_fine_tuning/checking_job_status.html">Checking a fine-tuning job status</a></li>
<li class="toctree-l1"><a class="reference internal" href="../70_fine_tuning/list_available_models.html">Listing available models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Model Fine-Tuning locally</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Fine-tuning Gemma on local hardware</a></li>
<li class="toctree-l1"><a class="reference internal" href="merging_model.html">Merging fine-tuned models</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model.html">Testing the model</a></li>
<li class="toctree-l1"><a class="reference internal" href="hf_data_upload.html">Uploading training data to the Huggingface Hub</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Benchmarking</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../80_benchmarking_llms/10_CLIP_scores.html">Optimizing image generation prompting using CLIP scores</a></li>
<li class="toctree-l1"><a class="reference internal" href="../80_benchmarking_llms/20_vision_models.html">Vision Large Language Models for Counting objects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../80_benchmarking_llms/30_measuring_executability.html">Measuring code executability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../80_benchmarking_llms/40_summarize_error_messages.html">Summarizing generated code failure reasons</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Links</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../imprint.html">Imprint</a></li>

</ul>

    </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        <label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" data-toggle="tooltip" data-placement="right" title="Toggle primary sidebar">
            <span class="fa-solid fa-bars"></span>
        </label>
    </div>
    <div class="header-article__right">


<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
  </ul>
</div>

<button onclick="toggleFullScreen()"
  class="btn btn-sm"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<div class="dropdown dropdown-repository-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="https://github.com/ScaDS/generative-ai-notebooks" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">repository</span>
</a>
</a>
      
      <li><a href="https://github.com/ScaDS/generative-ai-notebooks/issues/new?title=Issue%20on%20page%20%2F71_fine_tuning_hf/fine-tune-gemma.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">open issue</span>
</a>
</a>
      
  </ul>
</div>



<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="../_sources/71_fine_tuning_hf/fine-tune-gemma.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</a>
      
      <li>
<button onclick="printPdf(this)"
  class="btn btn-sm dropdown-item"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</a>
      
  </ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary" data-toggle="tooltip" data-placement="left" title="Toggle secondary sidebar">
            <span class="fa-solid fa-list"></span>
        </label>
    </div>
</div>
            </div>
            
            

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Fine-tuning Gemma on local hardware</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#read-more">
   Read more
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#troubleshooting">
   Troubleshooting
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#configuration">
   Configuration
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialization-of-model-and-tokenizer">
   Initialization of model and tokenizer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset-preparation">
   Dataset preparation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#testing-the-model">
   Testing the model
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>

            <article class="bd-article" role="main">
              
  <section class="tex2jax_ignore mathjax_ignore" id="fine-tuning-gemma-on-local-hardware">
<h1>Fine-tuning Gemma on local hardware<a class="headerlink" href="#fine-tuning-gemma-on-local-hardware" title="Permalink to this heading">#</a></h1>
<p>In this notebook we are fine-tuning the <a class="reference external" href="https://huggingface.co/google/gemma-2b-it">google/gemma-2b-it</a> model using <a class="reference external" href="https://huggingface.co">huggingface</a> infrastructure, locally on our computer using a consumer-grade graphics card with 16 GB of memory. Gemma is provided under and subject to the Gemma Terms of Use found at <a class="reference external" href="https://ai.google.dev/gemma/terms">ai.google.dev/gemma/terms</a>. This notebook was written, modifying code from <a class="reference external" href="https://www.datacamp.com/tutorial/llama3-fine-tuning-locally">this article about fine-tuning LLama 3</a>, which is highly recommeded.</p>
<section id="read-more">
<h2>Read more<a class="headerlink" href="#read-more" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/2305.14314">QLoRA</a></p></li>
<li><p><a class="reference external" href="https://github.com/google-gemini/gemma-cookbook">Gemma Cookbook</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/google/gemma-7b/blob/main/examples/example_sft_qlora.py">example sft_qlora</a></p></li>
</ul>
</section>
<section id="troubleshooting">
<h2>Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>If you run this notebook on Windows and receive error messages mentioning that CUDA initialization failed, make sure you have <code class="docutils literal notranslate"><span class="pre">bitsandbytes</span></code> version 0.43.2 or larger installed.</p></li>
<li><p>If you run out of GPU memory, make sure you use the right hardware. This notebook was developed using an RTX 3080 mobile GPU with 16 GB of memory.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AutoModelForCausalLM</span><span class="p">,</span>
    <span class="n">AutoTokenizer</span><span class="p">,</span>
    <span class="n">BitsAndBytesConfig</span><span class="p">,</span>
    <span class="n">HfArgumentParser</span><span class="p">,</span>
    <span class="n">TrainingArguments</span><span class="p">,</span>
    <span class="n">pipeline</span><span class="p">,</span>
    <span class="n">logging</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">peft</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">LoraConfig</span><span class="p">,</span>
    <span class="n">PeftModel</span><span class="p">,</span>
    <span class="n">prepare_model_for_kbit_training</span><span class="p">,</span>
    <span class="n">get_peft_model</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">trl</span> <span class="kn">import</span> <span class="n">SFTTrainer</span><span class="p">,</span> <span class="n">setup_chat_format</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
</pre></div>
</div>
</div>
</div>
<p>First, we define the model we want to fine-tune and the name under which we will store the new fine-tuned model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">base_model</span> <span class="o">=</span> <span class="s2">&quot;google/gemma-2b-it&quot;</span>
<span class="c1">#&quot;google/codegemma-1.1-7b-it&quot;</span>
<span class="c1">#&quot;google/gemma-2b&quot;</span>
<span class="c1">#&quot;google/codegemma-2b&quot;</span>
<span class="c1">#&quot;google/gemma-2b-it&quot;</span>
<span class="n">new_model</span> <span class="o">=</span> <span class="s2">&quot;gemma-2b-it-bia-proof-of-concept2&quot;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="configuration">
<h2>Configuration<a class="headerlink" href="#configuration" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
<span class="n">attn_implementation</span> <span class="o">=</span> <span class="s2">&quot;eager&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>We will use the <a class="reference external" href="https://arxiv.org/abs/2305.14314">QLoRA</a> fine-tuning scheme, simply to save memory.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># QLoRA config</span>
<span class="n">bnb_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
    <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">bnb_4bit_quant_type</span><span class="o">=</span><span class="s2">&quot;nf4&quot;</span><span class="p">,</span>
    <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">torch_dtype</span><span class="p">,</span>
    <span class="n">bnb_4bit_use_double_quant</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="initialization-of-model-and-tokenizer">
<h2>Initialization of model and tokenizer<a class="headerlink" href="#initialization-of-model-and-tokenizer" title="Permalink to this heading">#</a></h2>
<p>Here we download and initialize the model and initialize the tokenizer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">base_model</span><span class="p">,</span>
    <span class="n">quantization_config</span><span class="o">=</span><span class="n">bnb_config</span><span class="p">,</span>
    <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="n">attn_implementation</span><span class="o">=</span><span class="n">attn_implementation</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.
Gemma&#39;s activation function will be set to `gelu_pytorch_tanh`. Please, use
`config.hidden_activation` if you want to override this behaviour.
See https://github.com/huggingface/transformers/pull/29402 for more details.
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "b3d4a840ada544db84c79084c3c7ffed", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load tokenizer</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">base_model</span><span class="p">)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">setup_chat_format</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s1">&#39;right&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># LoRA config</span>
<span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
    <span class="n">r</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">lora_dropout</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
    <span class="n">target_modules</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;up_proj&#39;</span><span class="p">,</span> <span class="s1">&#39;down_proj&#39;</span><span class="p">,</span> <span class="s1">&#39;gate_proj&#39;</span><span class="p">,</span> <span class="s1">&#39;k_proj&#39;</span><span class="p">,</span> <span class="s1">&#39;q_proj&#39;</span><span class="p">,</span> <span class="s1">&#39;v_proj&#39;</span><span class="p">,</span> <span class="s1">&#39;o_proj&#39;</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="dataset-preparation">
<h2>Dataset preparation<a class="headerlink" href="#dataset-preparation" title="Permalink to this heading">#</a></h2>
<p>Next we load our dataset for fine-tuning, from its <a class="reference external" href="https://huggingface.co/datasets/haesleinhuepf/bio-image-analysis-qa">Huggingface Hub page</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_name</span> <span class="o">=</span> <span class="s2">&quot;haesleinhuepf/bio-image-analysis-qa&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_raw</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">format_chat_template</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
    <span class="n">row_json</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">]},</span>
               <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">]}]</span>
    <span class="n">row</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">row_json</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">row</span>

<span class="n">format_chat_template_partial</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">format_chat_template</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>

<span class="n">dataset_w_template</span> <span class="o">=</span> <span class="n">dataset_raw</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
    <span class="n">format_chat_template_partial</span><span class="p">,</span>
    <span class="n">num_proc</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">dataset_w_template</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">][</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;|im_start|&gt;user
How can we use indices in Python to crop images, similar to cropping lists and tuples?&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant

This code imports the necessary functions from the skimage.io module. It then reads an image called &quot;blobs.tif&quot; and assigns it to the variable &#39;image&#39;. It crops the image, taking the first 128 rows, and assigns the result to &#39;cropped_image1&#39;. The cropped image is then displayed using the &#39;imshow&#39; function. Lastly, a list of numbers is created called &#39;mylist&#39;.

```python
from skimage.io import imread, imshow, imshow

image = imread(&quot;../../data/blobs.tif&quot;)

cropped_image1 = image[0:128]

imshow(cropped_image1);

mylist = [1,2,2,3,4,5,78]
```
&lt;|im_end|&gt;
</pre></div>
</div>
</div>
</div>
<p>We then split the data into two sets: for training and for testing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_train_test</span> <span class="o">=</span> <span class="n">dataset_w_template</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">dataset_train_test</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DatasetDict({
    train: Dataset({
        features: [&#39;question&#39;, &#39;answer&#39;, &#39;text&#39;],
        num_rows: 91
    })
    test: Dataset({
        features: [&#39;question&#39;, &#39;answer&#39;, &#39;text&#39;],
        num_rows: 39
    })
})
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">training_arguments</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="n">new_model</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">optim</span><span class="o">=</span><span class="s2">&quot;paged_adamw_32bit&quot;</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
    <span class="n">eval_steps</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">logging_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">logging_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">,</span>
    <span class="n">fp16</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">bf16</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">group_by_length</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">report_to</span><span class="o">=</span><span class="s2">&quot;none&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">SFTTrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset_train_test</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset_train_test</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span>
    <span class="n">peft_config</span><span class="o">=</span><span class="n">peft_config</span><span class="p">,</span>
    <span class="n">max_seq_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">dataset_text_field</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_arguments</span><span class="p">,</span>
    <span class="n">packing</span><span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\haase\miniconda3\envs\genai-gpu\Lib\site-packages\huggingface_hub\utils\_deprecation.py:100: FutureWarning: Deprecated argument(s) used in &#39;__init__&#39;: max_seq_length, dataset_text_field. Will not be supported from version &#39;1.0.0&#39;.

Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.
  warnings.warn(message, FutureWarning)
C:\Users\haase\miniconda3\envs\genai-gpu\Lib\site-packages\trl\trainer\sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.
  warnings.warn(
C:\Users\haase\miniconda3\envs\genai-gpu\Lib\site-packages\trl\trainer\sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.
  warnings.warn(
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "adcb96df7eb74918a020e43657f08127", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "1bf11768ca274e939fcf574ada00f4f2", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
    <div>
      
      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [450/450 03:26, Epoch 9/10]
    </div>
    <table border="1" class="dataframe">
  <thead>
 <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>90</td>
      <td>0.702000</td>
      <td>1.277717</td>
    </tr>
    <tr>
      <td>180</td>
      <td>0.208500</td>
      <td>1.599397</td>
    </tr>
    <tr>
      <td>270</td>
      <td>0.158900</td>
      <td>1.870157</td>
    </tr>
    <tr>
      <td>360</td>
      <td>0.060700</td>
      <td>2.060952</td>
    </tr>
    <tr>
      <td>450</td>
      <td>0.043300</td>
      <td>2.185464</td>
    </tr>
  </tbody>
</table><p></div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\haase\miniconda3\envs\genai-gpu\Lib\site-packages\peft\utils\save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>TrainOutput(global_step=450, training_loss=0.5049639929375714, metrics={&#39;train_runtime&#39;: 208.7607, &#39;train_samples_per_second&#39;: 4.359, &#39;train_steps_per_second&#39;: 2.156, &#39;total_flos&#39;: 2017628122275840.0, &#39;train_loss&#39;: 0.5049639929375714, &#39;epoch&#39;: 9.89010989010989})
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">new_model</span> <span class="o">+</span> <span class="s2">&quot;_temp&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\haase\miniconda3\envs\genai-gpu\Lib\site-packages\peft\utils\save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">new_model</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">(</span><span class="n">new_model</span><span class="p">,</span> <span class="n">use_temp_dir</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "8765ecd071204b7384cc3ba46ed2fa3a", "version_major": 2, "version_minor": 0}</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CommitInfo(commit_url=&#39;https://huggingface.co/haesleinhuepf/gemma-2b-it-bia-proof-of-concept2/commit/0261693ce0b873fffb094bd96ac633b58f8b85bd&#39;, commit_message=&#39;Upload model&#39;, commit_description=&#39;&#39;, oid=&#39;0261693ce0b873fffb094bd96ac633b58f8b85bd&#39;, pr_url=None, pr_revision=None, pr_num=None)
</pre></div>
</div>
</div>
</div>
</section>
<section id="testing-the-model">
<h2>Testing the model<a class="headerlink" href="#testing-the-model" title="Permalink to this heading">#</a></h2>
<p>After the model is trained, we can do first tests with it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Write Python code to load the image ../11a_prompt_engineering/data/blobs.tif,</span>
<span class="s2">segment the nuclei in it and</span>
<span class="s2">show the result</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">}]</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span>
    <span class="s2">&quot;text-generation&quot;</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
    <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;generated_text&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The model &#39;PeftModelForCausalLM&#39; is not supported for text-generation. Supported models are [&#39;BartForCausalLM&#39;, &#39;BertLMHeadModel&#39;, &#39;BertGenerationDecoder&#39;, &#39;BigBirdForCausalLM&#39;, &#39;BigBirdPegasusForCausalLM&#39;, &#39;BioGptForCausalLM&#39;, &#39;BlenderbotForCausalLM&#39;, &#39;BlenderbotSmallForCausalLM&#39;, &#39;BloomForCausalLM&#39;, &#39;CamembertForCausalLM&#39;, &#39;LlamaForCausalLM&#39;, &#39;CodeGenForCausalLM&#39;, &#39;CohereForCausalLM&#39;, &#39;CpmAntForCausalLM&#39;, &#39;CTRLLMHeadModel&#39;, &#39;Data2VecTextForCausalLM&#39;, &#39;DbrxForCausalLM&#39;, &#39;ElectraForCausalLM&#39;, &#39;ErnieForCausalLM&#39;, &#39;FalconForCausalLM&#39;, &#39;FuyuForCausalLM&#39;, &#39;GemmaForCausalLM&#39;, &#39;Gemma2ForCausalLM&#39;, &#39;GitForCausalLM&#39;, &#39;GPT2LMHeadModel&#39;, &#39;GPT2LMHeadModel&#39;, &#39;GPTBigCodeForCausalLM&#39;, &#39;GPTNeoForCausalLM&#39;, &#39;GPTNeoXForCausalLM&#39;, &#39;GPTNeoXJapaneseForCausalLM&#39;, &#39;GPTJForCausalLM&#39;, &#39;JambaForCausalLM&#39;, &#39;JetMoeForCausalLM&#39;, &#39;LlamaForCausalLM&#39;, &#39;MambaForCausalLM&#39;, &#39;MarianForCausalLM&#39;, &#39;MBartForCausalLM&#39;, &#39;MegaForCausalLM&#39;, &#39;MegatronBertForCausalLM&#39;, &#39;MistralForCausalLM&#39;, &#39;MixtralForCausalLM&#39;, &#39;MptForCausalLM&#39;, &#39;MusicgenForCausalLM&#39;, &#39;MusicgenMelodyForCausalLM&#39;, &#39;MvpForCausalLM&#39;, &#39;OlmoForCausalLM&#39;, &#39;OpenLlamaForCausalLM&#39;, &#39;OpenAIGPTLMHeadModel&#39;, &#39;OPTForCausalLM&#39;, &#39;PegasusForCausalLM&#39;, &#39;PersimmonForCausalLM&#39;, &#39;PhiForCausalLM&#39;, &#39;Phi3ForCausalLM&#39;, &#39;PLBartForCausalLM&#39;, &#39;ProphetNetForCausalLM&#39;, &#39;QDQBertLMHeadModel&#39;, &#39;Qwen2ForCausalLM&#39;, &#39;Qwen2MoeForCausalLM&#39;, &#39;RecurrentGemmaForCausalLM&#39;, &#39;ReformerModelWithLMHead&#39;, &#39;RemBertForCausalLM&#39;, &#39;RobertaForCausalLM&#39;, &#39;RobertaPreLayerNormForCausalLM&#39;, &#39;RoCBertForCausalLM&#39;, &#39;RoFormerForCausalLM&#39;, &#39;RwkvForCausalLM&#39;, &#39;Speech2Text2ForCausalLM&#39;, &#39;StableLmForCausalLM&#39;, &#39;Starcoder2ForCausalLM&#39;, &#39;TransfoXLLMHeadModel&#39;, &#39;TrOCRForCausalLM&#39;, &#39;WhisperForCausalLM&#39;, &#39;XGLMForCausalLM&#39;, &#39;XLMWithLMHeadModel&#39;, &#39;XLMProphetNetForCausalLM&#39;, &#39;XLMRobertaForCausalLM&#39;, &#39;XLMRobertaXLForCausalLM&#39;, &#39;XLNetLMHeadModel&#39;, &#39;XmodForCausalLM&#39;].
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;|im_start|&gt;user

Write Python code to load the image ../11a_prompt_engineering/data/blobs.tif,
segment the nuclei in it and
show the result
&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
The code is importing the `imread` and `imshow` functions from the `skimage.io` module, and the `pyclesperanto_prototype` module is imported and assigned to the variable `cle`.

```python
from skimage.io import imread, imshow
import pyclesperanto_prototype as cle

cle.load_image(&#39;../11a_prompt_engineering/data/blobs.tif&#39;)
```
The loaded image is then assigned to the variable `image`.

```python
image = cle.load_image(&#39;../11a_
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./71_fine_tuning_hf"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

            </article>
            

            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="../70_fine_tuning/list_available_models.html" title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Listing available models</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="merging_model.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Merging fine-tuned models</p>
  </div>
  <i class="fa-solid fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#read-more">
   Read more
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#troubleshooting">
   Troubleshooting
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#configuration">
   Configuration
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialization-of-model-and-tokenizer">
   Initialization of model and tokenizer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset-preparation">
   Dataset preparation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#testing-the-model">
   Testing the model
  </a>
 </li>
</ul>

</nav>
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Robert Haase
</p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    <p class="last-updated">
Last updated on 2024-07-30.<br>
</p>
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>
Copyright: Licensed <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC-BY 4.0</a> unless mentioned otherwise. 
Contributions and feedback are welcome.
</p>

</div>
  </div>
  
</div>
          </div>
        </footer>
        

      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  </body>
</html>